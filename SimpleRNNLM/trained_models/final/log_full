Building the model...
Compiling theano functions...
Building a network for generating...
Done


Starting epoch 1...

Done 200 batches in 81.38s	training loss:	6.885579
Done 400 batches in 161.44s	training loss:	6.158662
Done 600 batches in 242.90s	training loss:	5.855629
Done 800 batches in 323.08s	training loss:	5.654957
Done 1000 batches in 403.83s	training loss:	5.496617
Done 1200 batches in 484.41s	training loss:	5.362316
Done 1400 batches in 564.63s	training loss:	5.244036
Done 1600 batches in 644.84s	training loss:	5.139904
Done 1800 batches in 725.03s	training loss:	5.047017
Done 2000 batches in 806.94s	training loss:	4.966823
Done 2200 batches in 888.74s	training loss:	4.895003
Done 2400 batches in 969.57s	training loss:	4.831552
Done 2600 batches in 1051.11s	training loss:	4.775335
Done 2800 batches in 1132.91s	training loss:	4.725071
Done 3000 batches in 1214.87s	training loss:	4.680198
Done 3200 batches in 1294.56s	training loss:	4.638773
Done 3400 batches in 1375.27s	training loss:	4.600845
Done 3600 batches in 1454.98s	training loss:	4.565592
Done 3800 batches in 1534.44s	training loss:	4.533312
Done 4000 batches in 1615.73s	training loss:	4.503786
Done 4200 batches in 1697.32s	training loss:	4.477037
Done 4400 batches in 1779.95s	training loss:	4.451732
Done 4600 batches in 1860.22s	training loss:	4.428012
Done 4800 batches in 1941.87s	training loss:	4.405880
Done 5000 batches in 2022.25s	training loss:	4.384137
Done 5200 batches in 2102.38s	training loss:	4.364087
Done 5400 batches in 2183.01s	training loss:	4.344801
Done 5600 batches in 2263.96s	training loss:	4.326675
Done 5800 batches in 2344.21s	training loss:	4.309619
Done 6000 batches in 2424.96s	training loss:	4.293247
Done 6200 batches in 2504.44s	training loss:	4.277534
Done 6400 batches in 2584.64s	training loss:	4.262322
Done 100 batches in 8.47s
Done 200 batches in 16.86s
Done 300 batches in 25.29s
Done 400 batches in 33.98s
Done 500 batches in 42.45s
Done 600 batches in 51.01s
Done 700 batches in 59.83s
Done 800 batches in 68.68s

Training loss:   4.25514120947
Validation loss: 3.80101870647

Saving model...
Done saving.


Starting epoch 2...

Done 200 batches in 81.15s	training loss:	3.779663
Done 400 batches in 161.05s	training loss:	3.769488
Done 600 batches in 242.33s	training loss:	3.774276
Done 800 batches in 322.33s	training loss:	3.767766
Done 1000 batches in 402.67s	training loss:	3.764800
Done 1200 batches in 482.85s	training loss:	3.760306
Done 1400 batches in 562.67s	training loss:	3.756025
Done 1600 batches in 642.33s	training loss:	3.751683
Done 1800 batches in 722.01s	training loss:	3.746157
Done 2000 batches in 803.77s	training loss:	3.743790
Done 2200 batches in 885.71s	training loss:	3.740562
Done 2400 batches in 966.72s	training loss:	3.736817
Done 2600 batches in 1048.44s	training loss:	3.733523
Done 2800 batches in 1130.36s	training loss:	3.730656
Done 3000 batches in 1212.29s	training loss:	3.728429
Done 3200 batches in 1292.22s	training loss:	3.725313
Done 3400 batches in 1372.60s	training loss:	3.722187
Done 3600 batches in 1452.14s	training loss:	3.718687
Done 3800 batches in 1531.64s	training loss:	3.715400
Done 4000 batches in 1612.92s	training loss:	3.713193
Done 4200 batches in 1694.41s	training loss:	3.711457
Done 4400 batches in 1777.15s	training loss:	3.709400
Done 4600 batches in 1857.31s	training loss:	3.707162
Done 4800 batches in 1938.86s	training loss:	3.705245
Done 5000 batches in 2019.23s	training loss:	3.702381
Done 5200 batches in 2099.41s	training loss:	3.699987
Done 5400 batches in 2180.17s	training loss:	3.697363
Done 5600 batches in 2261.07s	training loss:	3.695055
Done 5800 batches in 2341.55s	training loss:	3.692955
Done 6000 batches in 2422.31s	training loss:	3.690853
Done 6200 batches in 2502.17s	training loss:	3.688630
Done 6400 batches in 2582.59s	training loss:	3.686258
Done 100 batches in 8.39s
Done 200 batches in 16.79s
Done 300 batches in 25.22s
Done 400 batches in 34.00s
Done 500 batches in 42.56s
Done 600 batches in 51.20s
Done 700 batches in 60.03s
Done 800 batches in 68.90s

Training loss:   3.68516441151
Validation loss: 3.6469055168

Saving model...
Done saving.


Starting epoch 3...

Done 200 batches in 81.07s	training loss:	3.611062
Done 400 batches in 160.79s	training loss:	3.601887
Done 600 batches in 241.84s	training loss:	3.608731
Done 800 batches in 321.56s	training loss:	3.604635
Done 1000 batches in 401.73s	training loss:	3.603917
Done 1200 batches in 481.77s	training loss:	3.601556
Done 1400 batches in 561.41s	training loss:	3.599282
Done 1600 batches in 640.98s	training loss:	3.597036
Done 1800 batches in 720.61s	training loss:	3.593401
Done 2000 batches in 802.11s	training loss:	3.592815
Done 2200 batches in 884.00s	training loss:	3.591484
Done 2400 batches in 964.71s	training loss:	3.589452
Done 2600 batches in 1046.34s	training loss:	3.587925
Done 2800 batches in 1128.06s	training loss:	3.586688
Done 3000 batches in 1209.62s	training loss:	3.586028
Done 3200 batches in 1289.07s	training loss:	3.584454
Done 3400 batches in 1369.43s	training loss:	3.582828
Done 3600 batches in 1449.07s	training loss:	3.580758
Done 3800 batches in 1528.44s	training loss:	3.578904
Done 4000 batches in 1609.65s	training loss:	3.578126
Done 4200 batches in 1691.04s	training loss:	3.577711
Done 4400 batches in 1773.70s	training loss:	3.576922
Done 4600 batches in 1853.91s	training loss:	3.575904
Done 4800 batches in 1935.56s	training loss:	3.575172
Done 5000 batches in 2015.85s	training loss:	3.573498
Done 5200 batches in 2096.11s	training loss:	3.572222
Done 5400 batches in 2177.18s	training loss:	3.570734
Done 5600 batches in 2258.15s	training loss:	3.569538
Done 5800 batches in 2338.47s	training loss:	3.568507
Done 6000 batches in 2419.76s	training loss:	3.567444
Done 6200 batches in 2499.70s	training loss:	3.566233
Done 6400 batches in 2579.97s	training loss:	3.564868
Done 100 batches in 8.50s
Done 200 batches in 16.89s
Done 300 batches in 25.32s
Done 400 batches in 34.10s
Done 500 batches in 42.65s
Done 600 batches in 51.22s
Done 700 batches in 59.97s
Done 800 batches in 68.75s

Training loss:   3.56425618011
Validation loss: 3.57379538122

Saving model...
Done saving.


Starting epoch 4...

Done 200 batches in 81.22s	training loss:	3.522510
Done 400 batches in 161.21s	training loss:	3.513737
Done 600 batches in 242.42s	training loss:	3.520966
Done 800 batches in 322.14s	training loss:	3.517570
Done 1000 batches in 402.60s	training loss:	3.517344
Done 1200 batches in 482.90s	training loss:	3.515505
Done 1400 batches in 562.54s	training loss:	3.513680
Done 1600 batches in 642.13s	training loss:	3.512038
Done 1800 batches in 721.70s	training loss:	3.508961
Done 2000 batches in 803.24s	training loss:	3.508847
Done 2200 batches in 885.25s	training loss:	3.508078
Done 2400 batches in 965.97s	training loss:	3.506557
Done 2600 batches in 1047.57s	training loss:	3.505594
Done 2800 batches in 1129.28s	training loss:	3.504817
Done 3000 batches in 1210.69s	training loss:	3.504586
Done 3200 batches in 1290.31s	training loss:	3.503496
Done 3400 batches in 1370.68s	training loss:	3.502346
Done 3600 batches in 1450.14s	training loss:	3.500684
Done 3800 batches in 1529.65s	training loss:	3.499281
Done 4000 batches in 1611.01s	training loss:	3.498968
Done 4200 batches in 1692.55s	training loss:	3.498971
Done 4400 batches in 1775.02s	training loss:	3.498613
Done 4600 batches in 1855.09s	training loss:	3.498001
Done 4800 batches in 1936.40s	training loss:	3.497654
Done 5000 batches in 2016.71s	training loss:	3.496371
Done 5200 batches in 2096.89s	training loss:	3.495474
Done 5400 batches in 2177.53s	training loss:	3.494391
Done 5600 batches in 2258.49s	training loss:	3.493586
Done 5800 batches in 2338.96s	training loss:	3.492956
Done 6000 batches in 2419.82s	training loss:	3.492267
Done 6200 batches in 2499.71s	training loss:	3.491426
Done 6400 batches in 2580.00s	training loss:	3.490443
Done 100 batches in 8.45s
Done 200 batches in 16.83s
Done 300 batches in 25.28s
Done 400 batches in 34.06s
Done 500 batches in 42.63s
Done 600 batches in 51.27s
Done 700 batches in 60.10s
Done 800 batches in 68.97s

Training loss:   3.49002199644
Validation loss: 3.52667270663

Saving model...
Done saving.


Starting epoch 5...

Done 200 batches in 81.47s	training loss:	3.460438
Done 400 batches in 161.52s	training loss:	3.452035
Done 600 batches in 242.84s	training loss:	3.459412
Done 800 batches in 322.78s	training loss:	3.456420
Done 1000 batches in 403.36s	training loss:	3.456438
Done 1200 batches in 483.90s	training loss:	3.454804
Done 1400 batches in 563.75s	training loss:	3.453251
Done 1600 batches in 643.43s	training loss:	3.451925
Done 1800 batches in 723.27s	training loss:	3.449131
Done 2000 batches in 804.90s	training loss:	3.449250
Done 2200 batches in 886.85s	training loss:	3.448778
Done 2400 batches in 967.79s	training loss:	3.447540
Done 2600 batches in 1050.20s	training loss:	3.446890
Done 2800 batches in 1132.00s	training loss:	3.446332
Done 3000 batches in 1213.72s	training loss:	3.446319
Done 3200 batches in 1293.43s	training loss:	3.445492
Done 3400 batches in 1374.06s	training loss:	3.444576
Done 3600 batches in 1453.67s	training loss:	3.443143
Done 3800 batches in 1533.02s	training loss:	3.441973
Done 4000 batches in 1614.21s	training loss:	3.441920
Done 4200 batches in 1695.69s	training loss:	3.442129
Done 4400 batches in 1778.29s	training loss:	3.442005
Done 4600 batches in 1858.72s	training loss:	3.441607
Done 4800 batches in 1940.43s	training loss:	3.441443
Done 5000 batches in 2020.74s	training loss:	3.440360
Done 5200 batches in 2100.83s	training loss:	3.439670
Done 5400 batches in 2181.75s	training loss:	3.438819
Done 5600 batches in 2263.29s	training loss:	3.438237
Done 5800 batches in 2343.97s	training loss:	3.437824
Done 6000 batches in 2425.20s	training loss:	3.437340
Done 6200 batches in 2505.15s	training loss:	3.436698
Done 6400 batches in 2585.72s	training loss:	3.435924
Done 100 batches in 8.52s
Done 200 batches in 16.92s
Done 300 batches in 25.36s
Done 400 batches in 34.14s
Done 500 batches in 42.70s
Done 600 batches in 51.34s
Done 700 batches in 60.17s
Done 800 batches in 69.04s

Training loss:   3.43561201347
Validation loss: 3.49310687701

Saving model...
Done saving.


Starting epoch 6...

Done 200 batches in 81.53s	training loss:	3.412822
Done 400 batches in 161.62s	training loss:	3.404647
Done 600 batches in 243.09s	training loss:	3.411988
Done 800 batches in 323.16s	training loss:	3.409232
Done 1000 batches in 403.86s	training loss:	3.409411
Done 1200 batches in 484.27s	training loss:	3.407869
Done 1400 batches in 564.19s	training loss:	3.406505
Done 1600 batches in 644.02s	training loss:	3.405368
Done 1800 batches in 723.83s	training loss:	3.402732
Done 2000 batches in 805.58s	training loss:	3.402988
Done 2200 batches in 887.63s	training loss:	3.402697
Done 2400 batches in 968.59s	training loss:	3.401639
Done 2600 batches in 1050.44s	training loss:	3.401164
Done 2800 batches in 1132.52s	training loss:	3.400740
Done 3000 batches in 1214.17s	training loss:	3.400856
Done 3200 batches in 1293.94s	training loss:	3.400185
Done 3400 batches in 1374.48s	training loss:	3.399413
Done 3600 batches in 1454.16s	training loss:	3.398138
Done 3800 batches in 1533.52s	training loss:	3.397098
Done 4000 batches in 1614.69s	training loss:	3.397196
Done 4200 batches in 1696.29s	training loss:	3.397515
Done 4400 batches in 1779.07s	training loss:	3.397530
Done 4600 batches in 1859.48s	training loss:	3.397262
Done 4800 batches in 1941.05s	training loss:	3.397205
Done 5000 batches in 2021.46s	training loss:	3.396245
Done 5200 batches in 2101.86s	training loss:	3.395678
Done 5400 batches in 2182.79s	training loss:	3.394973
Done 5600 batches in 2263.85s	training loss:	3.394520
Done 5800 batches in 2344.40s	training loss:	3.394237
Done 6000 batches in 2425.38s	training loss:	3.393876
Done 6200 batches in 2505.08s	training loss:	3.393360
Done 6400 batches in 2585.42s	training loss:	3.392722
Done 100 batches in 8.49s
Done 200 batches in 16.88s
Done 300 batches in 25.32s
Done 400 batches in 34.09s
Done 500 batches in 42.65s
Done 600 batches in 51.29s
Done 700 batches in 60.11s
Done 800 batches in 68.97s

Training loss:   3.39247839278
Validation loss: 3.4677615441

Saving model...
Done saving.


Starting epoch 7...

Done 200 batches in 81.62s	training loss:	3.374007
Done 400 batches in 161.66s	training loss:	3.365953
Done 600 batches in 242.95s	training loss:	3.373226
Done 800 batches in 322.92s	training loss:	3.370654
Done 1000 batches in 403.51s	training loss:	3.370932
Done 1200 batches in 483.92s	training loss:	3.369432
Done 1400 batches in 563.66s	training loss:	3.368203
Done 1600 batches in 643.42s	training loss:	3.367174
Done 1800 batches in 723.07s	training loss:	3.364649
Done 2000 batches in 804.54s	training loss:	3.364992
Done 2200 batches in 886.51s	training loss:	3.364831
Done 2400 batches in 967.51s	training loss:	3.363909
Done 2600 batches in 1049.22s	training loss:	3.363547
Done 2800 batches in 1131.19s	training loss:	3.363206
Done 3000 batches in 1212.58s	training loss:	3.363410
Done 3200 batches in 1292.32s	training loss:	3.362853
Done 3400 batches in 1372.69s	training loss:	3.362175
Done 3600 batches in 1452.24s	training loss:	3.361012
Done 3800 batches in 1531.34s	training loss:	3.360062
Done 4000 batches in 1612.35s	training loss:	3.360264
Done 4200 batches in 1693.76s	training loss:	3.360652
Done 4400 batches in 1776.30s	training loss:	3.360759
Done 4600 batches in 1856.45s	training loss:	3.360580
Done 4800 batches in 1937.94s	training loss:	3.360594
Done 5000 batches in 2018.26s	training loss:	3.359719
Done 5200 batches in 2098.38s	training loss:	3.359235
Done 5400 batches in 2179.08s	training loss:	3.358631
Done 5600 batches in 2259.80s	training loss:	3.358277
Done 5800 batches in 2339.96s	training loss:	3.358087
Done 6000 batches in 2420.79s	training loss:	3.357810
Done 6200 batches in 2500.32s	training loss:	3.357382
Done 6400 batches in 2580.29s	training loss:	3.356833
Done 100 batches in 8.50s
Done 200 batches in 16.90s
Done 300 batches in 25.28s
Done 400 batches in 34.00s
Done 500 batches in 42.49s
Done 600 batches in 51.06s
Done 700 batches in 59.90s
Done 800 batches in 68.77s

Training loss:   3.35663880712
Validation loss: 3.44803917764

Saving model...
Done saving.


Starting epoch 8...

Done 200 batches in 81.34s	training loss:	3.341073
Done 400 batches in 161.31s	training loss:	3.333112
Done 600 batches in 242.45s	training loss:	3.340351
Done 800 batches in 322.36s	training loss:	3.337913
Done 1000 batches in 403.14s	training loss:	3.338279
Done 1200 batches in 483.50s	training loss:	3.336786
Done 1400 batches in 563.40s	training loss:	3.335655
Done 1600 batches in 642.98s	training loss:	3.334727
Done 1800 batches in 722.62s	training loss:	3.332285
Done 2000 batches in 804.15s	training loss:	3.332687
Done 2200 batches in 886.12s	training loss:	3.332625
Done 2400 batches in 967.02s	training loss:	3.331806
Done 2600 batches in 1048.64s	training loss:	3.331527
Done 2800 batches in 1130.50s	training loss:	3.331247
Done 3000 batches in 1212.08s	training loss:	3.331508
Done 3200 batches in 1291.73s	training loss:	3.331039
Done 3400 batches in 1372.34s	training loss:	3.330433
Done 3600 batches in 1451.89s	training loss:	3.329350
Done 3800 batches in 1531.16s	training loss:	3.328464
Done 4000 batches in 1612.31s	training loss:	3.328747
Done 4200 batches in 1693.73s	training loss:	3.329189
Done 4400 batches in 1776.20s	training loss:	3.329359
Done 4600 batches in 1856.28s	training loss:	3.329244
Done 4800 batches in 1937.68s	training loss:	3.329307
Done 5000 batches in 2017.97s	training loss:	3.328492
Done 5200 batches in 2098.33s	training loss:	3.328064
Done 5400 batches in 2178.99s	training loss:	3.327534
Done 5600 batches in 2259.99s	training loss:	3.327246
Done 5800 batches in 2340.81s	training loss:	3.327115
Done 6000 batches in 2422.47s	training loss:	3.326896
Done 6200 batches in 2501.95s	training loss:	3.326533
Done 6400 batches in 2582.02s	training loss:	3.326049
Done 100 batches in 8.42s
Done 200 batches in 16.79s
Done 300 batches in 25.20s
Done 400 batches in 33.96s
Done 500 batches in 42.49s
Done 600 batches in 51.11s
Done 700 batches in 59.91s
Done 800 batches in 68.75s

Training loss:   3.32589179946
Validation loss: 3.43245066142

Saving model...
Done saving.


Starting epoch 9...

Done 200 batches in 81.08s	training loss:	3.312412
Done 400 batches in 160.99s	training loss:	3.304491
Done 600 batches in 242.12s	training loss:	3.311677
Done 800 batches in 321.87s	training loss:	3.309339
Done 1000 batches in 402.18s	training loss:	3.309794
Done 1200 batches in 482.28s	training loss:	3.308307
Done 1400 batches in 561.96s	training loss:	3.307252
Done 1600 batches in 641.60s	training loss:	3.306400
Done 1800 batches in 721.02s	training loss:	3.304021
Done 2000 batches in 802.55s	training loss:	3.304469
Done 2200 batches in 884.31s	training loss:	3.304485
Done 2400 batches in 965.03s	training loss:	3.303745
Done 2600 batches in 1046.53s	training loss:	3.303523
Done 2800 batches in 1128.38s	training loss:	3.303300
Done 3000 batches in 1210.07s	training loss:	3.303595
Done 3200 batches in 1289.83s	training loss:	3.303192
Done 3400 batches in 1370.47s	training loss:	3.302637
Done 3600 batches in 1450.05s	training loss:	3.301617
Done 3800 batches in 1529.53s	training loss:	3.300781
Done 4000 batches in 1610.87s	training loss:	3.301125
Done 4200 batches in 1692.92s	training loss:	3.301605
Done 4400 batches in 1776.72s	training loss:	3.301837
Done 4600 batches in 1856.93s	training loss:	3.301769
Done 4800 batches in 1938.43s	training loss:	3.301871
Done 5000 batches in 2018.70s	training loss:	3.301101
Done 5200 batches in 2098.86s	training loss:	3.300713
Done 5400 batches in 2179.49s	training loss:	3.300239
Done 5600 batches in 2260.30s	training loss:	3.300003
Done 5800 batches in 2340.79s	training loss:	3.299924
Done 6000 batches in 2421.68s	training loss:	3.299745
Done 6200 batches in 2501.32s	training loss:	3.299430
Done 6400 batches in 2581.53s	training loss:	3.298994
Done 100 batches in 8.48s
Done 200 batches in 16.86s
Done 300 batches in 25.29s
Done 400 batches in 34.06s
Done 500 batches in 42.61s
Done 600 batches in 51.24s
Done 700 batches in 60.06s
Done 800 batches in 68.92s

Training loss:   3.29886525785
Validation loss: 3.41997679426

Saving model...
Done saving.


Starting epoch 10...

Done 200 batches in 81.18s	training loss:	3.287054
Done 400 batches in 161.10s	training loss:	3.279105
Done 600 batches in 242.22s	training loss:	3.286235
Done 800 batches in 322.09s	training loss:	3.283975
Done 1000 batches in 402.41s	training loss:	3.284485
Done 1200 batches in 482.44s	training loss:	3.282989
Done 1400 batches in 562.28s	training loss:	3.282002
Done 1600 batches in 641.80s	training loss:	3.281218
Done 1800 batches in 721.48s	training loss:	3.278894
Done 2000 batches in 803.29s	training loss:	3.279378
Done 2200 batches in 884.97s	training loss:	3.279460
Done 2400 batches in 965.65s	training loss:	3.278783
Done 2600 batches in 1047.07s	training loss:	3.278613
Done 2800 batches in 1128.69s	training loss:	3.278433
Done 3000 batches in 1210.20s	training loss:	3.278757
Done 3200 batches in 1289.94s	training loss:	3.278410
Done 3400 batches in 1370.55s	training loss:	3.277895
Done 3600 batches in 1450.27s	training loss:	3.276928
Done 3800 batches in 1529.67s	training loss:	3.276130
Done 4000 batches in 1610.83s	training loss:	3.276523
Done 4200 batches in 1692.38s	training loss:	3.277033
Done 4400 batches in 1775.03s	training loss:	3.277288
Done 4600 batches in 1855.36s	training loss:	3.277256
Done 4800 batches in 1936.86s	training loss:	3.277392
Done 5000 batches in 2017.32s	training loss:	3.276658
Done 5200 batches in 2097.66s	training loss:	3.276304
Done 5400 batches in 2178.48s	training loss:	3.275878
Done 5600 batches in 2259.61s	training loss:	3.275685
Done 5800 batches in 2340.14s	training loss:	3.275648
Done 6000 batches in 2421.05s	training loss:	3.275499
Done 6200 batches in 2500.67s	training loss:	3.275221
Done 6400 batches in 2580.92s	training loss:	3.274825
Done 100 batches in 8.49s
Done 200 batches in 16.89s
Done 300 batches in 25.33s
Done 400 batches in 34.12s
Done 500 batches in 42.68s
Done 600 batches in 51.32s
Done 700 batches in 60.14s
Done 800 batches in 69.01s

Training loss:   3.27471970347
Validation loss: 3.40982994426

Saving model...
Done saving.


Starting epoch 11...

Done 200 batches in 81.32s	training loss:	3.264275
Done 400 batches in 161.22s	training loss:	3.256248
Done 600 batches in 242.49s	training loss:	3.263320
Done 800 batches in 322.27s	training loss:	3.261109
Done 1000 batches in 402.69s	training loss:	3.261672
Done 1200 batches in 482.87s	training loss:	3.260171
Done 1400 batches in 562.57s	training loss:	3.259244
Done 1600 batches in 642.06s	training loss:	3.258516
Done 1800 batches in 721.57s	training loss:	3.256230
Done 2000 batches in 802.92s	training loss:	3.256744
Done 2200 batches in 884.81s	training loss:	3.256881
Done 2400 batches in 965.58s	training loss:	3.256253
Done 2600 batches in 1047.30s	training loss:	3.256127
Done 2800 batches in 1129.15s	training loss:	3.255973
Done 3000 batches in 1211.04s	training loss:	3.256319
Done 3200 batches in 1290.74s	training loss:	3.256016
Done 3400 batches in 1371.34s	training loss:	3.255538
Done 3600 batches in 1450.87s	training loss:	3.254613
Done 3800 batches in 1530.19s	training loss:	3.253843
Done 4000 batches in 1611.21s	training loss:	3.254278
Done 4200 batches in 1692.53s	training loss:	3.254809
Done 4400 batches in 1774.98s	training loss:	3.255093
Done 4600 batches in 1855.03s	training loss:	3.255085
Done 4800 batches in 1936.39s	training loss:	3.255245
Done 5000 batches in 2016.89s	training loss:	3.254538
Done 5200 batches in 2097.44s	training loss:	3.254210
Done 5400 batches in 2178.10s	training loss:	3.253825
Done 5600 batches in 2258.94s	training loss:	3.253665
Done 5800 batches in 2339.12s	training loss:	3.253663
Done 6000 batches in 2419.94s	training loss:	3.253536
Done 6200 batches in 2499.70s	training loss:	3.253285
Done 6400 batches in 2580.08s	training loss:	3.252922
Done 100 batches in 8.50s
Done 200 batches in 16.91s
Done 300 batches in 25.36s
Done 400 batches in 34.16s
Done 500 batches in 42.73s
Done 600 batches in 51.38s
Done 700 batches in 60.22s
Done 800 batches in 69.09s

Training loss:   3.25283867348
Validation loss: 3.40154252679

Saving model...
Done saving.


Starting epoch 12...

Done 200 batches in 81.40s	training loss:	3.243581
Done 400 batches in 161.29s	training loss:	3.235453
Done 600 batches in 242.71s	training loss:	3.242455
Done 800 batches in 322.78s	training loss:	3.240283
Done 1000 batches in 403.38s	training loss:	3.240896
Done 1200 batches in 483.59s	training loss:	3.239383
Done 1400 batches in 563.43s	training loss:	3.238500
Done 1600 batches in 643.01s	training loss:	3.237820
Done 1800 batches in 722.65s	training loss:	3.235566
Done 2000 batches in 804.25s	training loss:	3.236103
Done 2200 batches in 886.41s	training loss:	3.236285
Done 2400 batches in 967.17s	training loss:	3.235699
Done 2600 batches in 1049.05s	training loss:	3.235614
Done 2800 batches in 1130.97s	training loss:	3.235483
Done 3000 batches in 1212.73s	training loss:	3.235847
Done 3200 batches in 1292.61s	training loss:	3.235583
Done 3400 batches in 1373.32s	training loss:	3.235132
Done 3600 batches in 1452.91s	training loss:	3.234242
Done 3800 batches in 1532.47s	training loss:	3.233500
Done 4000 batches in 1613.69s	training loss:	3.233969
Done 4200 batches in 1695.32s	training loss:	3.234510
Done 4400 batches in 1778.17s	training loss:	3.234819
Done 4600 batches in 1858.31s	training loss:	3.234829
Done 4800 batches in 1939.67s	training loss:	3.235009
Done 5000 batches in 2020.13s	training loss:	3.234324
Done 5200 batches in 2100.42s	training loss:	3.234014
Done 5400 batches in 2181.22s	training loss:	3.233663
Done 5600 batches in 2262.31s	training loss:	3.233534
Done 5800 batches in 2342.73s	training loss:	3.233561
Done 6000 batches in 2424.02s	training loss:	3.233450
Done 6200 batches in 2503.60s	training loss:	3.233220
Done 6400 batches in 2583.79s	training loss:	3.232884
Done 100 batches in 8.50s
Done 200 batches in 16.90s
Done 300 batches in 25.34s
Done 400 batches in 34.12s
Done 500 batches in 42.67s
Done 600 batches in 51.30s
Done 700 batches in 60.12s
Done 800 batches in 68.99s

Training loss:   3.23281867271
Validation loss: 3.39481699347

Saving model...
Done saving.


Starting epoch 13...

Done 200 batches in 81.21s	training loss:	3.224573
Done 400 batches in 161.14s	training loss:	3.216323
Done 600 batches in 242.34s	training loss:	3.223263
Done 800 batches in 322.06s	training loss:	3.221109
Done 1000 batches in 402.68s	training loss:	3.221764
Done 1200 batches in 482.78s	training loss:	3.220239
Done 1400 batches in 562.70s	training loss:	3.219388
Done 1600 batches in 642.32s	training loss:	3.218758
Done 1800 batches in 721.89s	training loss:	3.216532
Done 2000 batches in 803.40s	training loss:	3.217088
Done 2200 batches in 885.30s	training loss:	3.217311
Done 2400 batches in 966.22s	training loss:	3.216762
Done 2600 batches in 1047.88s	training loss:	3.216718
Done 2800 batches in 1129.91s	training loss:	3.216602
Done 3000 batches in 1211.56s	training loss:	3.216979
Done 3200 batches in 1291.20s	training loss:	3.216749
Done 3400 batches in 1371.94s	training loss:	3.216321
Done 3600 batches in 1451.64s	training loss:	3.215461
Done 3800 batches in 1531.28s	training loss:	3.214739
Done 4000 batches in 1612.54s	training loss:	3.215239
Done 4200 batches in 1694.04s	training loss:	3.215788
Done 4400 batches in 1776.60s	training loss:	3.216116
Done 4600 batches in 1856.81s	training loss:	3.216138
Done 4800 batches in 1938.57s	training loss:	3.216335
Done 5000 batches in 2019.16s	training loss:	3.215668
Done 5200 batches in 2099.72s	training loss:	3.215371
Done 5400 batches in 2180.52s	training loss:	3.215052
Done 5600 batches in 2261.42s	training loss:	3.214943
Done 5800 batches in 2341.67s	training loss:	3.214996
Done 6000 batches in 2422.49s	training loss:	3.214898
Done 6200 batches in 2502.28s	training loss:	3.214686
Done 6400 batches in 2582.46s	training loss:	3.214373
Done 100 batches in 8.36s
Done 200 batches in 16.75s
Done 300 batches in 25.17s
Done 400 batches in 33.94s
Done 500 batches in 42.49s
Done 600 batches in 51.11s
Done 700 batches in 59.93s
Done 800 batches in 68.78s

Training loss:   3.21432288474
Validation loss: 3.38930488383

Saving model...
Done saving.


Starting epoch 14...

Done 200 batches in 81.33s	training loss:	3.206954
Done 400 batches in 161.30s	training loss:	3.198581
Done 600 batches in 242.45s	training loss:	3.205459
Done 800 batches in 322.19s	training loss:	3.203332
Done 1000 batches in 402.62s	training loss:	3.204013
Done 1200 batches in 482.75s	training loss:	3.202477
Done 1400 batches in 562.44s	training loss:	3.201652
Done 1600 batches in 642.08s	training loss:	3.201068
Done 1800 batches in 721.58s	training loss:	3.198865
Done 2000 batches in 802.96s	training loss:	3.199431
Done 2200 batches in 884.90s	training loss:	3.199694
Done 2400 batches in 965.56s	training loss:	3.199174
Done 2600 batches in 1047.10s	training loss:	3.199165
Done 2800 batches in 1128.91s	training loss:	3.199060
Done 3000 batches in 1210.59s	training loss:	3.199445
Done 3200 batches in 1290.36s	training loss:	3.199240
Done 3400 batches in 1370.94s	training loss:	3.198828
Done 3600 batches in 1450.63s	training loss:	3.197992
Done 3800 batches in 1530.13s	training loss:	3.197285
Done 4000 batches in 1611.22s	training loss:	3.197810
Done 4200 batches in 1692.92s	training loss:	3.198367
Done 4400 batches in 1775.65s	training loss:	3.198711
Done 4600 batches in 1855.86s	training loss:	3.198742
Done 4800 batches in 1937.50s	training loss:	3.198951
Done 5000 batches in 2018.00s	training loss:	3.198301
Done 5200 batches in 2098.33s	training loss:	3.198014
Done 5400 batches in 2179.26s	training loss:	3.197722
Done 5600 batches in 2260.18s	training loss:	3.197632
Done 5800 batches in 2340.61s	training loss:	3.197703
Done 6000 batches in 2421.58s	training loss:	3.197614
Done 6200 batches in 2501.34s	training loss:	3.197414
Done 6400 batches in 2581.43s	training loss:	3.197120
Done 100 batches in 8.48s
Done 200 batches in 16.87s
Done 300 batches in 25.30s
Done 400 batches in 34.08s
Done 500 batches in 42.63s
Done 600 batches in 51.27s
Done 700 batches in 60.09s
Done 800 batches in 68.95s

Training loss:   3.19708506953
Validation loss: 3.3848025901

Saving model...
Done saving.


Starting epoch 15...

Done 200 batches in 81.22s	training loss:	3.190482
Done 400 batches in 161.05s	training loss:	3.181976
Done 600 batches in 242.26s	training loss:	3.188799
Done 800 batches in 321.98s	training loss:	3.186694
Done 1000 batches in 402.30s	training loss:	3.187394
Done 1200 batches in 482.37s	training loss:	3.185844
Done 1400 batches in 562.09s	training loss:	3.185039
Done 1600 batches in 641.88s	training loss:	3.184498
Done 1800 batches in 721.59s	training loss:	3.182320
Done 2000 batches in 803.11s	training loss:	3.182889
Done 2200 batches in 885.28s	training loss:	3.183185
Done 2400 batches in 966.04s	training loss:	3.182692
Done 2600 batches in 1047.57s	training loss:	3.182717
Done 2800 batches in 1129.24s	training loss:	3.182622
Done 3000 batches in 1210.77s	training loss:	3.183011
Done 3200 batches in 1290.45s	training loss:	3.182826
Done 3400 batches in 1370.75s	training loss:	3.182429
Done 3600 batches in 1450.37s	training loss:	3.181614
Done 3800 batches in 1529.72s	training loss:	3.180922
Done 4000 batches in 1610.83s	training loss:	3.181467
Done 4200 batches in 1692.32s	training loss:	3.182032
Done 4400 batches in 1775.00s	training loss:	3.182390
Done 4600 batches in 1855.60s	training loss:	3.182428
Done 4800 batches in 1937.10s	training loss:	3.182649
Done 5000 batches in 2017.28s	training loss:	3.182012
Done 5200 batches in 2097.47s	training loss:	3.181731
Done 5400 batches in 2178.26s	training loss:	3.181464
Done 5600 batches in 2259.25s	training loss:	3.181391
Done 5800 batches in 2339.60s	training loss:	3.181479
Done 6000 batches in 2420.67s	training loss:	3.181399
Done 6200 batches in 2500.59s	training loss:	3.181212
Done 6400 batches in 2580.85s	training loss:	3.180935
Done 100 batches in 8.45s
Done 200 batches in 16.85s
Done 300 batches in 25.29s
Done 400 batches in 34.08s
Done 500 batches in 42.65s
Done 600 batches in 51.29s
Done 700 batches in 60.12s
Done 800 batches in 68.99s

Training loss:   3.18091422999
Validation loss: 3.38118143451

Saving model...
Done saving.


Starting epoch 16...

Done 200 batches in 81.30s	training loss:	3.174985
Done 400 batches in 161.28s	training loss:	3.166348
Done 600 batches in 242.46s	training loss:	3.173117
Done 800 batches in 322.50s	training loss:	3.171028
Done 1000 batches in 403.11s	training loss:	3.171743
Done 1200 batches in 483.32s	training loss:	3.170178
Done 1400 batches in 563.06s	training loss:	3.169390
Done 1600 batches in 642.71s	training loss:	3.168892
Done 1800 batches in 722.26s	training loss:	3.166736
Done 2000 batches in 803.92s	training loss:	3.167308
Done 2200 batches in 885.72s	training loss:	3.167637
Done 2400 batches in 966.55s	training loss:	3.167170
Done 2600 batches in 1048.31s	training loss:	3.167224
Done 2800 batches in 1130.19s	training loss:	3.167138
Done 3000 batches in 1211.87s	training loss:	3.167528
Done 3200 batches in 1291.56s	training loss:	3.167363
Done 3400 batches in 1372.18s	training loss:	3.166978
Done 3600 batches in 1452.03s	training loss:	3.166179
Done 3800 batches in 1531.40s	training loss:	3.165501
Done 4000 batches in 1612.51s	training loss:	3.166064
Done 4200 batches in 1693.93s	training loss:	3.166633
Done 4400 batches in 1776.51s	training loss:	3.167005
Done 4600 batches in 1856.61s	training loss:	3.167049
Done 4800 batches in 1938.29s	training loss:	3.167280
Done 5000 batches in 2018.71s	training loss:	3.166656
Done 5200 batches in 2098.95s	training loss:	3.166378
Done 5400 batches in 2179.57s	training loss:	3.166132
Done 5600 batches in 2260.48s	training loss:	3.166072
Done 5800 batches in 2340.73s	training loss:	3.166176
Done 6000 batches in 2421.49s	training loss:	3.166103
Done 6200 batches in 2501.19s	training loss:	3.165923
Done 6400 batches in 2581.27s	training loss:	3.165660
Done 100 batches in 8.46s
Done 200 batches in 16.83s
Done 300 batches in 25.24s
Done 400 batches in 33.97s
Done 500 batches in 42.42s
Done 600 batches in 50.96s
Done 700 batches in 59.73s
Done 800 batches in 68.58s

Training loss:   3.16565187491
Validation loss: 3.37827827174

Saving model...
Done saving.


Starting epoch 17...

Done 200 batches in 81.17s	training loss:	3.160329
Done 400 batches in 161.08s	training loss:	3.151569
Done 600 batches in 242.40s	training loss:	3.158288
Done 800 batches in 322.21s	training loss:	3.156226
Done 1000 batches in 402.86s	training loss:	3.156951
Done 1200 batches in 483.20s	training loss:	3.155364
Done 1400 batches in 563.06s	training loss:	3.154592
Done 1600 batches in 642.57s	training loss:	3.154129
Done 1800 batches in 722.37s	training loss:	3.151993
Done 2000 batches in 803.89s	training loss:	3.152566
Done 2200 batches in 885.79s	training loss:	3.152926
Done 2400 batches in 966.76s	training loss:	3.152484
Done 2600 batches in 1048.50s	training loss:	3.152563
Done 2800 batches in 1130.40s	training loss:	3.152484
Done 3000 batches in 1212.20s	training loss:	3.152872
Done 3200 batches in 1292.07s	training loss:	3.152725
Done 3400 batches in 1372.58s	training loss:	3.152355
Done 3600 batches in 1452.17s	training loss:	3.151571
Done 3800 batches in 1531.54s	training loss:	3.150902
Done 4000 batches in 1612.68s	training loss:	3.151480
Done 4200 batches in 1694.31s	training loss:	3.152051
Done 4400 batches in 1777.02s	training loss:	3.152433
Done 4600 batches in 1857.25s	training loss:	3.152481
Done 4800 batches in 1938.73s	training loss:	3.152721
Done 5000 batches in 2019.11s	training loss:	3.152108
Done 5200 batches in 2099.46s	training loss:	3.151833
Done 5400 batches in 2180.31s	training loss:	3.151607
Done 5600 batches in 2261.27s	training loss:	3.151558
Done 5800 batches in 2341.67s	training loss:	3.151676
Done 6000 batches in 2422.66s	training loss:	3.151609
Done 6200 batches in 2502.13s	training loss:	3.151436
Done 6400 batches in 2582.58s	training loss:	3.151186
Done 100 batches in 8.49s
Done 200 batches in 16.91s
Done 300 batches in 25.35s
Done 400 batches in 34.13s
Done 500 batches in 42.69s
Done 600 batches in 51.33s
Done 700 batches in 60.16s
Done 800 batches in 69.03s

Training loss:   3.15119006356
Validation loss: 3.37603011289

Saving model...
Done saving.


Starting epoch 18...

Done 200 batches in 81.24s	training loss:	3.146390
Done 400 batches in 161.01s	training loss:	3.137511
Done 600 batches in 242.14s	training loss:	3.144182
Done 800 batches in 322.01s	training loss:	3.142130
Done 1000 batches in 402.43s	training loss:	3.142866
Done 1200 batches in 482.67s	training loss:	3.141260
Done 1400 batches in 562.68s	training loss:	3.140506
Done 1600 batches in 642.25s	training loss:	3.140080
Done 1800 batches in 721.78s	training loss:	3.137964
Done 2000 batches in 803.55s	training loss:	3.138540
Done 2200 batches in 885.24s	training loss:	3.138930
Done 2400 batches in 965.89s	training loss:	3.138510
Done 2600 batches in 1047.57s	training loss:	3.138615
Done 2800 batches in 1129.43s	training loss:	3.138545
Done 3000 batches in 1211.15s	training loss:	3.138931
Done 3200 batches in 1290.92s	training loss:	3.138800
Done 3400 batches in 1371.29s	training loss:	3.138441
Done 3600 batches in 1450.92s	training loss:	3.137667
Done 3800 batches in 1530.49s	training loss:	3.137009
Done 4000 batches in 1611.64s	training loss:	3.137601
Done 4200 batches in 1693.08s	training loss:	3.138176
Done 4400 batches in 1775.72s	training loss:	3.138570
Done 4600 batches in 1856.00s	training loss:	3.138622
Done 4800 batches in 1937.58s	training loss:	3.138868
Done 5000 batches in 2017.87s	training loss:	3.138268
Done 5200 batches in 2098.20s	training loss:	3.137995
Done 5400 batches in 2179.24s	training loss:	3.137787
Done 5600 batches in 2260.27s	training loss:	3.137749
Done 5800 batches in 2340.67s	training loss:	3.137879
Done 6000 batches in 2421.68s	training loss:	3.137819
Done 6200 batches in 2501.39s	training loss:	3.137652
Done 6400 batches in 2581.73s	training loss:	3.137414
Done 100 batches in 8.41s
Done 200 batches in 16.78s
Done 300 batches in 25.21s
Done 400 batches in 33.99s
Done 500 batches in 42.55s
Done 600 batches in 51.18s
Done 700 batches in 60.00s
Done 800 batches in 68.86s

Training loss:   3.13742853119
Validation loss: 3.37437222872

Saving model...
Done saving.


Starting epoch 19...

Done 200 batches in 81.63s	training loss:	3.133219
Done 400 batches in 161.65s	training loss:	3.124171
Done 600 batches in 242.91s	training loss:	3.130778
Done 800 batches in 322.86s	training loss:	3.128724
Done 1000 batches in 403.33s	training loss:	3.129459
Done 1200 batches in 483.45s	training loss:	3.127834
Done 1400 batches in 563.08s	training loss:	3.127093
Done 1600 batches in 642.89s	training loss:	3.126701
Done 1800 batches in 722.36s	training loss:	3.124607
Done 2000 batches in 803.90s	training loss:	3.125187
Done 2200 batches in 885.93s	training loss:	3.125607
Done 2400 batches in 966.77s	training loss:	3.125206
Done 2600 batches in 1048.32s	training loss:	3.125330
Done 2800 batches in 1130.05s	training loss:	3.125264
Done 3000 batches in 1211.55s	training loss:	3.125643
Done 3200 batches in 1291.25s	training loss:	3.125528
Done 3400 batches in 1371.75s	training loss:	3.125180
Done 3600 batches in 1451.39s	training loss:	3.124415
Done 3800 batches in 1530.65s	training loss:	3.123767
Done 4000 batches in 1611.92s	training loss:	3.124368
Done 4200 batches in 1693.49s	training loss:	3.124945
Done 4400 batches in 1775.99s	training loss:	3.125348
Done 4600 batches in 1856.09s	training loss:	3.125402
Done 4800 batches in 1937.65s	training loss:	3.125652
Done 5000 batches in 2018.04s	training loss:	3.125064
Done 5200 batches in 2098.43s	training loss:	3.124790
Done 5400 batches in 2179.43s	training loss:	3.124597
Done 5600 batches in 2260.54s	training loss:	3.124569
Done 5800 batches in 2341.06s	training loss:	3.124711
Done 6000 batches in 2422.31s	training loss:	3.124653
Done 6200 batches in 2502.06s	training loss:	3.124493
Done 6400 batches in 2582.63s	training loss:	3.124264
Done 100 batches in 8.43s
Done 200 batches in 16.83s
Done 300 batches in 25.29s
Done 400 batches in 34.10s
Done 500 batches in 42.69s
Done 600 batches in 51.35s
Done 700 batches in 60.20s
Done 800 batches in 69.08s

Training loss:   3.12428971058
Validation loss: 3.37321662297

Saving model...
Done saving.


Starting epoch 20...

Done 200 batches in 81.38s	training loss:	3.120458
Done 400 batches in 161.53s	training loss:	3.111316
Done 600 batches in 242.97s	training loss:	3.117889
Done 800 batches in 322.79s	training loss:	3.115844
Done 1000 batches in 403.16s	training loss:	3.116592
Done 1200 batches in 483.39s	training loss:	3.114963
Done 1400 batches in 563.13s	training loss:	3.114240
Done 1600 batches in 642.84s	training loss:	3.113886
Done 1800 batches in 722.45s	training loss:	3.111810
Done 2000 batches in 803.98s	training loss:	3.112389
Done 2200 batches in 885.74s	training loss:	3.112838
Done 2400 batches in 966.38s	training loss:	3.112453
Done 2600 batches in 1047.87s	training loss:	3.112595
Done 2800 batches in 1129.62s	training loss:	3.112536
Done 3000 batches in 1211.24s	training loss:	3.112911
Done 3200 batches in 1291.05s	training loss:	3.112813
Done 3400 batches in 1371.52s	training loss:	3.112478
Done 3600 batches in 1451.07s	training loss:	3.111721
Done 3800 batches in 1530.70s	training loss:	3.111082
Done 4000 batches in 1611.85s	training loss:	3.111692
Done 4200 batches in 1693.22s	training loss:	3.112268
Done 4400 batches in 1775.61s	training loss:	3.112682
Done 4600 batches in 1855.64s	training loss:	3.112737
Done 4800 batches in 1936.98s	training loss:	3.112992
Done 5000 batches in 2017.27s	training loss:	3.112415
Done 5200 batches in 2097.84s	training loss:	3.112139
Done 5400 batches in 2178.65s	training loss:	3.111962
Done 5600 batches in 2259.44s	training loss:	3.111943
Done 5800 batches in 2339.59s	training loss:	3.112095
Done 6000 batches in 2420.41s	training loss:	3.112041
Done 6200 batches in 2499.91s	training loss:	3.111886
Done 6400 batches in 2580.02s	training loss:	3.111667
Done 100 batches in 8.40s
Done 200 batches in 16.76s
Done 300 batches in 25.11s
Done 400 batches in 33.81s
Done 500 batches in 42.31s
Done 600 batches in 50.88s
Done 700 batches in 59.71s
Done 800 batches in 68.59s

Training loss:   3.11170143042
Validation loss: 3.37250647355

Saving model...
Done saving.


Starting epoch 21...

Done 200 batches in 81.29s	training loss:	3.108262
Done 400 batches in 161.27s	training loss:	3.099007
Done 600 batches in 242.48s	training loss:	3.105526
Done 800 batches in 322.41s	training loss:	3.103483
Done 1000 batches in 402.89s	training loss:	3.104239
Done 1200 batches in 483.30s	training loss:	3.102606
Done 1400 batches in 563.32s	training loss:	3.101894
Done 1600 batches in 642.96s	training loss:	3.101568
Done 1800 batches in 722.55s	training loss:	3.099516
Done 2000 batches in 804.03s	training loss:	3.100097
Done 2200 batches in 886.05s	training loss:	3.100575
Done 2400 batches in 967.17s	training loss:	3.100204
Done 2600 batches in 1048.88s	training loss:	3.100366
Done 2800 batches in 1130.64s	training loss:	3.100313
Done 3000 batches in 1212.38s	training loss:	3.100683
Done 3200 batches in 1292.25s	training loss:	3.100599
Done 3400 batches in 1372.65s	training loss:	3.100278
Done 3600 batches in 1452.14s	training loss:	3.099528
Done 3800 batches in 1531.65s	training loss:	3.098895
Done 4000 batches in 1612.74s	training loss:	3.099515
Done 4200 batches in 1694.24s	training loss:	3.100091
Done 4400 batches in 1776.91s	training loss:	3.100510
Done 4600 batches in 1857.09s	training loss:	3.100567
Done 4800 batches in 1938.64s	training loss:	3.100826
Done 5000 batches in 2018.97s	training loss:	3.100260
Done 5200 batches in 2099.25s	training loss:	3.099981
Done 5400 batches in 2180.15s	training loss:	3.099817
Done 5600 batches in 2260.94s	training loss:	3.099808
Done 5800 batches in 2341.20s	training loss:	3.099970
Done 6000 batches in 2422.09s	training loss:	3.099919
Done 6200 batches in 2501.57s	training loss:	3.099770
Done 6400 batches in 2581.67s	training loss:	3.099560
Done 100 batches in 8.46s
Done 200 batches in 16.84s
Done 300 batches in 25.25s
Done 400 batches in 34.01s
Done 500 batches in 42.49s
Done 600 batches in 51.04s
Done 700 batches in 59.81s
Done 800 batches in 68.66s

Training loss:   3.0996044237
Validation loss: 3.37220933121

Saving model...
Done saving.


Starting epoch 22...

Done 200 batches in 81.51s	training loss:	3.096536
Done 400 batches in 161.37s	training loss:	3.087183
Done 600 batches in 242.65s	training loss:	3.093648
Done 800 batches in 322.44s	training loss:	3.091601
Done 1000 batches in 402.81s	training loss:	3.092363
Done 1200 batches in 482.91s	training loss:	3.090726
Done 1400 batches in 562.60s	training loss:	3.090025
Done 1600 batches in 642.14s	training loss:	3.089727
Done 1800 batches in 721.65s	training loss:	3.087698
Done 2000 batches in 803.35s	training loss:	3.088278
Done 2200 batches in 885.30s	training loss:	3.088781
Done 2400 batches in 966.96s	training loss:	3.088423
Done 2600 batches in 1048.63s	training loss:	3.088600
Done 2800 batches in 1130.62s	training loss:	3.088552
Done 3000 batches in 1212.35s	training loss:	3.088916
Done 3200 batches in 1292.16s	training loss:	3.088847
Done 3400 batches in 1372.68s	training loss:	3.088539
Done 3600 batches in 1452.27s	training loss:	3.087796
Done 3800 batches in 1531.52s	training loss:	3.087170
Done 4000 batches in 1612.59s	training loss:	3.087799
Done 4200 batches in 1693.90s	training loss:	3.088373
Done 4400 batches in 1776.47s	training loss:	3.088800
Done 4600 batches in 1856.93s	training loss:	3.088856
Done 4800 batches in 1938.40s	training loss:	3.089118
Done 5000 batches in 2018.93s	training loss:	3.088563
Done 5200 batches in 2099.23s	training loss:	3.088281
Done 5400 batches in 2179.91s	training loss:	3.088129
Done 5600 batches in 2260.82s	training loss:	3.088132
Done 5800 batches in 2341.35s	training loss:	3.088303
Done 6000 batches in 2422.08s	training loss:	3.088254
Done 6200 batches in 2501.53s	training loss:	3.088109
Done 6400 batches in 2581.78s	training loss:	3.087907
Done 100 batches in 8.44s
Done 200 batches in 16.82s
Done 300 batches in 25.25s
Done 400 batches in 34.02s
Done 500 batches in 42.57s
Done 600 batches in 51.20s
Done 700 batches in 60.02s
Done 800 batches in 68.88s

Training loss:   3.08796012639
Validation loss: 3.37220239404

Saving model...
Done saving.


Starting epoch 23...

Done 200 batches in 81.53s	training loss:	3.085233
Done 400 batches in 161.65s	training loss:	3.075773
Done 600 batches in 242.95s	training loss:	3.082192
Done 800 batches in 322.74s	training loss:	3.080139
Done 1000 batches in 403.04s	training loss:	3.080910
Done 1200 batches in 483.18s	training loss:	3.079270
Done 1400 batches in 562.73s	training loss:	3.078581
Done 1600 batches in 642.17s	training loss:	3.078312
Done 1800 batches in 721.89s	training loss:	3.076305
Done 2000 batches in 803.35s	training loss:	3.076887
Done 2200 batches in 885.17s	training loss:	3.077417
Done 2400 batches in 965.72s	training loss:	3.077072
Done 2600 batches in 1047.37s	training loss:	3.077262
Done 2800 batches in 1129.22s	training loss:	3.077220
Done 3000 batches in 1210.79s	training loss:	3.077577
Done 3200 batches in 1290.51s	training loss:	3.077522
Done 3400 batches in 1371.01s	training loss:	3.077226
Done 3600 batches in 1450.64s	training loss:	3.076488
Done 3800 batches in 1530.21s	training loss:	3.075868
Done 4000 batches in 1611.33s	training loss:	3.076504
Done 4200 batches in 1692.92s	training loss:	3.077077
Done 4400 batches in 1775.55s	training loss:	3.077508
Done 4600 batches in 1855.78s	training loss:	3.077564
Done 4800 batches in 1937.33s	training loss:	3.077828
Done 5000 batches in 2017.72s	training loss:	3.077283
Done 5200 batches in 2098.13s	training loss:	3.076997
Done 5400 batches in 2179.06s	training loss:	3.076857
Done 5600 batches in 2259.84s	training loss:	3.076865
Done 5800 batches in 2340.17s	training loss:	3.077045
Done 6000 batches in 2421.19s	training loss:	3.077000
Done 6200 batches in 2500.96s	training loss:	3.076858
Done 6400 batches in 2581.22s	training loss:	3.076665
Done 100 batches in 8.49s
Done 200 batches in 16.89s
Done 300 batches in 25.33s
Done 400 batches in 34.11s
Done 500 batches in 42.67s
Done 600 batches in 51.31s
Done 700 batches in 60.14s
Done 800 batches in 69.01s

Training loss:   3.07672612533
Validation loss: 3.37257398658


Starting epoch 24...

Done 200 batches in 81.30s	training loss:	3.074311
Done 400 batches in 161.21s	training loss:	3.064750
Done 600 batches in 242.45s	training loss:	3.071120
Done 800 batches in 322.49s	training loss:	3.069062
Done 1000 batches in 402.94s	training loss:	3.069841
Done 1200 batches in 483.32s	training loss:	3.068203
Done 1400 batches in 563.07s	training loss:	3.067528
Done 1600 batches in 642.82s	training loss:	3.067288
Done 1800 batches in 722.30s	training loss:	3.065304
Done 2000 batches in 803.75s	training loss:	3.065886
Done 2200 batches in 885.56s	training loss:	3.066443
Done 2400 batches in 966.36s	training loss:	3.066105
Done 2600 batches in 1047.82s	training loss:	3.066309
Done 2800 batches in 1129.66s	training loss:	3.066270
Done 3000 batches in 1211.31s	training loss:	3.066623
Done 3200 batches in 1291.00s	training loss:	3.066580
Done 3400 batches in 1371.36s	training loss:	3.066295
Done 3600 batches in 1451.18s	training loss:	3.065562
Done 3800 batches in 1530.57s	training loss:	3.064947
Done 4000 batches in 1611.47s	training loss:	3.065591
Done 4200 batches in 1692.80s	training loss:	3.066161
Done 4400 batches in 1775.26s	training loss:	3.066597
Done 4600 batches in 1855.29s	training loss:	3.066653
Done 4800 batches in 1936.63s	training loss:	3.066918
Done 5000 batches in 2016.93s	training loss:	3.066385
Done 5200 batches in 2097.35s	training loss:	3.066096
Done 5400 batches in 2178.75s	training loss:	3.065967
Done 5600 batches in 2259.53s	training loss:	3.065981
Done 5800 batches in 2339.76s	training loss:	3.066168
Done 6000 batches in 2420.77s	training loss:	3.066123
Done 6200 batches in 2500.56s	training loss:	3.065986
Done 6400 batches in 2581.11s	training loss:	3.065800
Done 100 batches in 8.50s
Done 200 batches in 16.91s
Done 300 batches in 25.37s
Done 400 batches in 34.16s
Done 500 batches in 42.74s
Done 600 batches in 51.39s
Done 700 batches in 60.23s
Done 800 batches in 69.12s

Training loss:   3.06586942661
Validation loss: 3.37318401069


Starting epoch 25...

Done 200 batches in 81.14s	training loss:	3.063744
Done 400 batches in 161.07s	training loss:	3.054081
Done 600 batches in 242.53s	training loss:	3.060409
Done 800 batches in 322.38s	training loss:	3.058346
Done 1000 batches in 402.85s	training loss:	3.059134
Done 1200 batches in 482.99s	training loss:	3.057498
Done 1400 batches in 562.92s	training loss:	3.056843
Done 1600 batches in 643.17s	training loss:	3.056632
Done 1800 batches in 722.72s	training loss:	3.054667
Done 2000 batches in 804.24s	training loss:	3.055250
Done 2200 batches in 886.23s	training loss:	3.055835
Done 2400 batches in 967.14s	training loss:	3.055506
Done 2600 batches in 1048.85s	training loss:	3.055722
Done 2800 batches in 1130.70s	training loss:	3.055686
Done 3000 batches in 1212.32s	training loss:	3.056030
Done 3200 batches in 1292.18s	training loss:	3.056000
Done 3400 batches in 1372.84s	training loss:	3.055727
Done 3600 batches in 1452.52s	training loss:	3.055000
Done 3800 batches in 1531.77s	training loss:	3.054392
Done 4000 batches in 1613.12s	training loss:	3.055042
Done 4200 batches in 1694.60s	training loss:	3.055609
Done 4400 batches in 1777.09s	training loss:	3.056047
Done 4600 batches in 1857.27s	training loss:	3.056102
Done 4800 batches in 1938.80s	training loss:	3.056366
Done 5000 batches in 2018.87s	training loss:	3.055842
Done 5200 batches in 2098.97s	training loss:	3.055548
Done 5400 batches in 2179.70s	training loss:	3.055432
Done 5600 batches in 2260.38s	training loss:	3.055451
Done 5800 batches in 2341.22s	training loss:	3.055644
Done 6000 batches in 2421.98s	training loss:	3.055599
Done 6200 batches in 2501.40s	training loss:	3.055467
Done 6400 batches in 2581.49s	training loss:	3.055288
Done 100 batches in 8.48s
Done 200 batches in 16.86s
Done 300 batches in 25.28s
Done 400 batches in 34.04s
Done 500 batches in 42.58s
Done 600 batches in 51.19s
Done 700 batches in 60.00s
Done 800 batches in 68.84s

Training loss:   3.0553652104
Validation loss: 3.37410577658


Starting epoch 26...

Done 200 batches in 81.08s	training loss:	3.053481
Done 400 batches in 160.90s	training loss:	3.043734
Done 600 batches in 242.24s	training loss:	3.050023
Done 800 batches in 322.17s	training loss:	3.047957
Done 1000 batches in 402.60s	training loss:	3.048754
Done 1200 batches in 482.87s	training loss:	3.047120
Done 1400 batches in 562.65s	training loss:	3.046473
Done 1600 batches in 642.39s	training loss:	3.046288
Done 1800 batches in 722.05s	training loss:	3.044347
Done 2000 batches in 804.04s	training loss:	3.044933
Done 2200 batches in 885.93s	training loss:	3.045546
Done 2400 batches in 966.71s	training loss:	3.045227
Done 2600 batches in 1048.43s	training loss:	3.045456
Done 2800 batches in 1130.21s	training loss:	3.045424
Done 3000 batches in 1211.85s	training loss:	3.045767
Done 3200 batches in 1291.64s	training loss:	3.045750
Done 3400 batches in 1372.16s	training loss:	3.045489
Done 3600 batches in 1451.79s	training loss:	3.044765
Done 3800 batches in 1531.12s	training loss:	3.044160
Done 4000 batches in 1612.21s	training loss:	3.044816
Done 4200 batches in 1694.06s	training loss:	3.045381
Done 4400 batches in 1776.56s	training loss:	3.045822
Done 4600 batches in 1856.74s	training loss:	3.045877
Done 4800 batches in 1938.23s	training loss:	3.046141
Done 5000 batches in 2018.48s	training loss:	3.045625
Done 5200 batches in 2098.89s	training loss:	3.045328
Done 5400 batches in 2179.86s	training loss:	3.045219
Done 5600 batches in 2260.68s	training loss:	3.045243
Done 5800 batches in 2341.27s	training loss:	3.045443
Done 6000 batches in 2422.20s	training loss:	3.045401
Done 6200 batches in 2501.75s	training loss:	3.045271
Done 6400 batches in 2581.99s	training loss:	3.045100
Done 100 batches in 8.48s
Done 200 batches in 16.86s
Done 300 batches in 25.29s
Done 400 batches in 34.06s
Done 500 batches in 42.61s
Done 600 batches in 51.24s
Done 700 batches in 60.06s
Done 800 batches in 68.91s

Training loss:   3.04518469817
Validation loss: 3.37524289025
Done 100 batches in 8.72s
Done 200 batches in 17.66s
Done 300 batches in 26.57s
Done 400 batches in 35.24s
Done 500 batches in 44.12s
Done 600 batches in 52.82s
Done 700 batches in 61.87s
Done 800 batches in 70.79s


Total training time: 70091.49s
Best model after 22 epochs with loss 3.37220239404
Validation set perplexity: 29.1426400076
Model saved as ../trained_models/final/w2vInit_300_300_full_bs30_cut200_nosplit_early5.npz

Test loss: 3.36032356496
Test set perplexity: 28.79850756
