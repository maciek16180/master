{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, nltk, io, pickle\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from string import whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More careful prepocessing\n",
    "##### (tried to replicate prep from FastQA paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/pio/data/data/squad/glove840B/careful_prep/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/dev-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    dev = json.load(f)\n",
    "\n",
    "with io.open('/pio/data/data/squad/train-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove840B = np.load('/pio/data/data/glove_vec/840B/glove/glove.840B.wordlist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_to_i_840B = {glove840B[i] : i for i in xrange(len(glove840B))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(s, ans_idx=None):\n",
    "    tokens = []\n",
    "    buf = u''\n",
    "    \n",
    "    for i in range(len(s)):        \n",
    "        if ans_idx is not None:\n",
    "            if ans_idx == 0:\n",
    "                ans_start = len(tokens)\n",
    "            ans_idx -= 1\n",
    "        c = s[i]\n",
    "        if c.isspace():\n",
    "            if buf:\n",
    "                tokens.append(buf)\n",
    "            buf = u''\n",
    "        elif not c.isalnum():\n",
    "            if buf:\n",
    "                tokens.append(buf)\n",
    "            tokens.append(c)\n",
    "            buf = u''\n",
    "        else:\n",
    "            buf += c\n",
    "    if buf:\n",
    "        tokens.append(buf)\n",
    "        \n",
    "    if ans_idx is not None:\n",
    "        return tokens, ans_start\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = []\n",
    "\n",
    "for par in train['data']:\n",
    "    for con in par['paragraphs']:\n",
    "        context = con['context']\n",
    "        \n",
    "        for q in con['qas']:\n",
    "            question = q['question']\n",
    "            question_tok = tokenize(question)\n",
    "            answers = []\n",
    "            \n",
    "            for ans in q['answers']:\n",
    "                text = ans['text']\n",
    "                ans_start = ans['answer_start']\n",
    "                context_tok, ans_start = tokenize(context, ans_start)\n",
    "                ans_end = ans_start + len(tokenize(text)) - 1\n",
    "                \n",
    "                answers.append(([ans_start, ans_end], text))\n",
    "                   \n",
    "            data_train.append([answers, question_tok, context_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wywalam odpowiedzi, ktorych nie mamy szans sie nauczyc (bedace fragmentami slow)\n",
    "data_train = [d for d in data if u' '.join(d[2][d[0][0][0][0]:d[0][0][0][1]+1]) == u' '.join(tokenize(d[0][0][1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87269"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dev = []\n",
    "\n",
    "for par in dev['data']:\n",
    "    for con in par['paragraphs']:\n",
    "        context = con['context']\n",
    "        \n",
    "        for q in con['qas']:\n",
    "            question = q['question']\n",
    "            question_tok = tokenize(question)\n",
    "            answers = []\n",
    "            \n",
    "            Id = q['id']\n",
    "            \n",
    "            for ans in q['answers']:\n",
    "                text = ans['text']\n",
    "                ans_start = ans['answer_start']\n",
    "                context_tok, ans_start = tokenize(context, ans_start)\n",
    "                ans_end = ans_start + len(tokenize(text)) - 1\n",
    "                \n",
    "                answers.append(([ans_start, ans_end], text))\n",
    "                   \n",
    "            data_dev.append([answers, question_tok, context_tok, Id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path + 'train.pkl', 'w') as f:\n",
    "    pickle.dump(data_train, f)\n",
    "    \n",
    "with open(path + 'dev.pkl', 'w') as f:\n",
    "    pickle.dump(data_dev, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num = []\n",
    "for a, q, x in data_train:\n",
    "    a_num = list(range(a[0][0][0], a[0][0][1] + 1))\n",
    "    q_num = [w_to_i_840B.get(w, 0) for w in q]\n",
    "    x_num = [w_to_i_840B.get(w, 0) for w in x]\n",
    "    train_num.append([[a_num], q_num, x_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_num = []\n",
    "for a, q, x, _ in data_dev:\n",
    "    q_num = [w_to_i_840B.get(w, 0) for w in q]\n",
    "    x_num = [w_to_i_840B.get(w, 0) for w in x]\n",
    "    dev_num.append([[], q_num, x_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path + 'train_words.pkl', 'w') as f:\n",
    "    pickle.dump(train_num, f)\n",
    "    \n",
    "with open(path + 'dev_words.pkl', 'w') as f:\n",
    "    pickle.dump(dev_num, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bin_feats(sample):\n",
    "    q, x = sample[1:3]\n",
    "    qset = set(q)\n",
    "    return [w in qset for w in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bin_feats = map(make_bin_feats, data_train)\n",
    "dev_bin_feats = map(make_bin_feats, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path + 'train_bin_feats.pkl', 'w') as f:\n",
    "    pickle.dump(train_bin_feats, f)\n",
    "    \n",
    "with open(path + 'dev_bin_feats.pkl', 'w') as f:\n",
    "    pickle.dump(dev_bin_feats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 - unk\n",
    "# 1 - start\n",
    "# 2 - end\n",
    "# 3 - not_a_word char (added later, in wikipedia negative samples)\n",
    "# there are no 1s or 2s in data, so these are safe\n",
    "\n",
    "chars = [unichr(i) for i in xrange(128)]\n",
    "c_to_i = {chars[i] : i for i in xrange(128)}\n",
    "\n",
    "def get_char_nums_for_word(w):\n",
    "    return [1] + [c_to_i.get(c, 0) for c in w] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_char = []\n",
    "\n",
    "for _, q, x in data_train:\n",
    "    q_char = map(get_char_nums_for_word, q)\n",
    "    x_char = map(get_char_nums_for_word, x)\n",
    "    train_char.append([q_char, x_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_char = []\n",
    "\n",
    "for _, q, x, _ in data_dev:\n",
    "    q_char = map(get_char_nums_for_word, q)\n",
    "    x_char = map(get_char_nums_for_word, x)\n",
    "    dev_char.append([q_char, x_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path + 'train_char_ascii.pkl', 'w') as f:\n",
    "    pickle.dump(train_char, f)\n",
    "    \n",
    "with open(path + 'dev_char_ascii.pkl', 'w') as f:\n",
    "    pickle.dump(dev_char, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
