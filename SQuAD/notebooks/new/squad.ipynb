{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verified\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "sys.path.append('../..')\n",
    "from squad_tools import load_dict\n",
    "from my_tokenize import tokenize_with_ans_idx as tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# include glove version?\n",
    "\n",
    "out_path = '/pio/data/data/squad/test'\n",
    "glove_path = '/pio/data/data/glove_vec/6B/glove.6B.300d.txt'\n",
    "squad_path = '/pio/data/data/squad'\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "lower = True\n",
    "def lower_if_needed(s):\n",
    "    if lower:\n",
    "        s = s.lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(squad_path, 'dev-v1.1.json')) as f:\n",
    "    dev = json.load(f)\n",
    "\n",
    "with open(join(squad_path, 'train-v1.1.json')) as f:\n",
    "    train = json.load(f)\n",
    "    \n",
    "wordlist = load_dict(glove_path)\n",
    "    \n",
    "w_to_i = {w : i for i, w in enumerate(wordlist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(json_data, withId=False):\n",
    "    data = []\n",
    "\n",
    "    for par in json_data['data']:\n",
    "        for con in par['paragraphs']:\n",
    "            context = lower_if_needed(con['context'])\n",
    "\n",
    "            for q in con['qas']:\n",
    "                question = lower_if_needed(q['question'])\n",
    "                question_tok = tokenize(question)[0]\n",
    "                answers = []\n",
    "                \n",
    "                Id = q['id']\n",
    "\n",
    "                for ans in q['answers']:\n",
    "                    text = lower_if_needed(ans['text'])\n",
    "                    ans_start = ans['answer_start']\n",
    "                    context_tok, ans_start = tokenize(context, ans_start)\n",
    "                    ans_end = ans_start + len(tokenize(text)[0]) - 1\n",
    "\n",
    "                    answers.append(([ans_start, ans_end], text))\n",
    "\n",
    "                data.append([answers, question_tok, context_tok])\n",
    "                if withId:\n",
    "                    data[-1].append(Id)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 10570)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = prepare_data(train)\n",
    "data_dev = prepare_data(dev, withId=True)\n",
    "len(data_train), len(data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87269"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# throw out the questions with answers we can't possibly learn (the ones that aren't whole words)\n",
    "data_train = [d for d in data_train if \n",
    "              u' '.join(d[2][d[0][0][0][0]:d[0][0][0][1]+1]) == \\\n",
    "              u' '.join(tokenize(d[0][0][1])[0])]\n",
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(out_path, 'train.json'), 'w') as f:\n",
    "    json.dump(data_train, f)\n",
    "    \n",
    "with open(join(out_path, 'dev.json'), 'w') as f:\n",
    "    json.dump(data_dev, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_nums(s):\n",
    "    return [w_to_i.get(w, 0) for w in s]\n",
    "\n",
    "train_num = []\n",
    "for a, q, x in data_train:\n",
    "    a_num = list(range(a[0][0][0], a[0][0][1] + 1))\n",
    "    q_num = get_word_nums(q)\n",
    "    x_num = get_word_nums(x)\n",
    "    train_num.append([[a_num], q_num, x_num])\n",
    "    \n",
    "dev_num = []\n",
    "for a, q, x, _ in data_dev:\n",
    "    q_num = get_word_nums(q)\n",
    "    x_num = get_word_nums(x)\n",
    "    dev_num.append([[], q_num, x_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(out_path, 'train_words.json'), 'w') as f:\n",
    "    json.dump(train_num, f)\n",
    "    \n",
    "with open(join(out_path, 'dev_words.json'), 'w') as f:\n",
    "    json.dump(dev_num, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bin_feats(sample):\n",
    "    q, x = sample[1:3]\n",
    "    qset = set(q)\n",
    "    return [w in qset for w in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bin_feats = map(make_bin_feats, data_train)\n",
    "dev_bin_feats = map(make_bin_feats, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(out_path, 'train_bin_feats.json'), 'wb') as f:\n",
    "    json.dump(train_bin_feats, f)\n",
    "    \n",
    "with open(join(out_path, 'dev_bin_feats.json'), 'wb') as f:\n",
    "    json.dump(dev_bin_feats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 - unk\n",
    "# 1 - start\n",
    "# 2 - end\n",
    "# 3 - not_a_word char (added later, in wikipedia negative samples)\n",
    "\n",
    "chars = [unichr(i) for i in range(128)]\n",
    "c_to_i = {chars[i] : i for i in range(128)}\n",
    "\n",
    "def get_char_nums_for_word(w):\n",
    "    return [1] + [c_to_i.get(c, 0) for c in w] + [2]\n",
    "\n",
    "def prepare_chars(data):\n",
    "    data_char = []\n",
    "    for d in data:\n",
    "        _, q, x = d[:3]\n",
    "        q_char = map(get_char_nums_for_word, q)\n",
    "        x_char = map(get_char_nums_for_word, x)\n",
    "        data_char.append([q_char, x_char])\n",
    "    return data_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_char = prepare_chars(data_train)\n",
    "dev_char = prepare_chars(data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(out_path, 'train_char_ascii.json'), 'w') as f:\n",
    "    json.dump(train_char, f)\n",
    "    \n",
    "with open(join(out_path, 'dev_char_ascii.json'), 'w') as f:\n",
    "    json.dump(dev_char, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
