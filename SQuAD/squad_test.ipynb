{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, nltk, io, pickle\n",
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/train-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/dev-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    dev = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'answer_start': 177, u'text': u'Denver Broncos'},\n",
       " {u'answer_start': 177, u'text': u'Denver Broncos'},\n",
       " {u'answer_start': 177, u'text': u'Denver Broncos'}]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['data'][0]['paragraphs'][0]['qas'][0]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"The State Council declared a three-day period of national mourning for the quake victims starting from May 19 , 2008 ; the PRC 's National Flag and Regional Flags of Hong Kong and Macau Special Administrative Regions flown at half mast\",\n",
       " u'It was the first time that a national mourning period had been declared for something other than the death of a state leader , and many have called it the biggest display of mourning since the death of Mao Zedong',\n",
       " u'At 14:28 CST on May 19 , 2008 , a week after the earthquake , the Chinese public held a moment of silence',\n",
       " u'People stood silent for three minutes while air defense , police and fire sirens , and the horns of vehicles , vessels and trains sounded',\n",
       " u\"Cars and trucks on Beijing 's roads also came to a halt\",\n",
       " u\"People spontaneously burst into cheering `` Zhongguo jiayou ! '' ( Let 's go , China ! ) and `` Sichuan jiayou '' ( Let 's go , Sichuan ! ) afterwards .\"]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(nltk.word_tokenize(train['data'][10]['paragraphs'][60]['context'])).split(' . ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab all the question-answer pairs and create a wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = set()\n",
    "data = []\n",
    "lower = lambda x: x.lower()\n",
    "\n",
    "for par in train['data']:\n",
    "    title = par['title']\n",
    "    \n",
    "    for con in par['paragraphs']:\n",
    "        context = con['context']\n",
    "        context_tok = map(lower, nltk.word_tokenize(context))\n",
    "        words |= set(context_tok)\n",
    "        \n",
    "        for q in con['qas']:\n",
    "            question = q['question']\n",
    "            question_tok = map(lower, nltk.word_tokenize(question))\n",
    "            words |= set(question_tok)\n",
    "            \n",
    "            Id = q['id']\n",
    "            \n",
    "            answers = []\n",
    "            \n",
    "            for ans in q['answers']:\n",
    "                text = ans['text']\n",
    "                text_tok = map(lower, nltk.word_tokenize(text))\n",
    "                ans_start = ans['answer_start']\n",
    "                \n",
    "                answers.append((ans_start, text_tok))\n",
    "                \n",
    "            data.append([answers, question_tok, context_tok])\n",
    "            \n",
    "words.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599 102802\n"
     ]
    }
   ],
   "source": [
    "print len(data), len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    if len(d[0]) > 1:\n",
    "        print d\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn words into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_on_dot(s):\n",
    "    res = [[]]\n",
    "    for w in s:\n",
    "        res[-1].append(w)\n",
    "        if w == u'.':\n",
    "            res.append([])\n",
    "    return res if res[-1] else res[:-1]\n",
    "\n",
    "def words_to_num(s):\n",
    "    return map(lambda x: w_to_i.get(x, w_to_i['<unk>']), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_to_w = dict(enumerate(words))\n",
    "w_to_i = {v:k for (k,v) in i_to_w.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data)):\n",
    "    data[i][2] = split_on_dot(data[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num = []\n",
    "\n",
    "for a, q, c in data:\n",
    "    answers = []\n",
    "    for ans in a:\n",
    "        answers.append((ans[0], words_to_num(ans[1])))        \n",
    "    data_num.append([answers, words_to_num(q), map(words_to_num, c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some answers don't work, because of the tokenizer\n",
    "\n",
    "bugged_answers = 0\n",
    "\n",
    "for ans,_,_ in data_num:\n",
    "    for _,a in ans:\n",
    "        if w_to_i['<unk>'] in a:\n",
    "            bugged_answers += 1\n",
    "bugged_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num = map(lambda l: [l[0], [l[1]] + l[2]], data_num)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num = map(lambda l: [map(lambda t: t[1], l[0]), l[1]], data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are more broken answers, because I tag words instead of characters\n",
    "\n",
    "k = 0\n",
    "for a, q in data_num:\n",
    "    for w in a[0]:\n",
    "        if w not in list(chain(*q[1:])):\n",
    "            k += 1\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find answer indices on words, not characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = []\n",
    "\n",
    "for a, q in data_num:\n",
    "    ans = []\n",
    "    tot_q = list(chain(*q[1:]))\n",
    "    for x in a:\n",
    "        for i in xrange(len(tot_q)):\n",
    "            if x == tot_q[i:i+len(x)]:\n",
    "                ans.append(list(xrange(i, i + len(x))))\n",
    "                break\n",
    "    inds.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data_num)):\n",
    "    data_num[i][0] = inds[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_words = map(lambda x: x[0], sorted(w_to_i.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/wordlist.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in sorted_words:\n",
    "        f.write(unicode(w + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[102, 103, 104]],\n",
       " [[78406,\n",
       "   50177,\n",
       "   45612,\n",
       "   67711,\n",
       "   87146,\n",
       "   71884,\n",
       "   58619,\n",
       "   29587,\n",
       "   94338,\n",
       "   55795,\n",
       "   94338,\n",
       "   72312,\n",
       "   97133,\n",
       "   83077],\n",
       "  [100780, 44968, 67711, 60695, 608, 43315, 89195, 32610, 492],\n",
       "  [40701,\n",
       "   67711,\n",
       "   45830,\n",
       "   54332,\n",
       "   55792,\n",
       "   78791,\n",
       "   78506,\n",
       "   19554,\n",
       "   43315,\n",
       "   51341,\n",
       "   10820,\n",
       "   23764,\n",
       "   67711,\n",
       "   87146,\n",
       "   71884,\n",
       "   492],\n",
       "  [83032,\n",
       "   94338,\n",
       "   95628,\n",
       "   23764,\n",
       "   67711,\n",
       "   45830,\n",
       "   54332,\n",
       "   49698,\n",
       "   33470,\n",
       "   19557,\n",
       "   44968,\n",
       "   19554,\n",
       "   43315,\n",
       "   85100,\n",
       "   10820,\n",
       "   23764,\n",
       "   99569,\n",
       "   1485,\n",
       "   96317,\n",
       "   37478,\n",
       "   1485,\n",
       "   67711,\n",
       "   78483,\n",
       "   64851,\n",
       "   101002,\n",
       "   14122,\n",
       "   32833,\n",
       "   66547,\n",
       "   77561,\n",
       "   492],\n",
       "  [19445,\n",
       "   78406,\n",
       "   67711,\n",
       "   45830,\n",
       "   54332,\n",
       "   19554,\n",
       "   67711,\n",
       "   32756,\n",
       "   23764,\n",
       "   67711,\n",
       "   7991,\n",
       "   80913,\n",
       "   492],\n",
       "  [83032,\n",
       "   71615,\n",
       "   67711,\n",
       "   32756,\n",
       "   19554,\n",
       "   67711,\n",
       "   16921,\n",
       "   44968,\n",
       "   43315,\n",
       "   50307,\n",
       "   87507,\n",
       "   23764,\n",
       "   55111,\n",
       "   49698,\n",
       "   18814,\n",
       "   492],\n",
       "  [19557,\n",
       "   19554,\n",
       "   43315,\n",
       "   41529,\n",
       "   23764,\n",
       "   67711,\n",
       "   16921,\n",
       "   14138,\n",
       "   72312,\n",
       "   44968,\n",
       "   97133,\n",
       "   39657,\n",
       "   67711,\n",
       "   87146,\n",
       "   71884,\n",
       "   52733,\n",
       "   15575,\n",
       "   78406,\n",
       "   1880,\n",
       "   11294,\n",
       "   70764,\n",
       "   94338,\n",
       "   55795,\n",
       "   492],\n",
       "  [14138,\n",
       "   67711,\n",
       "   22438,\n",
       "   23764,\n",
       "   67711,\n",
       "   45830,\n",
       "   58251,\n",
       "   87309,\n",
       "   49698,\n",
       "   94338,\n",
       "   43315,\n",
       "   9478,\n",
       "   66270,\n",
       "   94548,\n",
       "   44767,\n",
       "   59287,\n",
       "   42821,\n",
       "   9093,\n",
       "   49698,\n",
       "   67711,\n",
       "   78791,\n",
       "   78506,\n",
       "   60426,\n",
       "   44968,\n",
       "   19554,\n",
       "   43315,\n",
       "   85325,\n",
       "   44968,\n",
       "   83589,\n",
       "   91160,\n",
       "   10820,\n",
       "   23764,\n",
       "   71884,\n",
       "   492]]]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file has a lot of redundant parts, context is repeated for each question.\n",
    "# It only slows down the initial loading.\n",
    "\n",
    "with open('/pio/data/data/squad/train.pkl', 'w') as f:\n",
    "    pickle.dump(data_num, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.load('/pio/data/data/squad/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[102, 103, 104]],\n",
       " [[78406,\n",
       "   50177,\n",
       "   45612,\n",
       "   67711,\n",
       "   87146,\n",
       "   71884,\n",
       "   58619,\n",
       "   29587,\n",
       "   94338,\n",
       "   55795,\n",
       "   94338,\n",
       "   72312,\n",
       "   97133,\n",
       "   83077],\n",
       "  [100780, 44968, 67711, 60695, 608, 43315, 89195, 32610, 492],\n",
       "  [40701,\n",
       "   67711,\n",
       "   45830,\n",
       "   54332,\n",
       "   55792,\n",
       "   78791,\n",
       "   78506,\n",
       "   19554,\n",
       "   43315,\n",
       "   51341,\n",
       "   10820,\n",
       "   23764,\n",
       "   67711,\n",
       "   87146,\n",
       "   71884,\n",
       "   492],\n",
       "  [83032,\n",
       "   94338,\n",
       "   95628,\n",
       "   23764,\n",
       "   67711,\n",
       "   45830,\n",
       "   54332,\n",
       "   49698,\n",
       "   33470,\n",
       "   19557,\n",
       "   44968,\n",
       "   19554,\n",
       "   43315,\n",
       "   85100,\n",
       "   10820,\n",
       "   23764,\n",
       "   99569,\n",
       "   1485,\n",
       "   96317,\n",
       "   37478,\n",
       "   1485,\n",
       "   67711,\n",
       "   78483,\n",
       "   64851,\n",
       "   101002,\n",
       "   14122,\n",
       "   32833,\n",
       "   66547,\n",
       "   77561,\n",
       "   492],\n",
       "  [19445,\n",
       "   78406,\n",
       "   67711,\n",
       "   45830,\n",
       "   54332,\n",
       "   19554,\n",
       "   67711,\n",
       "   32756,\n",
       "   23764,\n",
       "   67711,\n",
       "   7991,\n",
       "   80913,\n",
       "   492],\n",
       "  [83032,\n",
       "   71615,\n",
       "   67711,\n",
       "   32756,\n",
       "   19554,\n",
       "   67711,\n",
       "   16921,\n",
       "   44968,\n",
       "   43315,\n",
       "   50307,\n",
       "   87507,\n",
       "   23764,\n",
       "   55111,\n",
       "   49698,\n",
       "   18814,\n",
       "   492],\n",
       "  [19557,\n",
       "   19554,\n",
       "   43315,\n",
       "   41529,\n",
       "   23764,\n",
       "   67711,\n",
       "   16921,\n",
       "   14138,\n",
       "   72312,\n",
       "   44968,\n",
       "   97133,\n",
       "   39657,\n",
       "   67711,\n",
       "   87146,\n",
       "   71884,\n",
       "   52733,\n",
       "   15575,\n",
       "   78406,\n",
       "   1880,\n",
       "   11294,\n",
       "   70764,\n",
       "   94338,\n",
       "   55795,\n",
       "   492],\n",
       "  [14138,\n",
       "   67711,\n",
       "   22438,\n",
       "   23764,\n",
       "   67711,\n",
       "   45830,\n",
       "   58251,\n",
       "   87309,\n",
       "   49698,\n",
       "   94338,\n",
       "   43315,\n",
       "   9478,\n",
       "   66270,\n",
       "   94548,\n",
       "   44767,\n",
       "   59287,\n",
       "   42821,\n",
       "   9093,\n",
       "   49698,\n",
       "   67711,\n",
       "   78791,\n",
       "   78506,\n",
       "   60426,\n",
       "   44968,\n",
       "   19554,\n",
       "   43315,\n",
       "   85325,\n",
       "   44968,\n",
       "   83589,\n",
       "   91160,\n",
       "   10820,\n",
       "   23764,\n",
       "   71884,\n",
       "   492]]]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = {}\n",
    "idx = 0\n",
    "\n",
    "with io.open('/pio/data/data/squad/wordlist.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        b[line[:-1]] = idx\n",
    "        idx += 1\n",
    "        \n",
    "rev_b = {v:k for (k,v) in b.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'?'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_b[83077]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
