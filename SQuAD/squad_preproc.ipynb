{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import json, nltk, io, pickle\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import lasagne as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/train-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/dev-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    dev = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'answer_start': 177, u'text': u'Denver Broncos'},\n",
       " {u'answer_start': 177, u'text': u'Denver Broncos'},\n",
       " {u'answer_start': 177, u'text': u'Denver Broncos'}]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['data'][0]['paragraphs'][0]['qas'][0]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"The State Council declared a three-day period of national mourning for the quake victims starting from May 19 , 2008 ; the PRC 's National Flag and Regional Flags of Hong Kong and Macau Special Administrative Regions flown at half mast\",\n",
       " u'It was the first time that a national mourning period had been declared for something other than the death of a state leader , and many have called it the biggest display of mourning since the death of Mao Zedong',\n",
       " u'At 14:28 CST on May 19 , 2008 , a week after the earthquake , the Chinese public held a moment of silence',\n",
       " u'People stood silent for three minutes while air defense , police and fire sirens , and the horns of vehicles , vessels and trains sounded',\n",
       " u\"Cars and trucks on Beijing 's roads also came to a halt\",\n",
       " u\"People spontaneously burst into cheering `` Zhongguo jiayou ! '' ( Let 's go , China ! ) and `` Sichuan jiayou '' ( Let 's go , Sichuan ! ) afterwards .\"]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(nltk.word_tokenize(train['data'][10]['paragraphs'][60]['context'])).split(' . ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save glove vectors as npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_vec = []\n",
    "\n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        glove_vec.append(np.matrix(str(' '.join(line.split()[1:]))))\n",
    "        \n",
    "glove_vec = np.vstack(glove_vec).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/pio/data/data/glove_vec/6B/glove.6B.300d', glove_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a glove wordlist\n",
    "\n",
    "glove_words = []\n",
    "\n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        glove_words.append(line.split()[0])\n",
    "        \n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.wordlist.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in glove_words:\n",
    "        f.write(unicode(w + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(515, [u'saint', u'bernadette', u'soubirous'])],\n",
       " [u'to',\n",
       "  u'whom',\n",
       "  u'did',\n",
       "  u'the',\n",
       "  u'virgin',\n",
       "  u'mary',\n",
       "  u'allegedly',\n",
       "  u'appear',\n",
       "  u'in',\n",
       "  u'1858',\n",
       "  u'in',\n",
       "  u'lourdes',\n",
       "  u'france',\n",
       "  u'?'],\n",
       " [[u'architecturally',\n",
       "   u',',\n",
       "   u'the',\n",
       "   u'school',\n",
       "   u'has',\n",
       "   u'a',\n",
       "   u'catholic',\n",
       "   u'character',\n",
       "   u'.'],\n",
       "  [u'atop',\n",
       "   u'the',\n",
       "   u'main',\n",
       "   u'building',\n",
       "   u\"'s\",\n",
       "   u'gold',\n",
       "   u'dome',\n",
       "   u'is',\n",
       "   u'a',\n",
       "   u'golden',\n",
       "   u'statue',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'virgin',\n",
       "   u'mary',\n",
       "   u'.'],\n",
       "  [u'immediately',\n",
       "   u'in',\n",
       "   u'front',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'main',\n",
       "   u'building',\n",
       "   u'and',\n",
       "   u'facing',\n",
       "   u'it',\n",
       "   u',',\n",
       "   u'is',\n",
       "   u'a',\n",
       "   u'copper',\n",
       "   u'statue',\n",
       "   u'of',\n",
       "   u'christ',\n",
       "   u'with',\n",
       "   u'arms',\n",
       "   u'upraised',\n",
       "   u'with',\n",
       "   u'the',\n",
       "   u'legend',\n",
       "   u'``',\n",
       "   u'venite',\n",
       "   u'ad',\n",
       "   u'me',\n",
       "   u'omnes',\n",
       "   u\"''\",\n",
       "   u'.'],\n",
       "  [u'next',\n",
       "   u'to',\n",
       "   u'the',\n",
       "   u'main',\n",
       "   u'building',\n",
       "   u'is',\n",
       "   u'the',\n",
       "   u'basilica',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'sacred',\n",
       "   u'heart',\n",
       "   u'.'],\n",
       "  [u'immediately',\n",
       "   u'behind',\n",
       "   u'the',\n",
       "   u'basilica',\n",
       "   u'is',\n",
       "   u'the',\n",
       "   u'grotto',\n",
       "   u',',\n",
       "   u'a',\n",
       "   u'marian',\n",
       "   u'place',\n",
       "   u'of',\n",
       "   u'prayer',\n",
       "   u'and',\n",
       "   u'reflection',\n",
       "   u'.'],\n",
       "  [u'it',\n",
       "   u'is',\n",
       "   u'a',\n",
       "   u'replica',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'grotto',\n",
       "   u'at',\n",
       "   u'lourdes',\n",
       "   u',',\n",
       "   u'france',\n",
       "   u'where',\n",
       "   u'the',\n",
       "   u'virgin',\n",
       "   u'mary',\n",
       "   u'reputedly',\n",
       "   u'appeared',\n",
       "   u'to',\n",
       "   u'saint',\n",
       "   u'bernadette',\n",
       "   u'soubirous',\n",
       "   u'in',\n",
       "   u'1858',\n",
       "   u'.'],\n",
       "  [u'at',\n",
       "   u'the',\n",
       "   u'end',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'main',\n",
       "   u'drive',\n",
       "   u'(',\n",
       "   u'and',\n",
       "   u'in',\n",
       "   u'a',\n",
       "   u'direct',\n",
       "   u'line',\n",
       "   u'that',\n",
       "   u'connects',\n",
       "   u'through',\n",
       "   u'3',\n",
       "   u'statues',\n",
       "   u'and',\n",
       "   u'the',\n",
       "   u'gold',\n",
       "   u'dome',\n",
       "   u')',\n",
       "   u',',\n",
       "   u'is',\n",
       "   u'a',\n",
       "   u'simple',\n",
       "   u',',\n",
       "   u'modern',\n",
       "   u'stone',\n",
       "   u'statue',\n",
       "   u'of',\n",
       "   u'mary',\n",
       "   u'.']]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_words = {w for l in data for w in l[0][0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42848"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6659"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_words - set(glove_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代田法\n",
      "vergiliana\n",
      "tampa/st\n",
      "samarran\n",
      "cove-st.\n",
      ":35–36\n",
      "ddirectly\n",
      "aerodome\n",
      "neminem\n",
      "27,573\n",
      "knon\n",
      "sytle\n",
      "1889–1894\n",
      "brance\n",
      "morphologist\n",
      "v-pet\n",
      "re-targeted\n",
      "kirants\n",
      "1,269,765\n",
      "stain-resistant\n",
      "5151\n",
      "king—implied\n",
      "11+\n",
      "יִשְׂרָאֵל‎\n",
      "post-divorce\n",
      "əˈlɛktrik\n",
      "hamović\n",
      "geexbox\n",
      "leaa\n",
      "bing-based\n",
      "71–91\n",
      "csad\n",
      "statenvertaling\n",
      "“all\n",
      "británico\n",
      "refromed\n",
      "all-in-all\n",
      "church’s\n",
      "隶书\n",
      "poety\n",
      "al-irsyad\n",
      "finger-muscle\n",
      "1976–77\n",
      "nàng\n",
      "wouldn’t\n",
      "mandarines\n",
      "league—had\n",
      "i/ˈbɒstən/\n",
      "μουσηγέτης\n",
      "faqīh\n",
      "western-funded\n",
      "quitensis\n",
      "conímbriga\n",
      "supermalls\n",
      "writers.”\n",
      "government—as\n",
      "riwaaydo\n",
      "265,517\n",
      "achenial\n",
      "iparque\n",
      "temnospondyli\n",
      "circulaires\n",
      "2,361.6\n",
      "'haut\n",
      "magnesium-doped\n",
      "/ælps/\n",
      "90,731\n",
      "rice/millet\n",
      "loan-translation\n",
      "baladhuri\n",
      "pedanius\n",
      "dönitz—would—on\n",
      "phytogeographically\n",
      "pre-arthropod\n",
      "eritrean–ethiopian\n",
      "neo-grec\n",
      "'la\n",
      "9,902\n",
      "β-chitin\n",
      "sin-itiro\n",
      "4,671\n",
      "livability.com\n",
      "copers\n",
      "vendée—a\n",
      "2240:1982\n",
      "πάνορμος\n",
      "⟨ʰp⟩\n",
      "minacs\n",
      "'time\n",
      "obscurations\n",
      "1664-1729\n",
      "tsimshianic\n",
      "jingning\n",
      "p'ohang-dong\n",
      "tax-reform\n",
      "'intellectual\n",
      "post-idol\n",
      "watson-wentworth\n",
      "hamovic\n",
      "2014—on\n"
     ]
    }
   ],
   "source": [
    "for w in list(words - set(glove_words))[-100:]:\n",
    "    print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102802"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab all the question-answer pairs and create a wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = set()\n",
    "data = []\n",
    "lower = lambda x: x.lower()\n",
    "\n",
    "for par in train['data']:\n",
    "    title = par['title']\n",
    "    \n",
    "    for con in par['paragraphs']:\n",
    "        context = con['context']\n",
    "        context_tok = map(lower, nltk.word_tokenize(context))\n",
    "        words |= set(context_tok)\n",
    "        \n",
    "        for q in con['qas']:\n",
    "            question = q['question']\n",
    "            question_tok = map(lower, nltk.word_tokenize(question))\n",
    "            words |= set(question_tok)\n",
    "            \n",
    "            Id = q['id']\n",
    "            \n",
    "            answers = []\n",
    "            \n",
    "            for ans in q['answers']:\n",
    "                text = ans['text']\n",
    "                text_tok = map(lower, nltk.word_tokenize(text))\n",
    "                ans_start = ans['answer_start']\n",
    "                \n",
    "                answers.append((ans_start, text_tok))\n",
    "                \n",
    "            data.append([answers, question_tok, context_tok])\n",
    "            \n",
    "words.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599 102802\n"
     ]
    }
   ],
   "source": [
    "print len(data), len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    if len(d[0]) > 1:\n",
    "        print d\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn words into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_to_w = dict(enumerate(words))\n",
    "w_to_i = {v:k for (k,v) in i_to_w.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_on_dot(s):\n",
    "    res = [[]]\n",
    "    for w in s:\n",
    "        res[-1].append(w)\n",
    "        if w == u'.':\n",
    "            res.append([])\n",
    "    return res if res[-1] else res[:-1]\n",
    "\n",
    "def words_to_num(s):\n",
    "    return map(lambda x: w_to_i.get(x, w_to_i['<unk>']), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data)):\n",
    "    data[i][2] = split_on_dot(data[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num = []\n",
    "\n",
    "for a, q, c in data:\n",
    "    answers = []\n",
    "    for ans in a:\n",
    "        answers.append((ans[0], words_to_num(ans[1])))        \n",
    "    data_num.append([answers, words_to_num(q), map(words_to_num, c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some answers don't work, because of the tokenizer\n",
    "\n",
    "bugged_answers = 0\n",
    "\n",
    "for ans,_,_ in data_num:\n",
    "    for _,a in ans:\n",
    "        if w_to_i['<unk>'] in a:\n",
    "            bugged_answers += 1\n",
    "bugged_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num = [[l[0], [l[1]] + l[2]] for l in data_num]\n",
    "data_num = [[[t[1] for t in l[0]], l[1]] for l in data_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are more broken answers, because I tag words instead of characters\n",
    "\n",
    "k = 0\n",
    "for a, q in data_num:\n",
    "    for w in a[0]:\n",
    "        if w not in list(chain(*q[1:])):\n",
    "            k += 1\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find answer indices on words, not characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = []\n",
    "\n",
    "for a, q in data_num:\n",
    "    ans = []\n",
    "    tot_q = list(chain(*q[1:]))\n",
    "    for x in a:\n",
    "        for i in xrange(len(tot_q)):\n",
    "            if x == tot_q[i:i+len(x)]:\n",
    "                ans.append(list(xrange(i, i + len(x))))\n",
    "                break\n",
    "    inds.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data_num)):\n",
    "    data_num[i][0] = inds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3), (1, 4), (2, 5)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(xrange(3,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get Glove vectors for words in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_vec = np.load('/pio/data/data/glove_vec/6B/glove.6B.300d.npy')\n",
    "\n",
    "glove_words = []\n",
    "\n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.wordlist.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        glove_words.append(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_i_to_w = dict(enumerate(glove_words))\n",
    "glove_w_to_i = {v:k for (k,v) in glove_i_to_w.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102802, 300)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = np.zeros((len(words), 300), dtype=np.float32)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73351"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_inds = [i for i in xrange(len(words)) if i_to_w[i] in glove_w_to_i]\n",
    "len(known_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = set(known_inds)\n",
    "unknown_inds = [i for i in xrange(len(words)) if i not in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embs[known_inds] = glove_vec[[glove_w_to_i[i_to_w[i]] for i in known_inds]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embs[unknown_inds] = L.init.Normal()((len(unknown_inds), 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_words = map(lambda x: x[0], sorted(w_to_i.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/wordlist.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in sorted_words:\n",
    "        f.write(unicode(w + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file has a lot of redundant parts, context is repeated for each question.\n",
    "# It only slows down the initial loading.\n",
    "\n",
    "with open('/pio/data/data/squad/train.pkl', 'w') as f:\n",
    "    pickle.dump(data_num, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/pio/data/data/squad/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_to_i = {}\n",
    "idx = 0\n",
    "\n",
    "with io.open('/pio/data/data/squad/wordlist.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        w_to_i[line[:-1]] = idx\n",
    "        idx += 1\n",
    "        \n",
    "i_to_w = {v:k for (k,v) in w_to_i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'it'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_to_w[19557]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = np.array(map(lambda x: len(x[1]), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_data(idx):\n",
    "    for s in data[idx][1]:\n",
    "        print ' '.join([i_to_w[x] for x in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the largest hottest continuously large area worldwide ?\n",
      "the sky is usually clear above the desert and the sunshine duration is extremely high everywhere in the sahara .\n",
      "most of the desert enjoys more than 3,600 h of bright sunshine annually or over 82 % of the time and a wide area in the eastern part experiences in excess of 4,000 h of bright sunshine a year or over 91 % of the time , and the highest values are very close to the theoretical maximum value .\n",
      "a value of 4,300 h or 98 % of the time would be recorded in upper egypt ( aswan , luxor ) and in the nubian desert ( wadi halfa ) .\n",
      "the annual average direct solar irradiation is around 2,800 kwh/ ( m2 year ) in the great desert .\n",
      "the sahara has a huge potential for solar energy production .\n",
      "the constantly high position of the sun , the extremely low relative humidity , the lack of vegetation and rainfall make the great desert the hottest continuously large area worldwide and certainly the hottest place on earth during summertime in some spots .\n",
      "the average high temperature exceeds 38 °c ( 100.4 °f ) - 40 °c ( 104 °f ) during the hottest month nearly everywhere in the desert except at very high mountainous areas .\n",
      "the highest officially recorded average high temperature was 47 °c ( 116.6 °f ) in a remote desert town in the algerian desert called bou bernous with an elevation of 378 meters above sea level .\n",
      "it 's the world 's highest recorded average high temperature and only death valley , california rivals it .\n",
      "other hot spots in algeria such as adrar , timimoun , in salah , ouallene , aoulef , reggane with an elevation between 200 and 400 meters above sea level get slightly lower summer average highs around 46 °c ( 114.8 °f ) during the hottest months of the year .\n",
      "salah , well known in algeria for its extreme heat , has an average high temperature of 43.8 °c ( 110.8 °f ) , 46.4 °c ( 115.5 °f ) , 45.5 ( 113.9 °f ) .\n",
      "furthermore , 41.9 °c ( 107.4 °f ) in june , july , august and september .\n",
      "in fact , there are even hotter spots in the sahara , but they are located in extremely remote areas , especially in the azalai , lying in northern mali .\n",
      "the major part of the desert experiences around 3 – 5 months when the average high strictly exceeds 40 °c ( 104 °f ) .\n",
      "the southern central part of the desert experiences up to 6 – 7 months when the average high temperature strictly exceeds 40 °c ( 104 °f ) which shows the constancy and the length of the really hot season in the sahara .\n",
      "some examples of this are bilma , niger and faya-largeau , chad .\n",
      "the annual average daily temperature exceeds 20 °c ( 68 °f ) everywhere and can approach 30 °c ( 86 °f ) in the hottest regions year-round .\n",
      "however , most of the desert has a value in excess of 25 °c ( 77 °f ) .\n",
      "the sand and ground temperatures are even more extreme .\n",
      "during daytime , the sand temperature is extremely high as it can easily reach 80 °c ( 176 °f ) or more .\n",
      "a sand temperature of 83.5 °c ( 182.3 °f ) has been recorded in port sudan .\n",
      "ground temperatures of 72 °c ( 161.6 °f ) have been recorded in the adrar of mauritania and a value of 75 °c ( 167 °f ) has been measured in borkou , northern chad .\n",
      "due to lack of cloud cover and very low humidity , the desert usually features high diurnal temperature variations between days and nights .\n",
      "however , it 's a myth that the nights are cold after extremely hot days in the sahara .\n",
      "the average diurnal temperature range is typically between 13 °c ( 55.4 °f ) and 20 °c ( 68 °f ) .\n",
      "the lowest values are found along the coastal regions due to high humidity and are often even lower than 10 °c ( 50 °f ) , while the highest values are found in inland desert areas where the humidity is the lowest , mainly in the southern sahara .\n",
      "still , it 's true that winter nights can be cold as it can drop to the freezing point and even below , especially in high-elevation areas .\n"
     ]
    }
   ],
   "source": [
    "show_data(60023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0,     0,  1665,  6015, 12958, 18663, 16891, 12176,  7727,\n",
       "        4709,  2711,  1677,   859,   636,   352,   223,   166,    60,\n",
       "          39,    24,     9,     0,     5,    19,     5,     0,     0,\n",
       "           0,    10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print max(lens)\n",
    "np.bincount(lens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
