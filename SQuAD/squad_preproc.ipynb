{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, nltk, io, pickle\n",
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/train-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/dev-v1.1.json', 'r', encoding='utf-8') as f:\n",
    "    dev = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'answer_start': 177, u'text': u'Denver Broncos'},\n",
       " {u'answer_start': 177, u'text': u'Denver Broncos'},\n",
       " {u'answer_start': 177, u'text': u'Denver Broncos'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['data'][0]['paragraphs'][0]['qas'][0]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev['data'][0]['paragraphs'][0]['qas'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'question', u'id', u'answers']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['data'][0]['paragraphs'][0]['qas'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"The State Council declared a three-day period of national mourning for the quake victims starting from May 19 , 2008 ; the PRC 's National Flag and Regional Flags of Hong Kong and Macau Special Administrative Regions flown at half mast\",\n",
       " u'It was the first time that a national mourning period had been declared for something other than the death of a state leader , and many have called it the biggest display of mourning since the death of Mao Zedong',\n",
       " u'At 14:28 CST on May 19 , 2008 , a week after the earthquake , the Chinese public held a moment of silence',\n",
       " u'People stood silent for three minutes while air defense , police and fire sirens , and the horns of vehicles , vessels and trains sounded',\n",
       " u\"Cars and trucks on Beijing 's roads also came to a halt\",\n",
       " u\"People spontaneously burst into cheering `` Zhongguo jiayou ! '' ( Let 's go , China ! ) and `` Sichuan jiayou '' ( Let 's go , Sichuan ! ) afterwards .\"]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(nltk.word_tokenize(train['data'][10]['paragraphs'][60]['context'])).split(' . ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save glove vectors as npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_vec = []\n",
    "\n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        glove_vec.append(np.matrix(str(' '.join(line.split()[1:]))))\n",
    "        \n",
    "glove_vec = np.vstack(glove_vec).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/pio/data/data/glove_vec/6B/glove.6B.300d', glove_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a glove wordlist\n",
    "\n",
    "glove_words = []\n",
    "\n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        glove_words.append(line.split()[0])\n",
    "        \n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.wordlist.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in glove_words:\n",
    "        f.write(unicode(w + '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab all the question-answer pairs and create a wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = set()\n",
    "data = []\n",
    "lower = lambda x: x.lower()\n",
    "\n",
    "for par in train['data']:\n",
    "    title = par['title']\n",
    "    \n",
    "    for con in par['paragraphs']:\n",
    "        context = con['context']\n",
    "        context_tok = map(lower, nltk.word_tokenize(context))\n",
    "        words |= set(context_tok)\n",
    "        \n",
    "        for q in con['qas']:\n",
    "            question = q['question']\n",
    "            question_tok = map(lower, nltk.word_tokenize(question))\n",
    "            words |= set(question_tok)\n",
    "            \n",
    "            Id = q['id']\n",
    "            \n",
    "            answers = []\n",
    "            \n",
    "            for ans in q['answers']:\n",
    "                text = ans['text']\n",
    "                text_tok = map(lower, nltk.word_tokenize(text))\n",
    "                ans_start = ans['answer_start']\n",
    "                \n",
    "                answers.append((ans_start, text_tok))\n",
    "                \n",
    "            data.append([answers, question_tok, context_tok])\n",
    "            \n",
    "words.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(92, [u'1854'])],\n",
       " [u'in',\n",
       "  u'what',\n",
       "  u'year',\n",
       "  u'was',\n",
       "  u'a',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'arts',\n",
       "  u'course',\n",
       "  u'first',\n",
       "  u'offered',\n",
       "  u'at',\n",
       "  u'notre',\n",
       "  u'dame',\n",
       "  u'?'],\n",
       " [u'the',\n",
       "  u'university',\n",
       "  u'first',\n",
       "  u'offered',\n",
       "  u'graduate',\n",
       "  u'degrees',\n",
       "  u',',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'form',\n",
       "  u'of',\n",
       "  u'a',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'arts',\n",
       "  u'(',\n",
       "  u'ma',\n",
       "  u')',\n",
       "  u',',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'1854\\u20131855',\n",
       "  u'academic',\n",
       "  u'year',\n",
       "  u'.',\n",
       "  u'the',\n",
       "  u'program',\n",
       "  u'expanded',\n",
       "  u'to',\n",
       "  u'include',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'laws',\n",
       "  u'(',\n",
       "  u'll.m',\n",
       "  u'.',\n",
       "  u')',\n",
       "  u'and',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'civil',\n",
       "  u'engineering',\n",
       "  u'in',\n",
       "  u'its',\n",
       "  u'early',\n",
       "  u'stages',\n",
       "  u'of',\n",
       "  u'growth',\n",
       "  u',',\n",
       "  u'before',\n",
       "  u'a',\n",
       "  u'formal',\n",
       "  u'graduate',\n",
       "  u'school',\n",
       "  u'education',\n",
       "  u'was',\n",
       "  u'developed',\n",
       "  u'with',\n",
       "  u'a',\n",
       "  u'thesis',\n",
       "  u'not',\n",
       "  u'required',\n",
       "  u'to',\n",
       "  u'receive',\n",
       "  u'the',\n",
       "  u'degrees',\n",
       "  u'.',\n",
       "  u'this',\n",
       "  u'changed',\n",
       "  u'in',\n",
       "  u'1924',\n",
       "  u'with',\n",
       "  u'formal',\n",
       "  u'requirements',\n",
       "  u'developed',\n",
       "  u'for',\n",
       "  u'graduate',\n",
       "  u'degrees',\n",
       "  u',',\n",
       "  u'including',\n",
       "  u'offering',\n",
       "  u'doctorate',\n",
       "  u'(',\n",
       "  u'phd',\n",
       "  u')',\n",
       "  u'degrees',\n",
       "  u'.',\n",
       "  u'today',\n",
       "  u'each',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'five',\n",
       "  u'colleges',\n",
       "  u'offer',\n",
       "  u'graduate',\n",
       "  u'education',\n",
       "  u'.',\n",
       "  u'most',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'departments',\n",
       "  u'from',\n",
       "  u'the',\n",
       "  u'college',\n",
       "  u'of',\n",
       "  u'arts',\n",
       "  u'and',\n",
       "  u'letters',\n",
       "  u'offer',\n",
       "  u'phd',\n",
       "  u'programs',\n",
       "  u',',\n",
       "  u'while',\n",
       "  u'a',\n",
       "  u'professional',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'divinity',\n",
       "  u'(',\n",
       "  u'm.div',\n",
       "  u'.',\n",
       "  u')',\n",
       "  u'program',\n",
       "  u'also',\n",
       "  u'exists',\n",
       "  u'.',\n",
       "  u'all',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'departments',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'college',\n",
       "  u'of',\n",
       "  u'science',\n",
       "  u'offer',\n",
       "  u'phd',\n",
       "  u'programs',\n",
       "  u',',\n",
       "  u'except',\n",
       "  u'for',\n",
       "  u'the',\n",
       "  u'department',\n",
       "  u'of',\n",
       "  u'pre-professional',\n",
       "  u'studies',\n",
       "  u'.',\n",
       "  u'the',\n",
       "  u'school',\n",
       "  u'of',\n",
       "  u'architecture',\n",
       "  u'offers',\n",
       "  u'a',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'architecture',\n",
       "  u',',\n",
       "  u'while',\n",
       "  u'each',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'departments',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'college',\n",
       "  u'of',\n",
       "  u'engineering',\n",
       "  u'offer',\n",
       "  u'phd',\n",
       "  u'programs',\n",
       "  u'.',\n",
       "  u'the',\n",
       "  u'college',\n",
       "  u'of',\n",
       "  u'business',\n",
       "  u'offers',\n",
       "  u'multiple',\n",
       "  u'professional',\n",
       "  u'programs',\n",
       "  u'including',\n",
       "  u'mba',\n",
       "  u'and',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'science',\n",
       "  u'in',\n",
       "  u'accountancy',\n",
       "  u'programs',\n",
       "  u'.',\n",
       "  u'it',\n",
       "  u'also',\n",
       "  u'operates',\n",
       "  u'facilities',\n",
       "  u'in',\n",
       "  u'chicago',\n",
       "  u'and',\n",
       "  u'cincinnati',\n",
       "  u'for',\n",
       "  u'its',\n",
       "  u'executive',\n",
       "  u'mba',\n",
       "  u'program',\n",
       "  u'.',\n",
       "  u'additionally',\n",
       "  u',',\n",
       "  u'the',\n",
       "  u'alliance',\n",
       "  u'for',\n",
       "  u'catholic',\n",
       "  u'education',\n",
       "  u'program',\n",
       "  u'offers',\n",
       "  u'a',\n",
       "  u'master',\n",
       "  u'of',\n",
       "  u'education',\n",
       "  u'program',\n",
       "  u'where',\n",
       "  u'students',\n",
       "  u'study',\n",
       "  u'at',\n",
       "  u'the',\n",
       "  u'university',\n",
       "  u'during',\n",
       "  u'the',\n",
       "  u'summer',\n",
       "  u'and',\n",
       "  u'teach',\n",
       "  u'in',\n",
       "  u'catholic',\n",
       "  u'elementary',\n",
       "  u'schools',\n",
       "  u',',\n",
       "  u'middle',\n",
       "  u'schools',\n",
       "  u',',\n",
       "  u'and',\n",
       "  u'high',\n",
       "  u'schools',\n",
       "  u'across',\n",
       "  u'the',\n",
       "  u'southern',\n",
       "  u'united',\n",
       "  u'states',\n",
       "  u'for',\n",
       "  u'two',\n",
       "  u'school',\n",
       "  u'years',\n",
       "  u'.']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87599 102802\n"
     ]
    }
   ],
   "source": [
    "print len(data), len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn words into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_to_w = dict(enumerate(words))\n",
    "w_to_i = {v:k for (k,v) in i_to_w.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_on_dot(s):\n",
    "    res = [[]]\n",
    "    for w in s:\n",
    "        res[-1].append(w)\n",
    "        if w == u'.':\n",
    "            res.append([])\n",
    "    return res if res[-1] else res[:-1]\n",
    "\n",
    "def words_to_num(s):\n",
    "    return map(lambda x: w_to_i.get(x, w_to_i['<unk>']), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data)):\n",
    "    data[i][2] = split_on_dot(data[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num = []\n",
    "\n",
    "for a, q, c in data:\n",
    "    answers = []\n",
    "    for ans in a:\n",
    "        answers.append((ans[0], words_to_num(ans[1])))        \n",
    "    data_num.append([answers, words_to_num(q), map(words_to_num, c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_num = [[l[0], [l[1]] + l[2]] for l in data_num]\n",
    "data_num = [[[t[1] for t in l[0]], l[1]] for l in data_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some broken answers, because of the tokenizer (I count words instead of characters)\n",
    "\n",
    "k = 0\n",
    "for a, q in data_num:\n",
    "    for w in a[0]:\n",
    "        if w not in list(chain(*q[1:])):\n",
    "            k += 1\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find answer indices on words, not characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = []\n",
    "\n",
    "for a, q in data_num:\n",
    "    ans = []\n",
    "    tot_q = list(chain(*q[1:]))\n",
    "    for x in a:\n",
    "        for i in xrange(len(tot_q)):\n",
    "            if x == tot_q[i:i+len(x)]:\n",
    "                ans.append(list(xrange(i, i + len(x))))\n",
    "                break\n",
    "    inds.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data_num)):\n",
    "    data_num[i][0] = inds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'super',\n",
       " u'bowl',\n",
       " u'50',\n",
       " u'was',\n",
       " u'an',\n",
       " u'american',\n",
       " u'football',\n",
       " u'game',\n",
       " u'to',\n",
       " u'determine',\n",
       " u'the',\n",
       " u'champion',\n",
       " u'of',\n",
       " u'the',\n",
       " u'national',\n",
       " u'football',\n",
       " u'league',\n",
       " u'(',\n",
       " u'nfl',\n",
       " u')',\n",
       " u'for',\n",
       " u'the',\n",
       " u'2015',\n",
       " u'season',\n",
       " u'.',\n",
       " u'the',\n",
       " u'american',\n",
       " u'football',\n",
       " u'conference',\n",
       " u'(',\n",
       " u'afc',\n",
       " u')',\n",
       " u'champion',\n",
       " u'denver',\n",
       " u'broncos',\n",
       " u'defeated',\n",
       " u'the',\n",
       " u'national',\n",
       " u'football',\n",
       " u'conference',\n",
       " u'(',\n",
       " u'nfc',\n",
       " u')',\n",
       " u'champion',\n",
       " u'carolina',\n",
       " u'panthers',\n",
       " u'24\\u201310',\n",
       " u'to',\n",
       " u'earn',\n",
       " u'their',\n",
       " u'third',\n",
       " u'super',\n",
       " u'bowl',\n",
       " u'title',\n",
       " u'.',\n",
       " u'the',\n",
       " u'game',\n",
       " u'was',\n",
       " u'played',\n",
       " u'on',\n",
       " u'february',\n",
       " u'7',\n",
       " u',',\n",
       " u'2016',\n",
       " u',',\n",
       " u'at',\n",
       " u'levi',\n",
       " u\"'s\",\n",
       " u'stadium',\n",
       " u'in',\n",
       " u'the',\n",
       " u'san',\n",
       " u'francisco',\n",
       " u'bay',\n",
       " u'area',\n",
       " u'at',\n",
       " u'santa',\n",
       " u'clara',\n",
       " u',',\n",
       " u'california',\n",
       " u'.',\n",
       " u'as',\n",
       " u'this',\n",
       " u'was',\n",
       " u'the',\n",
       " u'50th',\n",
       " u'super',\n",
       " u'bowl',\n",
       " u',',\n",
       " u'the',\n",
       " u'league',\n",
       " u'emphasized',\n",
       " u'the',\n",
       " u'``',\n",
       " u'golden',\n",
       " u'anniversary',\n",
       " u\"''\",\n",
       " u'with',\n",
       " u'various',\n",
       " u'gold-themed',\n",
       " u'initiatives',\n",
       " u',',\n",
       " u'as',\n",
       " u'well',\n",
       " u'as',\n",
       " u'temporarily',\n",
       " u'suspending',\n",
       " u'the',\n",
       " u'tradition',\n",
       " u'of',\n",
       " u'naming',\n",
       " u'each',\n",
       " u'super',\n",
       " u'bowl',\n",
       " u'game',\n",
       " u'with',\n",
       " u'roman',\n",
       " u'numerals',\n",
       " u'(',\n",
       " u'under',\n",
       " u'which',\n",
       " u'the',\n",
       " u'game',\n",
       " u'would',\n",
       " u'have',\n",
       " u'been',\n",
       " u'known',\n",
       " u'as',\n",
       " u'``',\n",
       " u'super',\n",
       " u'bowl',\n",
       " u'l',\n",
       " u\"''\",\n",
       " u')',\n",
       " u',',\n",
       " u'so',\n",
       " u'that',\n",
       " u'the',\n",
       " u'logo',\n",
       " u'could',\n",
       " u'prominently',\n",
       " u'feature',\n",
       " u'the',\n",
       " u'arabic',\n",
       " u'numerals',\n",
       " u'50',\n",
       " u'.']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'super',\n",
       "  u'bowl',\n",
       "  u'50',\n",
       "  u'was',\n",
       "  u'an',\n",
       "  u'american',\n",
       "  u'football',\n",
       "  u'game',\n",
       "  u'to',\n",
       "  u'determine',\n",
       "  u'the',\n",
       "  u'champion',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'national',\n",
       "  u'football',\n",
       "  u'league',\n",
       "  u'(',\n",
       "  u'nfl',\n",
       "  u')',\n",
       "  u'for',\n",
       "  u'the',\n",
       "  u'2015',\n",
       "  u'season',\n",
       "  u'.'],\n",
       " [u'the',\n",
       "  u'american',\n",
       "  u'football',\n",
       "  u'conference',\n",
       "  u'(',\n",
       "  u'afc',\n",
       "  u')',\n",
       "  u'champion',\n",
       "  u'denver',\n",
       "  u'broncos',\n",
       "  u'defeated',\n",
       "  u'the',\n",
       "  u'national',\n",
       "  u'football',\n",
       "  u'conference',\n",
       "  u'(',\n",
       "  u'nfc',\n",
       "  u')',\n",
       "  u'champion',\n",
       "  u'carolina',\n",
       "  u'panthers',\n",
       "  '<unk>',\n",
       "  u'to',\n",
       "  u'earn',\n",
       "  u'their',\n",
       "  u'third',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'title',\n",
       "  u'.'],\n",
       " [u'the',\n",
       "  u'game',\n",
       "  u'was',\n",
       "  u'played',\n",
       "  u'on',\n",
       "  u'february',\n",
       "  u'7',\n",
       "  u',',\n",
       "  u'2016',\n",
       "  u',',\n",
       "  u'at',\n",
       "  u'levi',\n",
       "  u\"'s\",\n",
       "  u'stadium',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'san',\n",
       "  u'francisco',\n",
       "  u'bay',\n",
       "  u'area',\n",
       "  u'at',\n",
       "  u'santa',\n",
       "  u'clara',\n",
       "  u',',\n",
       "  u'california',\n",
       "  u'.'],\n",
       " [u'as',\n",
       "  u'this',\n",
       "  u'was',\n",
       "  u'the',\n",
       "  u'50th',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u',',\n",
       "  u'the',\n",
       "  u'league',\n",
       "  u'emphasized',\n",
       "  u'the',\n",
       "  u'``',\n",
       "  u'golden',\n",
       "  u'anniversary',\n",
       "  u\"''\",\n",
       "  u'with',\n",
       "  u'various',\n",
       "  '<unk>',\n",
       "  u'initiatives',\n",
       "  u',',\n",
       "  u'as',\n",
       "  u'well',\n",
       "  u'as',\n",
       "  u'temporarily',\n",
       "  u'suspending',\n",
       "  u'the',\n",
       "  u'tradition',\n",
       "  u'of',\n",
       "  u'naming',\n",
       "  u'each',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'game',\n",
       "  u'with',\n",
       "  u'roman',\n",
       "  u'numerals',\n",
       "  u'(',\n",
       "  u'under',\n",
       "  u'which',\n",
       "  u'the',\n",
       "  u'game',\n",
       "  u'would',\n",
       "  u'have',\n",
       "  u'been',\n",
       "  u'known',\n",
       "  u'as',\n",
       "  u'``',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'l',\n",
       "  u\"''\",\n",
       "  u')',\n",
       "  u',',\n",
       "  u'so',\n",
       "  u'that',\n",
       "  u'the',\n",
       "  u'logo',\n",
       "  u'could',\n",
       "  u'prominently',\n",
       "  u'feature',\n",
       "  u'the',\n",
       "  u'arabic',\n",
       "  u'numerals',\n",
       "  u'50',\n",
       "  u'.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.load('dev_with_training_vocab_predictions_charemb.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('dev_with_training_vocab_predictions_charemb.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(u'{')\n",
    "    for i in xrange(len(data_dev)):\n",
    "        ans = ' '.join(data_dev[i][2][preds[i][0]:preds[i][1] + 1])\n",
    "        Id = data_dev[i][3]\n",
    "        f.write(u'\"{}\": \"{}\"'.format(Id, ans))\n",
    "        if i < len(data_dev) - 1:\n",
    "            f.write(u', ')\n",
    "    f.write(u'}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocess dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_dev = set()\n",
    "data_dev = []\n",
    "lower = lambda x: x.lower()\n",
    "\n",
    "for par in dev['data']:\n",
    "    title = par['title']\n",
    "    \n",
    "    for con in par['paragraphs']:\n",
    "        context = con['context']\n",
    "        context_tok = map(lower, nltk.word_tokenize(context))\n",
    "        words_dev |= set(context_tok)\n",
    "        \n",
    "        for q in con['qas']:\n",
    "            question = q['question']\n",
    "            question_tok = map(lower, nltk.word_tokenize(question))\n",
    "            words_dev |= set(question_tok)\n",
    "            \n",
    "            Id = q['id']\n",
    "            \n",
    "            answers = []\n",
    "            \n",
    "            for ans in q['answers']:\n",
    "                text = ans['text']\n",
    "                text_tok = map(lower, nltk.word_tokenize(text))\n",
    "                ans_start = ans['answer_start']\n",
    "                \n",
    "                answers.append((ans_start, text_tok))\n",
    "                \n",
    "            data_dev.append([answers, question_tok, context_tok, Id])\n",
    "            \n",
    "words_dev.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(102, [u'sun', u'life', u'stadium']),\n",
       "  (102, [u'sun', u'life', u'stadium']),\n",
       "  (102, [u'sun', u'life', u'stadium'])],\n",
       " [u'what',\n",
       "  u'venue',\n",
       "  u'in',\n",
       "  u'miami',\n",
       "  u'was',\n",
       "  u'a',\n",
       "  u'candidate',\n",
       "  u'for',\n",
       "  u'the',\n",
       "  u'site',\n",
       "  u'of',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'50',\n",
       "  u'?'],\n",
       " [u'the',\n",
       "  u'league',\n",
       "  u'eventually',\n",
       "  u'narrowed',\n",
       "  u'the',\n",
       "  u'bids',\n",
       "  u'to',\n",
       "  u'three',\n",
       "  u'sites',\n",
       "  u':',\n",
       "  u'new',\n",
       "  u'orleans',\n",
       "  u\"'\",\n",
       "  u'mercedes-benz',\n",
       "  u'superdome',\n",
       "  u',',\n",
       "  u'miami',\n",
       "  u\"'s\",\n",
       "  u'sun',\n",
       "  u'life',\n",
       "  u'stadium',\n",
       "  u',',\n",
       "  u'and',\n",
       "  u'the',\n",
       "  u'san',\n",
       "  u'francisco',\n",
       "  u'bay',\n",
       "  u'area',\n",
       "  u\"'s\",\n",
       "  u'levi',\n",
       "  u\"'s\",\n",
       "  u'stadium',\n",
       "  u'.'],\n",
       " u'56beb03c3aeaaa14008c920b']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570 26453\n"
     ]
    }
   ],
   "source": [
    "print len(data_dev), len(words_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6854"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_dev - words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data_dev)):\n",
    "    data_dev[i][2] = [w if w in words else '<unk>' for w in data_dev[i][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(data_dev)):\n",
    "    data_dev[i][2] = split_on_dot(data_dev[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_num_dev = []\n",
    "\n",
    "for a, q, c in data_dev:\n",
    "    answers = []\n",
    "    for ans in a:\n",
    "        answers.append((ans[0], words_to_num(ans[1])))        \n",
    "    data_num_dev.append([answers, words_to_num(q), map(words_to_num, c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_num_dev = [[l[0], [l[1]] + l[2]] for l in data_num_dev]\n",
    "data_num_dev = [[[t[1] for t in l[0]], l[1]] for l in data_num_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inds = []\n",
    "\n",
    "for a, q in data_num_dev:\n",
    "    ans = []\n",
    "    tot_q = list(chain(*q[1:]))\n",
    "    for x in a:\n",
    "        for i in xrange(len(tot_q)):\n",
    "            if x == tot_q[i:i+len(x)]:\n",
    "                ans.append(list(xrange(i, i + len(x))))\n",
    "                break\n",
    "    inds.append(ans)\n",
    "    \n",
    "for i in xrange(len(data_num_dev)):\n",
    "    data_num_dev[i][0] = inds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_num_dev = [[d[0]] + map(words_to_num, d[1:]) for d in data_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/pio/data/data/squad/dev_with_training_vocab.pkl', 'w') as f:\n",
    "    pickle.dump(data_num_dev, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get Glove vectors for words in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_vec = np.load('/pio/data/data/glove_vec/6B/glove.6B.300d.npy')\n",
    "\n",
    "glove_words = []\n",
    "\n",
    "with io.open('/pio/data/data/glove_vec/6B/glove.6B.wordlist.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        glove_words.append(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_i_to_w = dict(enumerate(glove_words))\n",
    "glove_w_to_i = {v:k for (k,v) in glove_i_to_w.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102802, 300)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = np.zeros((len(words), 300), dtype=np.float32)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73351"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_inds = [i for i in xrange(len(words)) if i_to_w[i] in glove_w_to_i]\n",
    "len(known_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = set(known_inds)\n",
    "unknown_inds = [i for i in xrange(len(words)) if i not in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embs[known_inds] = glove_vec[[glove_w_to_i[i_to_w[i]] for i in known_inds]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embs[unknown_inds] = L.init.Normal()((len(unknown_inds), 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_words = map(lambda x: x[0], sorted(w_to_i.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/wordlist.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in sorted_words:\n",
    "        f.write(unicode(w + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file has a lot of redundant parts, context is repeated for each question.\n",
    "# It only slows down the initial loading.\n",
    "\n",
    "with open('/pio/data/data/squad/train.pkl', 'w') as f:\n",
    "    pickle.dump(data_num, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/pio/data/data/squad/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_to_i = {}\n",
    "idx = 0\n",
    "\n",
    "with io.open('/pio/data/data/squad/wordlist.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        w_to_i[line[:-1]] = idx\n",
    "        idx += 1\n",
    "        \n",
    "i_to_w = {v:k for (k,v) in w_to_i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'it'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_to_w[19557]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = np.array(map(lambda x: len(x[1]), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_data(idx):\n",
    "    for s in data[idx][1]:\n",
    "        print ' '.join([i_to_w[x] for x in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the largest hottest continuously large area worldwide ?\n",
      "the sky is usually clear above the desert and the sunshine duration is extremely high everywhere in the sahara .\n",
      "most of the desert enjoys more than 3,600 h of bright sunshine annually or over 82 % of the time and a wide area in the eastern part experiences in excess of 4,000 h of bright sunshine a year or over 91 % of the time , and the highest values are very close to the theoretical maximum value .\n",
      "a value of 4,300 h or 98 % of the time would be recorded in upper egypt ( aswan , luxor ) and in the nubian desert ( wadi halfa ) .\n",
      "the annual average direct solar irradiation is around 2,800 kwh/ ( m2 year ) in the great desert .\n",
      "the sahara has a huge potential for solar energy production .\n",
      "the constantly high position of the sun , the extremely low relative humidity , the lack of vegetation and rainfall make the great desert the hottest continuously large area worldwide and certainly the hottest place on earth during summertime in some spots .\n",
      "the average high temperature exceeds 38 °c ( 100.4 °f ) - 40 °c ( 104 °f ) during the hottest month nearly everywhere in the desert except at very high mountainous areas .\n",
      "the highest officially recorded average high temperature was 47 °c ( 116.6 °f ) in a remote desert town in the algerian desert called bou bernous with an elevation of 378 meters above sea level .\n",
      "it 's the world 's highest recorded average high temperature and only death valley , california rivals it .\n",
      "other hot spots in algeria such as adrar , timimoun , in salah , ouallene , aoulef , reggane with an elevation between 200 and 400 meters above sea level get slightly lower summer average highs around 46 °c ( 114.8 °f ) during the hottest months of the year .\n",
      "salah , well known in algeria for its extreme heat , has an average high temperature of 43.8 °c ( 110.8 °f ) , 46.4 °c ( 115.5 °f ) , 45.5 ( 113.9 °f ) .\n",
      "furthermore , 41.9 °c ( 107.4 °f ) in june , july , august and september .\n",
      "in fact , there are even hotter spots in the sahara , but they are located in extremely remote areas , especially in the azalai , lying in northern mali .\n",
      "the major part of the desert experiences around 3 – 5 months when the average high strictly exceeds 40 °c ( 104 °f ) .\n",
      "the southern central part of the desert experiences up to 6 – 7 months when the average high temperature strictly exceeds 40 °c ( 104 °f ) which shows the constancy and the length of the really hot season in the sahara .\n",
      "some examples of this are bilma , niger and faya-largeau , chad .\n",
      "the annual average daily temperature exceeds 20 °c ( 68 °f ) everywhere and can approach 30 °c ( 86 °f ) in the hottest regions year-round .\n",
      "however , most of the desert has a value in excess of 25 °c ( 77 °f ) .\n",
      "the sand and ground temperatures are even more extreme .\n",
      "during daytime , the sand temperature is extremely high as it can easily reach 80 °c ( 176 °f ) or more .\n",
      "a sand temperature of 83.5 °c ( 182.3 °f ) has been recorded in port sudan .\n",
      "ground temperatures of 72 °c ( 161.6 °f ) have been recorded in the adrar of mauritania and a value of 75 °c ( 167 °f ) has been measured in borkou , northern chad .\n",
      "due to lack of cloud cover and very low humidity , the desert usually features high diurnal temperature variations between days and nights .\n",
      "however , it 's a myth that the nights are cold after extremely hot days in the sahara .\n",
      "the average diurnal temperature range is typically between 13 °c ( 55.4 °f ) and 20 °c ( 68 °f ) .\n",
      "the lowest values are found along the coastal regions due to high humidity and are often even lower than 10 °c ( 50 °f ) , while the highest values are found in inland desert areas where the humidity is the lowest , mainly in the southern sahara .\n",
      "still , it 's true that winter nights can be cold as it can drop to the freezing point and even below , especially in high-elevation areas .\n"
     ]
    }
   ],
   "source": [
    "show_data(60023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0,     0,  1665,  6015, 12958, 18663, 16891, 12176,  7727,\n",
       "        4709,  2711,  1677,   859,   636,   352,   223,   166,    60,\n",
       "          39,    24,     9,     0,     5,    19,     5,     0,     0,\n",
       "           0,    10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print max(lens)\n",
    "np.bincount(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'to',\n",
       " u'whom',\n",
       " u'did',\n",
       " u'the',\n",
       " u'virgin',\n",
       " u'mary',\n",
       " u'allegedly',\n",
       " u'appear',\n",
       " u'in',\n",
       " u'1858',\n",
       " u'in',\n",
       " u'lourdes',\n",
       " u'france',\n",
       " u'?',\n",
       " u'architecturally',\n",
       " u',',\n",
       " u'the',\n",
       " u'school',\n",
       " u'has',\n",
       " u'a',\n",
       " u'catholic',\n",
       " u'character',\n",
       " u'.',\n",
       " u'atop',\n",
       " u'the',\n",
       " u'main',\n",
       " u'building',\n",
       " u\"'s\",\n",
       " u'gold',\n",
       " u'dome',\n",
       " u'is',\n",
       " u'a',\n",
       " u'golden',\n",
       " u'statue',\n",
       " u'of',\n",
       " u'the',\n",
       " u'virgin',\n",
       " u'mary',\n",
       " u'.',\n",
       " u'immediately',\n",
       " u'in',\n",
       " u'front',\n",
       " u'of',\n",
       " u'the',\n",
       " u'main',\n",
       " u'building',\n",
       " u'and',\n",
       " u'facing',\n",
       " u'it',\n",
       " u',',\n",
       " u'is',\n",
       " u'a',\n",
       " u'copper',\n",
       " u'statue',\n",
       " u'of',\n",
       " u'christ',\n",
       " u'with',\n",
       " u'arms',\n",
       " u'upraised',\n",
       " u'with',\n",
       " u'the',\n",
       " u'legend',\n",
       " u'``',\n",
       " u'venite',\n",
       " u'ad',\n",
       " u'me',\n",
       " u'omnes',\n",
       " u\"''\",\n",
       " u'.',\n",
       " u'next',\n",
       " u'to',\n",
       " u'the',\n",
       " u'main',\n",
       " u'building',\n",
       " u'is',\n",
       " u'the',\n",
       " u'basilica',\n",
       " u'of',\n",
       " u'the',\n",
       " u'sacred',\n",
       " u'heart',\n",
       " u'.',\n",
       " u'immediately',\n",
       " u'behind',\n",
       " u'the',\n",
       " u'basilica',\n",
       " u'is',\n",
       " u'the',\n",
       " u'grotto',\n",
       " u',',\n",
       " u'a',\n",
       " u'marian',\n",
       " u'place',\n",
       " u'of',\n",
       " u'prayer',\n",
       " u'and',\n",
       " u'reflection',\n",
       " u'.',\n",
       " u'it',\n",
       " u'is',\n",
       " u'a',\n",
       " u'replica',\n",
       " u'of',\n",
       " u'the',\n",
       " u'grotto',\n",
       " u'at',\n",
       " u'lourdes',\n",
       " u',',\n",
       " u'france',\n",
       " u'where',\n",
       " u'the',\n",
       " u'virgin',\n",
       " u'mary',\n",
       " u'reputedly',\n",
       " u'appeared',\n",
       " u'to',\n",
       " u'saint',\n",
       " u'bernadette',\n",
       " u'soubirous',\n",
       " u'in',\n",
       " u'1858',\n",
       " u'.',\n",
       " u'at',\n",
       " u'the',\n",
       " u'end',\n",
       " u'of',\n",
       " u'the',\n",
       " u'main',\n",
       " u'drive',\n",
       " u'(',\n",
       " u'and',\n",
       " u'in',\n",
       " u'a',\n",
       " u'direct',\n",
       " u'line',\n",
       " u'that',\n",
       " u'connects',\n",
       " u'through',\n",
       " u'3',\n",
       " u'statues',\n",
       " u'and',\n",
       " u'the',\n",
       " u'gold',\n",
       " u'dome',\n",
       " u')',\n",
       " u',',\n",
       " u'is',\n",
       " u'a',\n",
       " u'simple',\n",
       " u',',\n",
       " u'modern',\n",
       " u'stone',\n",
       " u'statue',\n",
       " u'of',\n",
       " u'mary',\n",
       " u'.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chain(*data[0][1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun with characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data powinno być bezpośrednio po wykonaniu okienka, w którym jest inicjowane words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = {c for d in data for s in d[1:] for w in s for c in w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars_dev = {c for d in data_dev for s in d[1:3] for w in s for c in w}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_to_c = dict(enumerate(chars))\n",
    "c_to_i = {v:k for (k,v) in i_to_c.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_char = []\n",
    "\n",
    "for _, q, x in data:\n",
    "    q_char = [[c_to_i[c] for c in w] for w in q]\n",
    "    x_char = [[c_to_i[c] for c in w] for w in x]\n",
    "    data_char.append([q_char, x_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dev_char = []\n",
    "\n",
    "for _, q, x, _ in data_dev:\n",
    "    q_char = [[c_to_i.get(c, c_to_i['<unk>']) for c in w] for w in q]\n",
    "    x_char = [[c_to_i.get(c, c_to_i['<unk>']) for c in w] for w in x]\n",
    "    data_dev_char.append([q_char, x_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'which',\n",
       "  u'nfl',\n",
       "  u'team',\n",
       "  u'represented',\n",
       "  u'the',\n",
       "  u'afc',\n",
       "  u'at',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'50',\n",
       "  u'?'],\n",
       " [u'super',\n",
       "  u'bowl',\n",
       "  u'50',\n",
       "  u'was',\n",
       "  u'an',\n",
       "  u'american',\n",
       "  u'football',\n",
       "  u'game',\n",
       "  u'to',\n",
       "  u'determine',\n",
       "  u'the',\n",
       "  u'champion',\n",
       "  u'of',\n",
       "  u'the',\n",
       "  u'national',\n",
       "  u'football',\n",
       "  u'league',\n",
       "  u'(',\n",
       "  u'nfl',\n",
       "  u')',\n",
       "  u'for',\n",
       "  u'the',\n",
       "  u'2015',\n",
       "  u'season',\n",
       "  u'.',\n",
       "  u'the',\n",
       "  u'american',\n",
       "  u'football',\n",
       "  u'conference',\n",
       "  u'(',\n",
       "  u'afc',\n",
       "  u')',\n",
       "  u'champion',\n",
       "  u'denver',\n",
       "  u'broncos',\n",
       "  u'defeated',\n",
       "  u'the',\n",
       "  u'national',\n",
       "  u'football',\n",
       "  u'conference',\n",
       "  u'(',\n",
       "  u'nfc',\n",
       "  u')',\n",
       "  u'champion',\n",
       "  u'carolina',\n",
       "  u'panthers',\n",
       "  u'24\\u201310',\n",
       "  u'to',\n",
       "  u'earn',\n",
       "  u'their',\n",
       "  u'third',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'title',\n",
       "  u'.',\n",
       "  u'the',\n",
       "  u'game',\n",
       "  u'was',\n",
       "  u'played',\n",
       "  u'on',\n",
       "  u'february',\n",
       "  u'7',\n",
       "  u',',\n",
       "  u'2016',\n",
       "  u',',\n",
       "  u'at',\n",
       "  u'levi',\n",
       "  u\"'s\",\n",
       "  u'stadium',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'san',\n",
       "  u'francisco',\n",
       "  u'bay',\n",
       "  u'area',\n",
       "  u'at',\n",
       "  u'santa',\n",
       "  u'clara',\n",
       "  u',',\n",
       "  u'california',\n",
       "  u'.',\n",
       "  u'as',\n",
       "  u'this',\n",
       "  u'was',\n",
       "  u'the',\n",
       "  u'50th',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u',',\n",
       "  u'the',\n",
       "  u'league',\n",
       "  u'emphasized',\n",
       "  u'the',\n",
       "  u'``',\n",
       "  u'golden',\n",
       "  u'anniversary',\n",
       "  u\"''\",\n",
       "  u'with',\n",
       "  u'various',\n",
       "  u'gold-themed',\n",
       "  u'initiatives',\n",
       "  u',',\n",
       "  u'as',\n",
       "  u'well',\n",
       "  u'as',\n",
       "  u'temporarily',\n",
       "  u'suspending',\n",
       "  u'the',\n",
       "  u'tradition',\n",
       "  u'of',\n",
       "  u'naming',\n",
       "  u'each',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'game',\n",
       "  u'with',\n",
       "  u'roman',\n",
       "  u'numerals',\n",
       "  u'(',\n",
       "  u'under',\n",
       "  u'which',\n",
       "  u'the',\n",
       "  u'game',\n",
       "  u'would',\n",
       "  u'have',\n",
       "  u'been',\n",
       "  u'known',\n",
       "  u'as',\n",
       "  u'``',\n",
       "  u'super',\n",
       "  u'bowl',\n",
       "  u'l',\n",
       "  u\"''\",\n",
       "  u')',\n",
       "  u',',\n",
       "  u'so',\n",
       "  u'that',\n",
       "  u'the',\n",
       "  u'logo',\n",
       "  u'could',\n",
       "  u'prominently',\n",
       "  u'feature',\n",
       "  u'the',\n",
       "  u'arabic',\n",
       "  u'numerals',\n",
       "  u'50',\n",
       "  u'.']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev[0][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[470, 679, 919, 754, 679],\n",
       "  [96, 223, 386],\n",
       "  [1015, 1241, 304, 612],\n",
       "  [541, 1241, 75, 541, 1241, 766, 1241, 96, 1015, 1241, 1005],\n",
       "  [1015, 679, 1241],\n",
       "  [304, 223, 754],\n",
       "  [304, 1015],\n",
       "  [766, 1248, 75, 1241, 541],\n",
       "  [666, 1088, 470, 386],\n",
       "  [1209, 30],\n",
       "  [76]],\n",
       " [[766, 1248, 75, 1241, 541],\n",
       "  [666, 1088, 470, 386],\n",
       "  [1209, 30],\n",
       "  [470, 304, 766],\n",
       "  [304, 96],\n",
       "  [304, 612, 1241, 541, 919, 754, 304, 96],\n",
       "  [223, 1088, 1088, 1015, 666, 304, 386, 386],\n",
       "  [460, 304, 612, 1241],\n",
       "  [1015, 1088],\n",
       "  [1005, 1241, 1015, 1241, 541, 612, 919, 96, 1241],\n",
       "  [1015, 679, 1241],\n",
       "  [754, 679, 304, 612, 75, 919, 1088, 96],\n",
       "  [1088, 223],\n",
       "  [1015, 679, 1241],\n",
       "  [96, 304, 1015, 919, 1088, 96, 304, 386],\n",
       "  [223, 1088, 1088, 1015, 666, 304, 386, 386],\n",
       "  [386, 1241, 304, 460, 1248, 1241],\n",
       "  [641],\n",
       "  [96, 223, 386],\n",
       "  [876],\n",
       "  [223, 1088, 541],\n",
       "  [1015, 679, 1241],\n",
       "  [504, 30, 270, 1209],\n",
       "  [766, 1241, 304, 766, 1088, 96],\n",
       "  [801],\n",
       "  [1015, 679, 1241],\n",
       "  [304, 612, 1241, 541, 919, 754, 304, 96],\n",
       "  [223, 1088, 1088, 1015, 666, 304, 386, 386],\n",
       "  [754, 1088, 96, 223, 1241, 541, 1241, 96, 754, 1241],\n",
       "  [641],\n",
       "  [304, 223, 754],\n",
       "  [876],\n",
       "  [754, 679, 304, 612, 75, 919, 1088, 96],\n",
       "  [1005, 1241, 96, 231, 1241, 541],\n",
       "  [666, 541, 1088, 96, 754, 1088, 766],\n",
       "  [1005, 1241, 223, 1241, 304, 1015, 1241, 1005],\n",
       "  [1015, 679, 1241],\n",
       "  [96, 304, 1015, 919, 1088, 96, 304, 386],\n",
       "  [223, 1088, 1088, 1015, 666, 304, 386, 386],\n",
       "  [754, 1088, 96, 223, 1241, 541, 1241, 96, 754, 1241],\n",
       "  [641],\n",
       "  [96, 223, 754],\n",
       "  [876],\n",
       "  [754, 679, 304, 612, 75, 919, 1088, 96],\n",
       "  [754, 304, 541, 1088, 386, 919, 96, 304],\n",
       "  [75, 304, 96, 1015, 679, 1241, 541, 766],\n",
       "  [504, 972, 701, 270, 30],\n",
       "  [1015, 1088],\n",
       "  [1241, 304, 541, 96],\n",
       "  [1015, 679, 1241, 919, 541],\n",
       "  [1015, 679, 919, 541, 1005],\n",
       "  [766, 1248, 75, 1241, 541],\n",
       "  [666, 1088, 470, 386],\n",
       "  [1015, 919, 1015, 386, 1241],\n",
       "  [801],\n",
       "  [1015, 679, 1241],\n",
       "  [460, 304, 612, 1241],\n",
       "  [470, 304, 766],\n",
       "  [75, 386, 304, 931, 1241, 1005],\n",
       "  [1088, 96],\n",
       "  [223, 1241, 666, 541, 1248, 304, 541, 931],\n",
       "  [431],\n",
       "  [344],\n",
       "  [504, 30, 270, 192],\n",
       "  [344],\n",
       "  [304, 1015],\n",
       "  [386, 1241, 231, 919],\n",
       "  [420, 766],\n",
       "  [766, 1015, 304, 1005, 919, 1248, 612],\n",
       "  [919, 96],\n",
       "  [1015, 679, 1241],\n",
       "  [766, 304, 96],\n",
       "  [223, 541, 304, 96, 754, 919, 766, 754, 1088],\n",
       "  [666, 304, 931],\n",
       "  [304, 541, 1241, 304],\n",
       "  [304, 1015],\n",
       "  [766, 304, 96, 1015, 304],\n",
       "  [754, 386, 304, 541, 304],\n",
       "  [344],\n",
       "  [754, 304, 386, 919, 223, 1088, 541, 96, 919, 304],\n",
       "  [801],\n",
       "  [304, 766],\n",
       "  [1015, 679, 919, 766],\n",
       "  [470, 304, 766],\n",
       "  [1015, 679, 1241],\n",
       "  [1209, 30, 1015, 679],\n",
       "  [766, 1248, 75, 1241, 541],\n",
       "  [666, 1088, 470, 386],\n",
       "  [344],\n",
       "  [1015, 679, 1241],\n",
       "  [386, 1241, 304, 460, 1248, 1241],\n",
       "  [1241, 612, 75, 679, 304, 766, 919, 1174, 1241, 1005],\n",
       "  [1015, 679, 1241],\n",
       "  [64, 64],\n",
       "  [460, 1088, 386, 1005, 1241, 96],\n",
       "  [304, 96, 96, 919, 231, 1241, 541, 766, 304, 541, 931],\n",
       "  [420, 420],\n",
       "  [470, 919, 1015, 679],\n",
       "  [231, 304, 541, 919, 1088, 1248, 766],\n",
       "  [460, 1088, 386, 1005, 574, 1015, 679, 1241, 612, 1241, 1005],\n",
       "  [919, 96, 919, 1015, 919, 304, 1015, 919, 231, 1241, 766],\n",
       "  [344],\n",
       "  [304, 766],\n",
       "  [470, 1241, 386, 386],\n",
       "  [304, 766],\n",
       "  [1015, 1241, 612, 75, 1088, 541, 304, 541, 919, 386, 931],\n",
       "  [766, 1248, 766, 75, 1241, 96, 1005, 919, 96, 460],\n",
       "  [1015, 679, 1241],\n",
       "  [1015, 541, 304, 1005, 919, 1015, 919, 1088, 96],\n",
       "  [1088, 223],\n",
       "  [96, 304, 612, 919, 96, 460],\n",
       "  [1241, 304, 754, 679],\n",
       "  [766, 1248, 75, 1241, 541],\n",
       "  [666, 1088, 470, 386],\n",
       "  [460, 304, 612, 1241],\n",
       "  [470, 919, 1015, 679],\n",
       "  [541, 1088, 612, 304, 96],\n",
       "  [96, 1248, 612, 1241, 541, 304, 386, 766],\n",
       "  [641],\n",
       "  [1248, 96, 1005, 1241, 541],\n",
       "  [470, 679, 919, 754, 679],\n",
       "  [1015, 679, 1241],\n",
       "  [460, 304, 612, 1241],\n",
       "  [470, 1088, 1248, 386, 1005],\n",
       "  [679, 304, 231, 1241],\n",
       "  [666, 1241, 1241, 96],\n",
       "  [149, 96, 1088, 470, 96],\n",
       "  [304, 766],\n",
       "  [64, 64],\n",
       "  [766, 1248, 75, 1241, 541],\n",
       "  [666, 1088, 470, 386],\n",
       "  [386],\n",
       "  [420, 420],\n",
       "  [876],\n",
       "  [344],\n",
       "  [766, 1088],\n",
       "  [1015, 679, 304, 1015],\n",
       "  [1015, 679, 1241],\n",
       "  [386, 1088, 460, 1088],\n",
       "  [754, 1088, 1248, 386, 1005],\n",
       "  [75, 541, 1088, 612, 919, 96, 1241, 96, 1015, 386, 931],\n",
       "  [223, 1241, 304, 1015, 1248, 541, 1241],\n",
       "  [1015, 679, 1241],\n",
       "  [304, 541, 304, 666, 919, 754],\n",
       "  [96, 1248, 612, 1241, 541, 304, 386, 766],\n",
       "  [1209, 30],\n",
       "  [801]]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_chars = map(lambda x: x[0], sorted(c_to_i.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with io.open('/pio/data/data/squad/train_charlist.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in sorted_chars:\n",
    "        f.write(unicode(w + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/pio/data/data/squad/train_char.pkl', 'w') as f:\n",
    "    pickle.dump(data_char, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/pio/data/data/squad/dev_char_with_training_charlist.pkl', 'w') as f:\n",
    "    pickle.dump(data_dev_char, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
