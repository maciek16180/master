{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np\n",
    "import lasagne as L\n",
    "from squad_load import get_glove_train_embs, get_squad_train_voc, load_squad_train, get_squad_train_chars\n",
    "from itertools import chain\n",
    "\n",
    "%aimport QANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples total: 87599 87599 87599\n",
      "Working examples: 86355 86355 86355\n",
      "CPU times: user 1min 14s, sys: 326 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "squad_path = '/pio/data/data/squad/'\n",
    "glove_path = '/pio/data/data/glove_vec/6B/glove/'\n",
    "\n",
    "data = np.load(squad_path + 'train_with_glove_vocab.pkl')\n",
    "data_char = np.load(squad_path + 'train_char_ascii.pkl')\n",
    "train_bin_feats = np.load(squad_path + 'train_bin_feats.pkl')\n",
    "glove_embs = np.load(glove_path + 'glove.6B.300d.npy')\n",
    "voc_size = glove_embs.shape[0]\n",
    "alphabet_size = 128\n",
    "\n",
    "# Some answers get broken in the process of tokenization, because some answer words are not properly split.\n",
    "def filter_broken_answers(data, data_char, train_bin_feats):\n",
    "    data_new = []\n",
    "    data_char_new = []\n",
    "    train_bin_feats_new = []\n",
    "    for i in xrange(len(data)):\n",
    "        if data[i][0]:\n",
    "            data_new.append(data[i])\n",
    "            data_char_new.append(data_char[i])\n",
    "            train_bin_feats_new.append(train_bin_feats[i])\n",
    "    return data_new, data_char_new, train_bin_feats_new\n",
    "\n",
    "def trim_data(data, data_char, train_bin_feats, trim=300):\n",
    "    data_new = []\n",
    "    data_char_new = []\n",
    "    train_bin_feats_new = []\n",
    "    for i in xrange(len(data)):\n",
    "        if len(data[i][2]) > trim:\n",
    "            if data[i][0][0][-1] < trim:\n",
    "                data_new.append(data[i][:2] + [data[i][2][:trim]])\n",
    "                data_char_new.append([data_char[i][0], data_char[i][1][:trim]])\n",
    "                train_bin_feats_new.append(train_bin_feats[i][:trim])\n",
    "        else:\n",
    "            data_new.append(data[i])\n",
    "            data_char_new.append(data_char[i])\n",
    "            train_bin_feats_new.append(train_bin_feats[i])\n",
    "    return data_new, data_char_new, train_bin_feats_new\n",
    "\n",
    "print 'Examples total:', len(data), len(data_char), len(train_bin_feats)\n",
    "\n",
    "data, data_char, train_bin_feats = filter_broken_answers(data, data_char, train_bin_feats)\n",
    "data, data_char, train_bin_feats = trim_data(data, data_char, train_bin_feats)\n",
    "\n",
    "print 'Working examples:', len(data), len(data_char), len(train_bin_feats)\n",
    "\n",
    "data = (data, data_char, train_bin_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.77 s, sys: 19.5 ms, total: 9.79 s\n",
      "Wall time: 9.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_dev = np.load(squad_path + 'dev_with_glove_vocab.pkl')\n",
    "data_dev_char = np.load(squad_path + 'dev_char_ascii.pkl')\n",
    "dev_bin_feats = np.load(squad_path + 'dev_bin_feats.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dev_all = data_dev, data_dev_char, dev_bin_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions:\n",
      "    train_fn...\n",
      "    get_start_probs_fn...\n",
      "    get_end_probs_fn...\n",
      "Done\n",
      "CPU times: user 1min 11s, sys: 1.33 s, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qa_net = QANet.QANet(voc_size=voc_size,\n",
    "                     alphabet_size=alphabet_size,\n",
    "                     emb_size=300,\n",
    "                     emb_char_size=20,\n",
    "                     num_emb_char_filters=200,\n",
    "                     rec_size=300,\n",
    "                     emb_init=glove_embs,\n",
    "                     train_inds=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_net.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# qa_net.load_params('trained_models/glove_vocab/charemb_all_fixed_ep3.npz', glove_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 5 batches in 5.63s\ttraining loss:\t9.283470\n",
      "Done 10 batches in 9.76s\ttraining loss:\t8.741427\n",
      "Done 15 batches in 14.02s\ttraining loss:\t8.487012\n",
      "Done 20 batches in 18.36s\ttraining loss:\t8.358544\n",
      "Calculating validation f1...\n",
      "Done 1000 examples\n",
      "Done 2000 examples\n",
      "Done 3000 examples\n",
      "Done 4000 examples\n",
      "Done 5000 examples\n",
      "Done 6000 examples\n",
      "Done 7000 examples\n",
      "Done 8000 examples\n",
      "Done 9000 examples\n",
      "Done 10000 examples\n",
      "Predictions done\n",
      "F1:  8.27234666418\n",
      "Done 25 batches in 283.49s\ttraining loss:\t8.171664\n",
      "Done 30 batches in 287.56s\ttraining loss:\t7.942222\n",
      "Done 35 batches in 291.60s\ttraining loss:\t7.719355\n",
      "Done 40 batches in 295.70s\ttraining loss:\t7.661161\n",
      "Calculating validation f1...\n",
      "Done 1000 examples\n",
      "Done 2000 examples\n",
      "Done 3000 examples\n",
      "Done 4000 examples\n",
      "Done 5000 examples\n",
      "Done 6000 examples\n",
      "Done 7000 examples\n",
      "Done 8000 examples\n",
      "Done 9000 examples\n",
      "Done 10000 examples\n",
      "Predictions done\n",
      "F1:  8.57612258945\n",
      "Done 45 batches in 556.93s\ttraining loss:\t7.599194\n",
      "Done 50 batches in 560.72s\ttraining loss:\t7.545116\n",
      "Done 55 batches in 564.62s\ttraining loss:\t7.433833\n",
      "Done 60 batches in 568.49s\ttraining loss:\t7.320189\n",
      "Calculating validation f1...\n",
      "Done 1000 examples\n",
      "Done 2000 examples\n",
      "Done 3000 examples\n",
      "Done 4000 examples\n",
      "Done 5000 examples\n",
      "Done 6000 examples\n",
      "Done 7000 examples\n",
      "Done 8000 examples\n",
      "Done 9000 examples\n",
      "Done 10000 examples\n",
      "Predictions done\n",
      "F1:  8.15068828469\n",
      "Lowering rate...\n",
      "Done 65 batches in 836.04s\ttraining loss:\t7.288531\n",
      "Done 70 batches in 840.51s\ttraining loss:\t7.233426\n",
      "Done 75 batches in 844.66s\ttraining loss:\t7.167850\n",
      "Done 80 batches in 849.06s\ttraining loss:\t7.088366\n",
      "Calculating validation f1...\n",
      "Done 1000 examples\n",
      "Done 2000 examples\n",
      "Done 3000 examples\n",
      "Done 4000 examples\n",
      "Done 5000 examples\n",
      "Done 6000 examples\n",
      "Done 7000 examples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-b437cab52eda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# słownik glove, unk to średnie słowo, nie trenujemy zanurzeń słów, char-embeddings ma losowy init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mqa_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/pio/scratch/1/i258346/masters_thesis/SQuAD/QANet.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, train_data, batch_size, log_interval, premade_bin_feats)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples_since_last_checkpoint\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_examples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_f1_log\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_f1_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calc_dev_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_f1_log\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_f1_log\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Lowering rate...'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/scratch/1/i258346/masters_thesis/SQuAD/QANet.py\u001b[0m in \u001b[0;36m_calc_dev_f1\u001b[1;34m(self, checkpoint, batch_size)\u001b[0m\n\u001b[0;32m    288\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_dev_num\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                               self.data_dev_num[2][idx:idx + batch_size]]\n\u001b[1;32m--> 290\u001b[1;33m             \u001b[0mspans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_spans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dev_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m             \u001b[0mpredicted_spans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/scratch/1/i258346/masters_thesis/SQuAD/QANet.py\u001b[0m in \u001b[0;36m_predict_spans\u001b[1;34m(self, data, beam, batch_size)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mnum_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mstart_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_start_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpremade_bin_feats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[0mbest_starts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbeam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mbeam\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/scratch/1/i258346/masters_thesis/SQuAD/QANet.py\u001b[0m in \u001b[0;36mget_start_probs\u001b[1;34m(self, data, batch_size, premade_bin_feats)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mquestion_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_char_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_char_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             out = self.get_start_probs_fn(contexts, questions, contexts_char, questions_char, bin_feats, \n\u001b[1;32m--> 156\u001b[1;33m                                           context_mask, question_mask, context_char_mask, question_char_mask)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# z char-embeddings\n",
    "\n",
    "# dane są przycięte do długości 300 (jeśli odpowiedź się nie mieści, to pytanie jest usuwane z danych)\n",
    "# przycięto około 1400 próbek, usunięto 119\n",
    "\n",
    "# słownik glove, unk to średnie słowo, nie trenujemy zanurzeń słów, char-embeddings ma losowy init\n",
    "\n",
    "qa_net.train_one_epoch(data, 15, log_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa_net.save_params('trained_models/glove_vocab/charemb_all_fixed_ep4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QANet tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "charemb all_fixed 2ep {\"f1\": 63.93851222573222, \"exact_match\": 53.33964049195837} \n",
    "charemb all_fixed 3ep {\"f1\": 64.65644340794375, \"exact_match\": 54.71144749290445}\n",
    "charemb all_fixed 3ep with premadeBin {\"f1\": 65.03551561149246, \"exact_match\": 55.052034058656574}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_spans(data, beam=10, batch_size=10, premade_bin_feats=True):\n",
    "    num_examples = len(data[0])\n",
    "    \n",
    "    start_probs = qa_net.get_start_probs(data, batch_size, premade_bin_feats=premade_bin_feats)\n",
    "    best_starts = start_probs.argpartition(-beam, axis=1)[:, -beam:].astype(np.int32)\n",
    "    \n",
    "    scores = start_probs[np.arange(num_examples)[:, np.newaxis], best_starts]\n",
    "    scores = np.tile(scores[:, np.newaxis], (beam, 1)).transpose(0, 2, 1)\n",
    "    \n",
    "    best_ends_all = []\n",
    "    for i in xrange(beam):\n",
    "        end_probs = qa_net.get_end_probs(data, best_starts[:, i], batch_size, \n",
    "                                         premade_bin_feats=premade_bin_feats)\n",
    "        best_ends = end_probs.argpartition(-beam, axis=1)[:, -beam:]\n",
    "        scores[:, i, :] *= end_probs[np.arange(num_examples)[:, np.newaxis], best_ends]\n",
    "        best_ends_all.append(best_ends)\n",
    "        \n",
    "    best_ends_all = np.hstack(best_ends_all)\n",
    "        \n",
    "    scores = scores.reshape(num_examples, beam**2)\n",
    "    best_spans = scores.argmax(axis=1)\n",
    "    starts = [i / beam for i in best_spans]\n",
    "    \n",
    "    starts = best_starts[np.arange(num_examples), starts]\n",
    "    ends = best_ends_all[np.arange(num_examples), best_spans]\n",
    "    \n",
    "    return starts, ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 examples\n",
      "2000 examples\n",
      "3000 examples\n",
      "4000 examples\n",
      "5000 examples\n",
      "6000 examples\n",
      "7000 examples\n",
      "8000 examples\n",
      "9000 examples\n",
      "10000 examples\n",
      "Predictions done\n",
      "CPU times: user 13min 42s, sys: 36min 23s, total: 50min 5s\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_spans = []\n",
    "batch_size = 10\n",
    "\n",
    "idx = 0\n",
    "while idx < len(data_dev):\n",
    "    data_dev_batch = [data_dev[idx:idx + batch_size], \n",
    "                      data_dev_char[idx:idx + batch_size], \n",
    "                      dev_bin_feats[idx:idx + batch_size]]\n",
    "    spans = predict_spans(data_dev_batch, beam=1)\n",
    "    predicted_spans.append(np.vstack(spans))\n",
    "    idx += batch_size\n",
    "    if not idx % 1000:\n",
    "        print idx, 'examples'\n",
    "        \n",
    "print 'Predictions done'\n",
    "    \n",
    "predicted_spans = np.hstack(predicted_spans).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez('evaluate/glove_vocab/pred_glove_premadeBin_charemb_all_fixed_ep3.npz', predicted_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
