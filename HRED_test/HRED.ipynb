{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "\n",
    "import lasagne as L\n",
    "from itertools import chain\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../rnn_ex/')\n",
    "\n",
    "from SimpleRNNLM import iterate_minibatches\n",
    "from SampledSoftmaxLayer import SampledSoftmaxDenseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember, now the pad value is the same as the <utt_end> token\n",
    "\n",
    "pad_value = -1 # <utt_end>'s vector is the last one\n",
    "\n",
    "def split_utt(utt):\n",
    "    u1, u2, u3 = [i for i,j in enumerate(utt) if j == 1]\n",
    "    return [utt[:u2], utt[u2:u3], utt[u3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "mt_path = \"/home/maciek/Desktop/mgr/DATA/MovieTriples_Dataset/\"\n",
    "\n",
    "def load_mt(path=mt_path):\n",
    "    tr = np.load(mt_path + 'Training.triples.pkl')\n",
    "    vl = np.load(mt_path + 'Validation.triples.pkl')\n",
    "    ts = np.load(mt_path + 'Test.triples.pkl')\n",
    "    \n",
    "    tr = chain(*map(split_utt, tr))\n",
    "    vl = chain(*map(split_utt, vl))\n",
    "    ts = chain(*map(split_utt, ts))\n",
    "    \n",
    "    return tr, vl, ts\n",
    "\n",
    "train, valid, test = load_mt()\n",
    "\n",
    "train = [utt for utt in train if len(utt) < 200]\n",
    "valid = [utt for utt in valid if len(utt) < 200]\n",
    "test  = [utt for utt in test  if len(utt) < 200]\n",
    "\n",
    "\n",
    "def get_mt_voc(mt_path=mt_path, train_len=len(train)):\n",
    "    word_list = np.load(mt_path + 'Training.dict.pkl')\n",
    "    word_list.sort(key=lambda x: x[1])\n",
    "    freqs = np.array(map(lambda x: x[2], word_list) + [train_len])\n",
    "    total_count = float(sum(freqs))\n",
    "    \n",
    "    words = map(lambda x: x[:2], word_list)\n",
    "    \n",
    "    w_to_idx = dict(words)\n",
    "    w_to_idx['<utt_end>'] = pad_value\n",
    "    idx_to_w = {v : k for (k,v) in w_to_idx.items()}\n",
    "    \n",
    "    return idx_to_w, w_to_idx, len(w_to_idx), freqs / total_count\n",
    "\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_mt_voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_embs, word2vec_embs_mask = np.load(mt_path + 'Word2Vec_WordEmb.pkl')\n",
    "word2vec_embs = np.vstack([word2vec_embs, L.init.GlorotUniform()((1,300))]).astype(np.float32)\n",
    "word2vec_embs_mask = np.vstack([word2vec_embs_mask, np.ones((1,300))])\n",
    "\n",
    "w2v_train_mask = np.where(word2vec_embs_mask[:,0] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_hred(input_var, mask_input_var, voc_size, emb_size, lv1_rec_size, lv2_rec_size, out_emb_size,\n",
    "               emb_init=None, train_emb=True):\n",
    "    l_in = L.layers.InputLayer(shape=(None, None), input_var=input_var)\n",
    "    \n",
    "    l_mask = None\n",
    "    if mask_input_var is not None:\n",
    "        l_mask = L.layers.InputLayer(shape=(None, None), input_var=mask_input_var)\n",
    "    \n",
    "    if emb_init is None:\n",
    "        l_emb = L.layers.EmbeddingLayer(l_in,\n",
    "                                        input_size=voc_size,  # not voc_size+1, because pad_value = <utt_end>\n",
    "                                        output_size=emb_size)\n",
    "    else:\n",
    "        l_emb = L.layers.EmbeddingLayer(l_in,\n",
    "                                        input_size=voc_size,\n",
    "                                        output_size=emb_size,\n",
    "                                        W=emb_init)\n",
    "        if not train_emb:\n",
    "            l_emb.params[l_emb.W].remove('trainable')\n",
    "            \n",
    "    l_lv1_enc = L.layers.GRULayer(l_emb, # we process all utts in parallel, out_shape is batch_size x lv1_rec_size\n",
    "                                  num_units=lv1_rec_size,\n",
    "                                  grad_clipping=100,\n",
    "                                  mask_input=l_mask,\n",
    "                                  only_return_final=True)\n",
    "    \n",
    "#     l_lv1_enc_back = L.layers.GRULayer(l_emb,\n",
    "#                                        num_units=lv1_rec_size,\n",
    "#                                        grad_clipping=100,\n",
    "#                                        mask_input=l_mask,\n",
    "#                                        only_return_final=True,\n",
    "#                                        backwards=True)\n",
    "    \n",
    "    l_resh = L.layers.ReshapeLayer(l_lv1_enc, shape=(-1, 3, lv1_rec_size)) # 3 is because movie *triples*\n",
    "    \n",
    "    l_lv2_enc = L.layers.GRULayer(l_resh, # out_shape is batch_size/3 x 3 x lv2_rec_size (has to be shifted!)\n",
    "                                  num_units=lv2_rec_size,\n",
    "                                  grad_clipping=100)\n",
    "    \n",
    "#     l_zeros = L.layers.InputLayer(shape=())\n",
    "\n",
    "    l_resh2 = L.layers.ReshapeLayer(l_lv2_enc, shape=(-1, lv2_rec_size))\n",
    "    \n",
    "    l_dec_inits = L.layers.DenseLayer(l_resh2, # out_shape is batch_size x lv1_rec_size\n",
    "                                      num_units=lv1_rec_size,\n",
    "                                      nonlinearity=L.nonlinearities.tanh)\n",
    "    \n",
    "    l_dec = L.layers.GRULayer(l_emb, # out_shape is batch_size x seq_len x lv1_rec_size\n",
    "                              num_units=lv1_rec_size,\n",
    "                              grad_clipping=100,\n",
    "                              mask_input=l_mask,\n",
    "                              hid_init=l_dec_inits)\n",
    "    \n",
    "    l_resh3 = L.layers.ReshapeLayer(l_dec, shape=(-1, lv1_rec_size))\n",
    "    \n",
    "    l_H0 = L.layers.DenseLayer(l_resh3,\n",
    "                               num_units=out_emb_size,\n",
    "                               nonlinearity=None)\n",
    "    \n",
    "    l_resh4 = L.layers.ReshapeLayer(l_emb, shape=(-1, emb_size))\n",
    "    \n",
    "    l_E0 = L.layers.DenseLayer(l_resh4,\n",
    "                               num_units=out_emb_size,\n",
    "                               b=None,\n",
    "                               nonlinearity=None)\n",
    "    \n",
    "    l_soft_in = L.layers.ElemwiseSumLayer([l_H0, l_E0])\n",
    "    \n",
    "    l_soft = L.layers.DenseLayer(l_soft_in,\n",
    "                                 num_units=voc_size,\n",
    "                                 nonlinearity=L.nonlinearities.softmax)\n",
    "    \n",
    "    l_out = L.layers.ReshapeLayer(l_soft, shape=(input_var.shape[0], input_var.shape[1], voc_size))\n",
    "\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 300\n",
    "lv1_rec_size = 300\n",
    "lv2_rec_size = 300\n",
    "out_emb_size = 300\n",
    "\n",
    "update_fn = lambda l, p: L.updates.adagrad(l, p, learning_rate=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling theano functions...\n"
     ]
    }
   ],
   "source": [
    "input_var = T.imatrix('inputs')\n",
    "target_var = T.imatrix('targets')  # these will be inputs shifted by 1\n",
    "mask_input_var = T.matrix('input_mask')\n",
    "mask_idx = mask_input_var.nonzero()\n",
    "\n",
    "net = build_hred(input_var, mask_input_var, voc_size, emb_size, lv1_rec_size, lv2_rec_size, out_emb_size,\n",
    "                 emb_init=word2vec_embs)\n",
    "\n",
    "train_out = L.layers.get_output(net)\n",
    "test_out = L.layers.get_output(net, deterministic=True)\n",
    "\n",
    "train_loss = L.objectives.categorical_crossentropy(train_out[mask_idx], target_var[mask_idx]).mean()\n",
    "test_loss = L.objectives.categorical_crossentropy(test_out[mask_idx], target_var[mask_idx]).mean()\n",
    "\n",
    "params = L.layers.get_all_params(net, trainable=True)\n",
    "updates = update_fn(train_loss, params)\n",
    "\n",
    "print 'Compiling theano functions...'\n",
    "\n",
    "train_fn = theano.function([input_var, target_var, mask_input_var], train_loss, updates=updates)\n",
    "val_fn = theano.function([input_var, target_var, mask_input_var], test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}