{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "    train_fn...\n",
      "    val_fn...\n",
      "Skipping generating part...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lasagne as L\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from HRED import HRED\n",
    "\n",
    "from data_load.redditv3_load import load_pairs\n",
    "\n",
    "reddit_path = \"/pio/data/data/reddit_sample/v3/\"\n",
    "\n",
    "train_pairs, test_pairs = load_pairs(path=reddit_path)\n",
    "\n",
    "glove6B = np.load('/pio/data/data/glove_vec/6B/glove/glove.6B.300d.npy')\n",
    "\n",
    "idx_to_w = np.load('/pio/data/data/glove_vec/6B/glove/glove.6B.wordlist.pkl')\n",
    "voc_size = len(idx_to_w)\n",
    "w_to_idx = {idx_to_w[i] : i for i in xrange(voc_size)}\n",
    "\n",
    "###\n",
    "\n",
    "net = HRED(voc_size=voc_size,\n",
    "           emb_size=300,\n",
    "           lv1_rec_size=300,\n",
    "           lv2_rec_size=300,\n",
    "           out_emb_size=300,\n",
    "           num_sampled=1000,\n",
    "           emb_init=glove6B,\n",
    "           train_emb=False,\n",
    "           train_inds=[0, 400002, 400003],\n",
    "           skip_gen=True)\n",
    "\n",
    "\n",
    "# net = HRED(voc_size=200000,\n",
    "#            emb_size=300,\n",
    "#            lv1_rec_size=300,\n",
    "#            lv2_rec_size=300,\n",
    "#            out_emb_size=300,\n",
    "#            num_sampled=1000,\n",
    "#            emb_init=None,\n",
    "#            train_emb=True,\n",
    "#            # train_inds=[0, 400002, 400003],\n",
    "#            skip_gen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = L.layers.get_all_params(net.train_net, trainable=True)\n",
    "all_params = L.layers.get_all_params(net.train_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[emb.W,\n",
       " GRU1forw.W_in_to_updategate,\n",
       " GRU1forw.W_hid_to_updategate,\n",
       " GRU1forw.b_updategate,\n",
       " GRU1forw.W_in_to_resetgate,\n",
       " GRU1forw.W_hid_to_resetgate,\n",
       " GRU1forw.b_resetgate,\n",
       " GRU1forw.W_in_to_hidden_update,\n",
       " GRU1forw.W_hid_to_hidden_update,\n",
       " GRU1forw.b_hidden_update,\n",
       " GRU1back.W_in_to_updategate,\n",
       " GRU1back.W_hid_to_updategate,\n",
       " GRU1back.b_updategate,\n",
       " GRU1back.W_in_to_resetgate,\n",
       " GRU1back.W_hid_to_resetgate,\n",
       " GRU1back.b_resetgate,\n",
       " GRU1back.W_in_to_hidden_update,\n",
       " GRU1back.W_hid_to_hidden_update,\n",
       " GRU1back.b_hidden_update,\n",
       " GRU2.W_in_to_updategate,\n",
       " GRU2.W_hid_to_updategate,\n",
       " GRU2.b_updategate,\n",
       " GRU2.W_in_to_resetgate,\n",
       " GRU2.W_hid_to_resetgate,\n",
       " GRU2.b_resetgate,\n",
       " GRU2.W_in_to_hidden_update,\n",
       " GRU2.W_hid_to_hidden_update,\n",
       " GRU2.b_hidden_update,\n",
       " dec_init.W,\n",
       " dec_init.b,\n",
       " GRUdec.W_in_to_updategate,\n",
       " GRUdec.W_hid_to_updategate,\n",
       " GRUdec.b_updategate,\n",
       " GRUdec.W_in_to_resetgate,\n",
       " GRUdec.W_hid_to_resetgate,\n",
       " GRUdec.b_resetgate,\n",
       " GRUdec.W_in_to_hidden_update,\n",
       " GRUdec.W_hid_to_hidden_update,\n",
       " GRUdec.b_hidden_update,\n",
       " h0.W,\n",
       " h0.b,\n",
       " e0.W,\n",
       " soft.W,\n",
       " soft.b]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400004    300]        emb.E\n",
      "[  3 300]        emb.W\n",
      "[300 300]        GRU1forw.W_in_to_updategate\n",
      "[300 300]        GRU1forw.W_hid_to_updategate\n",
      "[300]        GRU1forw.b_updategate\n",
      "[300 300]        GRU1forw.W_in_to_resetgate\n",
      "[300 300]        GRU1forw.W_hid_to_resetgate\n",
      "[300]        GRU1forw.b_resetgate\n",
      "[300 300]        GRU1forw.W_in_to_hidden_update\n",
      "[300 300]        GRU1forw.W_hid_to_hidden_update\n",
      "[300]        GRU1forw.b_hidden_update\n",
      "[  1 300]        GRU1forw.hid_init\n",
      "[300 300]        GRU1back.W_in_to_updategate\n",
      "[300 300]        GRU1back.W_hid_to_updategate\n",
      "[300]        GRU1back.b_updategate\n",
      "[300 300]        GRU1back.W_in_to_resetgate\n",
      "[300 300]        GRU1back.W_hid_to_resetgate\n",
      "[300]        GRU1back.b_resetgate\n",
      "[300 300]        GRU1back.W_in_to_hidden_update\n",
      "[300 300]        GRU1back.W_hid_to_hidden_update\n",
      "[300]        GRU1back.b_hidden_update\n",
      "[  1 300]        GRU1back.hid_init\n",
      "[600 300]        GRU2.W_in_to_updategate\n",
      "[300 300]        GRU2.W_hid_to_updategate\n",
      "[300]        GRU2.b_updategate\n",
      "[600 300]        GRU2.W_in_to_resetgate\n",
      "[300 300]        GRU2.W_hid_to_resetgate\n",
      "[300]        GRU2.b_resetgate\n",
      "[600 300]        GRU2.W_in_to_hidden_update\n",
      "[300 300]        GRU2.W_hid_to_hidden_update\n",
      "[300]        GRU2.b_hidden_update\n",
      "[  1 300]        GRU2.hid_init\n",
      "[300 300]        dec_init.W\n",
      "[300]        dec_init.b\n",
      "[300 300]        GRUdec.W_in_to_updategate\n",
      "[300 300]        GRUdec.W_hid_to_updategate\n",
      "[300]        GRUdec.b_updategate\n",
      "[300 300]        GRUdec.W_in_to_resetgate\n",
      "[300 300]        GRUdec.W_hid_to_resetgate\n",
      "[300]        GRUdec.b_resetgate\n",
      "[300 300]        GRUdec.W_in_to_hidden_update\n",
      "[300 300]        GRUdec.W_hid_to_hidden_update\n",
      "[300]        GRUdec.b_hidden_update\n",
      "[300 300]        h0.W\n",
      "[300]        h0.b\n",
      "[300 300]        e0.W\n",
      "[   300 400004]        soft.W\n",
      "[400004]        soft.b\n",
      "[400004]        soft.p\n"
     ]
    }
   ],
   "source": [
    "for p in all_params:\n",
    "    print p.shape.eval(), '      ', p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = net.iterate_minibatches(train_pairs, 150).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2, 19)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting epoch 1...\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 264000000 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22(GpuElemwise{Add}[(0, 1)].0, GpuDimShuffle{1,0}.0)\nToposort index: 562\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(66000, 300), (300, 1000)]\nInputs strides: [(300, 1), (1, 300)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: ['', '']\nOutputs clients: [[GpuElemwise{add,no_inplace}(GpuDot22.0, GpuDimShuffle{x,0}.0)]]\n\nDebugprint of the apply node: \nGpuDot22 [id A] <CudaNdarrayType(float32, matrix)> ''   \n |GpuElemwise{Add}[(0, 1)] [id B] <CudaNdarrayType(float32, matrix)> ''   \n | |GpuDimShuffle{x,0} [id C] <CudaNdarrayType(float32, row)> ''   \n | | |h0.b [id D] <CudaNdarrayType(float32, vector)>\n | |GpuGemm{inplace} [id E] <CudaNdarrayType(float32, matrix)> ''   \n |   |GpuDot22 [id F] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuReshape{2} [id G] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |GpuDimShuffle{1,0,2} [id H] <CudaNdarrayType(float32, 3D)> ''   \n |   | | | |GpuSubtensor{int64:int64:int8} [id I] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   |forall_inplace,gpu,scan_fn} [id J] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | |GpuSubtensor{int64:int64:int8} [id M] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |GpuElemwise{Add}[(0, 0)] [id N] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | |GpuReshape{3} [id O] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | | |GpuDot22 [id P] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | |GpuReshape{2} [id Q] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | | |GpuDimShuffle{1,0,2} [id R] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | | | | | |GpuReshape{3} [id S] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | | | | |   |GpuAdvancedSubtensor1 [id T] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | | |   | |GpuAdvancedIncSubtensor1_dev20{no_inplace,set} [id U] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | | |   | | |emb.E [id V] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | | | |   | | |emb.W [id W] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | | | |   | | |TensorConstant{[     0 40..02 400003]} [id X] <TensorType(int64, vector)>\n |   | | |   | | | | | | |   | |Elemwise{Cast{int64}} [id Y] <TensorType(int64, vector)> ''   \n |   | | |   | | | | | | |   |   |Reshape{1} [id Z] <TensorType(int32, vector)> ''   \n |   | | |   | | | | | | |   |     |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | | | | | | |   |     |TensorConstant{(1,) of -1} [id BA] <TensorType(int64, (True,))>\n |   | | |   | | | | | | |   |MakeVector{dtype='int64'} [id BB] <TensorType(int64, vector)> ''   \n |   | | |   | | | | | | |     |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Elemwise{eq,no_inplace} [id BD] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | |     | | |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | | | |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | | | | | | |     | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | |   |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | | | | | | |     | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |     | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Elemwise{neg,no_inplace} [id BI] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | |Elemwise{mul,no_inplace} [id BJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |   |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     |Shape_i{1} [id BK] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |       |emb.E [id V] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | | | |MakeVector{dtype='int64'} [id BL] <TensorType(int64, vector)> ''   \n |   | | |   | | | | | |   |Elemwise{mul,no_inplace} [id BM] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   |Shape_i{1} [id BK] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |GpuJoin [id BN] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | |   |GRUdec.W_in_to_resetgate [id BP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | |   |GRUdec.W_in_to_updategate [id BQ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | |   |GRUdec.W_in_to_hidden_update [id BR] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | |MakeVector{dtype='int64'} [id BS] <TensorType(int64, vector)> ''   \n |   | | |   | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |   |Elemwise{add,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |     |Shape_i{1} [id BU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |     | |GRUdec.W_in_to_resetgate [id BP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | |     |Shape_i{1} [id BV] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |     | |GRUdec.W_in_to_updategate [id BQ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | |     |Shape_i{1} [id BW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |       |GRUdec.W_in_to_hidden_update [id BR] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | |GpuDimShuffle{x,x,0} [id BX] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |   |GpuJoin [id BY] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     |GRUdec.b_resetgate [id CA] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     |GRUdec.b_updategate [id CB] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     |GRUdec.b_hidden_update [id CC] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |ScalarFromTensor [id CD] <int64> ''   \n |   | | |   | | | |Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}} [id CE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |ScalarFromTensor [id CG] <int64> ''   \n |   | | |   | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |Constant{1} [id CH] <int8>\n |   | | |   | |GpuSubtensor{int64:int64:int8} [id CI] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |GpuDimShuffle{1,0,x} [id CJ] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | | |GpuReshape{2} [id CK] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |   |GpuFromHost [id CL] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |   | |input_mask [id CM] <TensorType(float32, 3D)>\n |   | | |   | | |   |MakeVector{dtype='int64'} [id CN] <TensorType(int64, vector)> ''   \n |   | | |   | | |     |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |ScalarFromTensor [id CD] <int64> ''   \n |   | | |   | | |ScalarFromTensor [id CG] <int64> ''   \n |   | | |   | | |Constant{1} [id CH] <int8>\n |   | | |   | |GpuIncSubtensor{InplaceSet;:int64:} [id CO] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |GpuAllocEmpty [id CP] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id CQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}} [id CR] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CS] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{lt,no_inplace} [id CT] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |Elemwise{le,no_inplace} [id CV] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | | | |Elemwise{sub,no_inplace} [id CW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |Elemwise{add,no_inplace} [id CY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id DA] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id DB] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |     |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | | | |   | |     |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | | |   |Elemwise{maximum,no_inplace} [id DF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | | | |   |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id DI] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id CY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id DA] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id DB] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{sub,no_inplace} [id DJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | |   | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id DK] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}} [id DM] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CS] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{le,no_inplace} [id CV] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}} [id DN] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | |Elemwise{add,no_inplace} [id DO] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id DI] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | |Elemwise{sub,no_inplace} [id CW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{-2} [id DP] <TensorType(int64, scalar)>\n |   | | |   | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{minimum,no_inplace} [id DQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |Elemwise{add,no_inplace} [id DO] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | | |TensorConstant{2} [id DR] <TensorType(int64, scalar)>\n |   | | |   | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DS] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | |   |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // (i4 * i1 * i5)), i6)}} [id DT] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{eq,no_inplace} [id BD] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{add,no_inplace} [id DU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DV] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | | |Elemwise{sub,no_inplace} [id DW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |     |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |     |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id DZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   |Elemwise{sub,no_inplace} [id EA] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |GRU2.hid_init [id EC] <CudaNdarrayType(float32, row)>\n |   | | |   | | | | |TensorConstant{-300} [id ED] <TensorType(int64, scalar)>\n |   | | |   | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |Shape_i{1} [id EE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |   |dec_init.W [id EF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |Rebroadcast{0} [id EG] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | |GpuDimShuffle{x,0,1} [id EH] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |   |GpuElemwise{Composite{tanh((i0 + i1))}}[(0, 0)] [id EI] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     |GpuDot22 [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | |GpuReshape{2} [id EK] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |GpuJoin [id EL] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | | |GpuAlloc{memset_0=True} [id EM] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | | | |CudaNdarrayConstant{[[[ 0.]]]} [id EN] <CudaNdarrayType(float32, (True, True, True))>\n |   | | |   | | |     | | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DV] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | | | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | | |GpuSubtensor{::, :int64:} [id EO] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |GpuDimShuffle{1,0,2} [id EP] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   | |GpuSubtensor{int64:int64:int8} [id EQ] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   |forall_inplace,gpu,scan_fn} [id ER] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | |GpuSubtensor{int64:int64:int8} [id ES] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | |GpuElemwise{Add}[(0, 0)] [id ET] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | |GpuReshape{3} [id EU] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | |GpuDot22 [id EV] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | |GpuReshape{2} [id EW] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |GpuDimShuffle{1,0,2} [id EX] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |GpuReshape{3} [id EY] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |GpuJoin [id EZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | |GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)] [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |GpuCAReduce{pre=sqr,red=add}{0,1,0} [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | | |GpuDimShuffle{1,0,2} [id FC] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |   |GpuSubtensor{int64:int64:int8} [id FD] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |forall_inplace,gpu,scan_fn} [id FE] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuSubtensor{int64:int64:int8} [id FF] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |GpuElemwise{Add}[(0, 0)] [id FG] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |GpuReshape{3} [id FH] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |GpuDot22 [id FI] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | | |GpuReshape{2} [id Q] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | | |GpuJoin [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |GRU1forw.W_in_to_resetgate [id FK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |GRU1forw.W_in_to_updategate [id FL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |GRU1forw.W_in_to_hidden_update [id FM] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |MakeVector{dtype='int64'} [id FN] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |   |Elemwise{add,no_inplace} [id FO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     |Shape_i{1} [id FP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     | |GRU1forw.W_in_to_resetgate [id FK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     |Shape_i{1} [id FQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     | |GRU1forw.W_in_to_updategate [id FL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     |Shape_i{1} [id FR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |       |GRU1forw.W_in_to_hidden_update [id FM] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |GpuDimShuffle{x,x,0} [id FS] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |   |GpuJoin [id FT] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GRU1forw.b_resetgate [id FU] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GRU1forw.b_updategate [id FV] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GRU1forw.b_hidden_update [id FW] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |ScalarFromTensor [id CD] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |ScalarFromTensor [id CG] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuSubtensor{int64:int64:int8} [id CI] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuIncSubtensor{InplaceSet;:int64:} [id FX] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |GpuAllocEmpty [id FY] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id CQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |Shape_i{1} [id FZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |   |GRU1forw.hid_init [id GA] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |Rebroadcast{0} [id GB] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |GpuDimShuffle{x,0,1} [id GC] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |   |GpuGer{inplace} [id GD] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GpuAlloc{memset_0=True} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |CudaNdarrayConstant{0.0} [id GF] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |Shape_i{1} [id FZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GpuDimShuffle{0} [id GH] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |GpuAlloc [id GI] <CudaNdarrayType(float32, col)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |   |CudaNdarrayConstant{1.0} [id GJ] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GpuDimShuffle{1} [id GK] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |       |GRU1forw.hid_init [id GA] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |Constant{1} [id GL] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuJoin [id GM] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |GRU1forw.W_hid_to_resetgate [id GN] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |GRU1forw.W_hid_to_updategate [id GO] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |GRU1forw.W_hid_to_hidden_update [id GP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |ScalarFromTensor [id GQ] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id GR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}} [id CR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |ScalarFromTensor [id GS] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id GT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}} [id CR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |GpuDimShuffle{x,x} [id GU] <CudaNdarrayType(float32, (True, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |   |GpuFromHost [id GV] <CudaNdarrayType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |     |Elemwise{Cast{float32}} [id GW] <TensorType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |       |Elemwise{sub,no_inplace} [id GX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |         |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |         |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)] [id GY] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |GpuCAReduce{pre=sqr,red=add}{0,1,0} [id GZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   | |GpuSubtensor{::, ::int64} [id HA] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |GpuDimShuffle{1,0,2} [id HB] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   | |GpuSubtensor{int64:int64:int8} [id HC] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |forall_inplace,gpu,scan_fn} [id HD] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuSubtensor{int64:int64:int64} [id HE] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |GpuElemwise{Add}[(0, 0)] [id HF] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |GpuReshape{3} [id HG] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |GpuDot22 [id HH] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |GpuReshape{2} [id Q] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |GpuJoin [id HI] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |GRU1back.W_in_to_resetgate [id HJ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |GRU1back.W_in_to_updategate [id HK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |GRU1back.W_in_to_hidden_update [id HL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |MakeVector{dtype='int64'} [id HM] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |   |Elemwise{add,no_inplace} [id HN] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     |Shape_i{1} [id HO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     | |GRU1back.W_in_to_resetgate [id HJ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     |Shape_i{1} [id HP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     | |GRU1back.W_in_to_updategate [id HK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     |Shape_i{1} [id HQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |       |GRU1back.W_in_to_hidden_update [id HL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |GpuDimShuffle{x,x,0} [id HR] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |GpuJoin [id HS] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GRU1back.b_resetgate [id HT] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GRU1back.b_updategate [id HU] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GRU1back.b_hidden_update [id HV] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id HW] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id HX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{le,no_inplace} [id HY] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |Elemwise{sub,no_inplace} [id HZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |Elemwise{add,no_inplace} [id IB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id IC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Elemwise{le,no_inplace} [id ID] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i1), i2), i2, (i1 + i1)), i1)}} [id IE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | |Elemwise{lt,no_inplace} [id IF] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Elemwise{maximum,no_inplace} [id DF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id IG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{add,no_inplace} [id IB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id IC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{le,no_inplace} [id ID] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i1), i2), i2, (i1 + i1)), i1)}} [id IE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{sub,no_inplace} [id DJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{add,no_inplace} [id DK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id IH] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id II] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{le,no_inplace} [id HY] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id IG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{sub,no_inplace} [id HZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{sub,no_inplace} [id DJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuSubtensor{int64:int64:int64} [id IK] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |GpuDimShuffle{1,0,x} [id CJ] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id HW] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id IH] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuIncSubtensor{InplaceSet;:int64:} [id IL] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |GpuAllocEmpty [id IM] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id IN] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id IO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i6 - i8), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}} [id IP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{le,no_inplace} [id IQ] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |Elemwise{sub,no_inplace} [id IR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |Elemwise{add,no_inplace} [id IT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id IU] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id IV] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, (i2 - i3)), i1, (i2 - i3)))}} [id IW] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{lt,no_inplace} [id IF] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | | |Elemwise{lt,no_inplace} [id IF] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id IZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{add,no_inplace} [id JA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |   |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id IZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id JB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id JA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id JC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{add,no_inplace} [id IT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id IU] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{le,no_inplace} [id IV] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{add,no_inplace} [id JB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, (i2 - i3)), i1, (i2 - i3)))}} [id IW] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id IZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}} [id JE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i6 - i8), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}} [id IP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{le,no_inplace} [id IQ] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id JC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{sub,no_inplace} [id IR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-2} [id DP] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{2} [id DR] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{sub,no_inplace} [id JF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id JG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |     |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |     |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Shape_i{1} [id JH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |GRU1back.hid_init [id JI] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Rebroadcast{0} [id JJ] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |GpuDimShuffle{x,0,1} [id JK] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |GpuGer{inplace} [id JL] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GpuAlloc{memset_0=True} [id JM] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     | |CudaNdarrayConstant{0.0} [id GF] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     | |Shape_i{1} [id JH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GpuDimShuffle{0} [id GH] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GpuDimShuffle{1} [id JN] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |       |GRU1back.hid_init [id JI] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Constant{1} [id GL] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuJoin [id JO] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |GRU1back.W_hid_to_resetgate [id JP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |GRU1back.W_hid_to_updategate [id JQ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |GRU1back.W_hid_to_hidden_update [id JR] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |ScalarFromTensor [id JS] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id JT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id JG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id IO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |ScalarFromTensor [id JU] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id JV] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id IO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |GpuDimShuffle{x,x} [id JW] <CudaNdarrayType(float32, (True, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |     |GpuFromHost [id JX] <CudaNdarrayType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |       |Elemwise{Composite{Cast{float32}((Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - (i1 + i2))}(i0, i1, Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2)), i2, i3), i2), Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - (i1 + i2))}(i0, i1, Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2)), i2, i3), i2), Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2))))}} [id JY] <TensorType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |         |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |         |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id JG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |         |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |         |Elemwise{sub,no_inplace} [id JF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |MakeVector{dtype='int64'} [id JZ] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |     |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |     |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |     |TensorConstant{600} [id KA] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |MakeVector{dtype='int64'} [id KB] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   |Elemwise{mul,no_inplace} [id KC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   |TensorConstant{600} [id KA] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |GpuJoin [id KD] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | |   |GRU2.W_in_to_resetgate [id KE] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | |   |GRU2.W_in_to_updategate [id KF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | |   |GRU2.W_in_to_hidden_update [id KG] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | |MakeVector{dtype='int64'} [id KH] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |   |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |   |Elemwise{add,no_inplace} [id KI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |     |Shape_i{1} [id KJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |     | |GRU2.W_in_to_resetgate [id KE] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | |     |Shape_i{1} [id KK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |     | |GRU2.W_in_to_updategate [id KF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | |     |Shape_i{1} [id KL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |       |GRU2.W_in_to_hidden_update [id KG] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | |GpuDimShuffle{x,x,0} [id KM] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |     | | |   |   | | |   |GpuJoin [id KN] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | |     |GRU2.b_resetgate [id KO] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | |     |GRU2.b_updategate [id KP] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | |     |GRU2.b_hidden_update [id KQ] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | |ScalarFromTensor [id KR] <int64> ''   \n |   | | |   | | |     | | |   |   | | | |Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}} [id KS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | |ScalarFromTensor [id KT] <int64> ''   \n |   | | |   | | |     | | |   |   | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | |GpuIncSubtensor{InplaceSet;:int64:} [id KU] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | |GpuAllocEmpty [id KV] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id KW] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id KX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id KY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{lt,no_inplace} [id KZ] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id LA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |Elemwise{le,no_inplace} [id LB] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |Elemwise{sub,no_inplace} [id LC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id LD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |Elemwise{add,no_inplace} [id LE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id LF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id LG] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, (i0 - i1)), i0, (i0 - i1))}} [id LH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id LI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id LI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id LJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id LK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id LE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id LF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id LG] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id LJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, (i0 - i1)), i0, (i0 - i1))}} [id LH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id LI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id LD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id LD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id LA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}} [id LM] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id KY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{le,no_inplace} [id LB] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}} [id LN] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{add,no_inplace} [id LO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id LK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{sub,no_inplace} [id LC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{-2} [id DP] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{minimum,no_inplace} [id LP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{add,no_inplace} [id LO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{2} [id DR] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |Elemwise{sub,no_inplace} [id EA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |Rebroadcast{0} [id LQ] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | |GpuDimShuffle{x,0,1} [id LR] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |     | | |   |   | | |   |GpuGer{inplace} [id LS] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | |     |GpuAlloc{memset_0=True} [id LT] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | |     | |CudaNdarrayConstant{0.0} [id GF] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | |     | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |     | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |     |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | |     |GpuDimShuffle{0} [id LU] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | |     | |GpuAlloc [id LV] <CudaNdarrayType(float32, col)> ''   \n |   | | |   | | |     | | |   |   | | |     |   |CudaNdarrayConstant{1.0} [id GJ] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | |     |   |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | |     |GpuDimShuffle{1} [id LW] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | |       |GRU2.hid_init [id EC] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | |Constant{1} [id GL] <int64>\n |   | | |   | | |     | | |   |   | |GpuJoin [id LX] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   |   |GRU2.W_hid_to_resetgate [id LY] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   |   |GRU2.W_hid_to_updategate [id LZ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   |   |GRU2.W_hid_to_hidden_update [id MA] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   |ScalarFromTensor [id MB] <int64> ''   \n |   | | |   | | |     | | |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id MC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id KX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |ScalarFromTensor [id MD] <int64> ''   \n |   | | |   | | |     | | |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id ME] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id KX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |MakeVector{dtype='int64'} [id MF] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | |   |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | |   |TensorConstant{300} [id MG] <TensorType(int64, scalar)>\n |   | | |   | | |     | |dec_init.W [id EF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     |GpuDimShuffle{x,0} [id MH] <CudaNdarrayType(float32, row)> ''   \n |   | | |   | | |       |dec_init.b [id MI] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |Constant{1} [id GL] <int64>\n |   | | |   | |GpuJoin [id MJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   |   |GRUdec.W_hid_to_resetgate [id MK] <CudaNdarrayType(float32, matrix)>\n |   | | |   |   |GRUdec.W_hid_to_updategate [id ML] <CudaNdarrayType(float32, matrix)>\n |   | | |   |   |GRUdec.W_hid_to_hidden_update [id MM] <CudaNdarrayType(float32, matrix)>\n |   | | |   |ScalarFromTensor [id GQ] <int64> ''   \n |   | | |   |ScalarFromTensor [id GS] <int64> ''   \n |   | | |   |Constant{1} [id CH] <int8>\n |   | | |MakeVector{dtype='int64'} [id MN] <TensorType(int64, vector)> ''   \n |   | |   |Elemwise{mul,no_inplace} [id BJ] <TensorType(int64, scalar)> ''   \n |   | |   |TensorConstant{300} [id MG] <TensorType(int64, scalar)>\n |   | |h0.W [id MO] <CudaNdarrayType(float32, matrix)>\n |   |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   |GpuReshape{2} [id MP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuAdvancedSubtensor1 [id T] <CudaNdarrayType(float32, matrix)> ''   \n |   | |MakeVector{dtype='int64'} [id MN] <TensorType(int64, vector)> ''   \n |   |e0.W [id MQ] <CudaNdarrayType(float32, matrix)>\n |   |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |GpuDimShuffle{1,0} [id MR] <CudaNdarrayType(float32, matrix)> ''   \n   |GpuAdvancedSubtensor1 [id MS] <CudaNdarrayType(float32, matrix)> ''   \n     |GpuDimShuffle{1,0} [id MT] <CudaNdarrayType(float32, matrix)> ''   \n     | |soft.W [id MU] <CudaNdarrayType(float32, matrix)>\n     |RepeatOp{axis=None} [id MV] <TensorType(int64, vector)> ''   \n       |Subtensor{int64} [id MW] <TensorType(int64, vector)> ''   \n       | |Nonzero [id MX] <TensorType(int64, matrix)> ''   \n       | | |Reshape{1} [id MY] <TensorType(int64, vector)> ''   \n       | |   |MultinomialFromUniform{int64} [id MZ] <TensorType(int64, row)> ''   \n       | |   | |InplaceDimShuffle{x,0} [id NA] <TensorType(float64, row)> ''   \n       | |   | | |soft.p [id NB] <TensorType(float64, vector)>\n       | |   | |HostFromGpu [id NC] <TensorType(float32, vector)> ''   \n       | |   | | |GPU_mrg_uniform{CudaNdarrayType(float32, vector),inplace}.1 [id ND] <CudaNdarrayType(float32, vector)> ''   \n       | |   | |   |<CudaNdarrayType(float32, vector)> [id NE] <CudaNdarrayType(float32, vector)>\n       | |   | |   |TensorConstant{(1,) of 1000} [id NF] <TensorType(int64, vector)>\n       | |   | |Constant{1000} [id NG] <int16>\n       | |   |TensorConstant{(1,) of -1} [id BA] <TensorType(int64, (True,))>\n       | |Constant{0} [id NH] <int64>\n       |AdvancedSubtensor1 [id NI] <TensorType(int64, vector)> ''   \n         |Reshape{1} [id MY] <TensorType(int64, vector)> ''   \n         |Subtensor{int64} [id MW] <TensorType(int64, vector)> ''   \n\nInner graphs of the scan ops:\n\nforall_inplace,gpu,scan_fn} [id J] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{Switch(i0, (((i1 - Composite{scalar_sigmoid((i0 + i1))}(i2, i3)) * i4) + (Composite{scalar_sigmoid((i0 + i1))}(i2, i3) * tanh((i5 + (scalar_sigmoid((i6 + i7)) * i8))))), i4)},no_inplace} [id NJ] <CudaNdarrayType(float32, matrix)> ''   \n > |<CudaNdarrayType(float32, col)> [id NK] <CudaNdarrayType(float32, col)> -> [id CI]\n > |CudaNdarrayConstant{[[ 1.]]} [id NL] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id NM] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id NN] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id NO] <CudaNdarrayType(float32, matrix)> -> [id CO]\n > | | |<CudaNdarrayType(float32, matrix)> [id NP] <CudaNdarrayType(float32, matrix)> -> [id MJ]\n > | |Constant{300} [id NQ] <int64>\n > | |Constant{600} [id NR] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NS] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id M]\n > | |Constant{300} [id NQ] <int64>\n > | |Constant{600} [id NR] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id NO] <CudaNdarrayType(float32, matrix)> -> [id CO]\n > |GpuSubtensor{::, int64:int64:} [id NU] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id M]\n > | |Constant{600} [id NR] <int64>\n > | |Constant{900} [id NV] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NW] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id NN] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id NX] <int64>\n > | |Constant{300} [id NQ] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NY] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id M]\n > | |Constant{0} [id NX] <int64>\n > | |Constant{300} [id NQ] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id NR] <int64>\n >   |Constant{900} [id NV] <int64>\n\nforall_inplace,gpu,scan_fn} [id ER] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{(((i0 - Composite{scalar_sigmoid((i0 + i1))}(i1, i2)) * i3) + (Composite{scalar_sigmoid((i0 + i1))}(i1, i2) * tanh((i4 + (scalar_sigmoid((i5 + i6)) * i7)))))},no_inplace} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n > |CudaNdarrayConstant{[[ 1.]]} [id OB] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id OC] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OD] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id OE] <CudaNdarrayType(float32, matrix)> -> [id KU]\n > | | |<CudaNdarrayType(float32, matrix)> [id OF] <CudaNdarrayType(float32, matrix)> -> [id LX]\n > | |Constant{300} [id OG] <int64>\n > | |Constant{600} [id OH] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OI] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id OJ] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | |Constant{300} [id OG] <int64>\n > | |Constant{600} [id OH] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id OE] <CudaNdarrayType(float32, matrix)> -> [id KU]\n > |GpuSubtensor{::, int64:int64:} [id OK] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id OJ] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | |Constant{600} [id OH] <int64>\n > | |Constant{900} [id OL] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OM] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OD] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id ON] <int64>\n > | |Constant{300} [id OG] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OO] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id OJ] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | |Constant{0} [id ON] <int64>\n > | |Constant{300} [id OG] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OP] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id OD] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id OH] <int64>\n >   |Constant{900} [id OL] <int64>\n\nforall_inplace,gpu,scan_fn} [id FE] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{Switch(i0, (((i1 - Composite{scalar_sigmoid((i0 + i1))}(i2, i3)) * i4) + (Composite{scalar_sigmoid((i0 + i1))}(i2, i3) * tanh((i5 + (scalar_sigmoid((i6 + i7)) * i8))))), i4)},no_inplace} [id OQ] <CudaNdarrayType(float32, matrix)> ''   \n > |<CudaNdarrayType(float32, col)> [id OR] <CudaNdarrayType(float32, col)> -> [id CI]\n > |CudaNdarrayConstant{[[ 1.]]} [id OS] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OU] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id OV] <CudaNdarrayType(float32, matrix)> -> [id FX]\n > | | |<CudaNdarrayType(float32, matrix)> [id OW] <CudaNdarrayType(float32, matrix)> -> [id GM]\n > | |Constant{300} [id OX] <int64>\n > | |Constant{600} [id OY] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OZ] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PA] <CudaNdarrayType(float32, matrix)> -> [id FF]\n > | |Constant{300} [id OX] <int64>\n > | |Constant{600} [id OY] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id OV] <CudaNdarrayType(float32, matrix)> -> [id FX]\n > |GpuSubtensor{::, int64:int64:} [id PB] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PA] <CudaNdarrayType(float32, matrix)> -> [id FF]\n > | |Constant{600} [id OY] <int64>\n > | |Constant{900} [id PC] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PD] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OU] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id PE] <int64>\n > | |Constant{300} [id OX] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PF] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PA] <CudaNdarrayType(float32, matrix)> -> [id FF]\n > | |Constant{0} [id PE] <int64>\n > | |Constant{300} [id OX] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PG] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id OU] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id OY] <int64>\n >   |Constant{900} [id PC] <int64>\n\nforall_inplace,gpu,scan_fn} [id HD] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{Switch(i0, (((i1 - Composite{scalar_sigmoid((i0 + i1))}(i2, i3)) * i4) + (Composite{scalar_sigmoid((i0 + i1))}(i2, i3) * tanh((i5 + (scalar_sigmoid((i6 + i7)) * i8))))), i4)},no_inplace} [id PH] <CudaNdarrayType(float32, matrix)> ''   \n > |<CudaNdarrayType(float32, col)> [id PI] <CudaNdarrayType(float32, col)> -> [id IK]\n > |CudaNdarrayConstant{[[ 1.]]} [id PJ] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id PK] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id PL] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id PM] <CudaNdarrayType(float32, matrix)> -> [id IL]\n > | | |<CudaNdarrayType(float32, matrix)> [id PN] <CudaNdarrayType(float32, matrix)> -> [id JO]\n > | |Constant{300} [id PO] <int64>\n > | |Constant{600} [id PP] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PQ] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PR] <CudaNdarrayType(float32, matrix)> -> [id HE]\n > | |Constant{300} [id PO] <int64>\n > | |Constant{600} [id PP] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id PM] <CudaNdarrayType(float32, matrix)> -> [id IL]\n > |GpuSubtensor{::, int64:int64:} [id PS] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PR] <CudaNdarrayType(float32, matrix)> -> [id HE]\n > | |Constant{600} [id PP] <int64>\n > | |Constant{900} [id PT] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PU] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id PL] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id PV] <int64>\n > | |Constant{300} [id PO] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PW] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PR] <CudaNdarrayType(float32, matrix)> -> [id HE]\n > | |Constant{0} [id PV] <int64>\n > | |Constant{300} [id PO] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PX] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id PL] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id PP] <int64>\n >   |Constant{900} [id PT] <int64>\n\nStorage map footprint:\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 400004), ElemSize: 4 Byte(s), TotalSize: 480004800 Byte(s)\n - emb.E, Shared Input, Shape: (400004, 300), ElemSize: 4 Byte(s), TotalSize: 480004800 Byte(s)\n - soft.W, Shared Input, Shape: (300, 400004), ElemSize: 4 Byte(s), TotalSize: 480004800 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (22, 3000, 900), ElemSize: 4 Byte(s), TotalSize: 237600000 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (22, 3000, 900), ElemSize: 4 Byte(s), TotalSize: 237600000 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (22, 3000, 900), ElemSize: 4 Byte(s), TotalSize: 237600000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (23, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 82800000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (23, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 82800000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (23, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 82800000 Byte(s)\n - GpuReshape{2}.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuReshape{2}.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuSubtensor{int64:int64:int8}.0, Shape: (22, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuReshape{2}.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuAdvancedSubtensor1.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuSubtensor{::, ::int64}.0, Shape: (3000, 22, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuElemwise{Add}[(0, 1)].0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (2, 1500, 900), ElemSize: 4 Byte(s), TotalSize: 10800000 Byte(s)\n - GpuReshape{2}.0, Shape: (3000, 600), ElemSize: 4 Byte(s), TotalSize: 7200000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (3, 1500, 300), ElemSize: 4 Byte(s), TotalSize: 5400000 Byte(s)\n - GpuElemwise{Composite{tanh((i0 + i1))}}[(0, 0)].0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)].0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - GpuReshape{2}.0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)].0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - soft.p, Shared Input, Shape: (400004,), ElemSize: 8 Byte(s), TotalSize: 3200032 Byte(s)\n - GpuJoin.0, Shape: (600, 900), ElemSize: 4 Byte(s), TotalSize: 2160000 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (400004,), ElemSize: 4 Byte(s), TotalSize: 1600016 Byte(s)\n - soft.b, Shared Input, Shape: (400004,), ElemSize: 4 Byte(s), TotalSize: 1600016 Byte(s)\n - GpuAdvancedSubtensor1.0, Shape: (1000, 300), ElemSize: 4 Byte(s), TotalSize: 1200000 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (300, 1000), ElemSize: 4 Byte(s), TotalSize: 1200000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - GRU2.W_in_to_resetgate, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - GRU2.W_in_to_updategate, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - GRU2.W_in_to_hidden_update, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (66000,), ElemSize: 8 Byte(s), TotalSize: 528000 Byte(s)\n - Elemwise{Composite{(i0 - log((i1 * i2)))}}.0, Shape: (66000, 1), ElemSize: 8 Byte(s), TotalSize: 528000 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (66000,), ElemSize: 8 Byte(s), TotalSize: 528000 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - GPU_mrg_uniform{CudaNdarrayType(float32, vector),inplace}.0, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_in_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_in_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - dec_init.W, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU2.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU2.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU2.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - e0.W, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - h0.W, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_in_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_in_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_in_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_in_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_in_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_in_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_in_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - inputs, Input, Shape: (1500, 2, 22), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - targets, Input, Shape: (1500, 2, 22), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - Reshape{1}.0, Shape: (66000,), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - GpuDimShuffle{1,0,x}.0, Shape: (22, 3000, 1), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - input_mask, Input, Shape: (1500, 2, 22), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - RepeatOp{axis=None}.0, Shape: (1000,), ElemSize: 8 Byte(s), TotalSize: 8000 Byte(s)\n - AdvancedSubtensor1.0, Shape: (1000,), ElemSize: 8 Byte(s), TotalSize: 8000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (3, 300), ElemSize: 4 Byte(s), TotalSize: 3600 Byte(s)\n - emb.W, Shared Input, Shape: (3, 300), ElemSize: 4 Byte(s), TotalSize: 3600 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.hid_init, Shared Input, Shape: (1, 300), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - dec_init.b, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - h0.b, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRUdec.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRUdec.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRUdec.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.hid_init, Shared Input, Shape: (1, 300), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.hid_init, Shared Input, Shape: (1, 300), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{[     0 40..02 400003]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // (i4 * i1 * i5)), i6)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{300}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{neg,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1) of 0.0}, Shape: (1, 1), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, Switch(LT((i1 + i1), i2), i2, (i1 + i1)), i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i6 - i8), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1.0}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-600}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1, 1) of 0.0}, Shape: (1, 1, 1), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{600}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of 1000}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{-300}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1) of 1000.0}, Shape: (1, 1), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.01]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[  9.99999997e-07]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999997e-07]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.00999999977648}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.01]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[[ 0.]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{1000}, Shape: (), ElemSize: 2 Byte(s), TotalSize: 2.0 Byte(s)\n - Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{le,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{eq,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{le,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 2956204302.0 Byte(s) 2.753 GB\n TotalSize inputs: 1469219734.0 Byte(s) 1.368 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b65c212e59c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_scores\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmax_epochs_wo_improvement\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlast_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_scores\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'\\n\\nStarting epoch {}...\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtrain_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mval_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'\\nTraining loss:   {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/scratch/1/i258346/masters_thesis/generators/HRED/HRED.pyc\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, train_data, batch_size, log_interval)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mnum_batch_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mnum_training_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 264000000 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22(GpuElemwise{Add}[(0, 1)].0, GpuDimShuffle{1,0}.0)\nToposort index: 562\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(66000, 300), (300, 1000)]\nInputs strides: [(300, 1), (1, 300)]\nInputs values: ['not shown', 'not shown']\nInputs type_num: ['', '']\nOutputs clients: [[GpuElemwise{add,no_inplace}(GpuDot22.0, GpuDimShuffle{x,0}.0)]]\n\nDebugprint of the apply node: \nGpuDot22 [id A] <CudaNdarrayType(float32, matrix)> ''   \n |GpuElemwise{Add}[(0, 1)] [id B] <CudaNdarrayType(float32, matrix)> ''   \n | |GpuDimShuffle{x,0} [id C] <CudaNdarrayType(float32, row)> ''   \n | | |h0.b [id D] <CudaNdarrayType(float32, vector)>\n | |GpuGemm{inplace} [id E] <CudaNdarrayType(float32, matrix)> ''   \n |   |GpuDot22 [id F] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuReshape{2} [id G] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |GpuDimShuffle{1,0,2} [id H] <CudaNdarrayType(float32, 3D)> ''   \n |   | | | |GpuSubtensor{int64:int64:int8} [id I] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   |forall_inplace,gpu,scan_fn} [id J] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | |GpuSubtensor{int64:int64:int8} [id M] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |GpuElemwise{Add}[(0, 0)] [id N] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | |GpuReshape{3} [id O] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | | |GpuDot22 [id P] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | |GpuReshape{2} [id Q] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | | |GpuDimShuffle{1,0,2} [id R] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | | | | | |GpuReshape{3} [id S] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | | | | |   |GpuAdvancedSubtensor1 [id T] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | | |   | |GpuAdvancedIncSubtensor1_dev20{no_inplace,set} [id U] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | | | |   | | |emb.E [id V] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | | | |   | | |emb.W [id W] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | | | |   | | |TensorConstant{[     0 40..02 400003]} [id X] <TensorType(int64, vector)>\n |   | | |   | | | | | | |   | |Elemwise{Cast{int64}} [id Y] <TensorType(int64, vector)> ''   \n |   | | |   | | | | | | |   |   |Reshape{1} [id Z] <TensorType(int32, vector)> ''   \n |   | | |   | | | | | | |   |     |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | | | | | | |   |     |TensorConstant{(1,) of -1} [id BA] <TensorType(int64, (True,))>\n |   | | |   | | | | | | |   |MakeVector{dtype='int64'} [id BB] <TensorType(int64, vector)> ''   \n |   | | |   | | | | | | |     |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Elemwise{eq,no_inplace} [id BD] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | |     | | |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | | | |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | | | | | | |     | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | |   |inputs [id L] <TensorType(int32, 3D)>\n |   | | |   | | | | | | |     | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |     | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Elemwise{neg,no_inplace} [id BI] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | | |Elemwise{mul,no_inplace} [id BJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |   |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     | |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |     |Shape_i{1} [id BK] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |       |emb.E [id V] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | | | |MakeVector{dtype='int64'} [id BL] <TensorType(int64, vector)> ''   \n |   | | |   | | | | | |   |Elemwise{mul,no_inplace} [id BM] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   |Shape_i{1} [id BK] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |GpuJoin [id BN] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | |   |GRUdec.W_in_to_resetgate [id BP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | |   |GRUdec.W_in_to_updategate [id BQ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | |   |GRUdec.W_in_to_hidden_update [id BR] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | | |MakeVector{dtype='int64'} [id BS] <TensorType(int64, vector)> ''   \n |   | | |   | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |   |Elemwise{add,no_inplace} [id BT] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |     |Shape_i{1} [id BU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |     | |GRUdec.W_in_to_resetgate [id BP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | |     |Shape_i{1} [id BV] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |     | |GRUdec.W_in_to_updategate [id BQ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | |     |Shape_i{1} [id BW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |       |GRUdec.W_in_to_hidden_update [id BR] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | | |GpuDimShuffle{x,x,0} [id BX] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |   |GpuJoin [id BY] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     |GRUdec.b_resetgate [id CA] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     |GRUdec.b_updategate [id CB] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     |GRUdec.b_hidden_update [id CC] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |ScalarFromTensor [id CD] <int64> ''   \n |   | | |   | | | |Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}} [id CE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |ScalarFromTensor [id CG] <int64> ''   \n |   | | |   | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |Constant{1} [id CH] <int8>\n |   | | |   | |GpuSubtensor{int64:int64:int8} [id CI] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |GpuDimShuffle{1,0,x} [id CJ] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | | |GpuReshape{2} [id CK] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |   |GpuFromHost [id CL] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |   | |input_mask [id CM] <TensorType(float32, 3D)>\n |   | | |   | | |   |MakeVector{dtype='int64'} [id CN] <TensorType(int64, vector)> ''   \n |   | | |   | | |     |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |ScalarFromTensor [id CD] <int64> ''   \n |   | | |   | | |ScalarFromTensor [id CG] <int64> ''   \n |   | | |   | | |Constant{1} [id CH] <int8>\n |   | | |   | |GpuIncSubtensor{InplaceSet;:int64:} [id CO] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |GpuAllocEmpty [id CP] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id CQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}} [id CR] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CS] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{lt,no_inplace} [id CT] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |Elemwise{le,no_inplace} [id CV] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | | | |Elemwise{sub,no_inplace} [id CW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |Elemwise{add,no_inplace} [id CY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id DA] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id DB] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |     |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | | | |   | |     |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | | |   |Elemwise{maximum,no_inplace} [id DF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   | |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | | | |   |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id DI] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id CY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id DA] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id DB] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DC] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{sub,no_inplace} [id DJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | |   | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id DK] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}} [id DM] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CS] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{le,no_inplace} [id CV] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}} [id DN] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | | | | |Elemwise{add,no_inplace} [id DO] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id DI] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | | | |Elemwise{sub,no_inplace} [id CW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{-2} [id DP] <TensorType(int64, scalar)>\n |   | | |   | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{minimum,no_inplace} [id DQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |Elemwise{add,no_inplace} [id DO] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | | |TensorConstant{2} [id DR] <TensorType(int64, scalar)>\n |   | | |   | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DS] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | |   |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // (i4 * i1 * i5)), i6)}} [id DT] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{eq,no_inplace} [id BD] <TensorType(bool, scalar)> ''   \n |   | | |   | | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{add,no_inplace} [id DU] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DV] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | | |Elemwise{sub,no_inplace} [id DW] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |     |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | | | | |     |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id DZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   |Elemwise{sub,no_inplace} [id EA] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DY] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | | | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | | |GRU2.hid_init [id EC] <CudaNdarrayType(float32, row)>\n |   | | |   | | | | |TensorConstant{-300} [id ED] <TensorType(int64, scalar)>\n |   | | |   | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | | | |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | | |Shape_i{1} [id EE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |   |dec_init.W [id EF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |Rebroadcast{0} [id EG] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | | |GpuDimShuffle{x,0,1} [id EH] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |   |GpuElemwise{Composite{tanh((i0 + i1))}}[(0, 0)] [id EI] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     |GpuDot22 [id EJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | |GpuReshape{2} [id EK] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |GpuJoin [id EL] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | | |GpuAlloc{memset_0=True} [id EM] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | | | |CudaNdarrayConstant{[[[ 0.]]]} [id EN] <CudaNdarrayType(float32, (True, True, True))>\n |   | | |   | | |     | | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DV] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | | | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | | |GpuSubtensor{::, :int64:} [id EO] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |GpuDimShuffle{1,0,2} [id EP] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   | |GpuSubtensor{int64:int64:int8} [id EQ] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   |forall_inplace,gpu,scan_fn} [id ER] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | |GpuSubtensor{int64:int64:int8} [id ES] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | |GpuElemwise{Add}[(0, 0)] [id ET] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | |GpuReshape{3} [id EU] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | |GpuDot22 [id EV] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | |GpuReshape{2} [id EW] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |GpuDimShuffle{1,0,2} [id EX] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |GpuReshape{3} [id EY] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |GpuJoin [id EZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | |GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)] [id FA] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |GpuCAReduce{pre=sqr,red=add}{0,1,0} [id FB] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | | |GpuDimShuffle{1,0,2} [id FC] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |   |GpuSubtensor{int64:int64:int8} [id FD] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |forall_inplace,gpu,scan_fn} [id FE] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuSubtensor{int64:int64:int8} [id FF] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |GpuElemwise{Add}[(0, 0)] [id FG] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |GpuReshape{3} [id FH] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |GpuDot22 [id FI] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | | |GpuReshape{2} [id Q] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | | |GpuJoin [id FJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |GRU1forw.W_in_to_resetgate [id FK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |GRU1forw.W_in_to_updategate [id FL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |   |GRU1forw.W_in_to_hidden_update [id FM] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | | |MakeVector{dtype='int64'} [id FN] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |   |Elemwise{add,no_inplace} [id FO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     |Shape_i{1} [id FP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     | |GRU1forw.W_in_to_resetgate [id FK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     |Shape_i{1} [id FQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     | |GRU1forw.W_in_to_updategate [id FL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |     |Shape_i{1} [id FR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |       |GRU1forw.W_in_to_hidden_update [id FM] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |GpuDimShuffle{x,x,0} [id FS] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |   |GpuJoin [id FT] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GRU1forw.b_resetgate [id FU] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GRU1forw.b_updategate [id FV] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GRU1forw.b_hidden_update [id FW] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |ScalarFromTensor [id CD] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |ScalarFromTensor [id CG] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuSubtensor{int64:int64:int8} [id CI] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuIncSubtensor{InplaceSet;:int64:} [id FX] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |GpuAllocEmpty [id FY] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id CQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |Shape_i{1} [id FZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |   |GRU1forw.hid_init [id GA] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |Rebroadcast{0} [id GB] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | | |GpuDimShuffle{x,0,1} [id GC] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |   |GpuGer{inplace} [id GD] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GpuAlloc{memset_0=True} [id GE] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |CudaNdarrayConstant{0.0} [id GF] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |Shape_i{1} [id FZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GpuDimShuffle{0} [id GH] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     | |GpuAlloc [id GI] <CudaNdarrayType(float32, col)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |   |CudaNdarrayConstant{1.0} [id GJ] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |     |GpuDimShuffle{1} [id GK] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |       |GRU1forw.hid_init [id GA] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | | |Constant{1} [id GL] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |GpuJoin [id GM] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |GRU1forw.W_hid_to_resetgate [id GN] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |GRU1forw.W_hid_to_updategate [id GO] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |GRU1forw.W_hid_to_hidden_update [id GP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |ScalarFromTensor [id GQ] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id GR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}} [id CR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |ScalarFromTensor [id GS] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id GT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}} [id CR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | | |     |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | | | | | | |   | | |GpuDimShuffle{x,x} [id GU] <CudaNdarrayType(float32, (True, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |   |GpuFromHost [id GV] <CudaNdarrayType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |     |Elemwise{Cast{float32}} [id GW] <TensorType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |       |Elemwise{sub,no_inplace} [id GX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |         |Elemwise{add,no_inplace} [id DL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |         |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   | |GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)] [id GY] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |GpuCAReduce{pre=sqr,red=add}{0,1,0} [id GZ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   | |GpuSubtensor{::, ::int64} [id HA] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |GpuDimShuffle{1,0,2} [id HB] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   | |GpuSubtensor{int64:int64:int8} [id HC] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |forall_inplace,gpu,scan_fn} [id HD] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuSubtensor{int64:int64:int64} [id HE] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |GpuElemwise{Add}[(0, 0)] [id HF] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |GpuReshape{3} [id HG] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |GpuDot22 [id HH] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |GpuReshape{2} [id Q] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |GpuJoin [id HI] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |GRU1back.W_in_to_resetgate [id HJ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |GRU1back.W_in_to_updategate [id HK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |GRU1back.W_in_to_hidden_update [id HL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |MakeVector{dtype='int64'} [id HM] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |   |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |   |Elemwise{add,no_inplace} [id HN] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     |Shape_i{1} [id HO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     | |GRU1back.W_in_to_resetgate [id HJ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     |Shape_i{1} [id HP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     | |GRU1back.W_in_to_updategate [id HK] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |     |Shape_i{1} [id HQ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |       |GRU1back.W_in_to_hidden_update [id HL] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |GpuDimShuffle{x,x,0} [id HR] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |GpuJoin [id HS] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GRU1back.b_resetgate [id HT] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GRU1back.b_updategate [id HU] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GRU1back.b_hidden_update [id HV] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id HW] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id HX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{le,no_inplace} [id HY] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |Elemwise{sub,no_inplace} [id HZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |Elemwise{add,no_inplace} [id IB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id IC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Elemwise{le,no_inplace} [id ID] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i1), i2), i2, (i1 + i1)), i1)}} [id IE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | |Elemwise{lt,no_inplace} [id IF] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Elemwise{maximum,no_inplace} [id DF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id IG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{add,no_inplace} [id IB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4), i3), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Switch(i0, i1, i2), i1, i3), i1, i4))}} [id IC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{le,no_inplace} [id ID] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{add,no_inplace} [id DG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i1), i2), i2, (i1 + i1)), i1)}} [id IE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{sub,no_inplace} [id DJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{add,no_inplace} [id DK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id IH] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id II] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{le,no_inplace} [id HY] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum(i5, i2)))}(i2, i3, (i4 - i5), i5, i6, i7), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10)}} [id IG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{sub,no_inplace} [id HZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Elemwise{sub,no_inplace} [id DJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |Shape_i{2} [id K] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuSubtensor{int64:int64:int64} [id IK] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |GpuDimShuffle{1,0,x} [id CJ] <CudaNdarrayType(float32, (False, False, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id HW] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |ScalarFromTensor [id IH] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuIncSubtensor{InplaceSet;:int64:} [id IL] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |GpuAllocEmpty [id IM] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id IN] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id IO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i6 - i8), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}} [id IP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{le,no_inplace} [id IQ] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |Elemwise{sub,no_inplace} [id IR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |Elemwise{add,no_inplace} [id IT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id IU] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id IV] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, (i2 - i3)), i1, (i2 - i3)))}} [id IW] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{lt,no_inplace} [id IF] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | | |Elemwise{lt,no_inplace} [id IF] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id IZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | | |Elemwise{add,no_inplace} [id JA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |   |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id IZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id JB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id JA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id JC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{add,no_inplace} [id IT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id IU] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{le,no_inplace} [id IV] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{add,no_inplace} [id JB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i1, (i2 - i3)), i1, (i2 - i3)))}} [id IW] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id IZ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id IS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}} [id JE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i6 - i8), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}} [id IP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{le,no_inplace} [id IQ] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id JC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{sub,no_inplace} [id IR] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-2} [id DP] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{switch,no_inplace} [id IY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |TensorConstant{2} [id DR] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | | |Elemwise{sub,no_inplace} [id JF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id JG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |     |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |     |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |Shape_i{1} [id JH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |GRU1back.hid_init [id JI] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Rebroadcast{0} [id JJ] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | | |GpuDimShuffle{x,0,1} [id JK] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |   |GpuGer{inplace} [id JL] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GpuAlloc{memset_0=True} [id JM] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     | |CudaNdarrayConstant{0.0} [id GF] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     | |Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}} [id BC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     | |Shape_i{1} [id JH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GpuDimShuffle{0} [id GH] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |     |GpuDimShuffle{1} [id JN] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |       |GRU1back.hid_init [id JI] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | | |Constant{1} [id GL] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |GpuJoin [id JO] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |GRU1back.W_hid_to_resetgate [id JP] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |GRU1back.W_hid_to_updategate [id JQ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |GRU1back.W_hid_to_hidden_update [id JR] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |ScalarFromTensor [id JS] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id JT] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id JG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id IO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |ScalarFromTensor [id JU] <int64> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id JV] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{sub,no_inplace} [id DD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id IO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |   |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |   |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |   |   | | | | | | |   |   |GpuDimShuffle{x,x} [id JW] <CudaNdarrayType(float32, (True, True))> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |     |GpuFromHost [id JX] <CudaNdarrayType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |       |Elemwise{Composite{Cast{float32}((Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - (i1 + i2))}(i0, i1, Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2)), i2, i3), i2), Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - (i1 + i2))}(i0, i1, Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2)), i2, i3), i2), Composite{Switch(LT((i0 - i1), i2), i2, (i0 - i1))}(i0, i1, i2))))}} [id JY] <TensorType(float32, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |         |Elemwise{add,no_inplace} [id JD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |         |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id JG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |         |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |   |         |Elemwise{sub,no_inplace} [id JF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |   |MakeVector{dtype='int64'} [id JZ] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |     |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |     |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |     |TensorConstant{600} [id KA] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |MakeVector{dtype='int64'} [id KB] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   |Elemwise{mul,no_inplace} [id KC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |   |TensorConstant{600} [id KA] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |GpuJoin [id KD] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | | | |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | |   |GRU2.W_in_to_resetgate [id KE] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | |   |GRU2.W_in_to_updategate [id KF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | |   |GRU2.W_in_to_hidden_update [id KG] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | | |MakeVector{dtype='int64'} [id KH] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | | |   |   | | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |   |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |   |Elemwise{add,no_inplace} [id KI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |     |Shape_i{1} [id KJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |     | |GRU2.W_in_to_resetgate [id KE] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | |     |Shape_i{1} [id KK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |     | |GRU2.W_in_to_updategate [id KF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | |     |Shape_i{1} [id KL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |       |GRU2.W_in_to_hidden_update [id KG] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   | | | |GpuDimShuffle{x,x,0} [id KM] <CudaNdarrayType(float32, (True, True, False))> ''   \n |   | | |   | | |     | | |   |   | | |   |GpuJoin [id KN] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | |     |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | |     |GRU2.b_resetgate [id KO] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | |     |GRU2.b_updategate [id KP] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | |     |GRU2.b_hidden_update [id KQ] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |     | | |   |   | | |ScalarFromTensor [id KR] <int64> ''   \n |   | | |   | | |     | | |   |   | | | |Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}} [id KS] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | |ScalarFromTensor [id KT] <int64> ''   \n |   | | |   | | |     | | |   |   | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |   | |GpuIncSubtensor{InplaceSet;:int64:} [id KU] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | |GpuAllocEmpty [id KV] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id KW] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id KX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id KY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{lt,no_inplace} [id KZ] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id LA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |Elemwise{le,no_inplace} [id LB] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |Elemwise{sub,no_inplace} [id LC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id LD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |Elemwise{add,no_inplace} [id LE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id LF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id LG] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, (i0 - i1)), i0, (i0 - i1))}} [id LH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id LI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |   |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id LI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id LJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id LK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id LE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id LF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id LG] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id LJ] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, (i0 - i1)), i0, (i0 - i1))}} [id LH] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{sub,no_inplace} [id LL] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id LI] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |   |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id LD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id LD] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{0} [id CF] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id LA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}} [id LM] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id KY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{le,no_inplace} [id LB] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}} [id LN] <TensorType(bool, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{add,no_inplace} [id LO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | | |TensorConstant{-1} [id DH] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id LK] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{sub,no_inplace} [id LC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{-2} [id DP] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{minimum,no_inplace} [id LP] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Elemwise{add,no_inplace} [id LO] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | | |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{-1} [id BH] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{0} [id BZ] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |TensorConstant{2} [id DR] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | | | |Elemwise{sub,no_inplace} [id EA] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | | |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | | | |TensorConstant{1} [id CZ] <TensorType(int64, scalar)>\n |   | | |   | | |     | | |   |   | | | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |Rebroadcast{0} [id LQ] <CudaNdarrayType(float32, 3D)> ''   \n |   | | |   | | |     | | |   |   | | | |GpuDimShuffle{x,0,1} [id LR] <CudaNdarrayType(float32, (True, False, False))> ''   \n |   | | |   | | |     | | |   |   | | |   |GpuGer{inplace} [id LS] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | |     |GpuAlloc{memset_0=True} [id LT] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   | | |     | |CudaNdarrayConstant{0.0} [id GF] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | |     | |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |     | |Shape_i{1} [id EB] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |     |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | |     |GpuDimShuffle{0} [id LU] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | |     | |GpuAlloc [id LV] <CudaNdarrayType(float32, col)> ''   \n |   | | |   | | |     | | |   |   | | |     |   |CudaNdarrayConstant{1.0} [id GJ] <CudaNdarrayType(float32, scalar)>\n |   | | |   | | |     | | |   |   | | |     |   |Shape_i{0} [id BF] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   | | |     |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   | | |     |GpuDimShuffle{1} [id LW] <CudaNdarrayType(float32, vector)> ''   \n |   | | |   | | |     | | |   |   | | |       |GRU2.hid_init [id EC] <CudaNdarrayType(float32, row)>\n |   | | |   | | |     | | |   |   | | |Constant{1} [id GL] <int64>\n |   | | |   | | |     | | |   |   | |GpuJoin [id LX] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   | | |     | | |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   |   |GRU2.W_hid_to_resetgate [id LY] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   |   |GRU2.W_hid_to_updategate [id LZ] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   |   |GRU2.W_hid_to_hidden_update [id MA] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     | | |   |   |ScalarFromTensor [id MB] <int64> ''   \n |   | | |   | | |     | | |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id MC] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id DY] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id KX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |ScalarFromTensor [id MD] <int64> ''   \n |   | | |   | | |     | | |   |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id ME] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Elemwise{add,no_inplace} [id DX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |Shape_i{1} [id BG] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   | | |     | | |   |   |   |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}} [id KX] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | | |   |   |Constant{1} [id CH] <int8>\n |   | | |   | | |     | | |   |Constant{-1} [id IJ] <int64>\n |   | | |   | | |     | | |MakeVector{dtype='int64'} [id MF] <TensorType(int64, vector)> ''   \n |   | | |   | | |     | |   |Elemwise{mul,no_inplace} [id BE] <TensorType(int64, scalar)> ''   \n |   | | |   | | |     | |   |TensorConstant{300} [id MG] <TensorType(int64, scalar)>\n |   | | |   | | |     | |dec_init.W [id EF] <CudaNdarrayType(float32, matrix)>\n |   | | |   | | |     |GpuDimShuffle{x,0} [id MH] <CudaNdarrayType(float32, row)> ''   \n |   | | |   | | |       |dec_init.b [id MI] <CudaNdarrayType(float32, vector)>\n |   | | |   | | |Constant{1} [id GL] <int64>\n |   | | |   | |GpuJoin [id MJ] <CudaNdarrayType(float32, matrix)> ''   \n |   | | |   |   |TensorConstant{1} [id BO] <TensorType(int8, scalar)>\n |   | | |   |   |GRUdec.W_hid_to_resetgate [id MK] <CudaNdarrayType(float32, matrix)>\n |   | | |   |   |GRUdec.W_hid_to_updategate [id ML] <CudaNdarrayType(float32, matrix)>\n |   | | |   |   |GRUdec.W_hid_to_hidden_update [id MM] <CudaNdarrayType(float32, matrix)>\n |   | | |   |ScalarFromTensor [id GQ] <int64> ''   \n |   | | |   |ScalarFromTensor [id GS] <int64> ''   \n |   | | |   |Constant{1} [id CH] <int8>\n |   | | |MakeVector{dtype='int64'} [id MN] <TensorType(int64, vector)> ''   \n |   | |   |Elemwise{mul,no_inplace} [id BJ] <TensorType(int64, scalar)> ''   \n |   | |   |TensorConstant{300} [id MG] <TensorType(int64, scalar)>\n |   | |h0.W [id MO] <CudaNdarrayType(float32, matrix)>\n |   |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |   |GpuReshape{2} [id MP] <CudaNdarrayType(float32, matrix)> ''   \n |   | |GpuAdvancedSubtensor1 [id T] <CudaNdarrayType(float32, matrix)> ''   \n |   | |MakeVector{dtype='int64'} [id MN] <TensorType(int64, vector)> ''   \n |   |e0.W [id MQ] <CudaNdarrayType(float32, matrix)>\n |   |TensorConstant{1.0} [id GG] <TensorType(float32, scalar)>\n |GpuDimShuffle{1,0} [id MR] <CudaNdarrayType(float32, matrix)> ''   \n   |GpuAdvancedSubtensor1 [id MS] <CudaNdarrayType(float32, matrix)> ''   \n     |GpuDimShuffle{1,0} [id MT] <CudaNdarrayType(float32, matrix)> ''   \n     | |soft.W [id MU] <CudaNdarrayType(float32, matrix)>\n     |RepeatOp{axis=None} [id MV] <TensorType(int64, vector)> ''   \n       |Subtensor{int64} [id MW] <TensorType(int64, vector)> ''   \n       | |Nonzero [id MX] <TensorType(int64, matrix)> ''   \n       | | |Reshape{1} [id MY] <TensorType(int64, vector)> ''   \n       | |   |MultinomialFromUniform{int64} [id MZ] <TensorType(int64, row)> ''   \n       | |   | |InplaceDimShuffle{x,0} [id NA] <TensorType(float64, row)> ''   \n       | |   | | |soft.p [id NB] <TensorType(float64, vector)>\n       | |   | |HostFromGpu [id NC] <TensorType(float32, vector)> ''   \n       | |   | | |GPU_mrg_uniform{CudaNdarrayType(float32, vector),inplace}.1 [id ND] <CudaNdarrayType(float32, vector)> ''   \n       | |   | |   |<CudaNdarrayType(float32, vector)> [id NE] <CudaNdarrayType(float32, vector)>\n       | |   | |   |TensorConstant{(1,) of 1000} [id NF] <TensorType(int64, vector)>\n       | |   | |Constant{1000} [id NG] <int16>\n       | |   |TensorConstant{(1,) of -1} [id BA] <TensorType(int64, (True,))>\n       | |Constant{0} [id NH] <int64>\n       |AdvancedSubtensor1 [id NI] <TensorType(int64, vector)> ''   \n         |Reshape{1} [id MY] <TensorType(int64, vector)> ''   \n         |Subtensor{int64} [id MW] <TensorType(int64, vector)> ''   \n\nInner graphs of the scan ops:\n\nforall_inplace,gpu,scan_fn} [id J] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{Switch(i0, (((i1 - Composite{scalar_sigmoid((i0 + i1))}(i2, i3)) * i4) + (Composite{scalar_sigmoid((i0 + i1))}(i2, i3) * tanh((i5 + (scalar_sigmoid((i6 + i7)) * i8))))), i4)},no_inplace} [id NJ] <CudaNdarrayType(float32, matrix)> ''   \n > |<CudaNdarrayType(float32, col)> [id NK] <CudaNdarrayType(float32, col)> -> [id CI]\n > |CudaNdarrayConstant{[[ 1.]]} [id NL] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id NM] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id NN] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id NO] <CudaNdarrayType(float32, matrix)> -> [id CO]\n > | | |<CudaNdarrayType(float32, matrix)> [id NP] <CudaNdarrayType(float32, matrix)> -> [id MJ]\n > | |Constant{300} [id NQ] <int64>\n > | |Constant{600} [id NR] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NS] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id M]\n > | |Constant{300} [id NQ] <int64>\n > | |Constant{600} [id NR] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id NO] <CudaNdarrayType(float32, matrix)> -> [id CO]\n > |GpuSubtensor{::, int64:int64:} [id NU] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id M]\n > | |Constant{600} [id NR] <int64>\n > | |Constant{900} [id NV] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NW] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id NN] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id NX] <int64>\n > | |Constant{300} [id NQ] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NY] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id M]\n > | |Constant{0} [id NX] <int64>\n > | |Constant{300} [id NQ] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NZ] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id NN] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id NR] <int64>\n >   |Constant{900} [id NV] <int64>\n\nforall_inplace,gpu,scan_fn} [id ER] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{(((i0 - Composite{scalar_sigmoid((i0 + i1))}(i1, i2)) * i3) + (Composite{scalar_sigmoid((i0 + i1))}(i1, i2) * tanh((i4 + (scalar_sigmoid((i5 + i6)) * i7)))))},no_inplace} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n > |CudaNdarrayConstant{[[ 1.]]} [id OB] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id OC] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OD] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id OE] <CudaNdarrayType(float32, matrix)> -> [id KU]\n > | | |<CudaNdarrayType(float32, matrix)> [id OF] <CudaNdarrayType(float32, matrix)> -> [id LX]\n > | |Constant{300} [id OG] <int64>\n > | |Constant{600} [id OH] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OI] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id OJ] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | |Constant{300} [id OG] <int64>\n > | |Constant{600} [id OH] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id OE] <CudaNdarrayType(float32, matrix)> -> [id KU]\n > |GpuSubtensor{::, int64:int64:} [id OK] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id OJ] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | |Constant{600} [id OH] <int64>\n > | |Constant{900} [id OL] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OM] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OD] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id ON] <int64>\n > | |Constant{300} [id OG] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OO] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id OJ] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | |Constant{0} [id ON] <int64>\n > | |Constant{300} [id OG] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OP] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id OD] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id OH] <int64>\n >   |Constant{900} [id OL] <int64>\n\nforall_inplace,gpu,scan_fn} [id FE] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{Switch(i0, (((i1 - Composite{scalar_sigmoid((i0 + i1))}(i2, i3)) * i4) + (Composite{scalar_sigmoid((i0 + i1))}(i2, i3) * tanh((i5 + (scalar_sigmoid((i6 + i7)) * i8))))), i4)},no_inplace} [id OQ] <CudaNdarrayType(float32, matrix)> ''   \n > |<CudaNdarrayType(float32, col)> [id OR] <CudaNdarrayType(float32, col)> -> [id CI]\n > |CudaNdarrayConstant{[[ 1.]]} [id OS] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id OT] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OU] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id OV] <CudaNdarrayType(float32, matrix)> -> [id FX]\n > | | |<CudaNdarrayType(float32, matrix)> [id OW] <CudaNdarrayType(float32, matrix)> -> [id GM]\n > | |Constant{300} [id OX] <int64>\n > | |Constant{600} [id OY] <int64>\n > |GpuSubtensor{::, int64:int64:} [id OZ] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PA] <CudaNdarrayType(float32, matrix)> -> [id FF]\n > | |Constant{300} [id OX] <int64>\n > | |Constant{600} [id OY] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id OV] <CudaNdarrayType(float32, matrix)> -> [id FX]\n > |GpuSubtensor{::, int64:int64:} [id PB] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PA] <CudaNdarrayType(float32, matrix)> -> [id FF]\n > | |Constant{600} [id OY] <int64>\n > | |Constant{900} [id PC] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PD] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id OU] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id PE] <int64>\n > | |Constant{300} [id OX] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PF] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PA] <CudaNdarrayType(float32, matrix)> -> [id FF]\n > | |Constant{0} [id PE] <int64>\n > | |Constant{300} [id OX] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PG] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id OU] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id OY] <int64>\n >   |Constant{900} [id PC] <int64>\n\nforall_inplace,gpu,scan_fn} [id HD] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Composite{Switch(i0, (((i1 - Composite{scalar_sigmoid((i0 + i1))}(i2, i3)) * i4) + (Composite{scalar_sigmoid((i0 + i1))}(i2, i3) * tanh((i5 + (scalar_sigmoid((i6 + i7)) * i8))))), i4)},no_inplace} [id PH] <CudaNdarrayType(float32, matrix)> ''   \n > |<CudaNdarrayType(float32, col)> [id PI] <CudaNdarrayType(float32, col)> -> [id IK]\n > |CudaNdarrayConstant{[[ 1.]]} [id PJ] <CudaNdarrayType(float32, (True, True))>\n > |GpuSubtensor{::, int64:int64:} [id PK] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id PL] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, matrix)> [id PM] <CudaNdarrayType(float32, matrix)> -> [id IL]\n > | | |<CudaNdarrayType(float32, matrix)> [id PN] <CudaNdarrayType(float32, matrix)> -> [id JO]\n > | |Constant{300} [id PO] <int64>\n > | |Constant{600} [id PP] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PQ] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PR] <CudaNdarrayType(float32, matrix)> -> [id HE]\n > | |Constant{300} [id PO] <int64>\n > | |Constant{600} [id PP] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id PM] <CudaNdarrayType(float32, matrix)> -> [id IL]\n > |GpuSubtensor{::, int64:int64:} [id PS] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PR] <CudaNdarrayType(float32, matrix)> -> [id HE]\n > | |Constant{600} [id PP] <int64>\n > | |Constant{900} [id PT] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PU] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuDot22 [id PL] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id PV] <int64>\n > | |Constant{300} [id PO] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PW] <CudaNdarrayType(float32, matrix)> ''   \n > | |<CudaNdarrayType(float32, matrix)> [id PR] <CudaNdarrayType(float32, matrix)> -> [id HE]\n > | |Constant{0} [id PV] <int64>\n > | |Constant{300} [id PO] <int64>\n > |GpuSubtensor{::, int64:int64:} [id PX] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuDot22 [id PL] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{600} [id PP] <int64>\n >   |Constant{900} [id PT] <int64>\n\nStorage map footprint:\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 400004), ElemSize: 4 Byte(s), TotalSize: 480004800 Byte(s)\n - emb.E, Shared Input, Shape: (400004, 300), ElemSize: 4 Byte(s), TotalSize: 480004800 Byte(s)\n - soft.W, Shared Input, Shape: (300, 400004), ElemSize: 4 Byte(s), TotalSize: 480004800 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (22, 3000, 900), ElemSize: 4 Byte(s), TotalSize: 237600000 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (22, 3000, 900), ElemSize: 4 Byte(s), TotalSize: 237600000 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (22, 3000, 900), ElemSize: 4 Byte(s), TotalSize: 237600000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (23, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 82800000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (23, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 82800000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (23, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 82800000 Byte(s)\n - GpuReshape{2}.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuReshape{2}.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuSubtensor{int64:int64:int8}.0, Shape: (22, 3000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuReshape{2}.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuAdvancedSubtensor1.0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuSubtensor{::, ::int64}.0, Shape: (3000, 22, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuElemwise{Add}[(0, 1)].0, Shape: (66000, 300), ElemSize: 4 Byte(s), TotalSize: 79200000 Byte(s)\n - GpuElemwise{Add}[(0, 0)].0, Shape: (2, 1500, 900), ElemSize: 4 Byte(s), TotalSize: 10800000 Byte(s)\n - GpuReshape{2}.0, Shape: (3000, 600), ElemSize: 4 Byte(s), TotalSize: 7200000 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (3, 1500, 300), ElemSize: 4 Byte(s), TotalSize: 5400000 Byte(s)\n - GpuElemwise{Composite{tanh((i0 + i1))}}[(0, 0)].0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)].0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - GpuReshape{2}.0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - GpuElemwise{Composite{sqrt((i0 / i1))}}[(0, 0)].0, Shape: (3000, 300), ElemSize: 4 Byte(s), TotalSize: 3600000 Byte(s)\n - soft.p, Shared Input, Shape: (400004,), ElemSize: 8 Byte(s), TotalSize: 3200032 Byte(s)\n - GpuJoin.0, Shape: (600, 900), ElemSize: 4 Byte(s), TotalSize: 2160000 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (400004,), ElemSize: 4 Byte(s), TotalSize: 1600016 Byte(s)\n - soft.b, Shared Input, Shape: (400004,), ElemSize: 4 Byte(s), TotalSize: 1600016 Byte(s)\n - GpuAdvancedSubtensor1.0, Shape: (1000, 300), ElemSize: 4 Byte(s), TotalSize: 1200000 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (300, 1000), ElemSize: 4 Byte(s), TotalSize: 1200000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - GpuJoin.0, Shape: (300, 900), ElemSize: 4 Byte(s), TotalSize: 1080000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - GRU2.W_in_to_resetgate, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - GRU2.W_in_to_updategate, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - GRU2.W_in_to_hidden_update, Shared Input, Shape: (600, 300), ElemSize: 4 Byte(s), TotalSize: 720000 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (66000,), ElemSize: 8 Byte(s), TotalSize: 528000 Byte(s)\n - Elemwise{Composite{(i0 - log((i1 * i2)))}}.0, Shape: (66000, 1), ElemSize: 8 Byte(s), TotalSize: 528000 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (66000,), ElemSize: 8 Byte(s), TotalSize: 528000 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - GPU_mrg_uniform{CudaNdarrayType(float32, vector),inplace}.0, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_in_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_in_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - dec_init.W, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU2.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU2.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU2.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - e0.W, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - h0.W, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_in_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_in_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_in_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_in_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_hid_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_in_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_hid_to_updategate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1forw.W_in_to_hidden_update, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRU1back.W_hid_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - GRUdec.W_in_to_resetgate, Shared Input, Shape: (300, 300), ElemSize: 4 Byte(s), TotalSize: 360000 Byte(s)\n - inputs, Input, Shape: (1500, 2, 22), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - targets, Input, Shape: (1500, 2, 22), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - Reshape{1}.0, Shape: (66000,), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - GpuDimShuffle{1,0,x}.0, Shape: (22, 3000, 1), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - input_mask, Input, Shape: (1500, 2, 22), ElemSize: 4 Byte(s), TotalSize: 264000 Byte(s)\n - RepeatOp{axis=None}.0, Shape: (1000,), ElemSize: 8 Byte(s), TotalSize: 8000 Byte(s)\n - AdvancedSubtensor1.0, Shape: (1000,), ElemSize: 8 Byte(s), TotalSize: 8000 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (3, 300), ElemSize: 4 Byte(s), TotalSize: 3600 Byte(s)\n - emb.W, Shared Input, Shape: (3, 300), ElemSize: 4 Byte(s), TotalSize: 3600 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.hid_init, Shared Input, Shape: (1, 300), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - dec_init.b, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - h0.b, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRUdec.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRUdec.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRUdec.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1forw.hid_init, Shared Input, Shape: (1, 300), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.b_resetgate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU1back.hid_init, Shared Input, Shape: (1, 300), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.b_updategate, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - GRU2.b_hidden_update, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (300,), ElemSize: 4 Byte(s), TotalSize: 1200 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{[     0 40..02 400003]}, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // (i4 * i1 * i5)), i6)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{300}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{neg,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1) of 0.0}, Shape: (1, 1), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - i7) + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, Switch(LT((i1 + i1), i2), i2, (i1 + i1)), i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i6 - i8), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of -1.0}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum((i7 + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-600}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1, 1) of 0.0}, Shape: (1, 1, 1), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), minimum(i2, i6)))}(i1, i2, (i3 + i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8), i7), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(i2, (i3 - i4), i5))}(i1, i2, i3, i4, i5, i6), i2, i7), i2, i8))) - i9) // i10)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{600}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1,) of 1000}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{-300}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, ((i1 * i2 * i3) // i4), i5)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{(1, 1) of 1000.0}, Shape: (1, 1), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{2}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuFromHost.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.01]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[  9.99999997e-07]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999997e-07]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{0.00999999977648}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.01]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[[ 0.]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - Constant{1000}, Shape: (), ElemSize: 2 Byte(s), TotalSize: 2.0 Byte(s)\n - Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{le,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{eq,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{le,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 2956204302.0 Byte(s) 2.753 GB\n TotalSize inputs: 1469219734.0 Byte(s) 1.368 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'."
     ]
    }
   ],
   "source": [
    "last_scores = [np.inf]\n",
    "max_epochs_wo_improvement = 5\n",
    "tol = 0.001\n",
    "epoch = 1\n",
    "best_epoch = None\n",
    "\n",
    "model_filename = 'trained_models/test1/redditv3_pairs_gloveFixed_bs25_early5'\n",
    "\n",
    "t0 = time.time()\n",
    "while len(last_scores) <= max_epochs_wo_improvement or last_scores[0] > min(last_scores) + tol:\n",
    "    print '\\n\\nStarting epoch {}...\\n'.format(epoch)\n",
    "    train_error = net.train_one_epoch(train_data=train_pairs, batch_size=1500, log_interval=1)\n",
    "    val_error = net.validate(val_data=test_pairs, batch_size=1500)\n",
    "    print '\\nTraining loss:   {}'.format(train_error)\n",
    "    print 'Validation loss: {}'.format(val_error)\n",
    "\n",
    "    if val_error < min(last_scores):\n",
    "        print '\\nSaving model...'\n",
    "        net.save_params(model_filename + '_ep' + str(epoch) + '.npz')\n",
    "        print 'Done saving.'\n",
    "        best_epoch = epoch\n",
    "\n",
    "    last_scores.append(val_error)\n",
    "\n",
    "    if len(last_scores) > max_epochs_wo_improvement + 1:\n",
    "        del last_scores[0]\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "\n",
    "print '\\n\\nTotal training time: {:.2f}s'.format(time.time() - t0)\n",
    "print 'Best model after {} epochs with loss {}'.format(best_epoch, min(last_scores))\n",
    "print 'Validation set perplexity: {}'.format(np.exp(min(last_scores)))\n",
    "print 'Model saved as ' + model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from reddit_load import load_singles, load_pairs, get_reddit_voc\n",
    "\n",
    "%aimport HRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.62 s, sys: 109 ms, total: 9.72 s\n",
      "Wall time: 9.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reddit_path = \"/pio/data/data/reddit_sample/\"\n",
    "\n",
    "train_singles, test_singles = load_singles(path=reddit_path)\n",
    "data_pairs = load_pairs(path=reddit_path)\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_reddit_voc(path=reddit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "Building a network for generating...\n",
      "Done\n",
      "CPU times: user 36.5 s, sys: 965 ms, total: 37.5 s\n",
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hred_net = HRED.HRED(voc_size=voc_size,\n",
    "                     emb_size=300,\n",
    "                     lv1_rec_size=300, \n",
    "                     lv2_rec_size=300, \n",
    "                     out_emb_size=300, \n",
    "                     num_sampled=200,\n",
    "                     ssoft_probs=freqs,\n",
    "                     n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hred_net.load_params('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100 batches in 5.00s\ttraining loss:\t3.428550\n",
      "Done 200 batches in 9.97s\ttraining loss:\t3.421801\n",
      "Done 300 batches in 14.99s\ttraining loss:\t3.422451\n",
      "Done 400 batches in 19.95s\ttraining loss:\t3.414273\n",
      "Done 500 batches in 24.35s\ttraining loss:\t3.395562\n",
      "Done 600 batches in 28.43s\ttraining loss:\t3.354878\n",
      "Done 700 batches in 32.85s\ttraining loss:\t3.345874\n",
      "Done 800 batches in 37.86s\ttraining loss:\t3.360305\n",
      "Done 900 batches in 42.60s\ttraining loss:\t3.361262\n",
      "Done 1000 batches in 47.48s\ttraining loss:\t3.366504\n",
      "Done 1100 batches in 52.54s\ttraining loss:\t3.374706\n",
      "Done 1200 batches in 57.65s\ttraining loss:\t3.379332\n",
      "Done 1300 batches in 62.66s\ttraining loss:\t3.383389\n",
      "Done 1400 batches in 67.66s\ttraining loss:\t3.385690\n",
      "Done 1500 batches in 72.73s\ttraining loss:\t3.387937\n",
      "Done 1600 batches in 77.82s\ttraining loss:\t3.391383\n",
      "Done 1700 batches in 82.68s\ttraining loss:\t3.392958\n",
      "Done 1800 batches in 85.33s\ttraining loss:\t3.362766\n",
      "Done 1900 batches in 89.99s\ttraining loss:\t3.361663\n",
      "Done 2000 batches in 94.85s\ttraining loss:\t3.363971\n",
      "Done 2100 batches in 96.99s\ttraining loss:\t3.326400\n",
      "Done 2200 batches in 99.94s\ttraining loss:\t3.303825\n",
      "Done 2300 batches in 104.91s\ttraining loss:\t3.308987\n",
      "Done 2400 batches in 109.64s\ttraining loss:\t3.310637\n",
      "Done 2500 batches in 114.44s\ttraining loss:\t3.312929\n",
      "Done 2600 batches in 119.37s\ttraining loss:\t3.317765\n",
      "Done 2700 batches in 124.19s\ttraining loss:\t3.320777\n",
      "Done 2800 batches in 129.21s\ttraining loss:\t3.323297\n",
      "Done 2900 batches in 133.98s\ttraining loss:\t3.325065\n",
      "Done 3000 batches in 139.09s\ttraining loss:\t3.328608\n",
      "Done 3100 batches in 143.74s\ttraining loss:\t3.328521\n",
      "Done 3200 batches in 148.76s\ttraining loss:\t3.331962\n",
      "Done 3300 batches in 153.55s\ttraining loss:\t3.332994\n",
      "Done 3400 batches in 158.47s\ttraining loss:\t3.334687\n",
      "Done 3500 batches in 163.52s\ttraining loss:\t3.337504\n",
      "Done 3600 batches in 168.38s\ttraining loss:\t3.338439\n",
      "Done 3700 batches in 173.27s\ttraining loss:\t3.339498\n",
      "Done 3800 batches in 178.33s\ttraining loss:\t3.341534\n",
      "Done 3900 batches in 183.23s\ttraining loss:\t3.341984\n",
      "Done 4000 batches in 187.99s\ttraining loss:\t3.343080\n",
      "Done 4100 batches in 193.07s\ttraining loss:\t3.345124\n",
      "Done 4200 batches in 197.91s\ttraining loss:\t3.346413\n",
      "Done 4300 batches in 202.86s\ttraining loss:\t3.347371\n",
      "Done 4400 batches in 207.84s\ttraining loss:\t3.348810\n",
      "Done 4500 batches in 212.66s\ttraining loss:\t3.348936\n",
      "Done 4600 batches in 217.47s\ttraining loss:\t3.349333\n",
      "Done 4700 batches in 222.21s\ttraining loss:\t3.349221\n",
      "Done 4800 batches in 227.18s\ttraining loss:\t3.350744\n",
      "Done 4900 batches in 231.93s\ttraining loss:\t3.351112\n",
      "Done 5000 batches in 236.99s\ttraining loss:\t3.352300\n",
      "Done 5100 batches in 241.89s\ttraining loss:\t3.352861\n",
      "Done 5200 batches in 246.67s\ttraining loss:\t3.352331\n",
      "Done 5300 batches in 251.43s\ttraining loss:\t3.352643\n",
      "Done 5400 batches in 256.38s\ttraining loss:\t3.353570\n",
      "Done 5500 batches in 261.35s\ttraining loss:\t3.354185\n",
      "Done 5600 batches in 266.44s\ttraining loss:\t3.355435\n",
      "Done 5700 batches in 271.41s\ttraining loss:\t3.356232\n",
      "Done 5800 batches in 276.24s\ttraining loss:\t3.355837\n",
      "Done 5900 batches in 280.46s\ttraining loss:\t3.352065\n",
      "Done 6000 batches in 285.43s\ttraining loss:\t3.352880\n",
      "Done 6100 batches in 290.29s\ttraining loss:\t3.353812\n",
      "Done 6200 batches in 295.10s\ttraining loss:\t3.354064\n",
      "Done 6300 batches in 299.89s\ttraining loss:\t3.353981\n",
      "Done 6400 batches in 304.75s\ttraining loss:\t3.354698\n",
      "Done 6500 batches in 309.84s\ttraining loss:\t3.355447\n",
      "Done 6600 batches in 312.64s\ttraining loss:\t3.344616\n",
      "Done 6700 batches in 317.32s\ttraining loss:\t3.345339\n",
      "Done 6800 batches in 322.35s\ttraining loss:\t3.346360\n",
      "Done 6900 batches in 326.55s\ttraining loss:\t3.340021\n",
      "Done 7000 batches in 331.14s\ttraining loss:\t3.340170\n",
      "Done 7100 batches in 336.26s\ttraining loss:\t3.341681\n",
      "Done 7200 batches in 339.22s\ttraining loss:\t3.334692\n",
      "Done 7300 batches in 342.89s\ttraining loss:\t3.331145\n",
      "Done 7400 batches in 347.72s\ttraining loss:\t3.331568\n",
      "Done 7500 batches in 352.31s\ttraining loss:\t3.331861\n",
      "Done 7600 batches in 357.23s\ttraining loss:\t3.333004\n",
      "Done 7700 batches in 362.21s\ttraining loss:\t3.333788\n",
      "Done 7800 batches in 367.23s\ttraining loss:\t3.334768\n",
      "Done 7900 batches in 372.30s\ttraining loss:\t3.335551\n",
      "Done 8000 batches in 377.19s\ttraining loss:\t3.335925\n",
      "Done 8100 batches in 382.24s\ttraining loss:\t3.336791\n",
      "Done 8200 batches in 387.14s\ttraining loss:\t3.337220\n",
      "Done 8300 batches in 392.17s\ttraining loss:\t3.337931\n",
      "Done 8400 batches in 396.75s\ttraining loss:\t3.336967\n",
      "Done 8500 batches in 401.77s\ttraining loss:\t3.337559\n",
      "Done 8600 batches in 406.68s\ttraining loss:\t3.338129\n",
      "Done 8700 batches in 411.63s\ttraining loss:\t3.338805\n",
      "Done 8800 batches in 416.30s\ttraining loss:\t3.338236\n",
      "Done 8900 batches in 421.30s\ttraining loss:\t3.338801\n",
      "Done 9000 batches in 426.31s\ttraining loss:\t3.339661\n",
      "Done 9100 batches in 431.30s\ttraining loss:\t3.340363\n",
      "Done 9200 batches in 436.32s\ttraining loss:\t3.341013\n",
      "Done 9300 batches in 441.29s\ttraining loss:\t3.341597\n",
      "Done 9400 batches in 446.11s\ttraining loss:\t3.341663\n",
      "Done 9500 batches in 450.75s\ttraining loss:\t3.340806\n",
      "Done 9600 batches in 455.73s\ttraining loss:\t3.341199\n",
      "Done 9700 batches in 460.72s\ttraining loss:\t3.341527\n",
      "Done 9800 batches in 465.70s\ttraining loss:\t3.342097\n",
      "Done 9900 batches in 470.11s\ttraining loss:\t3.340926\n",
      "Done 10000 batches in 472.26s\ttraining loss:\t3.333082\n",
      "Done 10100 batches in 475.11s\ttraining loss:\t3.327698\n",
      "Done 10200 batches in 480.09s\ttraining loss:\t3.328707\n",
      "Done 10300 batches in 485.13s\ttraining loss:\t3.329389\n",
      "Done 10400 batches in 490.03s\ttraining loss:\t3.329261\n",
      "Done 10500 batches in 495.04s\ttraining loss:\t3.329918\n",
      "Done 10600 batches in 499.87s\ttraining loss:\t3.329940\n",
      "Done 10700 batches in 504.60s\ttraining loss:\t3.329851\n",
      "Done 10800 batches in 509.68s\ttraining loss:\t3.330947\n",
      "Done 10900 batches in 514.75s\ttraining loss:\t3.331647\n",
      "Done 11000 batches in 519.73s\ttraining loss:\t3.331958\n",
      "Done 11100 batches in 524.56s\ttraining loss:\t3.332008\n",
      "Done 11200 batches in 529.46s\ttraining loss:\t3.332297\n",
      "Done 11300 batches in 533.86s\ttraining loss:\t3.329958\n",
      "Done 11400 batches in 538.69s\ttraining loss:\t3.330312\n",
      "Done 11500 batches in 543.63s\ttraining loss:\t3.330588\n",
      "Done 11600 batches in 548.64s\ttraining loss:\t3.331057\n",
      "Done 11700 batches in 553.64s\ttraining loss:\t3.331453\n",
      "Done 11800 batches in 558.62s\ttraining loss:\t3.331927\n",
      "Done 11900 batches in 563.68s\ttraining loss:\t3.332581\n",
      "Done 12000 batches in 568.65s\ttraining loss:\t3.332860\n",
      "Done 12100 batches in 573.68s\ttraining loss:\t3.333435\n",
      "Done 12200 batches in 578.17s\ttraining loss:\t3.332561\n",
      "Done 12300 batches in 583.13s\ttraining loss:\t3.333272\n",
      "Done 12400 batches in 588.15s\ttraining loss:\t3.333813\n",
      "Done 12500 batches in 592.81s\ttraining loss:\t3.333055\n",
      "Done 12600 batches in 595.92s\ttraining loss:\t3.328162\n",
      "Done 12700 batches in 600.67s\ttraining loss:\t3.328408\n",
      "Done 12800 batches in 605.55s\ttraining loss:\t3.328652\n",
      "Done 12900 batches in 610.59s\ttraining loss:\t3.329297\n",
      "Done 13000 batches in 615.60s\ttraining loss:\t3.329774\n",
      "Done 13100 batches in 620.57s\ttraining loss:\t3.330050\n",
      "Done 13200 batches in 625.07s\ttraining loss:\t3.329675\n",
      "Done 13300 batches in 629.49s\ttraining loss:\t3.329219\n",
      "Done 13400 batches in 634.03s\ttraining loss:\t3.329054\n",
      "Done 13500 batches in 638.89s\ttraining loss:\t3.329420\n",
      "Done 13600 batches in 643.82s\ttraining loss:\t3.329859\n",
      "Done 13700 batches in 648.63s\ttraining loss:\t3.329812\n",
      "Done 13800 batches in 653.34s\ttraining loss:\t3.329309\n",
      "Done 13900 batches in 658.17s\ttraining loss:\t3.329473\n",
      "Done 14000 batches in 663.20s\ttraining loss:\t3.329979\n",
      "Done 14100 batches in 668.01s\ttraining loss:\t3.330005\n",
      "Done 14200 batches in 672.58s\ttraining loss:\t3.329859\n",
      "Done 14300 batches in 677.48s\ttraining loss:\t3.329879\n",
      "Done 14400 batches in 680.93s\ttraining loss:\t3.325560\n",
      "Done 14500 batches in 685.90s\ttraining loss:\t3.326033\n",
      "Done 14600 batches in 690.94s\ttraining loss:\t3.326532\n",
      "Done 14700 batches in 695.98s\ttraining loss:\t3.326988\n",
      "Done 14800 batches in 700.98s\ttraining loss:\t3.327079\n",
      "Done 14900 batches in 705.24s\ttraining loss:\t3.326119\n",
      "Done 15000 batches in 708.69s\ttraining loss:\t3.323729\n",
      "Done 15100 batches in 713.67s\ttraining loss:\t3.324178\n",
      "Done 15200 batches in 718.68s\ttraining loss:\t3.324622\n",
      "Done 15300 batches in 723.43s\ttraining loss:\t3.324472\n",
      "Done 15400 batches in 728.30s\ttraining loss:\t3.324736\n",
      "Done 15500 batches in 733.19s\ttraining loss:\t3.325081\n",
      "Done 15600 batches in 738.21s\ttraining loss:\t3.325348\n",
      "Done 15700 batches in 742.98s\ttraining loss:\t3.325366\n",
      "Done 15800 batches in 747.88s\ttraining loss:\t3.325408\n",
      "Done 15900 batches in 752.28s\ttraining loss:\t3.324579\n",
      "Done 16000 batches in 757.07s\ttraining loss:\t3.324494\n",
      "Done 16100 batches in 762.10s\ttraining loss:\t3.324864\n",
      "Done 16200 batches in 767.13s\ttraining loss:\t3.325366\n",
      "Done 16300 batches in 771.52s\ttraining loss:\t3.324946\n",
      "Done 16400 batches in 776.50s\ttraining loss:\t3.325376\n",
      "Done 16500 batches in 781.21s\ttraining loss:\t3.325471\n",
      "Done 16600 batches in 786.18s\ttraining loss:\t3.325722\n",
      "Done 16700 batches in 790.91s\ttraining loss:\t3.325644\n",
      "Done 16800 batches in 795.42s\ttraining loss:\t3.325366\n",
      "Done 16900 batches in 800.24s\ttraining loss:\t3.325689\n",
      "Done 17000 batches in 805.18s\ttraining loss:\t3.326023\n",
      "Done 17100 batches in 810.25s\ttraining loss:\t3.326415\n",
      "Done 17200 batches in 815.20s\ttraining loss:\t3.326544\n",
      "Done 17300 batches in 820.25s\ttraining loss:\t3.326807\n",
      "Done 17400 batches in 824.97s\ttraining loss:\t3.326099\n",
      "Done 17500 batches in 830.07s\ttraining loss:\t3.326552\n",
      "Done 17600 batches in 834.50s\ttraining loss:\t3.326173\n",
      "Done 17700 batches in 839.34s\ttraining loss:\t3.326290\n",
      "Done 17800 batches in 843.80s\ttraining loss:\t3.325348\n",
      "Done 17900 batches in 848.85s\ttraining loss:\t3.325716\n",
      "Done 18000 batches in 853.23s\ttraining loss:\t3.325222\n",
      "Done 18100 batches in 858.14s\ttraining loss:\t3.325485\n",
      "Done 18200 batches in 863.17s\ttraining loss:\t3.325744\n",
      "Done 18300 batches in 868.25s\ttraining loss:\t3.326111\n",
      "Done 18400 batches in 872.98s\ttraining loss:\t3.326179\n",
      "Done 18500 batches in 877.04s\ttraining loss:\t3.325336\n",
      "Done 18600 batches in 882.06s\ttraining loss:\t3.325804\n",
      "Done 18700 batches in 886.83s\ttraining loss:\t3.325582\n",
      "Done 18800 batches in 891.83s\ttraining loss:\t3.325894\n",
      "Done 18900 batches in 896.74s\ttraining loss:\t3.325916\n",
      "Done 19000 batches in 901.77s\ttraining loss:\t3.326071\n",
      "Done 19100 batches in 906.72s\ttraining loss:\t3.326343\n",
      "Done 19200 batches in 911.64s\ttraining loss:\t3.326510\n",
      "Done 19300 batches in 916.65s\ttraining loss:\t3.326690\n",
      "Done 19400 batches in 921.21s\ttraining loss:\t3.326446\n",
      "Done 19500 batches in 925.11s\ttraining loss:\t3.325255\n",
      "Done 19600 batches in 930.02s\ttraining loss:\t3.325485\n",
      "Done 19700 batches in 935.05s\ttraining loss:\t3.325646\n",
      "Done 19800 batches in 939.64s\ttraining loss:\t3.325417\n",
      "Done 19900 batches in 943.98s\ttraining loss:\t3.324903\n",
      "Done 20000 batches in 948.84s\ttraining loss:\t3.325148\n",
      "Done 20100 batches in 953.50s\ttraining loss:\t3.325056\n",
      "Done 20200 batches in 958.31s\ttraining loss:\t3.324960\n",
      "Done 20300 batches in 963.45s\ttraining loss:\t3.325267\n",
      "Done 20400 batches in 968.48s\ttraining loss:\t3.325593\n",
      "Done 20500 batches in 972.26s\ttraining loss:\t3.324069\n",
      "Done 20600 batches in 977.16s\ttraining loss:\t3.324470\n",
      "Done 20700 batches in 981.88s\ttraining loss:\t3.324387\n",
      "Done 20800 batches in 986.86s\ttraining loss:\t3.324582\n",
      "Done 20900 batches in 991.93s\ttraining loss:\t3.324800\n",
      "Done 21000 batches in 996.94s\ttraining loss:\t3.325052\n",
      "Done 21100 batches in 1001.65s\ttraining loss:\t3.324821\n",
      "Done 21200 batches in 1006.72s\ttraining loss:\t3.325147\n",
      "Done 21300 batches in 1011.75s\ttraining loss:\t3.325309\n",
      "Done 21400 batches in 1016.79s\ttraining loss:\t3.325337\n",
      "Done 21500 batches in 1021.72s\ttraining loss:\t3.325572\n",
      "Done 21600 batches in 1026.73s\ttraining loss:\t3.325679\n",
      "Done 21700 batches in 1031.35s\ttraining loss:\t3.325646\n",
      "Done 21800 batches in 1036.31s\ttraining loss:\t3.325697\n",
      "Done 21900 batches in 1041.34s\ttraining loss:\t3.325957\n",
      "Done 22000 batches in 1046.31s\ttraining loss:\t3.326135\n",
      "Done 22100 batches in 1050.99s\ttraining loss:\t3.325867\n",
      "Done 22200 batches in 1055.98s\ttraining loss:\t3.326012\n",
      "Done 22300 batches in 1061.03s\ttraining loss:\t3.326172\n",
      "Done 22400 batches in 1066.08s\ttraining loss:\t3.326399\n",
      "Done 22500 batches in 1071.08s\ttraining loss:\t3.326538\n",
      "Done 22600 batches in 1076.01s\ttraining loss:\t3.326555\n",
      "Done 22700 batches in 1081.01s\ttraining loss:\t3.326665\n",
      "Done 22800 batches in 1085.77s\ttraining loss:\t3.326649\n",
      "Done 22900 batches in 1090.77s\ttraining loss:\t3.326861\n",
      "Done 23000 batches in 1095.73s\ttraining loss:\t3.326972\n",
      "Done 23100 batches in 1100.80s\ttraining loss:\t3.327179\n",
      "Done 23200 batches in 1105.88s\ttraining loss:\t3.327121\n",
      "Done 23300 batches in 1110.68s\ttraining loss:\t3.327186\n",
      "Done 23400 batches in 1115.66s\ttraining loss:\t3.327272\n",
      "Done 23500 batches in 1120.24s\ttraining loss:\t3.326663\n",
      "Done 23600 batches in 1124.80s\ttraining loss:\t3.326606\n",
      "Done 23700 batches in 1129.69s\ttraining loss:\t3.326539\n",
      "Done 23800 batches in 1134.50s\ttraining loss:\t3.326445\n",
      "Done 23900 batches in 1139.06s\ttraining loss:\t3.326406\n",
      "Done 24000 batches in 1143.94s\ttraining loss:\t3.326515\n",
      "Done 24100 batches in 1148.97s\ttraining loss:\t3.326662\n",
      "Done 24200 batches in 1153.84s\ttraining loss:\t3.326742\n",
      "Done 24300 batches in 1158.66s\ttraining loss:\t3.326632\n",
      "Done 24400 batches in 1163.64s\ttraining loss:\t3.326845\n",
      "Done 24500 batches in 1168.51s\ttraining loss:\t3.326745\n",
      "Done 24600 batches in 1173.22s\ttraining loss:\t3.326516\n",
      "Done 24700 batches in 1178.19s\ttraining loss:\t3.326578\n",
      "Done 24800 batches in 1182.55s\ttraining loss:\t3.325784\n",
      "Done 24900 batches in 1187.18s\ttraining loss:\t3.325500\n",
      "Done 25000 batches in 1191.61s\ttraining loss:\t3.325338\n",
      "Done 25100 batches in 1196.11s\ttraining loss:\t3.325016\n",
      "Done 25200 batches in 1201.01s\ttraining loss:\t3.325070\n",
      "Done 25300 batches in 1205.85s\ttraining loss:\t3.325145\n",
      "Done 25400 batches in 1210.73s\ttraining loss:\t3.325114\n",
      "Done 25500 batches in 1215.27s\ttraining loss:\t3.324840\n",
      "Done 25600 batches in 1220.32s\ttraining loss:\t3.325056\n",
      "Done 25700 batches in 1225.33s\ttraining loss:\t3.325218\n",
      "Done 25800 batches in 1230.12s\ttraining loss:\t3.325281\n",
      "Done 25900 batches in 1235.08s\ttraining loss:\t3.325460\n",
      "Done 26000 batches in 1239.89s\ttraining loss:\t3.325565\n",
      "Done 26100 batches in 1244.74s\ttraining loss:\t3.325752\n",
      "Done 26200 batches in 1249.72s\ttraining loss:\t3.325842\n",
      "Done 26300 batches in 1254.76s\ttraining loss:\t3.325962\n",
      "Done 26400 batches in 1259.65s\ttraining loss:\t3.325664\n",
      "Done 26500 batches in 1263.73s\ttraining loss:\t3.324755\n",
      "Done 26600 batches in 1268.60s\ttraining loss:\t3.324928\n",
      "Done 26700 batches in 1273.37s\ttraining loss:\t3.325080\n",
      "Done 26800 batches in 1278.38s\ttraining loss:\t3.325223\n",
      "Done 26900 batches in 1283.31s\ttraining loss:\t3.325327\n",
      "Done 27000 batches in 1288.34s\ttraining loss:\t3.325504\n",
      "Done 27100 batches in 1293.11s\ttraining loss:\t3.325501\n",
      "Done 27200 batches in 1298.12s\ttraining loss:\t3.325670\n",
      "Done 27300 batches in 1303.18s\ttraining loss:\t3.325858\n",
      "Done 27400 batches in 1308.04s\ttraining loss:\t3.325860\n",
      "Done 27500 batches in 1312.97s\ttraining loss:\t3.325924\n",
      "Done 27600 batches in 1317.90s\ttraining loss:\t3.325995\n",
      "Done 27700 batches in 1322.95s\ttraining loss:\t3.326144\n",
      "Done 27800 batches in 1328.01s\ttraining loss:\t3.326177\n",
      "Done 27900 batches in 1332.91s\ttraining loss:\t3.326159\n",
      "Done 28000 batches in 1337.93s\ttraining loss:\t3.326284\n",
      "Done 28100 batches in 1342.87s\ttraining loss:\t3.326165\n",
      "Done 28200 batches in 1347.86s\ttraining loss:\t3.326165\n",
      "Done 28300 batches in 1351.71s\ttraining loss:\t3.325242\n",
      "Done 28400 batches in 1356.59s\ttraining loss:\t3.325370\n",
      "Done 28500 batches in 1360.85s\ttraining loss:\t3.324929\n",
      "Done 28600 batches in 1365.89s\ttraining loss:\t3.325054\n",
      "Done 28700 batches in 1370.93s\ttraining loss:\t3.325121\n",
      "Done 28800 batches in 1375.96s\ttraining loss:\t3.325219\n",
      "Done 28900 batches in 1381.00s\ttraining loss:\t3.325235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3252608175728415"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2ep\n",
    "\n",
    "hred_net.train_one_epoch(data_singles, 60, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hred_net.save_params('')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
