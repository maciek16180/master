{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 4007)\n",
      "/home/i258346/.local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "sys.path.insert(0, '../HSoftmaxLayerLasagne/')\n",
    "\n",
    "from HSoftmaxLayer import HierarchicalSoftmaxDenseLayer\n",
    "from SampledSoftmaxLayer import SampledSoftmaxDenseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "\n",
    "beg_token = '<utt_beg>'\n",
    "end_token = '<utt_end>'\n",
    "\n",
    "def get_mt_voc(path=mt_path):\n",
    "    i_to_w, w_to_i = {}, {}\n",
    "    \n",
    "    i_to_w[0] = end_token   # separate tokens for beginning and ending of an utterance\n",
    "    w_to_i[end_token] = 0   # <utt_end> serves only as a target for the last word in the input sequence\n",
    "    i_to_w[1] = beg_token   # <utt_beg> will always be the first generated word\n",
    "    w_to_i[beg_token] = 1    \n",
    "    wc = 2\n",
    "    \n",
    "    with open(path + \"WordsList.txt\", \"r\") as wl:\n",
    "        for w in wl:\n",
    "            i_to_w[wc] = w[:-1]\n",
    "            w_to_i[w[:-1]] = wc\n",
    "            wc += 1\n",
    "    \n",
    "    return i_to_w, w_to_i, wc\n",
    "\n",
    "mt_i_to_w, mt_w_to_i, mt_voc_size = get_mt_voc()\n",
    "\n",
    "\n",
    "def load_mt(path=mt_path):\n",
    "    tr = None\n",
    "    vl = None\n",
    "    ts = None\n",
    "    \n",
    "    with open(path + \"Training_Shuffled_Dataset.txt\") as f:\n",
    "        tr = []\n",
    "        for l in f:\n",
    "            if len(l.split()) < 1000:\n",
    "                tr.insert(0, [1] + map(lambda w: mt_w_to_i.get(w, mt_w_to_i['<unk>']), l.split()) + [0])\n",
    "        \n",
    "    with open(path + \"Validation_Shuffled_Dataset.txt\") as f:\n",
    "        vl = []\n",
    "        for l in f:\n",
    "            if len(l.split()) < 1000:\n",
    "                vl.insert(0, [1] + map(lambda w: mt_w_to_i.get(w, mt_w_to_i['<unk>']), l.split()) + [0])\n",
    "            \n",
    "    with open(path + \"Test_Shuffled_Dataset.txt\") as f:\n",
    "        ts = []\n",
    "        for l in f:\n",
    "            if len(l.split()) < 1000:\n",
    "                ts.insert(0, [1] + map(lambda w: mt_w_to_i.get(w, mt_w_to_i['<unk>']), l.split()) + [0])\n",
    "    \n",
    "    return tr, vl, ts\n",
    "\n",
    "mt_train, mt_val, mt_test = load_mt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similar to Lasagne mnist.py example, added input mask and different sequence lengths\n",
    "\n",
    "def iterate_minibatches(inputs, batchsize):\n",
    "    pad_value = -1\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        t0 = time.time() # time wasted preparing data, just for the info\n",
    "        \n",
    "        excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        inp = inputs[excerpt]\n",
    "        \n",
    "        inp_max_len = len(max(inp, key=len))\n",
    "        inp = map(lambda l: l + [pad_value]*(inp_max_len-len(l)), inp)\n",
    "        inp = np.asarray(inp, dtype=np.int32)\n",
    "        tar = np.hstack((inp[:,1:], np.asarray([pad_value]*batchsize, dtype=np.int32).reshape((-1,1))))\n",
    "        def gr_zero(x):\n",
    "            if x > 0:\n",
    "                return 1.\n",
    "            return 0.\n",
    "        v_gr_zero = np.vectorize(gr_zero, otypes=[np.float32])\n",
    "        mask = v_gr_zero(inp) # 0 in vocabulary represents <utt_end>, we don't feed that into the net\n",
    "        \n",
    "        yield inp, tar, mask, (time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_simple_rnnlm(input_var, mask_input_var, voc_size, emb_size, rec_size):\n",
    "    l_in = L.layers.InputLayer(shape=(None, None), input_var=input_var)    \n",
    "    batch_size, seq_len = l_in.input_var.shape\n",
    "    l_mask = L.layers.InputLayer(shape=(batch_size, seq_len), input_var=mask_input_var)\n",
    "    \n",
    "    l_emb = L.layers.EmbeddingLayer(l_in,\n",
    "                                    input_size=voc_size+1, \n",
    "                                    output_size=emb_size)\n",
    "    \n",
    "    l_lstm1 = L.layers.LSTMLayer(l_emb,\n",
    "                                 num_units=rec_size,\n",
    "                                 nonlinearity=L.nonlinearities.tanh,\n",
    "                                 grad_clipping=100,\n",
    "                                 mask_input=l_mask)\n",
    "    \n",
    "    l_resh = L.layers.ReshapeLayer(l_lstm1, shape=(-1, rec_size))\n",
    "    \n",
    "    l_soft = L.layers.DenseLayer(l_resh,\n",
    "                                num_units=voc_size,\n",
    "                                nonlinearity=L.nonlinearities.softmax)\n",
    "    \n",
    "    l_out = L.layers.ReshapeLayer(l_soft, shape=(batch_size, seq_len, voc_size))\n",
    "    \n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_hsoft_rnnlm(input_var, target_var, mask_input_var, voc_size, emb_size, rec_size):\n",
    "    l_in = L.layers.InputLayer(shape=(None, None), input_var=input_var)    \n",
    "    batch_size, seq_len = l_in.input_var.shape\n",
    "    l_mask = None\n",
    "    if mask_input_var != None:\n",
    "        print 'setting up input mask...'\n",
    "        l_mask = L.layers.InputLayer(shape=(batch_size, seq_len), input_var=mask_input_var)\n",
    "    \n",
    "    l_emb = L.layers.EmbeddingLayer(l_in,\n",
    "                                    input_size=voc_size+1, \n",
    "                                    output_size=emb_size)\n",
    "    \n",
    "    l_lstm1 = L.layers.LSTMLayer(l_emb,\n",
    "                                 num_units=rec_size,\n",
    "                                 nonlinearity=L.nonlinearities.tanh,\n",
    "                                 grad_clipping=100,\n",
    "                                 mask_input=l_mask)    \n",
    "    \n",
    "    l_resh = L.layers.ReshapeLayer(l_lstm1, shape=(-1, rec_size))\n",
    "    \n",
    "    # hierarchical softmax\n",
    "    \n",
    "    l_resh_tar = None\n",
    "    if target_var != None:\n",
    "        print 'setting up targets for hsoftmax...'\n",
    "        l_tar = L.layers.InputLayer(shape=(None, None), input_var=target_var)\n",
    "        l_resh_tar = L.layers.ReshapeLayer(l_tar, shape=(-1, 1))\n",
    "        \n",
    "    l_hsoft = HierarchicalSoftmaxDenseLayer(l_resh,\n",
    "                                                          num_units=voc_size,\n",
    "                                                          target=l_resh_tar)\n",
    "    l_out = None\n",
    "    if target_var != None:\n",
    "        l_out = L.layers.ReshapeLayer(l_hsoft, shape=(batch_size, seq_len))\n",
    "    else:\n",
    "        l_out = L.layers.ReshapeLayer(l_hsoft, shape=(batch_size, seq_len, voc_size))\n",
    "    \n",
    "    return l_out\n",
    "\n",
    "# 1 epoch on gpu with hsoft took about 700s, batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_sampledsoft_rnnlm(input_var, mask_input_var, voc_mask, voc_size, emb_size, rec_size):\n",
    "    l_in = L.layers.InputLayer(shape=(None, None), input_var=input_var)    \n",
    "    batch_size, seq_len = l_in.input_var.shape\n",
    "    l_mask = None\n",
    "    if mask_input_var != None:\n",
    "        print 'setting up input mask...'\n",
    "        l_mask = L.layers.InputLayer(shape=(batch_size, seq_len), input_var=mask_input_var)\n",
    "    \n",
    "    l_emb = L.layers.EmbeddingLayer(l_in,\n",
    "                                    input_size=voc_size+1, \n",
    "                                    output_size=emb_size)\n",
    "    \n",
    "    l_lstm1 = L.layers.LSTMLayer(l_emb,\n",
    "                                 num_units=rec_size,\n",
    "                                 nonlinearity=L.nonlinearities.tanh,\n",
    "                                 grad_clipping=100,\n",
    "                                 mask_input=l_mask)\n",
    "    \n",
    "    l_lstm2 = L.layers.LSTMLayer(l_lstm1,\n",
    "                                 num_units=rec_size,\n",
    "                                 nonlinearity=L.nonlinearities.tanh,\n",
    "                                 grad_clipping=100,\n",
    "                                 mask_input=l_mask)\n",
    "      \n",
    "    l_resh = L.layers.ReshapeLayer(l_lstm2, shape=(-1, rec_size))\n",
    "    \n",
    "    l_ssoft = SampledSoftmaxDenseLayer(l_resh, voc_mask, voc_size)\n",
    "    \n",
    "    l_out_final = L.layers.ReshapeLayer(l_ssoft, shape=(batch_size, seq_len, voc_size))\n",
    "    \n",
    "    return l_out_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voc_size = mt_voc_size\n",
    "emb_size = 100\n",
    "rec_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up input mask...\n"
     ]
    }
   ],
   "source": [
    "# sampled softmax test\n",
    "\n",
    "input_var = T.imatrix('inputs')\n",
    "targets = T.imatrix('targets') # these will be inputs shifted by 1\n",
    "mask_input_var = T.matrix('input_mask')\n",
    "voc_mask = T.vector('voc_mask')\n",
    "\n",
    "net = build_sampledsoft_rnnlm(input_var, mask_input_var, voc_mask, voc_size, emb_size, rec_size)\n",
    "out = L.layers.get_output(net)\n",
    "\n",
    "mask_idx = mask_input_var.nonzero()\n",
    "loss = L.objectives.categorical_crossentropy(out[mask_idx], targets[mask_idx])\n",
    "loss = loss.mean() # mean batch loss\n",
    "\n",
    "params = L.layers.get_all_params(net, trainable=True)\n",
    "updates = L.updates.adagrad(loss, params, learning_rate=.01)\n",
    "\n",
    "train_fn = theano.function([input_var, targets, mask_input_var, voc_mask], loss, updates=updates)\n",
    "\n",
    "### for validation\n",
    "\n",
    "test_out = L.layers.get_output(net, deterministic=True)\n",
    "test_loss = L.objectives.categorical_crossentropy(test_out[mask_idx], targets[mask_idx])\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_out, axis=1), targets), dtype=theano.config.floatX)\n",
    "\n",
    "val_fn = theano.function([input_var, targets, mask_input_var, voc_mask], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full softmax test\n",
    "\n",
    "input_var = T.imatrix('inputs')\n",
    "targets = T.imatrix('targets') # these will be inputs shifted by 1\n",
    "mask_input_var = T.matrix('input_mask')\n",
    "\n",
    "net = build_simple_rnnlm(input_var, mask_input_var, voc_size, emb_size, rec_size)\n",
    "out = L.layers.get_output(net)\n",
    "\n",
    "mask_idx = mask_input_var.nonzero()\n",
    "loss = L.objectives.categorical_crossentropy(out[mask_idx], targets[mask_idx])\n",
    "loss = loss.mean() # mean batch loss\n",
    "\n",
    "params = L.layers.get_all_params(net, trainable=True)\n",
    "updates = L.updates.adagrad(loss, params, learning_rate=.01)\n",
    "\n",
    "train_fn = theano.function([input_var, targets, mask_input_var], loss, updates=updates)\n",
    "\n",
    "### for validation\n",
    "\n",
    "test_out = L.layers.get_output(net, deterministic=True)\n",
    "test_loss = L.objectives.categorical_crossentropy(test_out[mask_idx], targets[mask_idx])\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_out, axis=1), targets), dtype=theano.config.floatX)\n",
    "\n",
    "val_fn = theano.function([input_var, targets, mask_input_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up input mask...\n",
      "setting up targets for hsoftmax...\n"
     ]
    }
   ],
   "source": [
    "# hierarchical softmax test\n",
    "\n",
    "input_var = T.imatrix('inputs')\n",
    "targets = T.imatrix('targets') # these will be inputs shifted by 1\n",
    "mask_input_var = T.matrix('input_mask')\n",
    "\n",
    "net = build_hsoft_rnnlm(input_var, targets, mask_input_var, voc_size, emb_size, rec_size)\n",
    "out = L.layers.get_output(net)\n",
    "\n",
    "mask_idx = mask_input_var.nonzero()\n",
    "loss = -T.sum(T.log(out[mask_idx])) / T.sum(mask_input_var)\n",
    "\n",
    "params = L.layers.get_all_params(net, trainable=True)\n",
    "#updates = L.updates.rmsprop(loss, params, learning_rate=.001, rho=.9, epsilon=1e-06)\n",
    "updates = L.updates.adagrad(loss, params, learning_rate=.01)\n",
    "\n",
    "train_fn = theano.function([input_var, targets, mask_input_var], loss, updates=updates)\n",
    "\n",
    "#### for validation\n",
    "\n",
    "test_out = L.layers.get_output(net, deterministic=True)\n",
    "test_loss = -T.sum(T.log(test_out[mask_idx])) / T.sum(mask_input_var)\n",
    "\n",
    "#test_acc = T.mean(T.eq(T.argmax(test_out, axis=1), targets), dtype=theano.config.floatX)\n",
    "\n",
    "val_fn = theano.function([input_var, targets, mask_input_var], test_loss)\n",
    "\n",
    "### dump weights\n",
    "\n",
    "# np.savez('model.npz', *L.layers.get_all_param_values(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with np.load('model_trained.npz') as f:\n",
    "#     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "#     L.layers.set_all_param_values(net, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 batches in 4.08 sec.    training loss:\t\t5.42535262108\n",
      "Done 20 batches in 8.16 sec.    training loss:\t\t5.24459784031\n",
      "Done 30 batches in 11.73 sec.    training loss:\t\t5.18125980695\n",
      "Done 40 batches in 15.66 sec.    training loss:\t\t5.13404990435\n",
      "Done 50 batches in 19.02 sec.    training loss:\t\t5.09522445679\n",
      "Done 60 batches in 23.27 sec.    training loss:\t\t5.07574270566\n",
      "Done 70 batches in 27.35 sec.    training loss:\t\t5.06155565126\n",
      "Done 80 batches in 31.64 sec.    training loss:\t\t5.05331097841\n",
      "Done 90 batches in 36.14 sec.    training loss:\t\t5.04104766316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-97d79d853211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mbatch_training_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mbatch_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;31m#         batch_err = train_fn(inputs, targets, mask)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inputs, out_)\u001b[0m\n\u001b[0;32m   2286\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2287\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minplace_increment\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2288\u001b[1;33m             \u001b[0minplace_increment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2289\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_legacy_perform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2290\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training, taken from mnist.py in lasagne examples\n",
    "\n",
    "num_epochs = 5\n",
    "mt_batch_size = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    time_wasted = 0\n",
    "    training_time = 0\n",
    "    \n",
    "    for batch in iterate_minibatches(mt_train, mt_batch_size):\n",
    "        \n",
    "        inputs, targets, mask, t = batch\n",
    "        \n",
    "        inp_u = np.unique(inputs)\n",
    "        if inp_u[0] == -1:\n",
    "            inp_u = inp_u[1:]\n",
    "        voc_mask = np.zeros((voc_size,), dtype=np.float32)\n",
    "        voc_mask[inp_u] = 1\n",
    "        \n",
    "        batch_training_time = time.time()\n",
    "        batch_err = train_fn(inputs, targets, mask, voc_mask)\n",
    "#         batch_err = train_fn(inputs, targets, mask)\n",
    "\n",
    "        train_err += batch_err\n",
    "        training_time += time.time() - batch_training_time\n",
    "        train_batches += 1\n",
    "        \n",
    "        time_wasted += t\n",
    "        if not train_batches % 10:\n",
    "            print \"Done {} batches in {:.2f} sec.    training loss:\\t\\t{}\".format(\n",
    "                train_batches, time.time() - start_time, train_err / train_batches)\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(mt_val, mt_batch_size):\n",
    "        inputs, targets, mask, t = batch\n",
    "        err = val_fn(inputs, targets, mask)\n",
    "        val_err += err\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print \"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time)\n",
    "    print \"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches)\n",
    "    print \"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches)\n",
    "    #print \"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "    #    val_acc / val_batches * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('model_trained_singleLSTM.npz', *L.layers.get_all_param_values(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_var = T.imatrix('inputs')\n",
    "gen_net = build_hsoft_rnnlm(input_var, None, None, voc_size, emb_size, rec_size)\n",
    "probs = L.layers.get_output(gen_net)[:,-1,:]\n",
    "get_probs = theano.function([input_var], probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with np.load('model_trained_singleLSTM.npz') as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    L.layers.set_all_param_values(gen_net, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i never had one because i ate it -- this isn ' t me ? i don ' t know .\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rnd_next_word(probs):\n",
    "    return np.random.choice(np.arange(len(probs[0])), p=probs[0])\n",
    "\n",
    "init_seq = ''\n",
    "utt = [1] + map(lambda w: mt_w_to_i.get(w, mt_w_to_i['<unk>']), init_seq.split())\n",
    "utt = np.asarray(utt, dtype=np.int32)[np.newaxis]\n",
    "\n",
    "i = 0\n",
    "while mt_i_to_w[utt[0,-1]] != '<utt_end>' and i < 50:\n",
    "    word_probs = get_probs(utt)\n",
    "    next_idx = rnd_next_word(word_probs)\n",
    "    utt = np.append(utt, next_idx)[np.newaxis].astype(np.int32)\n",
    "    i += 1\n",
    "    \n",
    "text = map(lambda i: mt_i_to_w[i], list(utt[0]))\n",
    "' '.join(text[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
