{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 5005)\n",
      "/home/maciek/anaconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "from itertools import chain\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "from SimpleRNNLM import SimpleRNNLM, iterate_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remember, now the pad value is the same as the <utt_end> token\n",
    "\n",
    "pad_value = -1 # <utt_end>'s vector is the last one\n",
    "\n",
    "def split_utt(utt):\n",
    "    u1, u2, u3 = [i for i,j in enumerate(utt) if j == 1]\n",
    "    return [utt[:u2], utt[u2:u3], utt[u3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "mt_path = \"/home/maciek/Desktop/mgr/DATA/MovieTriples_Dataset/\"\n",
    "\n",
    "def load_mt(path=mt_path):\n",
    "    tr = np.load(mt_path + 'Training.triples.pkl')\n",
    "    vl = np.load(mt_path + 'Validation.triples.pkl')\n",
    "    ts = np.load(mt_path + 'Test.triples.pkl')\n",
    "    \n",
    "    tr = chain(*map(split_utt, tr))\n",
    "    vl = chain(*map(split_utt, vl))\n",
    "    ts = chain(*map(split_utt, ts))\n",
    "    \n",
    "    return tr, vl, ts\n",
    "\n",
    "train, valid, test = load_mt()\n",
    "\n",
    "train = [utt for utt in train if len(utt) < 200]\n",
    "valid = [utt for utt in valid if len(utt) < 200]\n",
    "test  = [utt for utt in test  if len(utt) < 200]\n",
    "\n",
    "\n",
    "def get_mt_voc(mt_path=mt_path, train_len=len(train)):\n",
    "    word_list = np.load(mt_path + 'Training.dict.pkl')\n",
    "    word_list.sort(key=lambda x: x[1])\n",
    "    freqs = np.array(map(lambda x: x[2], word_list) + [train_len])\n",
    "    total_count = float(sum(freqs))\n",
    "    \n",
    "    words = map(lambda x: x[:2], word_list)\n",
    "    \n",
    "    w_to_idx = dict(words)\n",
    "    w_to_idx['<utt_end>'] = pad_value\n",
    "    idx_to_w = {v : k for (k,v) in w_to_idx.items()}\n",
    "    \n",
    "    return idx_to_w, w_to_idx, len(w_to_idx), freqs / total_count\n",
    "\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_mt_voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_embs, word2vec_embs_mask = np.load(mt_path + 'Word2Vec_WordEmb.pkl')\n",
    "word2vec_embs = np.vstack([word2vec_embs, L.init.GlorotUniform()((1,300))]).astype(np.float32)\n",
    "word2vec_embs_mask = np.vstack([word2vec_embs_mask, np.ones((1,300))])\n",
    "\n",
    "w2v_train_mask = np.where(word2vec_embs_mask[:,0] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "Building a network for generation...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "net = SimpleRNNLM(voc_size=voc_size,\n",
    "                  emb_size=300,\n",
    "                  rec_size=300,\n",
    "                  mode='ssoft',\n",
    "                  num_sampled=200,\n",
    "                  emb_init=word2vec_embs,\n",
    "                  ssoft_probs=freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# net.load_params(fname='5ep_w2vInit_300_300_ssoft(uni,200,non-unique)_bs50_cut200.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 batches in 1.41s\ttraining loss:\t7.494860\n",
      "Done 20 batches in 2.98s\ttraining loss:\t6.691600\n",
      "Done 30 batches in 4.30s\ttraining loss:\t6.356645\n",
      "Done 40 batches in 5.98s\ttraining loss:\t6.137196\n",
      "Done 50 batches in 7.51s\ttraining loss:\t5.986012\n",
      "Done 60 batches in 9.01s\ttraining loss:\t5.854042\n",
      "Done 70 batches in 10.15s\ttraining loss:\t5.732083\n",
      "Done 80 batches in 11.49s\ttraining loss:\t5.626317\n",
      "Done 90 batches in 13.05s\ttraining loss:\t5.543616\n",
      "Done 100 batches in 14.36s\ttraining loss:\t5.464922\n",
      "Done 110 batches in 15.65s\ttraining loss:\t5.397891\n",
      "Done 120 batches in 17.06s\ttraining loss:\t5.333810\n",
      "Done 130 batches in 18.37s\ttraining loss:\t5.279024\n",
      "Done 140 batches in 19.90s\ttraining loss:\t5.230633\n",
      "Done 150 batches in 21.53s\ttraining loss:\t5.188017\n",
      "Done 160 batches in 23.08s\ttraining loss:\t5.147366\n",
      "Done 170 batches in 24.40s\ttraining loss:\t5.105820\n",
      "Done 180 batches in 26.07s\ttraining loss:\t5.068550\n",
      "Done 190 batches in 27.38s\ttraining loss:\t5.032651\n",
      "Done 200 batches in 29.06s\ttraining loss:\t5.000240\n",
      "Done 210 batches in 30.73s\ttraining loss:\t4.969768\n",
      "Done 220 batches in 32.26s\ttraining loss:\t4.940278\n",
      "Done 230 batches in 33.59s\ttraining loss:\t4.912570\n",
      "Done 240 batches in 34.71s\ttraining loss:\t4.885700\n",
      "Done 250 batches in 36.15s\ttraining loss:\t4.858938\n",
      "Done 260 batches in 37.60s\ttraining loss:\t4.834797\n",
      "Done 270 batches in 38.97s\ttraining loss:\t4.811704\n",
      "Done 280 batches in 40.18s\ttraining loss:\t4.791600\n",
      "Done 290 batches in 41.78s\ttraining loss:\t4.772727\n",
      "Done 300 batches in 43.26s\ttraining loss:\t4.754163\n",
      "Done 310 batches in 44.65s\ttraining loss:\t4.735726\n",
      "Done 320 batches in 46.11s\ttraining loss:\t4.718475\n",
      "Done 330 batches in 47.78s\ttraining loss:\t4.702368\n",
      "Done 340 batches in 49.41s\ttraining loss:\t4.686933\n",
      "Done 350 batches in 50.93s\ttraining loss:\t4.671656\n",
      "Done 360 batches in 52.58s\ttraining loss:\t4.658708\n",
      "Done 370 batches in 54.08s\ttraining loss:\t4.644671\n",
      "Done 380 batches in 55.56s\ttraining loss:\t4.630506\n",
      "Done 390 batches in 56.99s\ttraining loss:\t4.616996\n",
      "Done 400 batches in 58.41s\ttraining loss:\t4.603601\n",
      "Done 410 batches in 59.71s\ttraining loss:\t4.591284\n",
      "Done 420 batches in 61.24s\ttraining loss:\t4.579348\n",
      "Done 430 batches in 62.73s\ttraining loss:\t4.568914\n",
      "Done 440 batches in 64.11s\ttraining loss:\t4.557980\n",
      "Done 450 batches in 65.33s\ttraining loss:\t4.546505\n",
      "Done 460 batches in 66.52s\ttraining loss:\t4.535601\n",
      "Done 470 batches in 67.82s\ttraining loss:\t4.525540\n",
      "Done 480 batches in 68.98s\ttraining loss:\t4.514896\n",
      "Done 490 batches in 70.42s\ttraining loss:\t4.506619\n",
      "Done 500 batches in 71.96s\ttraining loss:\t4.498465\n",
      "Done 510 batches in 73.32s\ttraining loss:\t4.489426\n",
      "Done 520 batches in 74.50s\ttraining loss:\t4.480385\n",
      "Done 530 batches in 75.83s\ttraining loss:\t4.471384\n",
      "Done 540 batches in 77.40s\ttraining loss:\t4.462224\n",
      "Done 550 batches in 78.88s\ttraining loss:\t4.454357\n",
      "Done 560 batches in 80.29s\ttraining loss:\t4.447320\n",
      "Done 570 batches in 81.73s\ttraining loss:\t4.440638\n",
      "Done 580 batches in 83.23s\ttraining loss:\t4.433264\n",
      "Done 590 batches in 84.57s\ttraining loss:\t4.425785\n",
      "Done 600 batches in 86.05s\ttraining loss:\t4.419724\n",
      "Done 610 batches in 87.40s\ttraining loss:\t4.412704\n",
      "Done 620 batches in 88.64s\ttraining loss:\t4.406111\n",
      "Done 630 batches in 89.94s\ttraining loss:\t4.399518\n",
      "Done 640 batches in 91.51s\ttraining loss:\t4.392891\n",
      "Done 650 batches in 93.60s\ttraining loss:\t4.387469\n",
      "Done 660 batches in 94.88s\ttraining loss:\t4.381361\n",
      "Done 670 batches in 96.25s\ttraining loss:\t4.375946\n",
      "Done 680 batches in 97.51s\ttraining loss:\t4.370121\n",
      "Done 690 batches in 98.84s\ttraining loss:\t4.364177\n",
      "Done 700 batches in 100.00s\ttraining loss:\t4.358205\n",
      "Done 710 batches in 101.25s\ttraining loss:\t4.352109\n",
      "Done 720 batches in 102.74s\ttraining loss:\t4.346446\n",
      "Done 730 batches in 104.00s\ttraining loss:\t4.341739\n",
      "Done 740 batches in 105.62s\ttraining loss:\t4.337243\n",
      "Done 750 batches in 107.18s\ttraining loss:\t4.333052\n",
      "Done 760 batches in 108.59s\ttraining loss:\t4.328178\n",
      "Done 770 batches in 110.20s\ttraining loss:\t4.323549\n",
      "Done 780 batches in 111.60s\ttraining loss:\t4.317978\n",
      "Done 790 batches in 112.76s\ttraining loss:\t4.313327\n",
      "Done 800 batches in 114.27s\ttraining loss:\t4.309084\n",
      "Done 810 batches in 116.02s\ttraining loss:\t4.304412\n",
      "Done 820 batches in 117.38s\ttraining loss:\t4.299417\n",
      "Done 830 batches in 118.69s\ttraining loss:\t4.295290\n",
      "Done 840 batches in 119.87s\ttraining loss:\t4.290998\n",
      "Done 850 batches in 121.42s\ttraining loss:\t4.286610\n",
      "Done 860 batches in 122.79s\ttraining loss:\t4.282770\n",
      "Done 870 batches in 124.12s\ttraining loss:\t4.278844\n",
      "Done 880 batches in 125.56s\ttraining loss:\t4.275041\n",
      "Done 890 batches in 127.09s\ttraining loss:\t4.270659\n",
      "Done 900 batches in 128.43s\ttraining loss:\t4.266424\n",
      "Done 910 batches in 129.68s\ttraining loss:\t4.262439\n",
      "Done 920 batches in 131.03s\ttraining loss:\t4.258859\n",
      "Done 930 batches in 132.47s\ttraining loss:\t4.255068\n",
      "Done 940 batches in 133.99s\ttraining loss:\t4.250799\n",
      "Done 950 batches in 135.37s\ttraining loss:\t4.247021\n",
      "Done 960 batches in 136.50s\ttraining loss:\t4.243503\n",
      "Done 970 batches in 137.91s\ttraining loss:\t4.239746\n",
      "Done 980 batches in 139.09s\ttraining loss:\t4.236356\n",
      "Done 990 batches in 140.47s\ttraining loss:\t4.233423\n",
      "Done 1000 batches in 141.83s\ttraining loss:\t4.229953\n",
      "Done 1010 batches in 143.23s\ttraining loss:\t4.226813\n",
      "Done 1020 batches in 144.66s\ttraining loss:\t4.223638\n",
      "Done 1030 batches in 145.91s\ttraining loss:\t4.220516\n",
      "Done 1040 batches in 147.34s\ttraining loss:\t4.217706\n",
      "Done 1050 batches in 148.80s\ttraining loss:\t4.214961\n",
      "Done 1060 batches in 150.16s\ttraining loss:\t4.211589\n",
      "Done 1070 batches in 151.47s\ttraining loss:\t4.208629\n",
      "Done 1080 batches in 153.08s\ttraining loss:\t4.205962\n",
      "Done 1090 batches in 154.20s\ttraining loss:\t4.203002\n",
      "Done 1100 batches in 155.60s\ttraining loss:\t4.199918\n",
      "Done 1110 batches in 157.01s\ttraining loss:\t4.197169\n",
      "Done 1120 batches in 158.41s\ttraining loss:\t4.194068\n",
      "Done 1130 batches in 159.86s\ttraining loss:\t4.191461\n",
      "Done 1140 batches in 161.03s\ttraining loss:\t4.188494\n",
      "Done 1150 batches in 162.57s\ttraining loss:\t4.185876\n",
      "Done 1160 batches in 163.78s\ttraining loss:\t4.182907\n",
      "Done 1170 batches in 165.04s\ttraining loss:\t4.180083\n",
      "Done 1180 batches in 166.86s\ttraining loss:\t4.177418\n",
      "Done 1190 batches in 168.13s\ttraining loss:\t4.174746\n",
      "Done 1200 batches in 169.42s\ttraining loss:\t4.172162\n",
      "Done 1210 batches in 170.68s\ttraining loss:\t4.169598\n",
      "Done 1220 batches in 172.09s\ttraining loss:\t4.166853\n",
      "Done 1230 batches in 173.38s\ttraining loss:\t4.164274\n",
      "Done 1240 batches in 174.77s\ttraining loss:\t4.161534\n",
      "Done 1250 batches in 176.08s\ttraining loss:\t4.158498\n",
      "Done 1260 batches in 177.67s\ttraining loss:\t4.156100\n",
      "Done 1270 batches in 178.90s\ttraining loss:\t4.153801\n",
      "Done 1280 batches in 180.26s\ttraining loss:\t4.151219\n",
      "Done 1290 batches in 181.68s\ttraining loss:\t4.149188\n",
      "Done 1300 batches in 183.16s\ttraining loss:\t4.146822\n",
      "Done 1310 batches in 184.74s\ttraining loss:\t4.144264\n",
      "Done 1320 batches in 186.41s\ttraining loss:\t4.141638\n",
      "Done 1330 batches in 187.63s\ttraining loss:\t4.138966\n",
      "Done 1340 batches in 189.20s\ttraining loss:\t4.136558\n",
      "Done 1350 batches in 190.60s\ttraining loss:\t4.134201\n",
      "Done 1360 batches in 191.78s\ttraining loss:\t4.131573\n",
      "Done 1370 batches in 193.02s\ttraining loss:\t4.129437\n",
      "Done 1380 batches in 194.53s\ttraining loss:\t4.127379\n",
      "Done 1390 batches in 195.93s\ttraining loss:\t4.125202\n",
      "Done 1400 batches in 197.39s\ttraining loss:\t4.123305\n",
      "Done 1410 batches in 199.21s\ttraining loss:\t4.121336\n",
      "Done 1420 batches in 200.42s\ttraining loss:\t4.119124\n",
      "Done 1430 batches in 201.80s\ttraining loss:\t4.116909\n",
      "Done 1440 batches in 203.41s\ttraining loss:\t4.114981\n",
      "Done 1450 batches in 204.81s\ttraining loss:\t4.113133\n",
      "Done 1460 batches in 205.93s\ttraining loss:\t4.111384\n",
      "Done 1470 batches in 207.27s\ttraining loss:\t4.109559\n",
      "Done 1480 batches in 208.55s\ttraining loss:\t4.107353\n",
      "Done 1490 batches in 209.78s\ttraining loss:\t4.105228\n",
      "Done 1500 batches in 211.32s\ttraining loss:\t4.103053\n",
      "Done 1510 batches in 212.62s\ttraining loss:\t4.100780\n",
      "Done 1520 batches in 214.11s\ttraining loss:\t4.098611\n",
      "Done 1530 batches in 215.40s\ttraining loss:\t4.096807\n",
      "Done 1540 batches in 216.57s\ttraining loss:\t4.094657\n",
      "Done 1550 batches in 217.95s\ttraining loss:\t4.092933\n",
      "Done 1560 batches in 219.45s\ttraining loss:\t4.091102\n",
      "Done 1570 batches in 221.00s\ttraining loss:\t4.089308\n",
      "Done 1580 batches in 222.37s\ttraining loss:\t4.087649\n",
      "Done 1590 batches in 223.74s\ttraining loss:\t4.085800\n",
      "Done 1600 batches in 225.08s\ttraining loss:\t4.084213\n",
      "Done 1610 batches in 225.98s\ttraining loss:\t4.082142\n",
      "Done 1620 batches in 227.62s\ttraining loss:\t4.080367\n",
      "Done 1630 batches in 229.08s\ttraining loss:\t4.078646\n",
      "Done 1640 batches in 230.35s\ttraining loss:\t4.076988\n",
      "Done 1650 batches in 231.66s\ttraining loss:\t4.075393\n",
      "Done 1660 batches in 233.08s\ttraining loss:\t4.073684\n",
      "Done 1670 batches in 234.32s\ttraining loss:\t4.072049\n",
      "Done 1680 batches in 236.22s\ttraining loss:\t4.070627\n",
      "Done 1690 batches in 237.53s\ttraining loss:\t4.068962\n",
      "Done 1700 batches in 238.89s\ttraining loss:\t4.067350\n",
      "Done 1710 batches in 240.08s\ttraining loss:\t4.065294\n",
      "Done 1720 batches in 241.59s\ttraining loss:\t4.063893\n",
      "Done 1730 batches in 242.72s\ttraining loss:\t4.062081\n",
      "Done 1740 batches in 243.91s\ttraining loss:\t4.060483\n",
      "Done 1750 batches in 245.62s\ttraining loss:\t4.058998\n",
      "Done 1760 batches in 246.86s\ttraining loss:\t4.057370\n",
      "Done 1770 batches in 248.37s\ttraining loss:\t4.055708\n",
      "Done 1780 batches in 249.59s\ttraining loss:\t4.054133\n",
      "Done 1790 batches in 250.82s\ttraining loss:\t4.052564\n",
      "Done 1800 batches in 252.17s\ttraining loss:\t4.051190\n",
      "Done 1810 batches in 253.80s\ttraining loss:\t4.049765\n",
      "Done 1820 batches in 255.10s\ttraining loss:\t4.048029\n",
      "Done 1830 batches in 256.56s\ttraining loss:\t4.046781\n",
      "Done 1840 batches in 257.76s\ttraining loss:\t4.045127\n",
      "Done 1850 batches in 259.14s\ttraining loss:\t4.043395\n",
      "Done 1860 batches in 260.47s\ttraining loss:\t4.041930\n",
      "Done 1870 batches in 261.91s\ttraining loss:\t4.040366\n",
      "Done 1880 batches in 263.23s\ttraining loss:\t4.038959\n",
      "Done 1890 batches in 264.39s\ttraining loss:\t4.037523\n",
      "Done 1900 batches in 265.72s\ttraining loss:\t4.035842\n",
      "Done 1910 batches in 267.03s\ttraining loss:\t4.034454\n",
      "Done 1920 batches in 268.46s\ttraining loss:\t4.033077\n",
      "Done 1930 batches in 269.69s\ttraining loss:\t4.031732\n",
      "Done 1940 batches in 271.15s\ttraining loss:\t4.030408\n",
      "Done 1950 batches in 272.64s\ttraining loss:\t4.028807\n",
      "Done 1960 batches in 273.76s\ttraining loss:\t4.027172\n",
      "Done 1970 batches in 275.06s\ttraining loss:\t4.026068\n",
      "Done 1980 batches in 276.62s\ttraining loss:\t4.024639\n",
      "Done 1990 batches in 277.84s\ttraining loss:\t4.023166\n",
      "Done 2000 batches in 279.25s\ttraining loss:\t4.022093\n",
      "Done 2010 batches in 280.60s\ttraining loss:\t4.020903\n",
      "Done 2020 batches in 281.81s\ttraining loss:\t4.019542\n",
      "Done 2030 batches in 283.21s\ttraining loss:\t4.018213\n",
      "Done 2040 batches in 284.57s\ttraining loss:\t4.017033\n",
      "Done 2050 batches in 285.67s\ttraining loss:\t4.015876\n",
      "Done 2060 batches in 287.10s\ttraining loss:\t4.014721\n",
      "Done 2070 batches in 288.45s\ttraining loss:\t4.013466\n",
      "Done 2080 batches in 289.90s\ttraining loss:\t4.012094\n",
      "Done 2090 batches in 291.21s\ttraining loss:\t4.010826\n",
      "Done 2100 batches in 292.66s\ttraining loss:\t4.009477\n",
      "Done 2110 batches in 293.98s\ttraining loss:\t4.008022\n",
      "Done 2120 batches in 295.43s\ttraining loss:\t4.006894\n",
      "Done 2130 batches in 296.59s\ttraining loss:\t4.005940\n",
      "Done 2140 batches in 297.98s\ttraining loss:\t4.004637\n",
      "Done 2150 batches in 299.41s\ttraining loss:\t4.003414\n",
      "Done 2160 batches in 300.62s\ttraining loss:\t4.002396\n",
      "Done 2170 batches in 302.07s\ttraining loss:\t4.001099\n",
      "Done 2180 batches in 303.35s\ttraining loss:\t3.999919\n",
      "Done 2190 batches in 304.69s\ttraining loss:\t3.998751\n",
      "Done 2200 batches in 305.83s\ttraining loss:\t3.997411\n",
      "Done 2210 batches in 306.94s\ttraining loss:\t3.996017\n",
      "Done 2220 batches in 308.69s\ttraining loss:\t3.994987\n",
      "Done 2230 batches in 310.29s\ttraining loss:\t3.993758\n",
      "Done 2240 batches in 311.60s\ttraining loss:\t3.992537\n",
      "Done 2250 batches in 312.86s\ttraining loss:\t3.991251\n",
      "Done 2260 batches in 314.17s\ttraining loss:\t3.990258\n",
      "Done 2270 batches in 315.59s\ttraining loss:\t3.989274\n",
      "Done 2280 batches in 316.71s\ttraining loss:\t3.988224\n",
      "Done 2290 batches in 318.06s\ttraining loss:\t3.987250\n",
      "Done 2300 batches in 319.30s\ttraining loss:\t3.986251\n",
      "Done 2310 batches in 320.89s\ttraining loss:\t3.985292\n",
      "Done 2320 batches in 322.19s\ttraining loss:\t3.984278\n",
      "Done 2330 batches in 323.50s\ttraining loss:\t3.982883\n",
      "Done 2340 batches in 325.11s\ttraining loss:\t3.981853\n",
      "Done 2350 batches in 326.38s\ttraining loss:\t3.980717\n",
      "Done 2360 batches in 327.70s\ttraining loss:\t3.979648\n",
      "Done 2370 batches in 328.99s\ttraining loss:\t3.978594\n",
      "Done 2380 batches in 330.27s\ttraining loss:\t3.977497\n",
      "Done 2390 batches in 331.85s\ttraining loss:\t3.976302\n",
      "Done 2400 batches in 333.15s\ttraining loss:\t3.975185\n",
      "Done 2410 batches in 334.60s\ttraining loss:\t3.974127\n",
      "Done 2420 batches in 335.79s\ttraining loss:\t3.972901\n",
      "Done 2430 batches in 336.88s\ttraining loss:\t3.971709\n",
      "Done 2440 batches in 338.39s\ttraining loss:\t3.970735\n",
      "Done 2450 batches in 339.68s\ttraining loss:\t3.969660\n",
      "Done 2460 batches in 340.94s\ttraining loss:\t3.968505\n",
      "Done 2470 batches in 342.31s\ttraining loss:\t3.967414\n",
      "Done 2480 batches in 344.01s\ttraining loss:\t3.966522\n",
      "Done 2490 batches in 345.43s\ttraining loss:\t3.965794\n",
      "Done 2500 batches in 346.60s\ttraining loss:\t3.964755\n",
      "Done 2510 batches in 347.72s\ttraining loss:\t3.963934\n",
      "Done 2520 batches in 349.03s\ttraining loss:\t3.962880\n",
      "Done 2530 batches in 350.57s\ttraining loss:\t3.961909\n",
      "Done 2540 batches in 351.66s\ttraining loss:\t3.960847\n",
      "Done 2550 batches in 353.06s\ttraining loss:\t3.959921\n",
      "Done 2560 batches in 354.44s\ttraining loss:\t3.958862\n",
      "Done 2570 batches in 355.96s\ttraining loss:\t3.957960\n",
      "Done 2580 batches in 357.33s\ttraining loss:\t3.956926\n",
      "Done 2590 batches in 358.48s\ttraining loss:\t3.956002\n",
      "Done 2600 batches in 360.06s\ttraining loss:\t3.954886\n",
      "Done 2610 batches in 361.09s\ttraining loss:\t3.954101\n",
      "Done 2620 batches in 362.69s\ttraining loss:\t3.953241\n",
      "Done 2630 batches in 364.06s\ttraining loss:\t3.952230\n",
      "Done 2640 batches in 365.35s\ttraining loss:\t3.951270\n",
      "Done 2650 batches in 366.75s\ttraining loss:\t3.950451\n",
      "Done 2660 batches in 368.12s\ttraining loss:\t3.949549\n",
      "Done 2670 batches in 369.56s\ttraining loss:\t3.948677\n",
      "Done 2680 batches in 371.03s\ttraining loss:\t3.947768\n",
      "Done 2690 batches in 372.28s\ttraining loss:\t3.946992\n",
      "Done 2700 batches in 373.56s\ttraining loss:\t3.946196\n",
      "Done 2710 batches in 375.11s\ttraining loss:\t3.945449\n",
      "Done 2720 batches in 376.19s\ttraining loss:\t3.944613\n",
      "Done 2730 batches in 377.38s\ttraining loss:\t3.943553\n",
      "Done 2740 batches in 378.50s\ttraining loss:\t3.942621\n",
      "Done 2750 batches in 379.93s\ttraining loss:\t3.941715\n",
      "Done 2760 batches in 381.29s\ttraining loss:\t3.940890\n",
      "Done 2770 batches in 382.74s\ttraining loss:\t3.940242\n",
      "Done 2780 batches in 384.40s\ttraining loss:\t3.939288\n",
      "Done 2790 batches in 385.79s\ttraining loss:\t3.938319\n",
      "Done 2800 batches in 387.02s\ttraining loss:\t3.937541\n",
      "Done 2810 batches in 388.48s\ttraining loss:\t3.936726\n",
      "Done 2820 batches in 389.63s\ttraining loss:\t3.935806\n",
      "Done 2830 batches in 390.82s\ttraining loss:\t3.934839\n",
      "Done 2840 batches in 392.20s\ttraining loss:\t3.934003\n",
      "Done 2850 batches in 393.82s\ttraining loss:\t3.933040\n",
      "Done 2860 batches in 395.12s\ttraining loss:\t3.932275\n",
      "Done 2870 batches in 396.29s\ttraining loss:\t3.931229\n",
      "Done 2880 batches in 397.50s\ttraining loss:\t3.930279\n",
      "Done 2890 batches in 398.92s\ttraining loss:\t3.929429\n",
      "Done 2900 batches in 400.26s\ttraining loss:\t3.928771\n",
      "Done 2910 batches in 401.58s\ttraining loss:\t3.928043\n",
      "Done 2920 batches in 402.81s\ttraining loss:\t3.927163\n",
      "Done 2930 batches in 404.14s\ttraining loss:\t3.926285\n",
      "Done 2940 batches in 405.46s\ttraining loss:\t3.925440\n",
      "Done 2950 batches in 406.75s\ttraining loss:\t3.924545\n",
      "Done 2960 batches in 408.20s\ttraining loss:\t3.923727\n",
      "Done 2970 batches in 409.63s\ttraining loss:\t3.922860\n",
      "Done 2980 batches in 410.74s\ttraining loss:\t3.921977\n",
      "Done 2990 batches in 411.76s\ttraining loss:\t3.921142\n",
      "Done 3000 batches in 413.08s\ttraining loss:\t3.920328\n",
      "Done 3010 batches in 414.39s\ttraining loss:\t3.919564\n",
      "Done 3020 batches in 415.48s\ttraining loss:\t3.918765\n",
      "Done 3030 batches in 416.98s\ttraining loss:\t3.918047\n",
      "Done 3040 batches in 418.27s\ttraining loss:\t3.917305\n",
      "Done 3050 batches in 419.86s\ttraining loss:\t3.916511\n",
      "Done 3060 batches in 420.84s\ttraining loss:\t3.915676\n",
      "Done 3070 batches in 422.02s\ttraining loss:\t3.914900\n",
      "Done 3080 batches in 423.14s\ttraining loss:\t3.913812\n",
      "Done 3090 batches in 424.65s\ttraining loss:\t3.913160\n",
      "Done 3100 batches in 425.92s\ttraining loss:\t3.912375\n",
      "Done 3110 batches in 427.66s\ttraining loss:\t3.911637\n",
      "Done 3120 batches in 428.96s\ttraining loss:\t3.910947\n",
      "Done 3130 batches in 430.20s\ttraining loss:\t3.910202\n",
      "Done 3140 batches in 431.49s\ttraining loss:\t3.909497\n",
      "Done 3150 batches in 432.75s\ttraining loss:\t3.908669\n",
      "Done 3160 batches in 433.91s\ttraining loss:\t3.907991\n",
      "Done 3170 batches in 435.34s\ttraining loss:\t3.907293\n",
      "Done 3180 batches in 436.44s\ttraining loss:\t3.906589\n",
      "Done 3190 batches in 437.70s\ttraining loss:\t3.905846\n",
      "Done 3200 batches in 439.11s\ttraining loss:\t3.905126\n",
      "Done 3210 batches in 440.56s\ttraining loss:\t3.904409\n",
      "Done 3220 batches in 441.78s\ttraining loss:\t3.903643\n",
      "Done 3230 batches in 443.07s\ttraining loss:\t3.902882\n",
      "Done 3240 batches in 444.44s\ttraining loss:\t3.902170\n",
      "Done 3250 batches in 445.63s\ttraining loss:\t3.901512\n",
      "Done 3260 batches in 447.01s\ttraining loss:\t3.900759\n",
      "Done 3270 batches in 448.29s\ttraining loss:\t3.900206\n",
      "Done 3280 batches in 449.78s\ttraining loss:\t3.899564\n",
      "Done 3290 batches in 450.96s\ttraining loss:\t3.898990\n",
      "Done 3300 batches in 452.14s\ttraining loss:\t3.898387\n",
      "Done 3310 batches in 453.49s\ttraining loss:\t3.897706\n",
      "Done 3320 batches in 454.76s\ttraining loss:\t3.896901\n",
      "Done 3330 batches in 456.22s\ttraining loss:\t3.896230\n",
      "Done 3340 batches in 457.47s\ttraining loss:\t3.895526\n",
      "Done 3350 batches in 458.73s\ttraining loss:\t3.894899\n",
      "Done 3360 batches in 460.32s\ttraining loss:\t3.894273\n",
      "Done 3370 batches in 461.78s\ttraining loss:\t3.893629\n",
      "Done 3380 batches in 463.27s\ttraining loss:\t3.892968\n",
      "Done 3390 batches in 464.86s\ttraining loss:\t3.892297\n",
      "Done 3400 batches in 466.05s\ttraining loss:\t3.891539\n",
      "Done 3410 batches in 467.60s\ttraining loss:\t3.890979\n",
      "Done 3420 batches in 468.80s\ttraining loss:\t3.890236\n",
      "Done 3430 batches in 470.08s\ttraining loss:\t3.889518\n",
      "Done 3440 batches in 471.44s\ttraining loss:\t3.888915\n",
      "Done 3450 batches in 472.59s\ttraining loss:\t3.888304\n",
      "Done 3460 batches in 473.87s\ttraining loss:\t3.887751\n",
      "Done 3470 batches in 475.17s\ttraining loss:\t3.887235\n",
      "Done 3480 batches in 476.74s\ttraining loss:\t3.886593\n",
      "Done 3490 batches in 478.14s\ttraining loss:\t3.885882\n",
      "Done 3500 batches in 479.32s\ttraining loss:\t3.885172\n",
      "Done 3510 batches in 480.74s\ttraining loss:\t3.884496\n",
      "Done 3520 batches in 482.17s\ttraining loss:\t3.883777\n",
      "Done 3530 batches in 483.53s\ttraining loss:\t3.883116\n",
      "Done 3540 batches in 485.14s\ttraining loss:\t3.882516\n",
      "Done 3550 batches in 486.53s\ttraining loss:\t3.881936\n",
      "Done 3560 batches in 487.72s\ttraining loss:\t3.881338\n",
      "Done 3570 batches in 489.27s\ttraining loss:\t3.880823\n",
      "Done 3580 batches in 491.01s\ttraining loss:\t3.880201\n",
      "Done 3590 batches in 492.45s\ttraining loss:\t3.879615\n",
      "Done 3600 batches in 493.78s\ttraining loss:\t3.878991\n",
      "Done 3610 batches in 495.21s\ttraining loss:\t3.878398\n",
      "Done 3620 batches in 496.57s\ttraining loss:\t3.877735\n",
      "Done 3630 batches in 498.05s\ttraining loss:\t3.877112\n",
      "Done 3640 batches in 499.72s\ttraining loss:\t3.876565\n",
      "Done 3650 batches in 500.90s\ttraining loss:\t3.875913\n",
      "Done 3660 batches in 502.12s\ttraining loss:\t3.875231\n",
      "Done 3670 batches in 503.49s\ttraining loss:\t3.874677\n",
      "Done 3680 batches in 504.61s\ttraining loss:\t3.874022\n",
      "Done 3690 batches in 506.24s\ttraining loss:\t3.873615\n",
      "Done 3700 batches in 507.23s\ttraining loss:\t3.872889\n",
      "Done 3710 batches in 508.71s\ttraining loss:\t3.872386\n",
      "Done 3720 batches in 510.07s\ttraining loss:\t3.871782\n",
      "Done 3730 batches in 511.41s\ttraining loss:\t3.871168\n",
      "Done 3740 batches in 512.71s\ttraining loss:\t3.870554\n",
      "Done 3750 batches in 514.11s\ttraining loss:\t3.869875\n",
      "Done 3760 batches in 515.58s\ttraining loss:\t3.869275\n",
      "Done 3770 batches in 517.06s\ttraining loss:\t3.868783\n",
      "Done 3780 batches in 518.43s\ttraining loss:\t3.868217\n",
      "Done 3790 batches in 519.83s\ttraining loss:\t3.867625\n",
      "Done 3800 batches in 521.22s\ttraining loss:\t3.867083\n",
      "Done 3810 batches in 522.34s\ttraining loss:\t3.866383\n",
      "Done 3820 batches in 523.70s\ttraining loss:\t3.865758\n",
      "Done 3830 batches in 525.29s\ttraining loss:\t3.865193\n",
      "Done 3840 batches in 526.94s\ttraining loss:\t3.864688\n",
      "Done 3850 batches in 528.08s\ttraining loss:\t3.863973\n",
      "Done 3860 batches in 529.46s\ttraining loss:\t3.863400\n",
      "Done 3870 batches in 530.66s\ttraining loss:\t3.862835\n",
      "Done 3880 batches in 531.95s\ttraining loss:\t3.862199\n",
      "Done 3890 batches in 533.32s\ttraining loss:\t3.861605\n",
      "Done 3900 batches in 534.89s\ttraining loss:\t3.861192\n",
      "Done 3910 batches in 536.14s\ttraining loss:\t3.860695\n",
      "Done 3920 batches in 537.26s\ttraining loss:\t3.860031\n",
      "Done 3930 batches in 538.48s\ttraining loss:\t3.859511\n",
      "Done 3940 batches in 539.93s\ttraining loss:\t3.859028\n",
      "Done 3950 batches in 541.32s\ttraining loss:\t3.858571\n",
      "Done 3960 batches in 542.62s\ttraining loss:\t3.857986\n",
      "Done 3970 batches in 543.96s\ttraining loss:\t3.857444\n",
      "Done 3980 batches in 545.49s\ttraining loss:\t3.856995\n",
      "Done 3990 batches in 546.54s\ttraining loss:\t3.856516\n",
      "Done 4000 batches in 547.75s\ttraining loss:\t3.855995\n",
      "Done 4010 batches in 549.07s\ttraining loss:\t3.855433\n",
      "Done 4020 batches in 550.35s\ttraining loss:\t3.854788\n",
      "Done 4030 batches in 551.48s\ttraining loss:\t3.854184\n",
      "Done 4040 batches in 552.72s\ttraining loss:\t3.853612\n",
      "Done 4050 batches in 554.23s\ttraining loss:\t3.853042\n",
      "Done 4060 batches in 555.57s\ttraining loss:\t3.852444\n",
      "Done 4070 batches in 556.87s\ttraining loss:\t3.851943\n",
      "Done 4080 batches in 558.57s\ttraining loss:\t3.851553\n",
      "Done 4090 batches in 560.07s\ttraining loss:\t3.850947\n",
      "Done 4100 batches in 561.62s\ttraining loss:\t3.850489\n",
      "Done 4110 batches in 563.01s\ttraining loss:\t3.850029\n",
      "Done 4120 batches in 564.20s\ttraining loss:\t3.849420\n",
      "Done 4130 batches in 565.64s\ttraining loss:\t3.848816\n",
      "Done 4140 batches in 567.15s\ttraining loss:\t3.848428\n",
      "Done 4150 batches in 568.64s\ttraining loss:\t3.847955\n",
      "Done 4160 batches in 570.02s\ttraining loss:\t3.847564\n",
      "Done 4170 batches in 571.48s\ttraining loss:\t3.847035\n",
      "Done 4180 batches in 572.99s\ttraining loss:\t3.846504\n",
      "Done 4190 batches in 574.32s\ttraining loss:\t3.845933\n",
      "Done 4200 batches in 575.58s\ttraining loss:\t3.845486\n",
      "Done 4210 batches in 576.88s\ttraining loss:\t3.844917\n",
      "Done 4220 batches in 578.23s\ttraining loss:\t3.844400\n",
      "Done 4230 batches in 579.43s\ttraining loss:\t3.843830\n",
      "Done 4240 batches in 580.78s\ttraining loss:\t3.843441\n",
      "Done 4250 batches in 582.14s\ttraining loss:\t3.842874\n",
      "Done 4260 batches in 583.63s\ttraining loss:\t3.842321\n",
      "Done 4270 batches in 584.88s\ttraining loss:\t3.841816\n",
      "Done 4280 batches in 585.93s\ttraining loss:\t3.841281\n",
      "Done 4290 batches in 587.30s\ttraining loss:\t3.840755\n",
      "Done 4300 batches in 588.80s\ttraining loss:\t3.840279\n",
      "Done 4310 batches in 589.88s\ttraining loss:\t3.839798\n",
      "Done 4320 batches in 591.65s\ttraining loss:\t3.839404\n",
      "Done 4330 batches in 593.12s\ttraining loss:\t3.838847\n",
      "Done 4340 batches in 594.35s\ttraining loss:\t3.838375\n",
      "Done 4350 batches in 595.83s\ttraining loss:\t3.837909\n",
      "Done 4360 batches in 597.04s\ttraining loss:\t3.837442\n",
      "Done 4370 batches in 598.74s\ttraining loss:\t3.836938\n",
      "Done 4380 batches in 600.15s\ttraining loss:\t3.836438\n",
      "Done 4390 batches in 601.56s\ttraining loss:\t3.835938\n",
      "Done 4400 batches in 602.94s\ttraining loss:\t3.835441\n",
      "Done 4410 batches in 604.41s\ttraining loss:\t3.835018\n",
      "Done 4420 batches in 605.52s\ttraining loss:\t3.834536\n",
      "Done 4430 batches in 606.91s\ttraining loss:\t3.834060\n",
      "Done 4440 batches in 608.11s\ttraining loss:\t3.833623\n",
      "Done 4450 batches in 609.40s\ttraining loss:\t3.833174\n",
      "Done 4460 batches in 610.83s\ttraining loss:\t3.832736\n",
      "Done 4470 batches in 612.38s\ttraining loss:\t3.832286\n",
      "Done 4480 batches in 613.64s\ttraining loss:\t3.831849\n",
      "Done 4490 batches in 615.18s\ttraining loss:\t3.831303\n",
      "Done 4500 batches in 616.39s\ttraining loss:\t3.830806\n",
      "Done 4510 batches in 617.65s\ttraining loss:\t3.830344\n",
      "Done 4520 batches in 619.17s\ttraining loss:\t3.829850\n",
      "Done 4530 batches in 620.55s\ttraining loss:\t3.829386\n",
      "Done 4540 batches in 622.06s\ttraining loss:\t3.828924\n",
      "Done 4550 batches in 623.51s\ttraining loss:\t3.828551\n",
      "Done 4560 batches in 625.03s\ttraining loss:\t3.828107\n",
      "Done 4570 batches in 626.39s\ttraining loss:\t3.827678\n",
      "Done 4580 batches in 627.67s\ttraining loss:\t3.827238\n",
      "Done 4590 batches in 629.07s\ttraining loss:\t3.826785\n",
      "Done 4600 batches in 630.59s\ttraining loss:\t3.826376\n",
      "Done 4610 batches in 631.97s\ttraining loss:\t3.825937\n",
      "Done 4620 batches in 633.40s\ttraining loss:\t3.825557\n",
      "Done 4630 batches in 634.57s\ttraining loss:\t3.825118\n",
      "Done 4640 batches in 635.79s\ttraining loss:\t3.824601\n",
      "Done 4650 batches in 637.06s\ttraining loss:\t3.824116\n",
      "Done 4660 batches in 638.25s\ttraining loss:\t3.823665\n",
      "Done 4670 batches in 639.59s\ttraining loss:\t3.823187\n",
      "Done 4680 batches in 640.81s\ttraining loss:\t3.822851\n",
      "Done 4690 batches in 642.38s\ttraining loss:\t3.822445\n",
      "Done 4700 batches in 643.73s\ttraining loss:\t3.822008\n",
      "Done 4710 batches in 644.80s\ttraining loss:\t3.821516\n",
      "Done 4720 batches in 646.24s\ttraining loss:\t3.821073\n",
      "Done 4730 batches in 647.85s\ttraining loss:\t3.820819\n",
      "Done 4740 batches in 649.15s\ttraining loss:\t3.820428\n",
      "Done 4750 batches in 650.36s\ttraining loss:\t3.820029\n",
      "Done 4760 batches in 651.89s\ttraining loss:\t3.819528\n",
      "Done 4770 batches in 653.19s\ttraining loss:\t3.819093\n",
      "Done 4780 batches in 654.45s\ttraining loss:\t3.818611\n",
      "Done 4790 batches in 655.73s\ttraining loss:\t3.818143\n",
      "Done 4800 batches in 657.35s\ttraining loss:\t3.817795\n",
      "Done 4810 batches in 658.51s\ttraining loss:\t3.817334\n",
      "Done 4820 batches in 659.99s\ttraining loss:\t3.816855\n",
      "Done 4830 batches in 661.39s\ttraining loss:\t3.816492\n",
      "Done 4840 batches in 662.49s\ttraining loss:\t3.816093\n",
      "Done 4850 batches in 663.70s\ttraining loss:\t3.815635\n",
      "Done 4860 batches in 665.22s\ttraining loss:\t3.815276\n",
      "Done 4870 batches in 666.61s\ttraining loss:\t3.814799\n",
      "Done 4880 batches in 667.96s\ttraining loss:\t3.814411\n",
      "Done 4890 batches in 669.41s\ttraining loss:\t3.813930\n",
      "Done 4900 batches in 670.71s\ttraining loss:\t3.813448\n",
      "Done 4910 batches in 671.90s\ttraining loss:\t3.813026\n",
      "Done 4920 batches in 673.38s\ttraining loss:\t3.812607\n",
      "Done 4930 batches in 674.69s\ttraining loss:\t3.812189\n",
      "Done 4940 batches in 676.10s\ttraining loss:\t3.811822\n",
      "Done 4950 batches in 677.62s\ttraining loss:\t3.811452\n",
      "Done 4960 batches in 679.22s\ttraining loss:\t3.811072\n",
      "Done 4970 batches in 680.49s\ttraining loss:\t3.810584\n",
      "Done 4980 batches in 681.79s\ttraining loss:\t3.810134\n",
      "Done 4990 batches in 683.26s\ttraining loss:\t3.809743\n",
      "Done 5000 batches in 684.76s\ttraining loss:\t3.809390\n",
      "Done 5010 batches in 686.13s\ttraining loss:\t3.808906\n",
      "Done 5020 batches in 687.58s\ttraining loss:\t3.808494\n",
      "Done 5030 batches in 689.00s\ttraining loss:\t3.808045\n",
      "Done 5040 batches in 690.22s\ttraining loss:\t3.807593\n",
      "Done 5050 batches in 691.39s\ttraining loss:\t3.807223\n",
      "Done 5060 batches in 692.65s\ttraining loss:\t3.806855\n",
      "Done 5070 batches in 694.23s\ttraining loss:\t3.806426\n",
      "Done 5080 batches in 695.68s\ttraining loss:\t3.806068\n",
      "Done 5090 batches in 697.10s\ttraining loss:\t3.805706\n",
      "Done 5100 batches in 698.52s\ttraining loss:\t3.805272\n",
      "Done 5110 batches in 699.75s\ttraining loss:\t3.804889\n",
      "Done 5120 batches in 701.38s\ttraining loss:\t3.804527\n",
      "Done 5130 batches in 702.61s\ttraining loss:\t3.804115\n",
      "Done 5140 batches in 704.10s\ttraining loss:\t3.803627\n",
      "Done 5150 batches in 705.48s\ttraining loss:\t3.803243\n",
      "Done 5160 batches in 707.37s\ttraining loss:\t3.802952\n",
      "Done 5170 batches in 708.61s\ttraining loss:\t3.802513\n",
      "Done 5180 batches in 709.82s\ttraining loss:\t3.802117\n",
      "Done 5190 batches in 711.23s\ttraining loss:\t3.801708\n",
      "Done 5200 batches in 712.83s\ttraining loss:\t3.801324\n",
      "Done 5210 batches in 714.33s\ttraining loss:\t3.800938\n",
      "Done 5220 batches in 715.82s\ttraining loss:\t3.800527\n",
      "Done 5230 batches in 717.13s\ttraining loss:\t3.800192\n",
      "Done 5240 batches in 718.48s\ttraining loss:\t3.799852\n",
      "Done 5250 batches in 719.89s\ttraining loss:\t3.799485\n",
      "Done 5260 batches in 721.23s\ttraining loss:\t3.799182\n",
      "Done 5270 batches in 722.84s\ttraining loss:\t3.798890\n",
      "Done 5280 batches in 724.05s\ttraining loss:\t3.798504\n",
      "Done 5290 batches in 725.51s\ttraining loss:\t3.798151\n",
      "Done 5300 batches in 726.87s\ttraining loss:\t3.797797\n",
      "Done 5310 batches in 728.06s\ttraining loss:\t3.797426\n",
      "Done 5320 batches in 729.57s\ttraining loss:\t3.797080\n",
      "Done 5330 batches in 730.99s\ttraining loss:\t3.796655\n",
      "Done 5340 batches in 732.14s\ttraining loss:\t3.796278\n",
      "Done 5350 batches in 733.37s\ttraining loss:\t3.795895\n",
      "Done 5360 batches in 734.84s\ttraining loss:\t3.795556\n",
      "Done 5370 batches in 736.33s\ttraining loss:\t3.795223\n",
      "Done 5380 batches in 737.75s\ttraining loss:\t3.794885\n",
      "Done 5390 batches in 738.97s\ttraining loss:\t3.794562\n",
      "Done 5400 batches in 740.35s\ttraining loss:\t3.794241\n",
      "Done 5410 batches in 741.72s\ttraining loss:\t3.793956\n",
      "Done 5420 batches in 743.21s\ttraining loss:\t3.793532\n",
      "Done 5430 batches in 744.38s\ttraining loss:\t3.793279\n",
      "Done 5440 batches in 745.71s\ttraining loss:\t3.792866\n",
      "Done 5450 batches in 747.12s\ttraining loss:\t3.792529\n",
      "Done 5460 batches in 748.46s\ttraining loss:\t3.792198\n",
      "Done 5470 batches in 749.84s\ttraining loss:\t3.791820\n",
      "Done 5480 batches in 751.45s\ttraining loss:\t3.791436\n",
      "Done 5490 batches in 752.78s\ttraining loss:\t3.791087\n",
      "Done 5500 batches in 754.24s\ttraining loss:\t3.790749\n",
      "Done 5510 batches in 755.79s\ttraining loss:\t3.790420\n",
      "Done 5520 batches in 757.04s\ttraining loss:\t3.790098\n",
      "Done 5530 batches in 758.42s\ttraining loss:\t3.789781\n",
      "Done 5540 batches in 759.78s\ttraining loss:\t3.789399\n",
      "Done 5550 batches in 761.55s\ttraining loss:\t3.789063\n",
      "Done 5560 batches in 763.03s\ttraining loss:\t3.788814\n",
      "Done 5570 batches in 764.32s\ttraining loss:\t3.788466\n",
      "Done 5580 batches in 765.79s\ttraining loss:\t3.788125\n",
      "Done 5590 batches in 767.10s\ttraining loss:\t3.787760\n",
      "Done 5600 batches in 768.26s\ttraining loss:\t3.787368\n",
      "Done 5610 batches in 769.41s\ttraining loss:\t3.787011\n",
      "Done 5620 batches in 770.92s\ttraining loss:\t3.786648\n",
      "Done 5630 batches in 772.29s\ttraining loss:\t3.786329\n",
      "Done 5640 batches in 773.45s\ttraining loss:\t3.786028\n",
      "Done 5650 batches in 774.80s\ttraining loss:\t3.785634\n",
      "Done 5660 batches in 776.22s\ttraining loss:\t3.785356\n",
      "Done 5670 batches in 777.64s\ttraining loss:\t3.785032\n",
      "Done 5680 batches in 778.88s\ttraining loss:\t3.784701\n",
      "Done 5690 batches in 780.11s\ttraining loss:\t3.784384\n",
      "Done 5700 batches in 781.76s\ttraining loss:\t3.784105\n",
      "Done 5710 batches in 782.96s\ttraining loss:\t3.783787\n",
      "Done 5720 batches in 784.59s\ttraining loss:\t3.783469\n",
      "Done 5730 batches in 786.05s\ttraining loss:\t3.783103\n",
      "Done 5740 batches in 787.29s\ttraining loss:\t3.782835\n",
      "Done 5750 batches in 788.78s\ttraining loss:\t3.782492\n",
      "Done 5760 batches in 789.96s\ttraining loss:\t3.782193\n",
      "Done 5770 batches in 791.40s\ttraining loss:\t3.781814\n",
      "Done 5780 batches in 792.59s\ttraining loss:\t3.781452\n",
      "Done 5790 batches in 794.04s\ttraining loss:\t3.781143\n",
      "Done 5800 batches in 795.15s\ttraining loss:\t3.780774\n",
      "Done 5810 batches in 796.72s\ttraining loss:\t3.780490\n",
      "Done 5820 batches in 798.15s\ttraining loss:\t3.780148\n",
      "Done 5830 batches in 799.72s\ttraining loss:\t3.779748\n",
      "Done 5840 batches in 801.23s\ttraining loss:\t3.779414\n",
      "Done 5850 batches in 802.81s\ttraining loss:\t3.779097\n",
      "Done 5860 batches in 804.15s\ttraining loss:\t3.778849\n",
      "Done 5870 batches in 805.29s\ttraining loss:\t3.778476\n",
      "Done 5880 batches in 806.54s\ttraining loss:\t3.778097\n",
      "Done 5890 batches in 808.16s\ttraining loss:\t3.777792\n",
      "Done 5900 batches in 809.64s\ttraining loss:\t3.777463\n",
      "Done 5910 batches in 811.11s\ttraining loss:\t3.777109\n",
      "Done 5920 batches in 812.57s\ttraining loss:\t3.776789\n",
      "Done 5930 batches in 813.73s\ttraining loss:\t3.776483\n",
      "Done 5940 batches in 814.82s\ttraining loss:\t3.776114\n",
      "Done 5950 batches in 816.02s\ttraining loss:\t3.775789\n",
      "Done 5960 batches in 817.18s\ttraining loss:\t3.775428\n",
      "Done 5970 batches in 818.65s\ttraining loss:\t3.775092\n",
      "Done 5980 batches in 820.07s\ttraining loss:\t3.774827\n",
      "Done 5990 batches in 821.27s\ttraining loss:\t3.774546\n",
      "Done 6000 batches in 822.64s\ttraining loss:\t3.774277\n",
      "Done 6010 batches in 824.02s\ttraining loss:\t3.773918\n",
      "Done 6020 batches in 825.27s\ttraining loss:\t3.773630\n",
      "Done 6030 batches in 826.73s\ttraining loss:\t3.773310\n",
      "Done 6040 batches in 828.08s\ttraining loss:\t3.772994\n",
      "Done 6050 batches in 829.74s\ttraining loss:\t3.772721\n",
      "Done 6060 batches in 831.13s\ttraining loss:\t3.772361\n",
      "Done 6070 batches in 832.66s\ttraining loss:\t3.771989\n",
      "Done 6080 batches in 833.90s\ttraining loss:\t3.771638\n",
      "Done 6090 batches in 835.39s\ttraining loss:\t3.771289\n",
      "Done 6100 batches in 836.95s\ttraining loss:\t3.770972\n",
      "Done 6110 batches in 838.25s\ttraining loss:\t3.770634\n",
      "Done 6120 batches in 839.50s\ttraining loss:\t3.770315\n",
      "Done 6130 batches in 840.77s\ttraining loss:\t3.770027\n",
      "Done 6140 batches in 842.49s\ttraining loss:\t3.769793\n",
      "Done 6150 batches in 843.66s\ttraining loss:\t3.769473\n",
      "Done 6160 batches in 845.15s\ttraining loss:\t3.769189\n",
      "Done 6170 batches in 846.51s\ttraining loss:\t3.768854\n",
      "Done 6180 batches in 847.67s\ttraining loss:\t3.768467\n",
      "Done 6190 batches in 849.08s\ttraining loss:\t3.768239\n",
      "Done 6200 batches in 850.43s\ttraining loss:\t3.767965\n",
      "Done 6210 batches in 851.61s\ttraining loss:\t3.767676\n",
      "Done 6220 batches in 852.86s\ttraining loss:\t3.767396\n",
      "Done 6230 batches in 854.05s\ttraining loss:\t3.767076\n",
      "Done 6240 batches in 855.43s\ttraining loss:\t3.766782\n",
      "Done 6250 batches in 856.63s\ttraining loss:\t3.766383\n",
      "Done 6260 batches in 857.79s\ttraining loss:\t3.766086\n",
      "Done 6270 batches in 859.35s\ttraining loss:\t3.765773\n",
      "Done 6280 batches in 860.94s\ttraining loss:\t3.765450\n",
      "Done 6290 batches in 862.03s\ttraining loss:\t3.765155\n",
      "Done 6300 batches in 863.38s\ttraining loss:\t3.764841\n",
      "Done 6310 batches in 864.75s\ttraining loss:\t3.764573\n",
      "Done 6320 batches in 865.96s\ttraining loss:\t3.764280\n",
      "Done 6330 batches in 867.24s\ttraining loss:\t3.764002\n",
      "Done 6340 batches in 868.78s\ttraining loss:\t3.763634\n",
      "Done 6350 batches in 869.79s\ttraining loss:\t3.763275\n",
      "Done 6360 batches in 871.02s\ttraining loss:\t3.763021\n",
      "Done 6370 batches in 872.19s\ttraining loss:\t3.762740\n",
      "Done 6380 batches in 873.54s\ttraining loss:\t3.762441\n",
      "Done 6390 batches in 874.89s\ttraining loss:\t3.762156\n",
      "Done 6400 batches in 875.99s\ttraining loss:\t3.761811\n",
      "Done 6410 batches in 877.07s\ttraining loss:\t3.761505\n",
      "Done 6420 batches in 878.24s\ttraining loss:\t3.761187\n",
      "Done 6430 batches in 879.55s\ttraining loss:\t3.760853\n",
      "Done 6440 batches in 881.02s\ttraining loss:\t3.760595\n",
      "Done 6450 batches in 882.45s\ttraining loss:\t3.760244\n",
      "Done 6460 batches in 883.48s\ttraining loss:\t3.759914\n",
      "Done 6470 batches in 884.84s\ttraining loss:\t3.759606\n",
      "Done 6480 batches in 886.20s\ttraining loss:\t3.759285\n",
      "Done 6490 batches in 887.30s\ttraining loss:\t3.758991\n",
      "Done 6500 batches in 888.44s\ttraining loss:\t3.758675\n",
      "Done 6510 batches in 889.93s\ttraining loss:\t3.758373\n",
      "Done 6520 batches in 891.28s\ttraining loss:\t3.758060\n",
      "Done 6530 batches in 892.52s\ttraining loss:\t3.757789\n",
      "Done 6540 batches in 893.97s\ttraining loss:\t3.757477\n",
      "Done 6550 batches in 895.64s\ttraining loss:\t3.757244\n",
      "Done 6560 batches in 896.96s\ttraining loss:\t3.756906\n",
      "Done 6570 batches in 898.22s\ttraining loss:\t3.756707\n",
      "Done 6580 batches in 899.50s\ttraining loss:\t3.756392\n",
      "Done 6590 batches in 901.05s\ttraining loss:\t3.756119\n",
      "Done 6600 batches in 902.19s\ttraining loss:\t3.755893\n",
      "Done 6610 batches in 903.33s\ttraining loss:\t3.755626\n",
      "Done 6620 batches in 904.69s\ttraining loss:\t3.755329\n",
      "Done 6630 batches in 906.28s\ttraining loss:\t3.755068\n",
      "Done 6640 batches in 907.61s\ttraining loss:\t3.754731\n",
      "Done 6650 batches in 909.09s\ttraining loss:\t3.754433\n",
      "Done 6660 batches in 910.40s\ttraining loss:\t3.754145\n",
      "Done 6670 batches in 911.79s\ttraining loss:\t3.753870\n",
      "Done 6680 batches in 913.24s\ttraining loss:\t3.753586\n",
      "Done 6690 batches in 914.95s\ttraining loss:\t3.753358\n",
      "Done 6700 batches in 916.47s\ttraining loss:\t3.753089\n",
      "Done 6710 batches in 917.51s\ttraining loss:\t3.752706\n",
      "Done 6720 batches in 918.90s\ttraining loss:\t3.752458\n",
      "Done 6730 batches in 920.35s\ttraining loss:\t3.752228\n",
      "Done 6740 batches in 921.86s\ttraining loss:\t3.751920\n",
      "Done 6750 batches in 923.24s\ttraining loss:\t3.751696\n",
      "Done 6760 batches in 924.52s\ttraining loss:\t3.751449\n",
      "Done 6770 batches in 925.77s\ttraining loss:\t3.751195\n",
      "Done 6780 batches in 927.24s\ttraining loss:\t3.750923\n",
      "Done 6790 batches in 928.63s\ttraining loss:\t3.750613\n",
      "Done 6800 batches in 930.16s\ttraining loss:\t3.750400\n",
      "Done 6810 batches in 931.54s\ttraining loss:\t3.750103\n",
      "Done 6820 batches in 932.97s\ttraining loss:\t3.749823\n",
      "Done 6830 batches in 934.34s\ttraining loss:\t3.749586\n",
      "Done 6840 batches in 935.67s\ttraining loss:\t3.749344\n",
      "Done 6850 batches in 936.65s\ttraining loss:\t3.749068\n",
      "Done 6860 batches in 937.95s\ttraining loss:\t3.748758\n",
      "Done 6870 batches in 939.29s\ttraining loss:\t3.748458\n",
      "Done 6880 batches in 940.69s\ttraining loss:\t3.748224\n",
      "Done 6890 batches in 941.86s\ttraining loss:\t3.747898\n",
      "Done 6900 batches in 943.24s\ttraining loss:\t3.747632\n",
      "Done 6910 batches in 944.77s\ttraining loss:\t3.747433\n",
      "Done 6920 batches in 946.01s\ttraining loss:\t3.747210\n",
      "Done 6930 batches in 947.53s\ttraining loss:\t3.746909\n",
      "Done 6940 batches in 949.23s\ttraining loss:\t3.746734\n",
      "Done 6950 batches in 950.90s\ttraining loss:\t3.746446\n",
      "Done 6960 batches in 952.49s\ttraining loss:\t3.746224\n",
      "Done 6970 batches in 954.05s\ttraining loss:\t3.745921\n",
      "Done 6980 batches in 955.46s\ttraining loss:\t3.745625\n",
      "Done 6990 batches in 956.78s\ttraining loss:\t3.745407\n",
      "Done 7000 batches in 958.11s\ttraining loss:\t3.745174\n",
      "Done 7010 batches in 959.36s\ttraining loss:\t3.744931\n",
      "Done 7020 batches in 960.57s\ttraining loss:\t3.744704\n",
      "Done 7030 batches in 962.25s\ttraining loss:\t3.744487\n",
      "Done 7040 batches in 963.54s\ttraining loss:\t3.744188\n",
      "Done 7050 batches in 965.09s\ttraining loss:\t3.743928\n",
      "Done 7060 batches in 966.70s\ttraining loss:\t3.743690\n",
      "Done 7070 batches in 967.85s\ttraining loss:\t3.743408\n",
      "Done 7080 batches in 969.21s\ttraining loss:\t3.743086\n",
      "Done 7090 batches in 970.60s\ttraining loss:\t3.742850\n",
      "Done 7100 batches in 971.91s\ttraining loss:\t3.742560\n",
      "Done 7110 batches in 973.19s\ttraining loss:\t3.742353\n",
      "Done 7120 batches in 974.33s\ttraining loss:\t3.742124\n",
      "Done 7130 batches in 976.16s\ttraining loss:\t3.741889\n",
      "Done 7140 batches in 977.48s\ttraining loss:\t3.741678\n",
      "Done 7150 batches in 978.91s\ttraining loss:\t3.741447\n",
      "Done 7160 batches in 980.29s\ttraining loss:\t3.741134\n",
      "Done 7170 batches in 981.38s\ttraining loss:\t3.740874\n",
      "Done 7180 batches in 982.51s\ttraining loss:\t3.740602\n",
      "Done 7190 batches in 983.96s\ttraining loss:\t3.740327\n",
      "Done 7200 batches in 985.52s\ttraining loss:\t3.740040\n",
      "Done 7210 batches in 986.74s\ttraining loss:\t3.739804\n",
      "Done 7220 batches in 988.03s\ttraining loss:\t3.739621\n",
      "Done 7230 batches in 989.62s\ttraining loss:\t3.739467\n",
      "Done 7240 batches in 990.81s\ttraining loss:\t3.739212\n",
      "Done 7250 batches in 991.91s\ttraining loss:\t3.738930\n",
      "Done 7260 batches in 993.28s\ttraining loss:\t3.738677\n",
      "Done 7270 batches in 994.60s\ttraining loss:\t3.738415\n",
      "Done 7280 batches in 995.86s\ttraining loss:\t3.738190\n",
      "Done 7290 batches in 997.37s\ttraining loss:\t3.737962\n",
      "Done 7300 batches in 998.68s\ttraining loss:\t3.737762\n",
      "Done 7310 batches in 1000.51s\ttraining loss:\t3.737595\n",
      "Done 7320 batches in 1001.62s\ttraining loss:\t3.737366\n",
      "Done 7330 batches in 1003.05s\ttraining loss:\t3.737141\n",
      "Done 7340 batches in 1004.62s\ttraining loss:\t3.736896\n",
      "Done 7350 batches in 1006.22s\ttraining loss:\t3.736745\n",
      "Done 7360 batches in 1007.38s\ttraining loss:\t3.736479\n",
      "Done 7370 batches in 1009.15s\ttraining loss:\t3.736208\n",
      "Done 7380 batches in 1010.40s\ttraining loss:\t3.735949\n",
      "Done 7390 batches in 1011.60s\ttraining loss:\t3.735763\n",
      "Done 7400 batches in 1012.86s\ttraining loss:\t3.735487\n",
      "Done 7410 batches in 1014.48s\ttraining loss:\t3.735328\n",
      "Done 7420 batches in 1015.78s\ttraining loss:\t3.735006\n",
      "Done 7430 batches in 1017.15s\ttraining loss:\t3.734797\n",
      "Done 7440 batches in 1018.62s\ttraining loss:\t3.734589\n",
      "Done 7450 batches in 1020.04s\ttraining loss:\t3.734386\n",
      "Done 7460 batches in 1021.26s\ttraining loss:\t3.734112\n",
      "Done 7470 batches in 1022.53s\ttraining loss:\t3.733896\n",
      "Done 7480 batches in 1023.82s\ttraining loss:\t3.733664\n",
      "Done 7490 batches in 1025.20s\ttraining loss:\t3.733431\n",
      "Done 7500 batches in 1026.46s\ttraining loss:\t3.733178\n",
      "Done 7510 batches in 1027.87s\ttraining loss:\t3.732911\n",
      "Done 7520 batches in 1029.25s\ttraining loss:\t3.732651\n",
      "Done 7530 batches in 1030.55s\ttraining loss:\t3.732441\n",
      "Done 7540 batches in 1031.85s\ttraining loss:\t3.732208\n",
      "Done 7550 batches in 1033.42s\ttraining loss:\t3.732039\n",
      "Done 7560 batches in 1035.09s\ttraining loss:\t3.731805\n",
      "Done 7570 batches in 1036.45s\ttraining loss:\t3.731582\n",
      "Done 7580 batches in 1037.78s\ttraining loss:\t3.731319\n",
      "Done 7590 batches in 1039.22s\ttraining loss:\t3.731073\n",
      "Done 7600 batches in 1040.61s\ttraining loss:\t3.730853\n",
      "Done 7610 batches in 1042.13s\ttraining loss:\t3.730586\n",
      "Done 7620 batches in 1043.58s\ttraining loss:\t3.730363\n",
      "Done 7630 batches in 1045.12s\ttraining loss:\t3.730100\n",
      "Done 7640 batches in 1046.53s\ttraining loss:\t3.729829\n",
      "Done 7650 batches in 1048.23s\ttraining loss:\t3.729574\n",
      "Done 7660 batches in 1049.55s\ttraining loss:\t3.729373\n",
      "Done 7670 batches in 1050.96s\ttraining loss:\t3.729148\n",
      "Done 7680 batches in 1052.20s\ttraining loss:\t3.728899\n",
      "Done 7690 batches in 1053.50s\ttraining loss:\t3.728673\n",
      "Done 7700 batches in 1055.17s\ttraining loss:\t3.728506\n",
      "Done 7710 batches in 1056.57s\ttraining loss:\t3.728297\n",
      "Done 7720 batches in 1057.87s\ttraining loss:\t3.728091\n",
      "Done 7730 batches in 1059.16s\ttraining loss:\t3.727844\n",
      "Done 7740 batches in 1060.53s\ttraining loss:\t3.727568\n",
      "Done 7750 batches in 1061.97s\ttraining loss:\t3.727333\n",
      "Done 7760 batches in 1063.23s\ttraining loss:\t3.727081\n",
      "Done 7770 batches in 1064.57s\ttraining loss:\t3.726820\n",
      "Done 7780 batches in 1066.09s\ttraining loss:\t3.726591\n",
      "Done 7790 batches in 1067.65s\ttraining loss:\t3.726443\n",
      "Done 7800 batches in 1068.84s\ttraining loss:\t3.726192\n",
      "Done 7810 batches in 1070.18s\ttraining loss:\t3.725941\n",
      "Done 7820 batches in 1071.75s\ttraining loss:\t3.725764\n",
      "Done 7830 batches in 1073.09s\ttraining loss:\t3.725506\n",
      "Done 7840 batches in 1074.75s\ttraining loss:\t3.725290\n",
      "Done 7850 batches in 1076.09s\ttraining loss:\t3.725030\n",
      "Done 7860 batches in 1077.41s\ttraining loss:\t3.724780\n",
      "Done 7870 batches in 1078.71s\ttraining loss:\t3.724568\n",
      "Done 7880 batches in 1080.28s\ttraining loss:\t3.724398\n",
      "Done 7890 batches in 1081.81s\ttraining loss:\t3.724152\n",
      "Done 7900 batches in 1083.10s\ttraining loss:\t3.723915\n",
      "Done 7910 batches in 1084.73s\ttraining loss:\t3.723651\n",
      "Done 7920 batches in 1086.14s\ttraining loss:\t3.723394\n",
      "Done 7930 batches in 1087.60s\ttraining loss:\t3.723242\n",
      "Done 7940 batches in 1088.76s\ttraining loss:\t3.723020\n",
      "Done 7950 batches in 1090.09s\ttraining loss:\t3.722796\n",
      "Done 7960 batches in 1091.99s\ttraining loss:\t3.722554\n",
      "Done 7970 batches in 1093.67s\ttraining loss:\t3.722376\n",
      "Done 7980 batches in 1095.16s\ttraining loss:\t3.722151\n",
      "Done 7990 batches in 1096.55s\ttraining loss:\t3.721932\n",
      "Done 8000 batches in 1097.87s\ttraining loss:\t3.721728\n",
      "Done 8010 batches in 1099.17s\ttraining loss:\t3.721518\n",
      "Done 8020 batches in 1100.41s\ttraining loss:\t3.721267\n",
      "Done 8030 batches in 1101.77s\ttraining loss:\t3.721025\n",
      "Done 8040 batches in 1103.39s\ttraining loss:\t3.720788\n",
      "Done 8050 batches in 1104.68s\ttraining loss:\t3.720512\n",
      "Done 8060 batches in 1106.08s\ttraining loss:\t3.720330\n",
      "Done 8070 batches in 1107.24s\ttraining loss:\t3.720102\n",
      "Done 8080 batches in 1108.86s\ttraining loss:\t3.719852\n",
      "Done 8090 batches in 1110.31s\ttraining loss:\t3.719642\n",
      "Done 8100 batches in 1111.70s\ttraining loss:\t3.719517\n",
      "Done 8110 batches in 1113.09s\ttraining loss:\t3.719302\n",
      "Done 8120 batches in 1114.55s\ttraining loss:\t3.719034\n",
      "Done 8130 batches in 1115.97s\ttraining loss:\t3.718834\n",
      "Done 8140 batches in 1117.21s\ttraining loss:\t3.718598\n",
      "Done 8150 batches in 1118.74s\ttraining loss:\t3.718415\n",
      "Done 8160 batches in 1119.99s\ttraining loss:\t3.718193\n",
      "Done 8170 batches in 1121.32s\ttraining loss:\t3.717980\n",
      "Done 8180 batches in 1122.51s\ttraining loss:\t3.717775\n",
      "Done 8190 batches in 1123.73s\ttraining loss:\t3.717620\n",
      "Done 8200 batches in 1124.76s\ttraining loss:\t3.717429\n",
      "Done 8210 batches in 1126.36s\ttraining loss:\t3.717274\n",
      "Done 8220 batches in 1127.75s\ttraining loss:\t3.717065\n",
      "Done 8230 batches in 1129.19s\ttraining loss:\t3.716808\n",
      "Done 8240 batches in 1130.73s\ttraining loss:\t3.716652\n",
      "Done 8250 batches in 1132.17s\ttraining loss:\t3.716449\n",
      "Done 8260 batches in 1133.28s\ttraining loss:\t3.716233\n",
      "Done 8270 batches in 1134.57s\ttraining loss:\t3.715992\n",
      "Done 8280 batches in 1136.23s\ttraining loss:\t3.715756\n",
      "Done 8290 batches in 1137.94s\ttraining loss:\t3.715570\n",
      "Done 8300 batches in 1139.44s\ttraining loss:\t3.715351\n",
      "Done 8310 batches in 1140.75s\ttraining loss:\t3.715124\n",
      "Done 8320 batches in 1142.14s\ttraining loss:\t3.714931\n",
      "Done 8330 batches in 1143.74s\ttraining loss:\t3.714793\n",
      "Done 8340 batches in 1145.03s\ttraining loss:\t3.714564\n",
      "Done 8350 batches in 1146.44s\ttraining loss:\t3.714421\n",
      "Done 8360 batches in 1147.70s\ttraining loss:\t3.714228\n",
      "Done 8370 batches in 1149.05s\ttraining loss:\t3.713959\n",
      "Done 8380 batches in 1150.22s\ttraining loss:\t3.713770\n",
      "Done 8390 batches in 1151.46s\ttraining loss:\t3.713590\n",
      "Done 8400 batches in 1152.96s\ttraining loss:\t3.713325\n",
      "Done 8410 batches in 1154.69s\ttraining loss:\t3.713127\n",
      "Done 8420 batches in 1155.81s\ttraining loss:\t3.712928\n",
      "Done 8430 batches in 1157.46s\ttraining loss:\t3.712764\n",
      "Done 8440 batches in 1158.88s\ttraining loss:\t3.712575\n",
      "Done 8450 batches in 1160.06s\ttraining loss:\t3.712336\n",
      "Done 8460 batches in 1161.42s\ttraining loss:\t3.712137\n",
      "Done 8470 batches in 1162.80s\ttraining loss:\t3.711959\n",
      "Done 8480 batches in 1164.06s\ttraining loss:\t3.711772\n",
      "Done 8490 batches in 1165.43s\ttraining loss:\t3.711557\n",
      "Done 8500 batches in 1167.02s\ttraining loss:\t3.711314\n",
      "Done 8510 batches in 1168.33s\ttraining loss:\t3.711106\n",
      "Done 8520 batches in 1169.96s\ttraining loss:\t3.710926\n",
      "Done 8530 batches in 1171.85s\ttraining loss:\t3.710701\n",
      "Done 8540 batches in 1173.15s\ttraining loss:\t3.710525\n",
      "Done 8550 batches in 1174.43s\ttraining loss:\t3.710327\n",
      "Done 8560 batches in 1175.77s\ttraining loss:\t3.710120\n",
      "Done 8570 batches in 1177.53s\ttraining loss:\t3.709900\n",
      "Done 8580 batches in 1179.26s\ttraining loss:\t3.709700\n",
      "Done 8590 batches in 1180.76s\ttraining loss:\t3.709473\n",
      "Done 8600 batches in 1182.00s\ttraining loss:\t3.709276\n",
      "Done 8610 batches in 1183.26s\ttraining loss:\t3.709048\n",
      "Done 8620 batches in 1184.89s\ttraining loss:\t3.708841\n",
      "Done 8630 batches in 1186.31s\ttraining loss:\t3.708617\n",
      "Done 8640 batches in 1187.79s\ttraining loss:\t3.708403\n",
      "Done 8650 batches in 1189.15s\ttraining loss:\t3.708200\n",
      "Done 8660 batches in 1190.61s\ttraining loss:\t3.707974\n",
      "Done 8670 batches in 1192.23s\ttraining loss:\t3.707847\n",
      "Done 8680 batches in 1193.61s\ttraining loss:\t3.707657\n",
      "Done 8690 batches in 1194.89s\ttraining loss:\t3.707416\n",
      "Done 8700 batches in 1196.25s\ttraining loss:\t3.707238\n",
      "Done 8710 batches in 1197.51s\ttraining loss:\t3.706987\n",
      "Done 8720 batches in 1199.16s\ttraining loss:\t3.706790\n",
      "Done 8730 batches in 1200.59s\ttraining loss:\t3.706614\n",
      "Done 8740 batches in 1202.11s\ttraining loss:\t3.706419\n",
      "Done 8750 batches in 1203.51s\ttraining loss:\t3.706136\n",
      "Done 8760 batches in 1205.01s\ttraining loss:\t3.705962\n",
      "Done 8770 batches in 1206.46s\ttraining loss:\t3.705766\n",
      "Done 8780 batches in 1207.63s\ttraining loss:\t3.705545\n",
      "Done 8790 batches in 1208.98s\ttraining loss:\t3.705326\n",
      "Done 8800 batches in 1210.45s\ttraining loss:\t3.705116\n",
      "Done 8810 batches in 1211.91s\ttraining loss:\t3.704888\n",
      "Done 8820 batches in 1213.48s\ttraining loss:\t3.704750\n",
      "Done 8830 batches in 1214.80s\ttraining loss:\t3.704517\n",
      "Done 8840 batches in 1215.91s\ttraining loss:\t3.704377\n",
      "Done 8850 batches in 1217.35s\ttraining loss:\t3.704185\n",
      "Done 8860 batches in 1218.49s\ttraining loss:\t3.703976\n",
      "Done 8870 batches in 1220.15s\ttraining loss:\t3.703767\n",
      "Done 8880 batches in 1221.35s\ttraining loss:\t3.703577\n",
      "Done 8890 batches in 1222.84s\ttraining loss:\t3.703385\n",
      "Done 8900 batches in 1224.20s\ttraining loss:\t3.703147\n",
      "Done 8910 batches in 1225.51s\ttraining loss:\t3.702962\n",
      "Done 8920 batches in 1226.93s\ttraining loss:\t3.702748\n",
      "Done 8930 batches in 1228.42s\ttraining loss:\t3.702611\n",
      "Done 8940 batches in 1229.82s\ttraining loss:\t3.702412\n",
      "Done 8950 batches in 1231.11s\ttraining loss:\t3.702239\n",
      "Done 8960 batches in 1232.65s\ttraining loss:\t3.702052\n",
      "Done 8970 batches in 1234.05s\ttraining loss:\t3.701852\n",
      "Done 8980 batches in 1235.55s\ttraining loss:\t3.701698\n",
      "Done 8990 batches in 1236.82s\ttraining loss:\t3.701521\n",
      "Done 9000 batches in 1238.21s\ttraining loss:\t3.701331\n",
      "Done 9010 batches in 1239.72s\ttraining loss:\t3.701143\n",
      "Done 9020 batches in 1241.18s\ttraining loss:\t3.700924\n",
      "Done 9030 batches in 1242.43s\ttraining loss:\t3.700753\n",
      "Done 9040 batches in 1243.69s\ttraining loss:\t3.700509\n",
      "Done 9050 batches in 1245.25s\ttraining loss:\t3.700322\n",
      "Done 9060 batches in 1246.80s\ttraining loss:\t3.700109\n",
      "Done 9070 batches in 1248.31s\ttraining loss:\t3.699955\n",
      "Done 9080 batches in 1249.77s\ttraining loss:\t3.699832\n",
      "Done 9090 batches in 1250.90s\ttraining loss:\t3.699642\n",
      "Done 9100 batches in 1252.64s\ttraining loss:\t3.699477\n",
      "Done 9110 batches in 1253.99s\ttraining loss:\t3.699299\n",
      "Done 9120 batches in 1255.44s\ttraining loss:\t3.699106\n",
      "Done 9130 batches in 1256.49s\ttraining loss:\t3.698972\n",
      "Done 9140 batches in 1257.96s\ttraining loss:\t3.698769\n",
      "Done 9150 batches in 1259.33s\ttraining loss:\t3.698555\n",
      "Done 9160 batches in 1260.91s\ttraining loss:\t3.698399\n",
      "Done 9170 batches in 1262.36s\ttraining loss:\t3.698157\n",
      "Done 9180 batches in 1263.95s\ttraining loss:\t3.698032\n",
      "Done 9190 batches in 1265.47s\ttraining loss:\t3.697841\n",
      "Done 9200 batches in 1266.79s\ttraining loss:\t3.697613\n",
      "Done 9210 batches in 1268.28s\ttraining loss:\t3.697425\n",
      "Done 9220 batches in 1269.51s\ttraining loss:\t3.697218\n",
      "Done 9230 batches in 1270.93s\ttraining loss:\t3.697016\n",
      "Done 9240 batches in 1272.40s\ttraining loss:\t3.696871\n",
      "Done 9250 batches in 1273.91s\ttraining loss:\t3.696691\n",
      "Done 9260 batches in 1275.48s\ttraining loss:\t3.696507\n",
      "Done 9270 batches in 1276.75s\ttraining loss:\t3.696292\n",
      "Done 9280 batches in 1278.17s\ttraining loss:\t3.696136\n",
      "Done 9290 batches in 1279.46s\ttraining loss:\t3.695938\n",
      "Done 9300 batches in 1280.96s\ttraining loss:\t3.695750\n",
      "Done 9310 batches in 1282.49s\ttraining loss:\t3.695549\n",
      "Done 9320 batches in 1283.80s\ttraining loss:\t3.695366\n",
      "Done 9330 batches in 1285.54s\ttraining loss:\t3.695168\n",
      "Done 9340 batches in 1286.95s\ttraining loss:\t3.694973\n",
      "Done 9350 batches in 1288.39s\ttraining loss:\t3.694810\n",
      "Done 9360 batches in 1289.73s\ttraining loss:\t3.694619\n",
      "Done 9370 batches in 1291.25s\ttraining loss:\t3.694467\n",
      "Done 9380 batches in 1292.68s\ttraining loss:\t3.694346\n",
      "Done 9390 batches in 1293.90s\ttraining loss:\t3.694192\n",
      "Done 9400 batches in 1295.38s\ttraining loss:\t3.694013\n",
      "Done 9410 batches in 1296.85s\ttraining loss:\t3.693863\n",
      "Done 9420 batches in 1298.08s\ttraining loss:\t3.693608\n",
      "Done 9430 batches in 1299.59s\ttraining loss:\t3.693414\n",
      "Done 9440 batches in 1301.15s\ttraining loss:\t3.693266\n",
      "Done 9450 batches in 1302.58s\ttraining loss:\t3.693061\n",
      "Done 9460 batches in 1303.91s\ttraining loss:\t3.692843\n",
      "Done 9470 batches in 1305.10s\ttraining loss:\t3.692660\n",
      "Done 9480 batches in 1306.33s\ttraining loss:\t3.692549\n",
      "Done 9490 batches in 1307.46s\ttraining loss:\t3.692374\n",
      "Done 9500 batches in 1308.83s\ttraining loss:\t3.692188\n",
      "Done 9510 batches in 1310.15s\ttraining loss:\t3.692031\n",
      "Done 9520 batches in 1311.51s\ttraining loss:\t3.691855\n",
      "Done 9530 batches in 1312.83s\ttraining loss:\t3.691687\n",
      "Done 9540 batches in 1314.27s\ttraining loss:\t3.691528\n",
      "Done 9550 batches in 1315.48s\ttraining loss:\t3.691310\n",
      "Done 9560 batches in 1316.79s\ttraining loss:\t3.691128\n",
      "Done 9570 batches in 1318.14s\ttraining loss:\t3.690928\n",
      "Done 9580 batches in 1319.60s\ttraining loss:\t3.690760\n",
      "Done 9590 batches in 1320.93s\ttraining loss:\t3.690597\n",
      "Done 9600 batches in 1322.33s\ttraining loss:\t3.690424\n",
      "Done 9610 batches in 1323.76s\ttraining loss:\t3.690299\n",
      "Done 9620 batches in 1325.35s\ttraining loss:\t3.690106\n",
      "Done 9630 batches in 1327.05s\ttraining loss:\t3.689926\n",
      "Done 9640 batches in 1328.35s\ttraining loss:\t3.689773\n",
      "Done 9650 batches in 1329.81s\ttraining loss:\t3.689620\n",
      "Done 9660 batches in 1331.22s\ttraining loss:\t3.689479\n",
      "Done 9670 batches in 1332.50s\ttraining loss:\t3.689324\n",
      "Done 9680 batches in 1334.07s\ttraining loss:\t3.689178\n",
      "Done 9690 batches in 1335.42s\ttraining loss:\t3.689014\n",
      "Done 9700 batches in 1336.75s\ttraining loss:\t3.688875\n",
      "Done 9710 batches in 1338.01s\ttraining loss:\t3.688696\n",
      "Done 9720 batches in 1339.33s\ttraining loss:\t3.688511\n",
      "Done 9730 batches in 1340.95s\ttraining loss:\t3.688352\n",
      "Done 9740 batches in 1342.38s\ttraining loss:\t3.688174\n",
      "Done 9750 batches in 1343.66s\ttraining loss:\t3.687995\n",
      "Done 9760 batches in 1345.09s\ttraining loss:\t3.687811\n",
      "Done 9770 batches in 1346.50s\ttraining loss:\t3.687759\n",
      "Done 9780 batches in 1348.05s\ttraining loss:\t3.687608\n",
      "Done 9790 batches in 1349.62s\ttraining loss:\t3.687479\n",
      "Done 9800 batches in 1350.88s\ttraining loss:\t3.687308\n",
      "Done 9810 batches in 1352.43s\ttraining loss:\t3.687149\n",
      "Done 9820 batches in 1353.82s\ttraining loss:\t3.686987\n",
      "Done 9830 batches in 1355.36s\ttraining loss:\t3.686799\n",
      "Done 9840 batches in 1356.92s\ttraining loss:\t3.686597\n",
      "Done 9850 batches in 1358.39s\ttraining loss:\t3.686440\n",
      "Done 9860 batches in 1359.89s\ttraining loss:\t3.686230\n",
      "Done 9870 batches in 1361.05s\ttraining loss:\t3.686044\n",
      "Done 9880 batches in 1362.58s\ttraining loss:\t3.685855\n",
      "Done 9890 batches in 1364.10s\ttraining loss:\t3.685665\n",
      "Done 9900 batches in 1365.69s\ttraining loss:\t3.685513\n",
      "Done 9910 batches in 1366.75s\ttraining loss:\t3.685398\n",
      "Done 9920 batches in 1368.49s\ttraining loss:\t3.685223\n",
      "Done 9930 batches in 1369.84s\ttraining loss:\t3.685020\n",
      "Done 9940 batches in 1371.27s\ttraining loss:\t3.684868\n",
      "Done 9950 batches in 1372.66s\ttraining loss:\t3.684684\n",
      "Done 9960 batches in 1374.09s\ttraining loss:\t3.684512\n",
      "Done 9970 batches in 1375.39s\ttraining loss:\t3.684361\n",
      "Done 9980 batches in 1376.98s\ttraining loss:\t3.684224\n",
      "Done 9990 batches in 1378.28s\ttraining loss:\t3.684054\n",
      "Done 10000 batches in 1379.55s\ttraining loss:\t3.683905\n",
      "Done 10010 batches in 1380.80s\ttraining loss:\t3.683742\n",
      "Done 10020 batches in 1381.99s\ttraining loss:\t3.683555\n",
      "Done 10030 batches in 1383.29s\ttraining loss:\t3.683381\n",
      "Done 10040 batches in 1384.72s\ttraining loss:\t3.683201\n",
      "Done 10050 batches in 1386.47s\ttraining loss:\t3.683055\n",
      "Done 10060 batches in 1387.76s\ttraining loss:\t3.682897\n",
      "Done 10070 batches in 1389.16s\ttraining loss:\t3.682727\n",
      "Done 10080 batches in 1390.28s\ttraining loss:\t3.682549\n",
      "Done 10090 batches in 1391.69s\ttraining loss:\t3.682351\n",
      "Done 10100 batches in 1393.04s\ttraining loss:\t3.682240\n",
      "Done 10110 batches in 1394.32s\ttraining loss:\t3.682107\n",
      "Done 10120 batches in 1395.74s\ttraining loss:\t3.681976\n",
      "Done 10130 batches in 1397.23s\ttraining loss:\t3.681832\n",
      "Done 10140 batches in 1398.65s\ttraining loss:\t3.681652\n",
      "Done 10150 batches in 1399.89s\ttraining loss:\t3.681453\n",
      "Done 10160 batches in 1401.46s\ttraining loss:\t3.681319\n",
      "Done 10170 batches in 1402.57s\ttraining loss:\t3.681101\n",
      "Done 10180 batches in 1404.08s\ttraining loss:\t3.680966\n",
      "Done 10190 batches in 1405.29s\ttraining loss:\t3.680785\n",
      "Done 10200 batches in 1406.57s\ttraining loss:\t3.680623\n",
      "Done 10210 batches in 1407.92s\ttraining loss:\t3.680471\n",
      "Done 10220 batches in 1409.20s\ttraining loss:\t3.680282\n",
      "Done 10230 batches in 1410.71s\ttraining loss:\t3.680127\n",
      "Done 10240 batches in 1412.01s\ttraining loss:\t3.679963\n",
      "Done 10250 batches in 1413.73s\ttraining loss:\t3.679821\n",
      "Done 10260 batches in 1414.92s\ttraining loss:\t3.679628\n",
      "Done 10270 batches in 1416.30s\ttraining loss:\t3.679472\n",
      "Done 10280 batches in 1417.59s\ttraining loss:\t3.679352\n",
      "Done 10290 batches in 1418.86s\ttraining loss:\t3.679203\n",
      "Done 10300 batches in 1420.19s\ttraining loss:\t3.679043\n",
      "Done 10310 batches in 1421.61s\ttraining loss:\t3.678922\n",
      "Done 10320 batches in 1422.77s\ttraining loss:\t3.678749\n",
      "Done 10330 batches in 1424.16s\ttraining loss:\t3.678574\n",
      "Done 10340 batches in 1425.41s\ttraining loss:\t3.678448\n",
      "Done 10350 batches in 1426.64s\ttraining loss:\t3.678283\n",
      "Done 10360 batches in 1428.17s\ttraining loss:\t3.678125\n",
      "Done 10370 batches in 1429.71s\ttraining loss:\t3.677952\n",
      "Done 10380 batches in 1431.01s\ttraining loss:\t3.677783\n",
      "Done 10390 batches in 1432.24s\ttraining loss:\t3.677657\n",
      "Done 10400 batches in 1433.43s\ttraining loss:\t3.677522\n",
      "Done 10410 batches in 1434.65s\ttraining loss:\t3.677401\n",
      "Done 10420 batches in 1436.12s\ttraining loss:\t3.677266\n",
      "Done 10430 batches in 1437.32s\ttraining loss:\t3.677082\n",
      "Done 10440 batches in 1438.52s\ttraining loss:\t3.676885\n",
      "Done 10450 batches in 1439.73s\ttraining loss:\t3.676739\n",
      "Done 10460 batches in 1440.96s\ttraining loss:\t3.676582\n",
      "Done 10470 batches in 1442.19s\ttraining loss:\t3.676434\n",
      "Done 10480 batches in 1443.49s\ttraining loss:\t3.676301\n",
      "Done 10490 batches in 1444.74s\ttraining loss:\t3.676176\n",
      "Done 10500 batches in 1446.03s\ttraining loss:\t3.675993\n",
      "Done 10510 batches in 1447.64s\ttraining loss:\t3.675804\n",
      "Done 10520 batches in 1448.94s\ttraining loss:\t3.675621\n",
      "Done 10530 batches in 1450.70s\ttraining loss:\t3.675512\n",
      "Done 10540 batches in 1452.12s\ttraining loss:\t3.675379\n",
      "Done 10550 batches in 1453.65s\ttraining loss:\t3.675245\n",
      "Done 10560 batches in 1454.80s\ttraining loss:\t3.675070\n",
      "Done 10570 batches in 1456.01s\ttraining loss:\t3.674895\n",
      "Done 10580 batches in 1457.47s\ttraining loss:\t3.674736\n",
      "Done 10590 batches in 1458.78s\ttraining loss:\t3.674610\n",
      "Done 10600 batches in 1460.08s\ttraining loss:\t3.674449\n",
      "Done 10610 batches in 1461.28s\ttraining loss:\t3.674292\n",
      "Done 10620 batches in 1462.86s\ttraining loss:\t3.674166\n",
      "Done 10630 batches in 1464.36s\ttraining loss:\t3.674016\n",
      "Done 10640 batches in 1465.68s\ttraining loss:\t3.673869\n",
      "Done 10650 batches in 1467.00s\ttraining loss:\t3.673709\n",
      "Done 10660 batches in 1468.23s\ttraining loss:\t3.673567\n",
      "Done 10670 batches in 1469.79s\ttraining loss:\t3.673476\n",
      "Done 10680 batches in 1471.09s\ttraining loss:\t3.673326\n",
      "Done 10690 batches in 1472.32s\ttraining loss:\t3.673110\n",
      "Done 10700 batches in 1473.61s\ttraining loss:\t3.672936\n",
      "Done 10710 batches in 1474.80s\ttraining loss:\t3.672815\n",
      "Done 10720 batches in 1476.34s\ttraining loss:\t3.672647\n",
      "Done 10730 batches in 1477.60s\ttraining loss:\t3.672469\n",
      "Done 10740 batches in 1478.85s\ttraining loss:\t3.672332\n",
      "Done 10750 batches in 1480.30s\ttraining loss:\t3.672201\n",
      "Done 10760 batches in 1481.61s\ttraining loss:\t3.672073\n",
      "Done 10770 batches in 1482.68s\ttraining loss:\t3.671887\n",
      "Done 10780 batches in 1484.19s\ttraining loss:\t3.671738\n",
      "Done 10790 batches in 1485.68s\ttraining loss:\t3.671560\n",
      "Done 10800 batches in 1487.11s\ttraining loss:\t3.671366\n",
      "Done 10810 batches in 1488.52s\ttraining loss:\t3.671201\n",
      "Done 10820 batches in 1490.06s\ttraining loss:\t3.671064\n",
      "Done 10830 batches in 1491.52s\ttraining loss:\t3.670941\n",
      "Done 10840 batches in 1492.97s\ttraining loss:\t3.670801\n",
      "Done 10850 batches in 1494.22s\ttraining loss:\t3.670611\n",
      "Done 10860 batches in 1495.87s\ttraining loss:\t3.670500\n",
      "Done 10870 batches in 1497.37s\ttraining loss:\t3.670354\n",
      "Done 10880 batches in 1498.50s\ttraining loss:\t3.670204\n",
      "Done 10890 batches in 1500.01s\ttraining loss:\t3.670027\n",
      "Done 10900 batches in 1501.82s\ttraining loss:\t3.669876\n",
      "Done 10910 batches in 1503.23s\ttraining loss:\t3.669718\n",
      "Done 10920 batches in 1504.57s\ttraining loss:\t3.669559\n",
      "Done 10930 batches in 1505.69s\ttraining loss:\t3.669383\n",
      "Done 10940 batches in 1507.07s\ttraining loss:\t3.669263\n",
      "Done 10950 batches in 1508.18s\ttraining loss:\t3.669123\n",
      "Done 10960 batches in 1509.60s\ttraining loss:\t3.668922\n",
      "Done 10970 batches in 1511.25s\ttraining loss:\t3.668786\n",
      "Done 10980 batches in 1512.56s\ttraining loss:\t3.668608\n",
      "Done 10990 batches in 1514.21s\ttraining loss:\t3.668432\n",
      "Done 11000 batches in 1515.55s\ttraining loss:\t3.668291\n",
      "Done 11010 batches in 1516.81s\ttraining loss:\t3.668100\n",
      "Done 11020 batches in 1518.30s\ttraining loss:\t3.667952\n",
      "Done 11030 batches in 1519.40s\ttraining loss:\t3.667792\n",
      "Done 11040 batches in 1520.77s\ttraining loss:\t3.667663\n",
      "Done 11050 batches in 1522.08s\ttraining loss:\t3.667512\n",
      "Done 11060 batches in 1523.55s\ttraining loss:\t3.667333\n",
      "Done 11070 batches in 1525.07s\ttraining loss:\t3.667198\n",
      "Done 11080 batches in 1526.35s\ttraining loss:\t3.667074\n",
      "Done 11090 batches in 1527.86s\ttraining loss:\t3.666941\n",
      "Done 11100 batches in 1528.94s\ttraining loss:\t3.666765\n",
      "Done 11110 batches in 1530.32s\ttraining loss:\t3.666590\n",
      "Done 11120 batches in 1531.67s\ttraining loss:\t3.666434\n",
      "Done 11130 batches in 1533.10s\ttraining loss:\t3.666312\n",
      "Done 11140 batches in 1534.40s\ttraining loss:\t3.666125\n",
      "Done 11150 batches in 1535.62s\ttraining loss:\t3.666001\n",
      "Done 11160 batches in 1536.93s\ttraining loss:\t3.665870\n",
      "Done 11170 batches in 1538.55s\ttraining loss:\t3.665725\n",
      "Done 11180 batches in 1539.73s\ttraining loss:\t3.665616\n",
      "Done 11190 batches in 1540.91s\ttraining loss:\t3.665410\n",
      "Done 11200 batches in 1541.98s\ttraining loss:\t3.665271\n",
      "Done 11210 batches in 1543.18s\ttraining loss:\t3.665117\n",
      "Done 11220 batches in 1544.63s\ttraining loss:\t3.665003\n",
      "Done 11230 batches in 1546.06s\ttraining loss:\t3.664873\n",
      "Done 11240 batches in 1547.51s\ttraining loss:\t3.664727\n",
      "Done 11250 batches in 1549.08s\ttraining loss:\t3.664593\n",
      "Done 11260 batches in 1550.36s\ttraining loss:\t3.664433\n",
      "Done 11270 batches in 1551.49s\ttraining loss:\t3.664282\n",
      "Done 11280 batches in 1552.88s\ttraining loss:\t3.664124\n",
      "Done 11290 batches in 1554.19s\ttraining loss:\t3.663967\n",
      "Done 11300 batches in 1555.67s\ttraining loss:\t3.663878\n",
      "Done 11310 batches in 1557.14s\ttraining loss:\t3.663740\n",
      "Done 11320 batches in 1558.52s\ttraining loss:\t3.663620\n",
      "Done 11330 batches in 1559.67s\ttraining loss:\t3.663451\n",
      "Done 11340 batches in 1561.18s\ttraining loss:\t3.663269\n",
      "Done 11350 batches in 1562.57s\ttraining loss:\t3.663108\n",
      "Done 11360 batches in 1563.79s\ttraining loss:\t3.662978\n",
      "Done 11370 batches in 1564.94s\ttraining loss:\t3.662864\n",
      "Done 11380 batches in 1566.38s\ttraining loss:\t3.662725\n",
      "Done 11390 batches in 1567.72s\ttraining loss:\t3.662578\n",
      "Done 11400 batches in 1568.99s\ttraining loss:\t3.662442\n",
      "Done 11410 batches in 1570.39s\ttraining loss:\t3.662298\n",
      "Done 11420 batches in 1571.72s\ttraining loss:\t3.662152\n",
      "Done 11430 batches in 1572.93s\ttraining loss:\t3.662021\n",
      "Done 11440 batches in 1574.49s\ttraining loss:\t3.661910\n",
      "Done 11450 batches in 1575.70s\ttraining loss:\t3.661783\n",
      "Done 11460 batches in 1577.20s\ttraining loss:\t3.661664\n",
      "Done 11470 batches in 1578.51s\ttraining loss:\t3.661523\n",
      "Done 11480 batches in 1579.75s\ttraining loss:\t3.661346\n",
      "Done 11490 batches in 1581.08s\ttraining loss:\t3.661220\n",
      "Done 11500 batches in 1582.41s\ttraining loss:\t3.661071\n",
      "Done 11510 batches in 1584.00s\ttraining loss:\t3.660949\n",
      "Done 11520 batches in 1585.39s\ttraining loss:\t3.660803\n",
      "Done 11530 batches in 1586.72s\ttraining loss:\t3.660700\n",
      "Done 11540 batches in 1588.49s\ttraining loss:\t3.660547\n",
      "Done 11550 batches in 1589.72s\ttraining loss:\t3.660380\n",
      "Done 11560 batches in 1591.11s\ttraining loss:\t3.660222\n",
      "Done 11570 batches in 1592.60s\ttraining loss:\t3.660108\n",
      "Done 11580 batches in 1593.94s\ttraining loss:\t3.659960\n",
      "Done 11590 batches in 1595.54s\ttraining loss:\t3.659806\n",
      "Done 11600 batches in 1597.12s\ttraining loss:\t3.659653\n",
      "Done 11610 batches in 1598.76s\ttraining loss:\t3.659507\n",
      "Done 11620 batches in 1600.12s\ttraining loss:\t3.659393\n",
      "Done 11630 batches in 1601.59s\ttraining loss:\t3.659267\n",
      "Done 11640 batches in 1603.17s\ttraining loss:\t3.659155\n",
      "Done 11650 batches in 1604.55s\ttraining loss:\t3.659005\n",
      "Done 11660 batches in 1605.96s\ttraining loss:\t3.658848\n",
      "Done 11670 batches in 1607.31s\ttraining loss:\t3.658716\n",
      "Done 11680 batches in 1608.78s\ttraining loss:\t3.658588\n",
      "Done 11690 batches in 1610.17s\ttraining loss:\t3.658435\n",
      "Done 11700 batches in 1611.43s\ttraining loss:\t3.658319\n",
      "Done 11710 batches in 1612.69s\ttraining loss:\t3.658160\n",
      "Done 11720 batches in 1614.00s\ttraining loss:\t3.658023\n",
      "Done 11730 batches in 1615.20s\ttraining loss:\t3.657889\n",
      "Done 11740 batches in 1616.37s\ttraining loss:\t3.657744\n",
      "Done 11750 batches in 1617.66s\ttraining loss:\t3.657633\n",
      "Done 11760 batches in 1619.08s\ttraining loss:\t3.657517\n",
      "Done 100 batches in 2.32s\n",
      "Done 200 batches in 4.97s\n",
      "Done 300 batches in 7.52s\n",
      "Done 400 batches in 10.08s\n",
      "Done 500 batches in 12.41s\n",
      "Done 600 batches in 14.80s\n",
      "Done 700 batches in 17.11s\n",
      "Done 800 batches in 19.48s\n",
      "Done 900 batches in 21.86s\n",
      "Done 1000 batches in 24.17s\n",
      "Done 1100 batches in 26.86s\n",
      "Done 1200 batches in 29.53s\n",
      "Done 1300 batches in 32.15s\n",
      "Done 1400 batches in 34.90s\n",
      "Done 1500 batches in 37.57s\n",
      "Done 1600 batches in 40.24s\n",
      "Done 1700 batches in 42.52s\n",
      "Done 1800 batches in 44.90s\n",
      "Done 1900 batches in 47.34s\n",
      "Done 2000 batches in 49.74s\n",
      "Done 2100 batches in 52.36s\n",
      "Done 2200 batches in 54.96s\n",
      "Done 2300 batches in 57.65s\n",
      "Done 2400 batches in 60.00s\n",
      "Done 2500 batches in 62.45s\n",
      "Done 2600 batches in 64.94s\n",
      "Done 2700 batches in 67.55s\n",
      "Done 2800 batches in 70.17s\n",
      "Done 2900 batches in 72.64s\n",
      "Epoch 1 of 5 took 1694.68s\n",
      "  training loss:\t\t3.657411\n",
      "  validation loss:\t\t3.547210\n",
      "Done 10 batches in 1.30s\ttraining loss:\t3.466012\n",
      "Done 20 batches in 2.83s\ttraining loss:\t3.471896\n",
      "Done 30 batches in 4.11s\ttraining loss:\t3.482664\n",
      "Done 40 batches in 5.72s\ttraining loss:\t3.490326\n",
      "Done 50 batches in 7.20s\ttraining loss:\t3.491512\n",
      "Done 60 batches in 8.65s\ttraining loss:\t3.488343\n",
      "Done 70 batches in 9.74s\ttraining loss:\t3.491474\n",
      "Done 80 batches in 11.02s\ttraining loss:\t3.492829\n",
      "Done 90 batches in 12.53s\ttraining loss:\t3.494145\n",
      "Done 100 batches in 13.84s\ttraining loss:\t3.494264\n",
      "Done 110 batches in 15.08s\ttraining loss:\t3.495891\n",
      "Done 120 batches in 16.46s\ttraining loss:\t3.495471\n",
      "Done 130 batches in 17.72s\ttraining loss:\t3.495543\n",
      "Done 140 batches in 19.17s\ttraining loss:\t3.495886\n",
      "Done 150 batches in 20.71s\ttraining loss:\t3.495300\n",
      "Done 160 batches in 22.31s\ttraining loss:\t3.495202\n",
      "Done 170 batches in 23.60s\ttraining loss:\t3.493890\n",
      "Done 180 batches in 25.77s\ttraining loss:\t3.493052\n",
      "Done 190 batches in 27.02s\ttraining loss:\t3.491594\n",
      "Done 200 batches in 28.62s\ttraining loss:\t3.490213\n",
      "Done 210 batches in 30.23s\ttraining loss:\t3.492142\n",
      "Done 220 batches in 31.68s\ttraining loss:\t3.492655\n",
      "Done 230 batches in 32.94s\ttraining loss:\t3.493052\n",
      "Done 240 batches in 34.00s\ttraining loss:\t3.493432\n",
      "Done 250 batches in 35.45s\ttraining loss:\t3.492204\n",
      "Done 260 batches in 36.81s\ttraining loss:\t3.492384\n",
      "Done 270 batches in 38.08s\ttraining loss:\t3.491023\n",
      "Done 280 batches in 39.20s\ttraining loss:\t3.490192\n",
      "Done 290 batches in 40.71s\ttraining loss:\t3.491153\n",
      "Done 300 batches in 42.08s\ttraining loss:\t3.491349\n",
      "Done 310 batches in 43.37s\ttraining loss:\t3.491320\n",
      "Done 320 batches in 44.74s\ttraining loss:\t3.490935\n",
      "Done 330 batches in 46.29s\ttraining loss:\t3.490205\n",
      "Done 340 batches in 47.77s\ttraining loss:\t3.489228\n",
      "Done 350 batches in 49.19s\ttraining loss:\t3.488896\n",
      "Done 360 batches in 50.74s\ttraining loss:\t3.490114\n",
      "Done 370 batches in 52.18s\ttraining loss:\t3.490377\n",
      "Done 380 batches in 53.60s\ttraining loss:\t3.490476\n",
      "Done 390 batches in 54.98s\ttraining loss:\t3.489527\n",
      "Done 400 batches in 56.35s\ttraining loss:\t3.489478\n",
      "Done 410 batches in 57.60s\ttraining loss:\t3.488464\n",
      "Done 420 batches in 59.08s\ttraining loss:\t3.489076\n",
      "Done 430 batches in 60.50s\ttraining loss:\t3.489031\n",
      "Done 440 batches in 61.84s\ttraining loss:\t3.488237\n",
      "Done 450 batches in 63.02s\ttraining loss:\t3.487626\n",
      "Done 460 batches in 64.15s\ttraining loss:\t3.487187\n",
      "Done 470 batches in 65.41s\ttraining loss:\t3.486786\n",
      "Done 480 batches in 66.64s\ttraining loss:\t3.486120\n",
      "Done 490 batches in 68.00s\ttraining loss:\t3.486151\n",
      "Done 500 batches in 69.43s\ttraining loss:\t3.486771\n",
      "Done 510 batches in 70.70s\ttraining loss:\t3.486762\n",
      "Done 520 batches in 71.83s\ttraining loss:\t3.485932\n",
      "Done 530 batches in 73.11s\ttraining loss:\t3.485142\n",
      "Done 540 batches in 74.63s\ttraining loss:\t3.484264\n",
      "Done 550 batches in 76.02s\ttraining loss:\t3.483919\n",
      "Done 560 batches in 77.35s\ttraining loss:\t3.484249\n",
      "Done 570 batches in 78.73s\ttraining loss:\t3.485196\n",
      "Done 580 batches in 80.17s\ttraining loss:\t3.484859\n",
      "Done 590 batches in 81.46s\ttraining loss:\t3.484600\n",
      "Done 600 batches in 82.84s\ttraining loss:\t3.485044\n",
      "Done 610 batches in 84.14s\ttraining loss:\t3.485164\n",
      "Done 620 batches in 85.34s\ttraining loss:\t3.485210\n",
      "Done 630 batches in 86.59s\ttraining loss:\t3.484532\n",
      "Done 640 batches in 88.09s\ttraining loss:\t3.484365\n",
      "Done 650 batches in 90.11s\ttraining loss:\t3.485434\n",
      "Done 660 batches in 91.34s\ttraining loss:\t3.485133\n",
      "Done 670 batches in 92.66s\ttraining loss:\t3.485653\n",
      "Done 680 batches in 93.87s\ttraining loss:\t3.485702\n",
      "Done 690 batches in 95.16s\ttraining loss:\t3.485529\n",
      "Done 700 batches in 96.27s\ttraining loss:\t3.485715\n",
      "Done 710 batches in 97.46s\ttraining loss:\t3.485206\n",
      "Done 720 batches in 98.88s\ttraining loss:\t3.484836\n",
      "Done 730 batches in 100.06s\ttraining loss:\t3.484959\n",
      "Done 740 batches in 101.60s\ttraining loss:\t3.484896\n",
      "Done 750 batches in 103.13s\ttraining loss:\t3.485767\n",
      "Done 760 batches in 104.53s\ttraining loss:\t3.485974\n",
      "Done 770 batches in 106.04s\ttraining loss:\t3.486007\n",
      "Done 780 batches in 107.38s\ttraining loss:\t3.485567\n",
      "Done 790 batches in 108.51s\ttraining loss:\t3.485625\n",
      "Done 800 batches in 109.93s\ttraining loss:\t3.485950\n",
      "Done 810 batches in 111.54s\ttraining loss:\t3.486037\n",
      "Done 820 batches in 112.80s\ttraining loss:\t3.485483\n",
      "Done 830 batches in 114.03s\ttraining loss:\t3.485437\n",
      "Done 840 batches in 115.19s\ttraining loss:\t3.484952\n",
      "Done 850 batches in 116.72s\ttraining loss:\t3.484428\n",
      "Done 860 batches in 118.08s\ttraining loss:\t3.484448\n",
      "Done 870 batches in 119.31s\ttraining loss:\t3.484480\n",
      "Done 880 batches in 120.73s\ttraining loss:\t3.484650\n",
      "Done 890 batches in 122.15s\ttraining loss:\t3.484170\n",
      "Done 900 batches in 123.44s\ttraining loss:\t3.483756\n",
      "Done 910 batches in 124.62s\ttraining loss:\t3.483577\n",
      "Done 920 batches in 125.93s\ttraining loss:\t3.483692\n",
      "Done 930 batches in 127.35s\ttraining loss:\t3.483474\n",
      "Done 940 batches in 128.80s\ttraining loss:\t3.483048\n",
      "Done 950 batches in 130.14s\ttraining loss:\t3.482791\n",
      "Done 960 batches in 131.23s\ttraining loss:\t3.482725\n",
      "Done 970 batches in 132.62s\ttraining loss:\t3.482766\n",
      "Done 980 batches in 133.80s\ttraining loss:\t3.482563\n",
      "Done 990 batches in 135.10s\ttraining loss:\t3.482687\n",
      "Done 1000 batches in 136.37s\ttraining loss:\t3.482755\n",
      "Done 1010 batches in 137.70s\ttraining loss:\t3.483151\n",
      "Done 1020 batches in 139.03s\ttraining loss:\t3.483337\n",
      "Done 1030 batches in 140.19s\ttraining loss:\t3.483386\n",
      "Done 1040 batches in 141.56s\ttraining loss:\t3.483515\n",
      "Done 1050 batches in 143.02s\ttraining loss:\t3.483573\n",
      "Done 1060 batches in 144.38s\ttraining loss:\t3.483501\n",
      "Done 1070 batches in 145.68s\ttraining loss:\t3.483512\n",
      "Done 1080 batches in 147.29s\ttraining loss:\t3.483572\n",
      "Done 1090 batches in 148.35s\ttraining loss:\t3.483443\n",
      "Done 1100 batches in 149.66s\ttraining loss:\t3.483205\n",
      "Done 1110 batches in 151.04s\ttraining loss:\t3.483405\n",
      "Done 1120 batches in 152.28s\ttraining loss:\t3.483231\n",
      "Done 1130 batches in 153.65s\ttraining loss:\t3.483489\n",
      "Done 1140 batches in 154.80s\ttraining loss:\t3.483453\n",
      "Done 1150 batches in 156.25s\ttraining loss:\t3.483519\n",
      "Done 1160 batches in 157.39s\ttraining loss:\t3.483347\n",
      "Done 1170 batches in 158.60s\ttraining loss:\t3.483229\n",
      "Done 1180 batches in 160.41s\ttraining loss:\t3.483193\n",
      "Done 1190 batches in 161.68s\ttraining loss:\t3.483111\n",
      "Done 1200 batches in 162.96s\ttraining loss:\t3.483101\n",
      "Done 1210 batches in 164.23s\ttraining loss:\t3.483029\n",
      "Done 1220 batches in 165.62s\ttraining loss:\t3.482779\n",
      "Done 1230 batches in 166.87s\ttraining loss:\t3.482773\n",
      "Done 1240 batches in 168.24s\ttraining loss:\t3.482772\n",
      "Done 1250 batches in 169.53s\ttraining loss:\t3.482562\n",
      "Done 1260 batches in 171.10s\ttraining loss:\t3.482766\n",
      "Done 1270 batches in 172.32s\ttraining loss:\t3.482677\n",
      "Done 1280 batches in 173.63s\ttraining loss:\t3.482653\n",
      "Done 1290 batches in 175.00s\ttraining loss:\t3.482825\n",
      "Done 1300 batches in 176.32s\ttraining loss:\t3.482597\n",
      "Done 1310 batches in 177.82s\ttraining loss:\t3.482478\n",
      "Done 1320 batches in 179.43s\ttraining loss:\t3.482166\n",
      "Done 1330 batches in 180.58s\ttraining loss:\t3.481882\n",
      "Done 1340 batches in 182.05s\ttraining loss:\t3.481586\n",
      "Done 1350 batches in 183.40s\ttraining loss:\t3.481449\n",
      "Done 1360 batches in 184.57s\ttraining loss:\t3.481311\n",
      "Done 1370 batches in 185.79s\ttraining loss:\t3.481334\n",
      "Done 1380 batches in 187.28s\ttraining loss:\t3.481336\n",
      "Done 1390 batches in 188.66s\ttraining loss:\t3.481178\n",
      "Done 1400 batches in 190.03s\ttraining loss:\t3.481275\n",
      "Done 1410 batches in 191.73s\ttraining loss:\t3.481415\n",
      "Done 1420 batches in 192.93s\ttraining loss:\t3.481303\n",
      "Done 1430 batches in 194.29s\ttraining loss:\t3.481295\n",
      "Done 1440 batches in 195.86s\ttraining loss:\t3.481401\n",
      "Done 1450 batches in 197.16s\ttraining loss:\t3.481302\n",
      "Done 1460 batches in 198.27s\ttraining loss:\t3.481397\n",
      "Done 1470 batches in 199.58s\ttraining loss:\t3.481461\n",
      "Done 1480 batches in 200.79s\ttraining loss:\t3.481372\n",
      "Done 1490 batches in 202.01s\ttraining loss:\t3.481178\n",
      "Done 1500 batches in 203.48s\ttraining loss:\t3.480944\n",
      "Done 1510 batches in 204.71s\ttraining loss:\t3.480582\n",
      "Done 1520 batches in 206.02s\ttraining loss:\t3.480547\n",
      "Done 1530 batches in 207.28s\ttraining loss:\t3.480469\n",
      "Done 1540 batches in 208.38s\ttraining loss:\t3.480190\n",
      "Done 1550 batches in 209.70s\ttraining loss:\t3.480056\n",
      "Done 1560 batches in 211.19s\ttraining loss:\t3.480102\n",
      "Done 1570 batches in 212.74s\ttraining loss:\t3.480233\n",
      "Done 1580 batches in 214.08s\ttraining loss:\t3.480289\n",
      "Done 1590 batches in 215.43s\ttraining loss:\t3.480133\n",
      "Done 1600 batches in 216.77s\ttraining loss:\t3.480256\n",
      "Done 1610 batches in 217.67s\ttraining loss:\t3.480057\n",
      "Done 1620 batches in 219.30s\ttraining loss:\t3.479960\n",
      "Done 1630 batches in 220.76s\ttraining loss:\t3.480146\n",
      "Done 1640 batches in 222.03s\ttraining loss:\t3.480028\n",
      "Done 1650 batches in 223.34s\ttraining loss:\t3.480082\n",
      "Done 1660 batches in 224.76s\ttraining loss:\t3.480249\n",
      "Done 1670 batches in 226.00s\ttraining loss:\t3.480211\n",
      "Done 1680 batches in 227.90s\ttraining loss:\t3.480448\n",
      "Done 1690 batches in 229.20s\ttraining loss:\t3.480350\n",
      "Done 1700 batches in 230.56s\ttraining loss:\t3.480281\n",
      "Done 1710 batches in 231.74s\ttraining loss:\t3.480041\n",
      "Done 1720 batches in 233.25s\ttraining loss:\t3.480053\n",
      "Done 1730 batches in 234.38s\ttraining loss:\t3.479815\n",
      "Done 1740 batches in 235.57s\ttraining loss:\t3.479734\n",
      "Done 1750 batches in 237.28s\ttraining loss:\t3.479850\n",
      "Done 1760 batches in 238.51s\ttraining loss:\t3.479892\n",
      "Done 1770 batches in 240.03s\ttraining loss:\t3.479569\n",
      "Done 1780 batches in 241.23s\ttraining loss:\t3.479503\n",
      "Done 1790 batches in 242.46s\ttraining loss:\t3.479207\n",
      "Done 1800 batches in 243.80s\ttraining loss:\t3.479278\n",
      "Done 1810 batches in 245.44s\ttraining loss:\t3.479359\n",
      "Done 1820 batches in 246.73s\ttraining loss:\t3.479226\n",
      "Done 1830 batches in 248.19s\ttraining loss:\t3.479304\n",
      "Done 1840 batches in 249.39s\ttraining loss:\t3.479197\n",
      "Done 1850 batches in 250.76s\ttraining loss:\t3.478913\n",
      "Done 1860 batches in 252.08s\ttraining loss:\t3.478809\n",
      "Done 1870 batches in 253.53s\ttraining loss:\t3.478571\n",
      "Done 1880 batches in 254.84s\ttraining loss:\t3.478539\n",
      "Done 1890 batches in 256.00s\ttraining loss:\t3.478433\n",
      "Done 1900 batches in 257.33s\ttraining loss:\t3.478169\n",
      "Done 1910 batches in 258.63s\ttraining loss:\t3.478084\n",
      "Done 1920 batches in 260.06s\ttraining loss:\t3.478089\n",
      "Done 1930 batches in 261.29s\ttraining loss:\t3.478229\n",
      "Done 1940 batches in 262.74s\ttraining loss:\t3.478145\n",
      "Done 1950 batches in 264.23s\ttraining loss:\t3.477892\n",
      "Done 1960 batches in 265.35s\ttraining loss:\t3.477748\n",
      "Done 1970 batches in 266.65s\ttraining loss:\t3.477821\n",
      "Done 1980 batches in 268.20s\ttraining loss:\t3.477701\n",
      "Done 1990 batches in 269.42s\ttraining loss:\t3.477511\n",
      "Done 2000 batches in 270.83s\ttraining loss:\t3.477723\n",
      "Done 2010 batches in 272.17s\ttraining loss:\t3.477792\n",
      "Done 2020 batches in 273.39s\ttraining loss:\t3.477700\n",
      "Done 2030 batches in 274.78s\ttraining loss:\t3.477596\n",
      "Done 2040 batches in 276.14s\ttraining loss:\t3.477682\n",
      "Done 2050 batches in 277.24s\ttraining loss:\t3.477766\n",
      "Done 2060 batches in 278.66s\ttraining loss:\t3.477778\n",
      "Done 2070 batches in 280.01s\ttraining loss:\t3.477788\n",
      "Done 2080 batches in 281.46s\ttraining loss:\t3.477717\n",
      "Done 2090 batches in 282.75s\ttraining loss:\t3.477540\n",
      "Done 2100 batches in 284.20s\ttraining loss:\t3.477384\n",
      "Done 2110 batches in 285.51s\ttraining loss:\t3.477203\n",
      "Done 2120 batches in 286.95s\ttraining loss:\t3.477241\n",
      "Done 2130 batches in 288.12s\ttraining loss:\t3.477523\n",
      "Done 2140 batches in 289.49s\ttraining loss:\t3.477520\n",
      "Done 2150 batches in 290.93s\ttraining loss:\t3.477581\n",
      "Done 2160 batches in 292.13s\ttraining loss:\t3.477593\n",
      "Done 2170 batches in 293.57s\ttraining loss:\t3.477488\n",
      "Done 2180 batches in 294.85s\ttraining loss:\t3.477508\n",
      "Done 2190 batches in 296.18s\ttraining loss:\t3.477520\n",
      "Done 2200 batches in 297.32s\ttraining loss:\t3.477337\n",
      "Done 2210 batches in 298.43s\ttraining loss:\t3.477121\n",
      "Done 2220 batches in 300.18s\ttraining loss:\t3.477209\n",
      "Done 2230 batches in 301.77s\ttraining loss:\t3.477181\n",
      "Done 2240 batches in 303.08s\ttraining loss:\t3.477108\n",
      "Done 2250 batches in 304.33s\ttraining loss:\t3.477008\n",
      "Done 2260 batches in 305.64s\ttraining loss:\t3.476988\n",
      "Done 2270 batches in 307.06s\ttraining loss:\t3.477042\n",
      "Done 2280 batches in 308.18s\ttraining loss:\t3.476956\n",
      "Done 2290 batches in 309.52s\ttraining loss:\t3.476894\n",
      "Done 2300 batches in 310.76s\ttraining loss:\t3.476948\n",
      "Done 2310 batches in 312.34s\ttraining loss:\t3.477129\n",
      "Done 2320 batches in 313.64s\ttraining loss:\t3.477134\n",
      "Done 2330 batches in 314.95s\ttraining loss:\t3.476821\n",
      "Done 2340 batches in 316.55s\ttraining loss:\t3.476667\n",
      "Done 2350 batches in 317.83s\ttraining loss:\t3.476617\n",
      "Done 2360 batches in 319.13s\ttraining loss:\t3.476503\n",
      "Done 2370 batches in 320.42s\ttraining loss:\t3.476374\n",
      "Done 2380 batches in 321.70s\ttraining loss:\t3.476264\n",
      "Done 2390 batches in 323.28s\ttraining loss:\t3.476124\n",
      "Done 2400 batches in 324.58s\ttraining loss:\t3.476009\n",
      "Done 2410 batches in 326.03s\ttraining loss:\t3.475972\n",
      "Done 2420 batches in 327.21s\ttraining loss:\t3.475798\n",
      "Done 2430 batches in 328.30s\ttraining loss:\t3.475565\n",
      "Done 2440 batches in 329.80s\ttraining loss:\t3.475669\n",
      "Done 2450 batches in 331.09s\ttraining loss:\t3.475548\n",
      "Done 2460 batches in 332.35s\ttraining loss:\t3.475300\n",
      "Done 2470 batches in 333.72s\ttraining loss:\t3.475224\n",
      "Done 2480 batches in 335.41s\ttraining loss:\t3.475231\n",
      "Done 2490 batches in 336.83s\ttraining loss:\t3.475311\n",
      "Done 2500 batches in 338.00s\ttraining loss:\t3.475305\n",
      "Done 2510 batches in 339.12s\ttraining loss:\t3.475412\n",
      "Done 2520 batches in 340.42s\ttraining loss:\t3.475340\n",
      "Done 2530 batches in 341.96s\ttraining loss:\t3.475248\n",
      "Done 2540 batches in 343.04s\ttraining loss:\t3.475086\n",
      "Done 2550 batches in 344.45s\ttraining loss:\t3.475174\n",
      "Done 2560 batches in 345.82s\ttraining loss:\t3.475100\n",
      "Done 2570 batches in 347.34s\ttraining loss:\t3.475090\n",
      "Done 2580 batches in 348.70s\ttraining loss:\t3.474962\n",
      "Done 2590 batches in 349.85s\ttraining loss:\t3.474897\n",
      "Done 2600 batches in 351.43s\ttraining loss:\t3.474700\n",
      "Done 2610 batches in 352.45s\ttraining loss:\t3.474759\n",
      "Done 2620 batches in 354.05s\ttraining loss:\t3.474854\n",
      "Done 2630 batches in 355.42s\ttraining loss:\t3.474759\n",
      "Done 2640 batches in 356.70s\ttraining loss:\t3.474674\n",
      "Done 2650 batches in 358.09s\ttraining loss:\t3.474670\n",
      "Done 2660 batches in 359.45s\ttraining loss:\t3.474590\n",
      "Done 2670 batches in 360.89s\ttraining loss:\t3.474645\n",
      "Done 2680 batches in 362.36s\ttraining loss:\t3.474609\n",
      "Done 2690 batches in 363.61s\ttraining loss:\t3.474696\n",
      "Done 2700 batches in 364.88s\ttraining loss:\t3.474725\n",
      "Done 2710 batches in 366.43s\ttraining loss:\t3.474849\n",
      "Done 2720 batches in 367.51s\ttraining loss:\t3.474796\n",
      "Done 2730 batches in 368.69s\ttraining loss:\t3.474618\n",
      "Done 2740 batches in 369.81s\ttraining loss:\t3.474490\n",
      "Done 2750 batches in 371.23s\ttraining loss:\t3.474415\n",
      "Done 2760 batches in 372.59s\ttraining loss:\t3.474371\n",
      "Done 2770 batches in 373.97s\ttraining loss:\t3.474419\n",
      "Done 2780 batches in 375.52s\ttraining loss:\t3.474316\n",
      "Done 2790 batches in 376.88s\ttraining loss:\t3.474187\n",
      "Done 2800 batches in 378.07s\ttraining loss:\t3.474210\n",
      "Done 2810 batches in 379.50s\ttraining loss:\t3.474225\n",
      "Done 2820 batches in 380.65s\ttraining loss:\t3.474059\n",
      "Done 2830 batches in 381.84s\ttraining loss:\t3.473882\n",
      "Done 2840 batches in 383.22s\ttraining loss:\t3.473837\n",
      "Done 2850 batches in 384.84s\ttraining loss:\t3.473669\n",
      "Done 2860 batches in 386.13s\ttraining loss:\t3.473640\n",
      "Done 2870 batches in 387.29s\ttraining loss:\t3.473526\n",
      "Done 2880 batches in 388.50s\ttraining loss:\t3.473389\n",
      "Done 2890 batches in 389.91s\ttraining loss:\t3.473281\n",
      "Done 2900 batches in 391.25s\ttraining loss:\t3.473412\n",
      "Done 2910 batches in 392.57s\ttraining loss:\t3.473486\n",
      "Done 2920 batches in 393.79s\ttraining loss:\t3.473390\n",
      "Done 2930 batches in 395.12s\ttraining loss:\t3.473298\n",
      "Done 2940 batches in 396.44s\ttraining loss:\t3.473210\n",
      "Done 2950 batches in 397.73s\ttraining loss:\t3.473063\n",
      "Done 2960 batches in 399.17s\ttraining loss:\t3.473212\n",
      "Done 2970 batches in 400.60s\ttraining loss:\t3.473148\n",
      "Done 2980 batches in 401.71s\ttraining loss:\t3.473000\n",
      "Done 2990 batches in 402.73s\ttraining loss:\t3.472824\n",
      "Done 3000 batches in 404.04s\ttraining loss:\t3.472741\n",
      "Done 3010 batches in 405.34s\ttraining loss:\t3.472689\n",
      "Done 3020 batches in 406.43s\ttraining loss:\t3.472570\n",
      "Done 3030 batches in 407.93s\ttraining loss:\t3.472525\n",
      "Done 3040 batches in 409.21s\ttraining loss:\t3.472472\n",
      "Done 3050 batches in 410.79s\ttraining loss:\t3.472460\n",
      "Done 3060 batches in 411.77s\ttraining loss:\t3.472386\n",
      "Done 3070 batches in 412.95s\ttraining loss:\t3.472342\n",
      "Done 3080 batches in 414.07s\ttraining loss:\t3.472057\n",
      "Done 3090 batches in 415.57s\ttraining loss:\t3.472064\n",
      "Done 3100 batches in 416.84s\ttraining loss:\t3.471922\n",
      "Done 3110 batches in 418.58s\ttraining loss:\t3.471890\n",
      "Done 3120 batches in 419.88s\ttraining loss:\t3.471971\n",
      "Done 3130 batches in 421.11s\ttraining loss:\t3.471970\n",
      "Done 3140 batches in 422.40s\ttraining loss:\t3.471954\n",
      "Done 3150 batches in 423.66s\ttraining loss:\t3.471827\n",
      "Done 3160 batches in 424.81s\ttraining loss:\t3.471777\n",
      "Done 3170 batches in 426.24s\ttraining loss:\t3.471710\n",
      "Done 3180 batches in 427.33s\ttraining loss:\t3.471669\n",
      "Done 3190 batches in 428.59s\ttraining loss:\t3.471639\n",
      "Done 3200 batches in 430.00s\ttraining loss:\t3.471584\n",
      "Done 3210 batches in 431.44s\ttraining loss:\t3.471556\n",
      "Done 3220 batches in 432.67s\ttraining loss:\t3.471376\n",
      "Done 3230 batches in 433.95s\ttraining loss:\t3.471287\n",
      "Done 3240 batches in 435.31s\ttraining loss:\t3.471248\n",
      "Done 3250 batches in 436.50s\ttraining loss:\t3.471209\n",
      "Done 3260 batches in 437.89s\ttraining loss:\t3.471096\n",
      "Done 3270 batches in 439.17s\ttraining loss:\t3.471035\n",
      "Done 3280 batches in 440.65s\ttraining loss:\t3.471012\n",
      "Done 3290 batches in 441.83s\ttraining loss:\t3.471058\n",
      "Done 3300 batches in 443.01s\ttraining loss:\t3.471093\n",
      "Done 3310 batches in 444.36s\ttraining loss:\t3.470974\n",
      "Done 3320 batches in 445.64s\ttraining loss:\t3.470853\n",
      "Done 3330 batches in 447.09s\ttraining loss:\t3.470773\n",
      "Done 3340 batches in 448.33s\ttraining loss:\t3.470739\n",
      "Done 3350 batches in 449.58s\ttraining loss:\t3.470701\n",
      "Done 3360 batches in 451.16s\ttraining loss:\t3.470668\n",
      "Done 3370 batches in 452.63s\ttraining loss:\t3.470604\n",
      "Done 3380 batches in 454.11s\ttraining loss:\t3.470703\n",
      "Done 3390 batches in 455.69s\ttraining loss:\t3.470763\n",
      "Done 3400 batches in 456.88s\ttraining loss:\t3.470569\n",
      "Done 3410 batches in 458.42s\ttraining loss:\t3.470672\n",
      "Done 3420 batches in 459.63s\ttraining loss:\t3.470549\n",
      "Done 3430 batches in 460.90s\ttraining loss:\t3.470345\n",
      "Done 3440 batches in 462.26s\ttraining loss:\t3.470275\n",
      "Done 3450 batches in 463.41s\ttraining loss:\t3.470175\n",
      "Done 3460 batches in 464.68s\ttraining loss:\t3.470281\n",
      "Done 3470 batches in 465.98s\ttraining loss:\t3.470318\n",
      "Done 3480 batches in 467.56s\ttraining loss:\t3.470278\n",
      "Done 3490 batches in 468.95s\ttraining loss:\t3.470135\n",
      "Done 3500 batches in 470.13s\ttraining loss:\t3.470011\n",
      "Done 3510 batches in 471.54s\ttraining loss:\t3.469934\n",
      "Done 3520 batches in 472.97s\ttraining loss:\t3.469858\n",
      "Done 3530 batches in 474.33s\ttraining loss:\t3.469798\n",
      "Done 3540 batches in 475.93s\ttraining loss:\t3.469764\n",
      "Done 3550 batches in 477.31s\ttraining loss:\t3.469827\n",
      "Done 3560 batches in 478.50s\ttraining loss:\t3.469790\n",
      "Done 3570 batches in 480.05s\ttraining loss:\t3.469800\n",
      "Done 3580 batches in 481.79s\ttraining loss:\t3.469657\n",
      "Done 3590 batches in 483.22s\ttraining loss:\t3.469599\n",
      "Done 3600 batches in 484.55s\ttraining loss:\t3.469529\n",
      "Done 3610 batches in 485.98s\ttraining loss:\t3.469556\n",
      "Done 3620 batches in 487.34s\ttraining loss:\t3.469414\n",
      "Done 3630 batches in 488.81s\ttraining loss:\t3.469342\n",
      "Done 3640 batches in 490.47s\ttraining loss:\t3.469379\n",
      "Done 3650 batches in 491.65s\ttraining loss:\t3.469315\n",
      "Done 3660 batches in 492.87s\ttraining loss:\t3.469144\n",
      "Done 3670 batches in 494.24s\ttraining loss:\t3.469127\n",
      "Done 3680 batches in 495.35s\ttraining loss:\t3.469005\n",
      "Done 3690 batches in 496.97s\ttraining loss:\t3.469126\n",
      "Done 3700 batches in 497.96s\ttraining loss:\t3.468953\n",
      "Done 3710 batches in 499.42s\ttraining loss:\t3.468897\n",
      "Done 3720 batches in 500.78s\ttraining loss:\t3.468852\n",
      "Done 3730 batches in 502.12s\ttraining loss:\t3.468754\n",
      "Done 3740 batches in 503.42s\ttraining loss:\t3.468749\n",
      "Done 3750 batches in 504.81s\ttraining loss:\t3.468587\n",
      "Done 3760 batches in 506.28s\ttraining loss:\t3.468544\n",
      "Done 3770 batches in 507.76s\ttraining loss:\t3.468553\n",
      "Done 3780 batches in 509.12s\ttraining loss:\t3.468447\n",
      "Done 3790 batches in 510.52s\ttraining loss:\t3.468335\n",
      "Done 3800 batches in 511.90s\ttraining loss:\t3.468333\n",
      "Done 3810 batches in 513.03s\ttraining loss:\t3.468205\n",
      "Done 3820 batches in 514.38s\ttraining loss:\t3.468120\n",
      "Done 3830 batches in 515.96s\ttraining loss:\t3.468117\n",
      "Done 3840 batches in 517.62s\ttraining loss:\t3.468054\n",
      "Done 3850 batches in 518.76s\ttraining loss:\t3.467898\n",
      "Done 3860 batches in 520.14s\ttraining loss:\t3.467856\n",
      "Done 3870 batches in 521.33s\ttraining loss:\t3.467755\n",
      "Done 3880 batches in 522.62s\ttraining loss:\t3.467666\n",
      "Done 3890 batches in 524.00s\ttraining loss:\t3.467545\n",
      "Done 3900 batches in 525.56s\ttraining loss:\t3.467633\n",
      "Done 3910 batches in 526.81s\ttraining loss:\t3.467598\n",
      "Done 3920 batches in 527.94s\ttraining loss:\t3.467431\n",
      "Done 3930 batches in 529.15s\ttraining loss:\t3.467383\n",
      "Done 3940 batches in 530.60s\ttraining loss:\t3.467410\n",
      "Done 3950 batches in 531.99s\ttraining loss:\t3.467433\n",
      "Done 3960 batches in 533.29s\ttraining loss:\t3.467325\n",
      "Done 3970 batches in 534.62s\ttraining loss:\t3.467310\n",
      "Done 3980 batches in 536.15s\ttraining loss:\t3.467362\n",
      "Done 3990 batches in 537.20s\ttraining loss:\t3.467374\n",
      "Done 4000 batches in 538.41s\ttraining loss:\t3.467306\n",
      "Done 4010 batches in 539.72s\ttraining loss:\t3.467250\n",
      "Done 4020 batches in 541.00s\ttraining loss:\t3.467096\n",
      "Done 4030 batches in 542.13s\ttraining loss:\t3.466984\n",
      "Done 4040 batches in 543.37s\ttraining loss:\t3.466917\n",
      "Done 4050 batches in 544.88s\ttraining loss:\t3.466828\n",
      "Done 4060 batches in 546.22s\ttraining loss:\t3.466768\n",
      "Done 4070 batches in 547.52s\ttraining loss:\t3.466693\n",
      "Done 4080 batches in 549.22s\ttraining loss:\t3.466698\n",
      "Done 4090 batches in 550.72s\ttraining loss:\t3.466574\n",
      "Done 4100 batches in 552.27s\ttraining loss:\t3.466572\n",
      "Done 4110 batches in 553.66s\ttraining loss:\t3.466527\n",
      "Done 4120 batches in 554.85s\ttraining loss:\t3.466440\n",
      "Done 4130 batches in 556.28s\ttraining loss:\t3.466320\n",
      "Done 4140 batches in 557.78s\ttraining loss:\t3.466270\n",
      "Done 4150 batches in 559.28s\ttraining loss:\t3.466202\n",
      "Done 4160 batches in 560.66s\ttraining loss:\t3.466262\n",
      "Done 4170 batches in 562.12s\ttraining loss:\t3.466247\n",
      "Done 4180 batches in 563.62s\ttraining loss:\t3.466258\n",
      "Done 4190 batches in 564.94s\ttraining loss:\t3.466207\n",
      "Done 4200 batches in 566.20s\ttraining loss:\t3.466144\n",
      "Done 4210 batches in 567.50s\ttraining loss:\t3.466032\n",
      "Done 4220 batches in 568.84s\ttraining loss:\t3.465967\n",
      "Done 4230 batches in 570.04s\ttraining loss:\t3.465838\n",
      "Done 4240 batches in 571.39s\ttraining loss:\t3.465846\n",
      "Done 4250 batches in 572.75s\ttraining loss:\t3.465766\n",
      "Done 4260 batches in 574.24s\ttraining loss:\t3.465624\n",
      "Done 4270 batches in 575.49s\ttraining loss:\t3.465557\n",
      "Done 4280 batches in 576.53s\ttraining loss:\t3.465495\n",
      "Done 4290 batches in 577.90s\ttraining loss:\t3.465442\n",
      "Done 4300 batches in 579.40s\ttraining loss:\t3.465352\n",
      "Done 4310 batches in 580.48s\ttraining loss:\t3.465270\n",
      "Done 4320 batches in 582.24s\ttraining loss:\t3.465270\n",
      "Done 4330 batches in 583.71s\ttraining loss:\t3.465171\n",
      "Done 4340 batches in 584.94s\ttraining loss:\t3.465146\n",
      "Done 4350 batches in 586.42s\ttraining loss:\t3.465182\n",
      "Done 4360 batches in 587.63s\ttraining loss:\t3.465112\n",
      "Done 4370 batches in 589.33s\ttraining loss:\t3.465076\n",
      "Done 4380 batches in 590.74s\ttraining loss:\t3.464969\n",
      "Done 4390 batches in 592.14s\ttraining loss:\t3.464849\n",
      "Done 4400 batches in 593.51s\ttraining loss:\t3.464778\n",
      "Done 4410 batches in 594.99s\ttraining loss:\t3.464783\n",
      "Done 4420 batches in 596.10s\ttraining loss:\t3.464755\n",
      "Done 4430 batches in 597.48s\ttraining loss:\t3.464736\n",
      "Done 4440 batches in 598.68s\ttraining loss:\t3.464716\n",
      "Done 4450 batches in 599.96s\ttraining loss:\t3.464649\n",
      "Done 4460 batches in 601.39s\ttraining loss:\t3.464570\n",
      "Done 4470 batches in 602.95s\ttraining loss:\t3.464568\n",
      "Done 4480 batches in 604.21s\ttraining loss:\t3.464560\n",
      "Done 4490 batches in 605.75s\ttraining loss:\t3.464436\n",
      "Done 4500 batches in 606.95s\ttraining loss:\t3.464394\n",
      "Done 4510 batches in 608.22s\ttraining loss:\t3.464350\n",
      "Done 4520 batches in 609.74s\ttraining loss:\t3.464334\n",
      "Done 4530 batches in 611.11s\ttraining loss:\t3.464234\n",
      "Done 4540 batches in 612.62s\ttraining loss:\t3.464227\n",
      "Done 4550 batches in 614.06s\ttraining loss:\t3.464185\n",
      "Done 4560 batches in 615.58s\ttraining loss:\t3.464120\n",
      "Done 4570 batches in 616.93s\ttraining loss:\t3.464093\n",
      "Done 4580 batches in 618.21s\ttraining loss:\t3.464060\n",
      "Done 4590 batches in 619.61s\ttraining loss:\t3.463984\n",
      "Done 4600 batches in 621.13s\ttraining loss:\t3.463975\n",
      "Done 4610 batches in 622.50s\ttraining loss:\t3.463940\n",
      "Done 4620 batches in 623.93s\ttraining loss:\t3.463957\n",
      "Done 4630 batches in 625.09s\ttraining loss:\t3.463860\n",
      "Done 4640 batches in 626.31s\ttraining loss:\t3.463785\n",
      "Done 4650 batches in 627.58s\ttraining loss:\t3.463732\n",
      "Done 4660 batches in 628.77s\ttraining loss:\t3.463680\n",
      "Done 4670 batches in 630.11s\ttraining loss:\t3.463564\n",
      "Done 4680 batches in 631.33s\ttraining loss:\t3.463681\n",
      "Done 4690 batches in 632.90s\ttraining loss:\t3.463690\n",
      "Done 4700 batches in 634.25s\ttraining loss:\t3.463633\n",
      "Done 4710 batches in 635.32s\ttraining loss:\t3.463511\n",
      "Done 4720 batches in 636.76s\ttraining loss:\t3.463525\n",
      "Done 4730 batches in 638.36s\ttraining loss:\t3.463604\n",
      "Done 4740 batches in 639.67s\ttraining loss:\t3.463590\n",
      "Done 4750 batches in 640.87s\ttraining loss:\t3.463536\n",
      "Done 4760 batches in 642.41s\ttraining loss:\t3.463438\n",
      "Done 4770 batches in 643.71s\ttraining loss:\t3.463373\n",
      "Done 4780 batches in 644.96s\ttraining loss:\t3.463277\n",
      "Done 4790 batches in 646.24s\ttraining loss:\t3.463191\n",
      "Done 4800 batches in 647.86s\ttraining loss:\t3.463229\n",
      "Done 4810 batches in 649.02s\ttraining loss:\t3.463157\n",
      "Done 4820 batches in 650.50s\ttraining loss:\t3.463081\n",
      "Done 4830 batches in 651.89s\ttraining loss:\t3.463027\n",
      "Done 4840 batches in 652.99s\ttraining loss:\t3.462986\n",
      "Done 4850 batches in 654.20s\ttraining loss:\t3.462942\n",
      "Done 4860 batches in 655.72s\ttraining loss:\t3.462913\n",
      "Done 4870 batches in 657.11s\ttraining loss:\t3.462829\n",
      "Done 4880 batches in 658.46s\ttraining loss:\t3.462836\n",
      "Done 4890 batches in 659.92s\ttraining loss:\t3.462757\n",
      "Done 4900 batches in 661.21s\ttraining loss:\t3.462653\n",
      "Done 4910 batches in 662.41s\ttraining loss:\t3.462619\n",
      "Done 4920 batches in 663.88s\ttraining loss:\t3.462578\n",
      "Done 4930 batches in 665.19s\ttraining loss:\t3.462562\n",
      "Done 4940 batches in 666.59s\ttraining loss:\t3.462552\n",
      "Done 4950 batches in 668.12s\ttraining loss:\t3.462573\n",
      "Done 4960 batches in 669.72s\ttraining loss:\t3.462551\n",
      "Done 4970 batches in 670.99s\ttraining loss:\t3.462426\n",
      "Done 4980 batches in 672.28s\ttraining loss:\t3.462388\n",
      "Done 4990 batches in 673.75s\ttraining loss:\t3.462374\n",
      "Done 5000 batches in 675.25s\ttraining loss:\t3.462377\n",
      "Done 5010 batches in 676.61s\ttraining loss:\t3.462231\n",
      "Done 5020 batches in 678.06s\ttraining loss:\t3.462234\n",
      "Done 5030 batches in 679.48s\ttraining loss:\t3.462150\n",
      "Done 5040 batches in 680.70s\ttraining loss:\t3.462026\n",
      "Done 5050 batches in 681.87s\ttraining loss:\t3.461984\n",
      "Done 5060 batches in 683.13s\ttraining loss:\t3.461934\n",
      "Done 5070 batches in 684.72s\ttraining loss:\t3.461873\n",
      "Done 5080 batches in 686.17s\ttraining loss:\t3.461872\n",
      "Done 5090 batches in 687.59s\ttraining loss:\t3.461834\n",
      "Done 5100 batches in 689.00s\ttraining loss:\t3.461769\n",
      "Done 5110 batches in 690.24s\ttraining loss:\t3.461667\n",
      "Done 5120 batches in 691.87s\ttraining loss:\t3.461691\n",
      "Done 5130 batches in 693.09s\ttraining loss:\t3.461733\n",
      "Done 5140 batches in 694.58s\ttraining loss:\t3.461640\n",
      "Done 5150 batches in 695.96s\ttraining loss:\t3.461643\n",
      "Done 5160 batches in 697.84s\ttraining loss:\t3.461624\n",
      "Done 5170 batches in 699.08s\ttraining loss:\t3.461555\n",
      "Done 5180 batches in 700.29s\ttraining loss:\t3.461474\n",
      "Done 5190 batches in 701.70s\ttraining loss:\t3.461413\n",
      "Done 5200 batches in 703.31s\ttraining loss:\t3.461374\n",
      "Done 5210 batches in 704.81s\ttraining loss:\t3.461299\n",
      "Done 5220 batches in 706.29s\ttraining loss:\t3.461246\n",
      "Done 5230 batches in 707.60s\ttraining loss:\t3.461273\n",
      "Done 5240 batches in 708.95s\ttraining loss:\t3.461203\n",
      "Done 5250 batches in 710.36s\ttraining loss:\t3.461162\n",
      "Done 5260 batches in 711.70s\ttraining loss:\t3.461146\n",
      "Done 5270 batches in 713.31s\ttraining loss:\t3.461201\n",
      "Done 5280 batches in 714.52s\ttraining loss:\t3.461159\n",
      "Done 5290 batches in 715.97s\ttraining loss:\t3.461184\n",
      "Done 5300 batches in 717.33s\ttraining loss:\t3.461162\n",
      "Done 5310 batches in 718.52s\ttraining loss:\t3.461129\n",
      "Done 5320 batches in 720.02s\ttraining loss:\t3.461105\n",
      "Done 5330 batches in 721.45s\ttraining loss:\t3.461053\n",
      "Done 5340 batches in 722.59s\ttraining loss:\t3.461021\n",
      "Done 5350 batches in 723.82s\ttraining loss:\t3.460960\n",
      "Done 5360 batches in 725.30s\ttraining loss:\t3.460928\n",
      "Done 5370 batches in 726.79s\ttraining loss:\t3.460947\n",
      "Done 5380 batches in 728.21s\ttraining loss:\t3.460908\n",
      "Done 5390 batches in 729.42s\ttraining loss:\t3.460904\n",
      "Done 5400 batches in 730.80s\ttraining loss:\t3.460915\n",
      "Done 5410 batches in 732.17s\ttraining loss:\t3.460923\n",
      "Done 5420 batches in 733.66s\ttraining loss:\t3.460851\n",
      "Done 5430 batches in 734.83s\ttraining loss:\t3.460844\n",
      "Done 5440 batches in 736.16s\ttraining loss:\t3.460780\n",
      "Done 5450 batches in 737.57s\ttraining loss:\t3.460769\n",
      "Done 5460 batches in 738.91s\ttraining loss:\t3.460771\n",
      "Done 5470 batches in 740.28s\ttraining loss:\t3.460696\n",
      "Done 5480 batches in 741.89s\ttraining loss:\t3.460624\n",
      "Done 5490 batches in 743.22s\ttraining loss:\t3.460708\n",
      "Done 5500 batches in 744.68s\ttraining loss:\t3.460693\n",
      "Done 5510 batches in 746.22s\ttraining loss:\t3.460699\n",
      "Done 5520 batches in 747.47s\ttraining loss:\t3.460688\n",
      "Done 5530 batches in 748.87s\ttraining loss:\t3.460672\n",
      "Done 5540 batches in 750.22s\ttraining loss:\t3.460642\n",
      "Done 5550 batches in 751.98s\ttraining loss:\t3.460589\n",
      "Done 5560 batches in 753.46s\ttraining loss:\t3.460633\n",
      "Done 5570 batches in 754.75s\ttraining loss:\t3.460592\n",
      "Done 5580 batches in 756.21s\ttraining loss:\t3.460551\n",
      "Done 5590 batches in 757.47s\ttraining loss:\t3.460518\n",
      "Done 5600 batches in 758.57s\ttraining loss:\t3.460448\n",
      "Done 5610 batches in 759.70s\ttraining loss:\t3.460399\n",
      "Done 5620 batches in 761.21s\ttraining loss:\t3.460350\n",
      "Done 5630 batches in 762.56s\ttraining loss:\t3.460358\n",
      "Done 5640 batches in 763.73s\ttraining loss:\t3.460331\n",
      "Done 5650 batches in 765.08s\ttraining loss:\t3.460232\n",
      "Done 5660 batches in 766.49s\ttraining loss:\t3.460194\n",
      "Done 5670 batches in 767.91s\ttraining loss:\t3.460132\n",
      "Done 5680 batches in 769.08s\ttraining loss:\t3.460139\n",
      "Done 5690 batches in 770.31s\ttraining loss:\t3.460103\n",
      "Done 5700 batches in 771.94s\ttraining loss:\t3.460110\n",
      "Done 5710 batches in 773.14s\ttraining loss:\t3.460107\n",
      "Done 5720 batches in 774.76s\ttraining loss:\t3.460046\n",
      "Done 5730 batches in 776.22s\ttraining loss:\t3.459967\n",
      "Done 5740 batches in 777.45s\ttraining loss:\t3.459967\n",
      "Done 5750 batches in 778.95s\ttraining loss:\t3.459930\n",
      "Done 5760 batches in 780.13s\ttraining loss:\t3.459895\n",
      "Done 5770 batches in 781.56s\ttraining loss:\t3.459794\n",
      "Done 5780 batches in 782.76s\ttraining loss:\t3.459711\n",
      "Done 5790 batches in 784.21s\ttraining loss:\t3.459711\n",
      "Done 5800 batches in 785.32s\ttraining loss:\t3.459653\n",
      "Done 5810 batches in 786.88s\ttraining loss:\t3.459662\n",
      "Done 5820 batches in 788.31s\ttraining loss:\t3.459640\n",
      "Done 5830 batches in 789.88s\ttraining loss:\t3.459549\n",
      "Done 5840 batches in 791.39s\ttraining loss:\t3.459514\n",
      "Done 5850 batches in 792.97s\ttraining loss:\t3.459502\n",
      "Done 5860 batches in 794.31s\ttraining loss:\t3.459527\n",
      "Done 5870 batches in 795.44s\ttraining loss:\t3.459454\n",
      "Done 5880 batches in 796.70s\ttraining loss:\t3.459377\n",
      "Done 5890 batches in 798.31s\ttraining loss:\t3.459356\n",
      "Done 5900 batches in 799.79s\ttraining loss:\t3.459344\n",
      "Done 5910 batches in 801.26s\ttraining loss:\t3.459230\n",
      "Done 5920 batches in 802.71s\ttraining loss:\t3.459236\n",
      "Done 5930 batches in 803.87s\ttraining loss:\t3.459232\n",
      "Done 5940 batches in 804.96s\ttraining loss:\t3.459123\n",
      "Done 5950 batches in 806.16s\ttraining loss:\t3.459057\n",
      "Done 5960 batches in 807.33s\ttraining loss:\t3.458998\n",
      "Done 5970 batches in 808.79s\ttraining loss:\t3.458962\n",
      "Done 5980 batches in 810.22s\ttraining loss:\t3.458966\n",
      "Done 5990 batches in 811.41s\ttraining loss:\t3.458987\n",
      "Done 6000 batches in 812.78s\ttraining loss:\t3.458960\n",
      "Done 6010 batches in 814.16s\ttraining loss:\t3.458863\n",
      "Done 6020 batches in 815.40s\ttraining loss:\t3.458851\n",
      "Done 6030 batches in 816.87s\ttraining loss:\t3.458759\n",
      "Done 6040 batches in 818.20s\ttraining loss:\t3.458706\n",
      "Done 6050 batches in 819.85s\ttraining loss:\t3.458738\n",
      "Done 6060 batches in 821.22s\ttraining loss:\t3.458649\n",
      "Done 6070 batches in 822.64s\ttraining loss:\t3.458557\n",
      "Done 6080 batches in 823.80s\ttraining loss:\t3.458476\n",
      "Done 6090 batches in 825.16s\ttraining loss:\t3.458373\n",
      "Done 6100 batches in 826.65s\ttraining loss:\t3.458289\n",
      "Done 6110 batches in 827.95s\ttraining loss:\t3.458212\n",
      "Done 6120 batches in 829.20s\ttraining loss:\t3.458162\n",
      "Done 6130 batches in 830.45s\ttraining loss:\t3.458101\n",
      "Done 6140 batches in 832.08s\ttraining loss:\t3.458091\n",
      "Done 6150 batches in 833.21s\ttraining loss:\t3.458053\n",
      "Done 6160 batches in 834.69s\ttraining loss:\t3.458012\n",
      "Done 6170 batches in 836.02s\ttraining loss:\t3.457956\n",
      "Done 6180 batches in 837.18s\ttraining loss:\t3.457831\n",
      "Done 6190 batches in 838.59s\ttraining loss:\t3.457864\n",
      "Done 6200 batches in 839.94s\ttraining loss:\t3.457857\n",
      "Done 6210 batches in 841.13s\ttraining loss:\t3.457828\n",
      "Done 6220 batches in 842.37s\ttraining loss:\t3.457834\n",
      "Done 6230 batches in 843.56s\ttraining loss:\t3.457769\n",
      "Done 6240 batches in 844.95s\ttraining loss:\t3.457767\n",
      "Done 6250 batches in 846.14s\ttraining loss:\t3.457661\n",
      "Done 6260 batches in 847.30s\ttraining loss:\t3.457634\n",
      "Done 6270 batches in 848.81s\ttraining loss:\t3.457584\n",
      "Done 6280 batches in 850.38s\ttraining loss:\t3.457501\n",
      "Done 6290 batches in 851.48s\ttraining loss:\t3.457472\n",
      "Done 6300 batches in 852.84s\ttraining loss:\t3.457432\n",
      "Done 6310 batches in 854.20s\ttraining loss:\t3.457400\n",
      "Done 6320 batches in 855.42s\ttraining loss:\t3.457348\n",
      "Done 6330 batches in 856.70s\ttraining loss:\t3.457323\n",
      "Done 6340 batches in 858.24s\ttraining loss:\t3.457238\n",
      "Done 6350 batches in 859.25s\ttraining loss:\t3.457123\n",
      "Done 6360 batches in 860.47s\ttraining loss:\t3.457140\n",
      "Done 6370 batches in 861.64s\ttraining loss:\t3.457109\n",
      "Done 6380 batches in 862.99s\ttraining loss:\t3.457088\n",
      "Done 6390 batches in 864.35s\ttraining loss:\t3.457092\n",
      "Done 6400 batches in 865.45s\ttraining loss:\t3.457047\n",
      "Done 6410 batches in 866.52s\ttraining loss:\t3.457029\n",
      "Done 6420 batches in 867.69s\ttraining loss:\t3.456960\n",
      "Done 6430 batches in 868.99s\ttraining loss:\t3.456926\n",
      "Done 6440 batches in 870.47s\ttraining loss:\t3.456914\n",
      "Done 6450 batches in 871.89s\ttraining loss:\t3.456821\n",
      "Done 6460 batches in 872.92s\ttraining loss:\t3.456754\n",
      "Done 6470 batches in 874.27s\ttraining loss:\t3.456684\n",
      "Done 6480 batches in 875.65s\ttraining loss:\t3.456612\n",
      "Done 6490 batches in 876.74s\ttraining loss:\t3.456571\n",
      "Done 6500 batches in 877.88s\ttraining loss:\t3.456536\n",
      "Done 6510 batches in 879.36s\ttraining loss:\t3.456478\n",
      "Done 6520 batches in 880.71s\ttraining loss:\t3.456407\n",
      "Done 6530 batches in 881.95s\ttraining loss:\t3.456365\n",
      "Done 6540 batches in 883.40s\ttraining loss:\t3.456314\n",
      "Done 6550 batches in 885.07s\ttraining loss:\t3.456298\n",
      "Done 6560 batches in 886.39s\ttraining loss:\t3.456240\n",
      "Done 6570 batches in 887.65s\ttraining loss:\t3.456295\n",
      "Done 6580 batches in 888.93s\ttraining loss:\t3.456242\n",
      "Done 6590 batches in 890.48s\ttraining loss:\t3.456225\n",
      "Done 6600 batches in 891.62s\ttraining loss:\t3.456206\n",
      "Done 6610 batches in 892.75s\ttraining loss:\t3.456183\n",
      "Done 6620 batches in 894.11s\ttraining loss:\t3.456138\n",
      "Done 6630 batches in 895.70s\ttraining loss:\t3.456150\n",
      "Done 6640 batches in 897.03s\ttraining loss:\t3.456061\n",
      "Done 6650 batches in 898.51s\ttraining loss:\t3.456003\n",
      "Done 6660 batches in 899.83s\ttraining loss:\t3.455967\n",
      "Done 6670 batches in 901.21s\ttraining loss:\t3.455935\n",
      "Done 6680 batches in 902.67s\ttraining loss:\t3.455886\n",
      "Done 6690 batches in 904.38s\ttraining loss:\t3.455899\n",
      "Done 6700 batches in 905.90s\ttraining loss:\t3.455871\n",
      "Done 6710 batches in 906.94s\ttraining loss:\t3.455768\n",
      "Done 6720 batches in 908.33s\ttraining loss:\t3.455729\n",
      "Done 6730 batches in 909.77s\ttraining loss:\t3.455701\n",
      "Done 6740 batches in 911.28s\ttraining loss:\t3.455666\n",
      "Done 6750 batches in 912.66s\ttraining loss:\t3.455628\n",
      "Done 6760 batches in 913.95s\ttraining loss:\t3.455617\n",
      "Done 6770 batches in 915.19s\ttraining loss:\t3.455567\n",
      "Done 6780 batches in 916.66s\ttraining loss:\t3.455507\n",
      "Done 6790 batches in 918.05s\ttraining loss:\t3.455427\n",
      "Done 6800 batches in 919.58s\ttraining loss:\t3.455417\n",
      "Done 6810 batches in 920.95s\ttraining loss:\t3.455375\n",
      "Done 6820 batches in 922.40s\ttraining loss:\t3.455342\n",
      "Done 6830 batches in 923.76s\ttraining loss:\t3.455328\n",
      "Done 6840 batches in 925.10s\ttraining loss:\t3.455339\n",
      "Done 6850 batches in 926.07s\ttraining loss:\t3.455293\n",
      "Done 6860 batches in 927.38s\ttraining loss:\t3.455231\n",
      "Done 6870 batches in 928.71s\ttraining loss:\t3.455191\n",
      "Done 6880 batches in 930.12s\ttraining loss:\t3.455205\n",
      "Done 6890 batches in 931.28s\ttraining loss:\t3.455129\n",
      "Done 6900 batches in 932.67s\ttraining loss:\t3.455091\n",
      "Done 6910 batches in 934.20s\ttraining loss:\t3.455122\n",
      "Done 6920 batches in 935.41s\ttraining loss:\t3.455145\n",
      "Done 6930 batches in 936.91s\ttraining loss:\t3.455071\n",
      "Done 6940 batches in 938.55s\ttraining loss:\t3.455062\n",
      "Done 6950 batches in 940.16s\ttraining loss:\t3.455022\n",
      "Done 6960 batches in 941.75s\ttraining loss:\t3.455021\n",
      "Done 6970 batches in 943.31s\ttraining loss:\t3.454963\n",
      "Done 6980 batches in 944.72s\ttraining loss:\t3.454917\n",
      "Done 6990 batches in 946.04s\ttraining loss:\t3.454901\n",
      "Done 7000 batches in 947.37s\ttraining loss:\t3.454854\n",
      "Done 7010 batches in 948.62s\ttraining loss:\t3.454838\n",
      "Done 7020 batches in 949.83s\ttraining loss:\t3.454820\n",
      "Done 7030 batches in 951.51s\ttraining loss:\t3.454840\n",
      "Done 7040 batches in 952.79s\ttraining loss:\t3.454776\n",
      "Done 7050 batches in 954.33s\ttraining loss:\t3.454700\n",
      "Done 7060 batches in 955.94s\ttraining loss:\t3.454659\n",
      "Done 7070 batches in 957.10s\ttraining loss:\t3.454606\n",
      "Done 7080 batches in 958.46s\ttraining loss:\t3.454522\n",
      "Done 7090 batches in 959.84s\ttraining loss:\t3.454528\n",
      "Done 7100 batches in 961.16s\ttraining loss:\t3.454457\n",
      "Done 7110 batches in 962.43s\ttraining loss:\t3.454451\n",
      "Done 7120 batches in 963.58s\ttraining loss:\t3.454447\n",
      "Done 7130 batches in 965.41s\ttraining loss:\t3.454449\n",
      "Done 7140 batches in 966.72s\ttraining loss:\t3.454442\n",
      "Done 7150 batches in 968.16s\ttraining loss:\t3.454411\n",
      "Done 7160 batches in 969.54s\ttraining loss:\t3.454334\n",
      "Done 7170 batches in 970.64s\ttraining loss:\t3.454309\n",
      "Done 7180 batches in 971.76s\ttraining loss:\t3.454285\n",
      "Done 7190 batches in 973.17s\ttraining loss:\t3.454212\n",
      "Done 7200 batches in 974.69s\ttraining loss:\t3.454141\n",
      "Done 7210 batches in 975.92s\ttraining loss:\t3.454141\n",
      "Done 7220 batches in 977.21s\ttraining loss:\t3.454158\n",
      "Done 7230 batches in 978.80s\ttraining loss:\t3.454201\n",
      "Done 7240 batches in 979.99s\ttraining loss:\t3.454164\n",
      "Done 7250 batches in 981.09s\ttraining loss:\t3.454081\n",
      "Done 7260 batches in 982.46s\ttraining loss:\t3.454024\n",
      "Done 7270 batches in 983.76s\ttraining loss:\t3.453989\n",
      "Done 7280 batches in 985.00s\ttraining loss:\t3.454002\n",
      "Done 7290 batches in 986.47s\ttraining loss:\t3.453998\n",
      "Done 7300 batches in 987.71s\ttraining loss:\t3.453988\n",
      "Done 7310 batches in 989.51s\ttraining loss:\t3.454014\n",
      "Done 7320 batches in 990.62s\ttraining loss:\t3.454018\n",
      "Done 7330 batches in 992.00s\ttraining loss:\t3.454020\n",
      "Done 7340 batches in 993.51s\ttraining loss:\t3.453972\n",
      "Done 7350 batches in 995.11s\ttraining loss:\t3.453958\n",
      "Done 7360 batches in 996.27s\ttraining loss:\t3.453879\n",
      "Done 7370 batches in 998.04s\ttraining loss:\t3.453852\n",
      "Done 7380 batches in 999.29s\ttraining loss:\t3.453821\n",
      "Done 7390 batches in 1000.47s\ttraining loss:\t3.453832\n",
      "Done 7400 batches in 1001.73s\ttraining loss:\t3.453769\n",
      "Done 7410 batches in 1003.33s\ttraining loss:\t3.453834\n",
      "Done 7420 batches in 1004.55s\ttraining loss:\t3.453781\n",
      "Done 7430 batches in 1005.83s\ttraining loss:\t3.453785\n",
      "Done 7440 batches in 1007.19s\ttraining loss:\t3.453778\n",
      "Done 7450 batches in 1008.51s\ttraining loss:\t3.453766\n",
      "Done 7460 batches in 1009.68s\ttraining loss:\t3.453691\n",
      "Done 7470 batches in 1010.95s\ttraining loss:\t3.453677\n",
      "Done 7480 batches in 1012.24s\ttraining loss:\t3.453619\n",
      "Done 7490 batches in 1013.61s\ttraining loss:\t3.453583\n",
      "Done 7500 batches in 1014.87s\ttraining loss:\t3.453536\n",
      "Done 7510 batches in 1016.28s\ttraining loss:\t3.453482\n",
      "Done 7520 batches in 1017.66s\ttraining loss:\t3.453430\n",
      "Done 7530 batches in 1018.96s\ttraining loss:\t3.453439\n",
      "Done 7540 batches in 1020.25s\ttraining loss:\t3.453441\n",
      "Done 7550 batches in 1021.81s\ttraining loss:\t3.453431\n",
      "Done 7560 batches in 1023.48s\ttraining loss:\t3.453379\n",
      "Done 7570 batches in 1024.84s\ttraining loss:\t3.453348\n",
      "Done 7580 batches in 1026.12s\ttraining loss:\t3.453311\n",
      "Done 7590 batches in 1027.51s\ttraining loss:\t3.453249\n",
      "Done 7600 batches in 1028.87s\ttraining loss:\t3.453220\n",
      "Done 7610 batches in 1030.29s\ttraining loss:\t3.453168\n",
      "Done 7620 batches in 1031.72s\ttraining loss:\t3.453136\n",
      "Done 7630 batches in 1033.25s\ttraining loss:\t3.453094\n",
      "Done 7640 batches in 1034.66s\ttraining loss:\t3.453033\n",
      "Done 7650 batches in 1036.33s\ttraining loss:\t3.452989\n",
      "Done 7660 batches in 1037.57s\ttraining loss:\t3.452972\n",
      "Done 7670 batches in 1038.96s\ttraining loss:\t3.452948\n",
      "Done 7680 batches in 1040.16s\ttraining loss:\t3.452908\n",
      "Done 7690 batches in 1041.45s\ttraining loss:\t3.452867\n",
      "Done 7700 batches in 1043.06s\ttraining loss:\t3.452912\n",
      "Done 7710 batches in 1044.41s\ttraining loss:\t3.452892\n",
      "Done 7720 batches in 1045.65s\ttraining loss:\t3.452853\n",
      "Done 7730 batches in 1046.93s\ttraining loss:\t3.452829\n",
      "Done 7740 batches in 1048.30s\ttraining loss:\t3.452772\n",
      "Done 7750 batches in 1049.74s\ttraining loss:\t3.452730\n",
      "Done 7760 batches in 1050.99s\ttraining loss:\t3.452636\n",
      "Done 7770 batches in 1052.34s\ttraining loss:\t3.452547\n",
      "Done 7780 batches in 1053.85s\ttraining loss:\t3.452512\n",
      "Done 7790 batches in 1055.41s\ttraining loss:\t3.452556\n",
      "Done 7800 batches in 1056.60s\ttraining loss:\t3.452528\n",
      "Done 7810 batches in 1057.95s\ttraining loss:\t3.452492\n",
      "Done 7820 batches in 1059.51s\ttraining loss:\t3.452491\n",
      "Done 7830 batches in 1060.85s\ttraining loss:\t3.452455\n",
      "Done 7840 batches in 1062.51s\ttraining loss:\t3.452422\n",
      "Done 7850 batches in 1063.84s\ttraining loss:\t3.452376\n",
      "Done 7860 batches in 1065.14s\ttraining loss:\t3.452333\n",
      "Done 7870 batches in 1066.44s\ttraining loss:\t3.452298\n",
      "Done 7880 batches in 1067.91s\ttraining loss:\t3.452304\n",
      "Done 7890 batches in 1069.32s\ttraining loss:\t3.452248\n",
      "Done 7900 batches in 1070.58s\ttraining loss:\t3.452186\n",
      "Done 7910 batches in 1072.20s\ttraining loss:\t3.452119\n",
      "Done 7920 batches in 1073.59s\ttraining loss:\t3.452074\n",
      "Done 7930 batches in 1075.02s\ttraining loss:\t3.452091\n",
      "Done 7940 batches in 1076.17s\ttraining loss:\t3.452077\n",
      "Done 7950 batches in 1077.50s\ttraining loss:\t3.452032\n",
      "Done 7960 batches in 1079.32s\ttraining loss:\t3.451986\n",
      "Done 7970 batches in 1080.91s\ttraining loss:\t3.451972\n",
      "Done 7980 batches in 1082.36s\ttraining loss:\t3.451940\n",
      "Done 7990 batches in 1083.73s\ttraining loss:\t3.451901\n",
      "Done 8000 batches in 1085.04s\ttraining loss:\t3.451870\n",
      "Done 8010 batches in 1086.34s\ttraining loss:\t3.451870\n",
      "Done 8020 batches in 1087.55s\ttraining loss:\t3.451803\n",
      "Done 8030 batches in 1088.91s\ttraining loss:\t3.451764\n",
      "Done 8040 batches in 1090.52s\ttraining loss:\t3.451737\n",
      "Done 8050 batches in 1091.78s\ttraining loss:\t3.451648\n",
      "Done 8060 batches in 1093.11s\ttraining loss:\t3.451626\n",
      "Done 8070 batches in 1094.25s\ttraining loss:\t3.451611\n",
      "Done 8080 batches in 1095.84s\ttraining loss:\t3.451569\n",
      "Done 8090 batches in 1097.28s\ttraining loss:\t3.451573\n",
      "Done 8100 batches in 1098.67s\ttraining loss:\t3.451626\n",
      "Done 8110 batches in 1100.06s\ttraining loss:\t3.451645\n",
      "Done 8120 batches in 1101.52s\ttraining loss:\t3.451565\n",
      "Done 8130 batches in 1102.93s\ttraining loss:\t3.451519\n",
      "Done 8140 batches in 1104.16s\ttraining loss:\t3.451449\n",
      "Done 8150 batches in 1105.68s\ttraining loss:\t3.451473\n",
      "Done 8160 batches in 1106.93s\ttraining loss:\t3.451456\n",
      "Done 8170 batches in 1108.25s\ttraining loss:\t3.451423\n",
      "Done 8180 batches in 1109.39s\ttraining loss:\t3.451396\n",
      "Done 8190 batches in 1110.59s\ttraining loss:\t3.451380\n",
      "Done 8200 batches in 1111.61s\ttraining loss:\t3.451373\n",
      "Done 8210 batches in 1113.13s\ttraining loss:\t3.451366\n",
      "Done 8220 batches in 1114.45s\ttraining loss:\t3.451325\n",
      "Done 8230 batches in 1115.85s\ttraining loss:\t3.451263\n",
      "Done 8240 batches in 1117.30s\ttraining loss:\t3.451243\n",
      "Done 8250 batches in 1118.67s\ttraining loss:\t3.451217\n",
      "Done 8260 batches in 1119.74s\ttraining loss:\t3.451186\n",
      "Done 8270 batches in 1120.96s\ttraining loss:\t3.451129\n",
      "Done 8280 batches in 1122.54s\ttraining loss:\t3.451082\n",
      "Done 8290 batches in 1124.26s\ttraining loss:\t3.451087\n",
      "Done 8300 batches in 1125.76s\ttraining loss:\t3.451033\n",
      "Done 8310 batches in 1127.06s\ttraining loss:\t3.450984\n",
      "Done 8320 batches in 1128.39s\ttraining loss:\t3.450959\n",
      "Done 8330 batches in 1129.92s\ttraining loss:\t3.451004\n",
      "Done 8340 batches in 1131.17s\ttraining loss:\t3.450974\n",
      "Done 8350 batches in 1132.58s\ttraining loss:\t3.450983\n",
      "Done 8360 batches in 1133.83s\ttraining loss:\t3.450953\n",
      "Done 8370 batches in 1135.19s\ttraining loss:\t3.450892\n",
      "Done 8380 batches in 1136.36s\ttraining loss:\t3.450888\n",
      "Done 8390 batches in 1137.60s\ttraining loss:\t3.450862\n",
      "Done 8400 batches in 1139.04s\ttraining loss:\t3.450743\n",
      "Done 8410 batches in 1140.76s\ttraining loss:\t3.450678\n",
      "Done 8420 batches in 1141.83s\ttraining loss:\t3.450658\n",
      "Done 8430 batches in 1143.34s\ttraining loss:\t3.450678\n",
      "Done 8440 batches in 1144.68s\ttraining loss:\t3.450643\n",
      "Done 8450 batches in 1145.78s\ttraining loss:\t3.450599\n",
      "Done 8460 batches in 1147.04s\ttraining loss:\t3.450580\n",
      "Done 8470 batches in 1148.35s\ttraining loss:\t3.450594\n",
      "Done 8480 batches in 1149.54s\ttraining loss:\t3.450585\n",
      "Done 8490 batches in 1150.82s\ttraining loss:\t3.450569\n",
      "Done 8500 batches in 1152.33s\ttraining loss:\t3.450494\n",
      "Done 8510 batches in 1153.57s\ttraining loss:\t3.450465\n",
      "Done 8520 batches in 1155.13s\ttraining loss:\t3.450470\n",
      "Done 8530 batches in 1156.93s\ttraining loss:\t3.450425\n",
      "Done 8540 batches in 1158.19s\ttraining loss:\t3.450426\n",
      "Done 8550 batches in 1159.42s\ttraining loss:\t3.450372\n",
      "Done 8560 batches in 1160.72s\ttraining loss:\t3.450322\n",
      "Done 8570 batches in 1162.42s\ttraining loss:\t3.450280\n",
      "Done 8580 batches in 1164.10s\ttraining loss:\t3.450257\n",
      "Done 8590 batches in 1165.55s\ttraining loss:\t3.450217\n",
      "Done 8600 batches in 1166.75s\ttraining loss:\t3.450184\n",
      "Done 8610 batches in 1167.95s\ttraining loss:\t3.450112\n",
      "Done 8620 batches in 1169.51s\ttraining loss:\t3.450085\n",
      "Done 8630 batches in 1170.88s\ttraining loss:\t3.450015\n",
      "Done 8640 batches in 1172.30s\ttraining loss:\t3.449949\n",
      "Done 8650 batches in 1173.62s\ttraining loss:\t3.449925\n",
      "Done 8660 batches in 1175.03s\ttraining loss:\t3.449878\n",
      "Done 8670 batches in 1176.61s\ttraining loss:\t3.449882\n",
      "Done 8680 batches in 1177.95s\ttraining loss:\t3.449870\n",
      "Done 8690 batches in 1179.20s\ttraining loss:\t3.449785\n",
      "Done 8700 batches in 1180.52s\ttraining loss:\t3.449778\n",
      "Done 8710 batches in 1181.74s\ttraining loss:\t3.449703\n",
      "Done 8720 batches in 1183.33s\ttraining loss:\t3.449659\n",
      "Done 8730 batches in 1184.71s\ttraining loss:\t3.449656\n",
      "Done 8740 batches in 1186.18s\ttraining loss:\t3.449591\n",
      "Done 8750 batches in 1187.54s\ttraining loss:\t3.449494\n",
      "Done 8760 batches in 1188.98s\ttraining loss:\t3.449481\n",
      "Done 8770 batches in 1190.38s\ttraining loss:\t3.449445\n",
      "Done 8780 batches in 1191.50s\ttraining loss:\t3.449392\n",
      "Done 8790 batches in 1192.81s\ttraining loss:\t3.449362\n",
      "Done 8800 batches in 1194.24s\ttraining loss:\t3.449337\n",
      "Done 8810 batches in 1195.65s\ttraining loss:\t3.449275\n",
      "Done 8820 batches in 1197.18s\ttraining loss:\t3.449263\n",
      "Done 8830 batches in 1198.46s\ttraining loss:\t3.449218\n",
      "Done 8840 batches in 1199.54s\ttraining loss:\t3.449213\n",
      "Done 8850 batches in 1200.94s\ttraining loss:\t3.449187\n",
      "Done 8860 batches in 1202.05s\ttraining loss:\t3.449131\n",
      "Done 8870 batches in 1203.67s\ttraining loss:\t3.449095\n",
      "Done 8880 batches in 1204.84s\ttraining loss:\t3.449070\n",
      "Done 8890 batches in 1206.28s\ttraining loss:\t3.449046\n",
      "Done 8900 batches in 1207.60s\ttraining loss:\t3.448977\n",
      "Done 8910 batches in 1208.88s\ttraining loss:\t3.448970\n",
      "Done 8920 batches in 1210.25s\ttraining loss:\t3.448915\n",
      "Done 8930 batches in 1211.71s\ttraining loss:\t3.448932\n",
      "Done 8940 batches in 1213.07s\ttraining loss:\t3.448912\n",
      "Done 8950 batches in 1214.33s\ttraining loss:\t3.448895\n",
      "Done 8960 batches in 1215.82s\ttraining loss:\t3.448870\n",
      "Done 8970 batches in 1217.19s\ttraining loss:\t3.448824\n",
      "Done 8980 batches in 1218.64s\ttraining loss:\t3.448831\n",
      "Done 8990 batches in 1219.88s\ttraining loss:\t3.448813\n",
      "Done 9000 batches in 1221.23s\ttraining loss:\t3.448759\n",
      "Done 9010 batches in 1222.70s\ttraining loss:\t3.448719\n",
      "Done 9020 batches in 1224.12s\ttraining loss:\t3.448657\n",
      "Done 9030 batches in 1225.33s\ttraining loss:\t3.448664\n",
      "Done 9040 batches in 1226.55s\ttraining loss:\t3.448584\n",
      "Done 9050 batches in 1228.07s\ttraining loss:\t3.448547\n",
      "Done 9060 batches in 1229.57s\ttraining loss:\t3.448504\n",
      "Done 9070 batches in 1231.03s\ttraining loss:\t3.448475\n",
      "Done 9080 batches in 1232.45s\ttraining loss:\t3.448487\n",
      "Done 9090 batches in 1233.54s\ttraining loss:\t3.448435\n",
      "Done 9100 batches in 1235.23s\ttraining loss:\t3.448425\n",
      "Done 9110 batches in 1236.53s\ttraining loss:\t3.448396\n",
      "Done 9120 batches in 1237.95s\ttraining loss:\t3.448363\n",
      "Done 9130 batches in 1238.97s\ttraining loss:\t3.448372\n",
      "Done 9140 batches in 1240.39s\ttraining loss:\t3.448293\n",
      "Done 9150 batches in 1241.72s\ttraining loss:\t3.448240\n",
      "Done 9160 batches in 1243.25s\ttraining loss:\t3.448241\n",
      "Done 9170 batches in 1244.66s\ttraining loss:\t3.448140\n",
      "Done 9180 batches in 1246.20s\ttraining loss:\t3.448156\n",
      "Done 9190 batches in 1247.68s\ttraining loss:\t3.448133\n",
      "Done 9200 batches in 1248.96s\ttraining loss:\t3.448064\n",
      "Done 9210 batches in 1250.41s\ttraining loss:\t3.448060\n",
      "Done 9220 batches in 1251.61s\ttraining loss:\t3.448024\n",
      "Done 9230 batches in 1252.98s\ttraining loss:\t3.447961\n",
      "Done 9240 batches in 1254.41s\ttraining loss:\t3.447958\n",
      "Done 9250 batches in 1255.87s\ttraining loss:\t3.447934\n",
      "Done 9260 batches in 1257.39s\ttraining loss:\t3.447902\n",
      "Done 9270 batches in 1258.62s\ttraining loss:\t3.447859\n",
      "Done 9280 batches in 1260.00s\ttraining loss:\t3.447850\n",
      "Done 9290 batches in 1261.26s\ttraining loss:\t3.447819\n",
      "Done 9300 batches in 1262.71s\ttraining loss:\t3.447768\n",
      "Done 9310 batches in 1264.20s\ttraining loss:\t3.447692\n",
      "Done 9320 batches in 1265.47s\ttraining loss:\t3.447670\n",
      "Done 9330 batches in 1267.16s\ttraining loss:\t3.447628\n",
      "Done 9340 batches in 1268.54s\ttraining loss:\t3.447585\n",
      "Done 9350 batches in 1269.94s\ttraining loss:\t3.447575\n",
      "Done 9360 batches in 1271.24s\ttraining loss:\t3.447530\n",
      "Done 9370 batches in 1272.72s\ttraining loss:\t3.447512\n",
      "Done 9380 batches in 1274.11s\ttraining loss:\t3.447535\n",
      "Done 9390 batches in 1275.30s\ttraining loss:\t3.447534\n",
      "Done 9400 batches in 1276.74s\ttraining loss:\t3.447492\n",
      "Done 9410 batches in 1278.18s\ttraining loss:\t3.447485\n",
      "Done 9420 batches in 1279.37s\ttraining loss:\t3.447393\n",
      "Done 9430 batches in 1280.84s\ttraining loss:\t3.447339\n",
      "Done 9440 batches in 1282.37s\ttraining loss:\t3.447331\n",
      "Done 9450 batches in 1283.76s\ttraining loss:\t3.447252\n",
      "Done 9460 batches in 1285.05s\ttraining loss:\t3.447194\n",
      "Done 9470 batches in 1286.21s\ttraining loss:\t3.447155\n",
      "Done 9480 batches in 1287.40s\ttraining loss:\t3.447163\n",
      "Done 9490 batches in 1288.50s\ttraining loss:\t3.447127\n",
      "Done 9500 batches in 1289.84s\ttraining loss:\t3.447068\n",
      "Done 9510 batches in 1291.12s\ttraining loss:\t3.447052\n",
      "Done 9520 batches in 1292.44s\ttraining loss:\t3.447026\n",
      "Done 9530 batches in 1293.73s\ttraining loss:\t3.447019\n",
      "Done 9540 batches in 1295.13s\ttraining loss:\t3.447043\n",
      "Done 9550 batches in 1296.30s\ttraining loss:\t3.446956\n",
      "Done 9560 batches in 1297.58s\ttraining loss:\t3.446913\n",
      "Done 9570 batches in 1298.89s\ttraining loss:\t3.446853\n",
      "Done 9580 batches in 1300.31s\ttraining loss:\t3.446848\n",
      "Done 9590 batches in 1301.60s\ttraining loss:\t3.446837\n",
      "Done 9600 batches in 1302.96s\ttraining loss:\t3.446811\n",
      "Done 9610 batches in 1304.35s\ttraining loss:\t3.446820\n",
      "Done 9620 batches in 1305.90s\ttraining loss:\t3.446778\n",
      "Done 9630 batches in 1307.55s\ttraining loss:\t3.446754\n",
      "Done 9640 batches in 1308.82s\ttraining loss:\t3.446746\n",
      "Done 9650 batches in 1310.25s\ttraining loss:\t3.446727\n",
      "Done 9660 batches in 1311.62s\ttraining loss:\t3.446715\n",
      "Done 9670 batches in 1312.86s\ttraining loss:\t3.446712\n",
      "Done 9680 batches in 1314.40s\ttraining loss:\t3.446734\n",
      "Done 9690 batches in 1315.71s\ttraining loss:\t3.446728\n",
      "Done 9700 batches in 1317.00s\ttraining loss:\t3.446720\n",
      "Done 9710 batches in 1318.23s\ttraining loss:\t3.446691\n",
      "Done 9720 batches in 1319.51s\ttraining loss:\t3.446648\n",
      "Done 9730 batches in 1321.09s\ttraining loss:\t3.446631\n",
      "Done 9740 batches in 1322.48s\ttraining loss:\t3.446587\n",
      "Done 9750 batches in 1323.73s\ttraining loss:\t3.446531\n",
      "Done 9760 batches in 1325.11s\ttraining loss:\t3.446492\n",
      "Done 9770 batches in 1326.48s\ttraining loss:\t3.446479\n",
      "Done 9780 batches in 1328.00s\ttraining loss:\t3.446454\n",
      "Done 9790 batches in 1329.53s\ttraining loss:\t3.446460\n",
      "Done 9800 batches in 1330.75s\ttraining loss:\t3.446429\n",
      "Done 9810 batches in 1332.27s\ttraining loss:\t3.446414\n",
      "Done 9820 batches in 1333.61s\ttraining loss:\t3.446382\n",
      "Done 9830 batches in 1335.12s\ttraining loss:\t3.446361\n",
      "Done 9840 batches in 1336.64s\ttraining loss:\t3.446303\n",
      "Done 9850 batches in 1338.07s\ttraining loss:\t3.446279\n",
      "Done 9860 batches in 1339.52s\ttraining loss:\t3.446199\n",
      "Done 9870 batches in 1340.65s\ttraining loss:\t3.446170\n",
      "Done 9880 batches in 1342.14s\ttraining loss:\t3.446120\n",
      "Done 9890 batches in 1343.61s\ttraining loss:\t3.446063\n",
      "Done 9900 batches in 1345.17s\ttraining loss:\t3.446052\n",
      "Done 9910 batches in 1346.20s\ttraining loss:\t3.446046\n",
      "Done 9920 batches in 1347.89s\ttraining loss:\t3.446009\n",
      "Done 9930 batches in 1349.20s\ttraining loss:\t3.445954\n",
      "Done 9940 batches in 1350.58s\ttraining loss:\t3.445906\n",
      "Done 9950 batches in 1351.93s\ttraining loss:\t3.445843\n",
      "Done 9960 batches in 1353.33s\ttraining loss:\t3.445812\n",
      "Done 9970 batches in 1354.59s\ttraining loss:\t3.445789\n",
      "Done 9980 batches in 1356.14s\ttraining loss:\t3.445778\n",
      "Done 9990 batches in 1357.40s\ttraining loss:\t3.445741\n",
      "Done 10000 batches in 1358.63s\ttraining loss:\t3.445721\n",
      "Done 10010 batches in 1359.85s\ttraining loss:\t3.445690\n",
      "Done 10020 batches in 1361.01s\ttraining loss:\t3.445653\n",
      "Done 10030 batches in 1362.27s\ttraining loss:\t3.445585\n",
      "Done 10040 batches in 1363.66s\ttraining loss:\t3.445539\n",
      "Done 10050 batches in 1365.35s\ttraining loss:\t3.445528\n",
      "Done 10060 batches in 1366.61s\ttraining loss:\t3.445492\n",
      "Done 10070 batches in 1367.97s\ttraining loss:\t3.445468\n",
      "Done 10080 batches in 1369.06s\ttraining loss:\t3.445420\n",
      "Done 10090 batches in 1370.43s\ttraining loss:\t3.445379\n",
      "Done 10100 batches in 1371.74s\ttraining loss:\t3.445408\n",
      "Done 10110 batches in 1372.98s\ttraining loss:\t3.445409\n",
      "Done 10120 batches in 1374.37s\ttraining loss:\t3.445401\n",
      "Done 10130 batches in 1375.82s\ttraining loss:\t3.445401\n",
      "Done 10140 batches in 1377.20s\ttraining loss:\t3.445371\n",
      "Done 10150 batches in 1378.41s\ttraining loss:\t3.445327\n",
      "Done 10160 batches in 1379.93s\ttraining loss:\t3.445316\n",
      "Done 10170 batches in 1381.00s\ttraining loss:\t3.445250\n",
      "Done 10180 batches in 1382.47s\ttraining loss:\t3.445246\n",
      "Done 10190 batches in 1383.66s\ttraining loss:\t3.445199\n",
      "Done 10200 batches in 1384.90s\ttraining loss:\t3.445164\n",
      "Done 10210 batches in 1386.22s\ttraining loss:\t3.445135\n",
      "Done 10220 batches in 1387.47s\ttraining loss:\t3.445095\n",
      "Done 10230 batches in 1388.95s\ttraining loss:\t3.445080\n",
      "Done 10240 batches in 1390.22s\ttraining loss:\t3.445053\n",
      "Done 10250 batches in 1391.89s\ttraining loss:\t3.445052\n",
      "Done 10260 batches in 1393.04s\ttraining loss:\t3.444994\n",
      "Done 10270 batches in 1394.38s\ttraining loss:\t3.444973\n",
      "Done 10280 batches in 1395.64s\ttraining loss:\t3.444994\n",
      "Done 10290 batches in 1396.86s\ttraining loss:\t3.444964\n",
      "Done 10300 batches in 1398.15s\ttraining loss:\t3.444935\n",
      "Done 10310 batches in 1399.54s\ttraining loss:\t3.444928\n",
      "Done 10320 batches in 1400.67s\ttraining loss:\t3.444892\n",
      "Done 10330 batches in 1402.02s\ttraining loss:\t3.444846\n",
      "Done 10340 batches in 1403.23s\ttraining loss:\t3.444842\n",
      "Done 10350 batches in 1404.43s\ttraining loss:\t3.444824\n",
      "Done 10360 batches in 1405.92s\ttraining loss:\t3.444807\n",
      "Done 10370 batches in 1407.41s\ttraining loss:\t3.444754\n",
      "Done 10380 batches in 1408.67s\ttraining loss:\t3.444715\n",
      "Done 10390 batches in 1409.87s\ttraining loss:\t3.444719\n",
      "Done 10400 batches in 1411.06s\ttraining loss:\t3.444715\n",
      "Done 10410 batches in 1412.28s\ttraining loss:\t3.444730\n",
      "Done 10420 batches in 1413.74s\ttraining loss:\t3.444747\n",
      "Done 10430 batches in 1414.94s\ttraining loss:\t3.444703\n",
      "Done 10440 batches in 1416.14s\ttraining loss:\t3.444643\n",
      "Done 10450 batches in 1417.35s\ttraining loss:\t3.444604\n",
      "Done 10460 batches in 1418.58s\ttraining loss:\t3.444596\n",
      "Done 10470 batches in 1419.80s\ttraining loss:\t3.444560\n",
      "Done 10480 batches in 1421.11s\ttraining loss:\t3.444508\n",
      "Done 10490 batches in 1422.36s\ttraining loss:\t3.444511\n",
      "Done 10500 batches in 1423.64s\ttraining loss:\t3.444452\n",
      "Done 10510 batches in 1425.25s\ttraining loss:\t3.444403\n",
      "Done 10520 batches in 1426.55s\ttraining loss:\t3.444348\n",
      "Done 10530 batches in 1428.31s\ttraining loss:\t3.444362\n",
      "Done 10540 batches in 1429.73s\ttraining loss:\t3.444356\n",
      "Done 10550 batches in 1431.26s\ttraining loss:\t3.444354\n",
      "Done 10560 batches in 1432.41s\ttraining loss:\t3.444312\n",
      "Done 10570 batches in 1433.62s\ttraining loss:\t3.444268\n",
      "Done 10580 batches in 1435.08s\ttraining loss:\t3.444254\n",
      "Done 10590 batches in 1436.39s\ttraining loss:\t3.444278\n",
      "Done 10600 batches in 1437.69s\ttraining loss:\t3.444239\n",
      "Done 10610 batches in 1438.89s\ttraining loss:\t3.444203\n",
      "Done 10620 batches in 1440.46s\ttraining loss:\t3.444194\n",
      "Done 10630 batches in 1441.96s\ttraining loss:\t3.444172\n",
      "Done 10640 batches in 1443.28s\ttraining loss:\t3.444142\n",
      "Done 10650 batches in 1444.59s\ttraining loss:\t3.444098\n",
      "Done 10660 batches in 1445.82s\ttraining loss:\t3.444084\n",
      "Done 10670 batches in 1447.38s\ttraining loss:\t3.444114\n",
      "Done 10680 batches in 1448.68s\ttraining loss:\t3.444092\n",
      "Done 10690 batches in 1449.91s\ttraining loss:\t3.444010\n",
      "Done 10700 batches in 1451.20s\ttraining loss:\t3.443954\n",
      "Done 10710 batches in 1452.39s\ttraining loss:\t3.443944\n",
      "Done 10720 batches in 1453.92s\ttraining loss:\t3.443915\n",
      "Done 10730 batches in 1455.16s\ttraining loss:\t3.443869\n",
      "Done 10740 batches in 1456.41s\ttraining loss:\t3.443856\n",
      "Done 10750 batches in 1457.86s\ttraining loss:\t3.443845\n",
      "Done 10760 batches in 1459.17s\ttraining loss:\t3.443824\n",
      "Done 10770 batches in 1460.24s\ttraining loss:\t3.443772\n",
      "Done 10780 batches in 1461.75s\ttraining loss:\t3.443767\n",
      "Done 10790 batches in 1463.25s\ttraining loss:\t3.443722\n",
      "Done 10800 batches in 1464.68s\ttraining loss:\t3.443657\n",
      "Done 10810 batches in 1466.08s\ttraining loss:\t3.443620\n",
      "Done 10820 batches in 1467.62s\ttraining loss:\t3.443596\n",
      "Done 10830 batches in 1469.09s\ttraining loss:\t3.443605\n",
      "Done 10840 batches in 1470.54s\ttraining loss:\t3.443585\n",
      "Done 10850 batches in 1471.79s\ttraining loss:\t3.443526\n",
      "Done 10860 batches in 1473.43s\ttraining loss:\t3.443518\n",
      "Done 10870 batches in 1474.94s\ttraining loss:\t3.443506\n",
      "Done 10880 batches in 1476.07s\ttraining loss:\t3.443492\n",
      "Done 10890 batches in 1477.57s\ttraining loss:\t3.443447\n",
      "Done 10900 batches in 1479.39s\ttraining loss:\t3.443415\n",
      "Done 10910 batches in 1480.80s\ttraining loss:\t3.443369\n",
      "Done 10920 batches in 1482.14s\ttraining loss:\t3.443331\n",
      "Done 10930 batches in 1483.26s\ttraining loss:\t3.443288\n",
      "Done 10940 batches in 1484.65s\ttraining loss:\t3.443280\n",
      "Done 10950 batches in 1485.75s\ttraining loss:\t3.443258\n",
      "Done 10960 batches in 1487.16s\ttraining loss:\t3.443187\n",
      "Done 10970 batches in 1488.75s\ttraining loss:\t3.443174\n",
      "Done 10980 batches in 1490.02s\ttraining loss:\t3.443130\n",
      "Done 10990 batches in 1491.61s\ttraining loss:\t3.443061\n",
      "Done 11000 batches in 1492.91s\ttraining loss:\t3.443042\n",
      "Done 11010 batches in 1494.13s\ttraining loss:\t3.442988\n",
      "Done 11020 batches in 1495.59s\ttraining loss:\t3.442966\n",
      "Done 11030 batches in 1496.66s\ttraining loss:\t3.442922\n",
      "Done 11040 batches in 1497.96s\ttraining loss:\t3.442911\n",
      "Done 11050 batches in 1499.20s\ttraining loss:\t3.442897\n",
      "Done 11060 batches in 1500.56s\ttraining loss:\t3.442848\n",
      "Done 11070 batches in 1501.96s\ttraining loss:\t3.442806\n",
      "Done 11080 batches in 1503.13s\ttraining loss:\t3.442776\n",
      "Done 11090 batches in 1504.61s\ttraining loss:\t3.442751\n",
      "Done 11100 batches in 1505.68s\ttraining loss:\t3.442713\n",
      "Done 11110 batches in 1507.02s\ttraining loss:\t3.442666\n",
      "Done 11120 batches in 1508.30s\ttraining loss:\t3.442625\n",
      "Done 11130 batches in 1509.67s\ttraining loss:\t3.442611\n",
      "Done 11140 batches in 1510.94s\ttraining loss:\t3.442541\n",
      "Done 11150 batches in 1512.16s\ttraining loss:\t3.442550\n",
      "Done 11160 batches in 1513.46s\ttraining loss:\t3.442549\n",
      "Done 11170 batches in 1515.05s\ttraining loss:\t3.442522\n",
      "Done 11180 batches in 1516.20s\ttraining loss:\t3.442530\n",
      "Done 11190 batches in 1517.32s\ttraining loss:\t3.442447\n",
      "Done 11200 batches in 1518.31s\ttraining loss:\t3.442398\n",
      "Done 11210 batches in 1519.45s\ttraining loss:\t3.442353\n",
      "Done 11220 batches in 1520.83s\ttraining loss:\t3.442341\n",
      "Done 11230 batches in 1522.21s\ttraining loss:\t3.442324\n",
      "Done 11240 batches in 1523.59s\ttraining loss:\t3.442282\n",
      "Done 11250 batches in 1525.08s\ttraining loss:\t3.442274\n",
      "Done 11260 batches in 1526.31s\ttraining loss:\t3.442238\n",
      "Done 11270 batches in 1527.38s\ttraining loss:\t3.442184\n",
      "Done 11280 batches in 1528.72s\ttraining loss:\t3.442150\n",
      "Done 11290 batches in 1529.98s\ttraining loss:\t3.442113\n",
      "Done 11300 batches in 1531.38s\ttraining loss:\t3.442125\n",
      "Done 11310 batches in 1532.79s\ttraining loss:\t3.442117\n",
      "Done 11320 batches in 1534.13s\ttraining loss:\t3.442112\n",
      "Done 11330 batches in 1535.28s\ttraining loss:\t3.442052\n",
      "Done 11340 batches in 1536.73s\ttraining loss:\t3.441993\n",
      "Done 11350 batches in 1538.12s\ttraining loss:\t3.441962\n",
      "Done 11360 batches in 1539.32s\ttraining loss:\t3.441962\n",
      "Done 11370 batches in 1540.46s\ttraining loss:\t3.441948\n",
      "Done 11380 batches in 1541.88s\ttraining loss:\t3.441932\n",
      "Done 11390 batches in 1543.21s\ttraining loss:\t3.441880\n",
      "Done 11400 batches in 1544.41s\ttraining loss:\t3.441864\n",
      "Done 11410 batches in 1545.76s\ttraining loss:\t3.441809\n",
      "Done 11420 batches in 1547.03s\ttraining loss:\t3.441774\n",
      "Done 11430 batches in 1548.21s\ttraining loss:\t3.441760\n",
      "Done 11440 batches in 1549.73s\ttraining loss:\t3.441778\n",
      "Done 11450 batches in 1550.89s\ttraining loss:\t3.441743\n",
      "Done 11460 batches in 1552.35s\ttraining loss:\t3.441715\n",
      "Done 11470 batches in 1553.60s\ttraining loss:\t3.441681\n",
      "Done 11480 batches in 1554.77s\ttraining loss:\t3.441615\n",
      "Done 11490 batches in 1556.04s\ttraining loss:\t3.441587\n",
      "Done 11500 batches in 1557.32s\ttraining loss:\t3.441575\n",
      "Done 11510 batches in 1558.86s\ttraining loss:\t3.441564\n",
      "Done 11520 batches in 1560.22s\ttraining loss:\t3.441516\n",
      "Done 11530 batches in 1561.53s\ttraining loss:\t3.441497\n",
      "Done 11540 batches in 1563.26s\ttraining loss:\t3.441464\n",
      "Done 11550 batches in 1564.48s\ttraining loss:\t3.441427\n",
      "Done 11560 batches in 1565.85s\ttraining loss:\t3.441399\n",
      "Done 11570 batches in 1567.33s\ttraining loss:\t3.441392\n",
      "Done 11580 batches in 1568.64s\ttraining loss:\t3.441351\n",
      "Done 11590 batches in 1570.19s\ttraining loss:\t3.441314\n",
      "Done 11600 batches in 1571.73s\ttraining loss:\t3.441269\n",
      "Done 11610 batches in 1573.28s\ttraining loss:\t3.441240\n",
      "Done 11620 batches in 1574.58s\ttraining loss:\t3.441193\n",
      "Done 11630 batches in 1576.01s\ttraining loss:\t3.441181\n",
      "Done 11640 batches in 1577.57s\ttraining loss:\t3.441181\n",
      "Done 11650 batches in 1578.95s\ttraining loss:\t3.441152\n",
      "Done 11660 batches in 1580.35s\ttraining loss:\t3.441115\n",
      "Done 11670 batches in 1581.70s\ttraining loss:\t3.441077\n",
      "Done 11680 batches in 1583.16s\ttraining loss:\t3.441056\n",
      "Done 11690 batches in 1584.54s\ttraining loss:\t3.441012\n",
      "Done 11700 batches in 1585.79s\ttraining loss:\t3.441003\n",
      "Done 11710 batches in 1587.04s\ttraining loss:\t3.440966\n",
      "Done 11720 batches in 1588.34s\ttraining loss:\t3.440929\n",
      "Done 11730 batches in 1589.53s\ttraining loss:\t3.440911\n",
      "Done 11740 batches in 1590.70s\ttraining loss:\t3.440880\n",
      "Done 11750 batches in 1591.99s\ttraining loss:\t3.440893\n",
      "Done 11760 batches in 1593.40s\ttraining loss:\t3.440889\n",
      "Done 100 batches in 2.30s\n",
      "Done 200 batches in 4.88s\n",
      "Done 300 batches in 7.39s\n",
      "Done 400 batches in 9.93s\n",
      "Done 500 batches in 12.23s\n",
      "Done 600 batches in 14.60s\n",
      "Done 700 batches in 16.88s\n",
      "Done 800 batches in 19.22s\n",
      "Done 900 batches in 21.50s\n",
      "Done 1000 batches in 23.72s\n",
      "Done 1100 batches in 26.31s\n",
      "Done 1200 batches in 28.89s\n",
      "Done 1300 batches in 31.39s\n",
      "Done 1400 batches in 33.98s\n",
      "Done 1500 batches in 36.54s\n",
      "Done 1600 batches in 39.14s\n",
      "Done 1700 batches in 41.36s\n",
      "Done 1800 batches in 43.69s\n",
      "Done 1900 batches in 46.08s\n",
      "Done 2000 batches in 48.43s\n",
      "Done 2100 batches in 50.91s\n",
      "Done 2200 batches in 53.43s\n",
      "Done 2300 batches in 55.96s\n",
      "Done 2400 batches in 58.26s\n",
      "Done 2500 batches in 60.68s\n",
      "Done 2600 batches in 63.14s\n",
      "Done 2700 batches in 65.71s\n",
      "Done 2800 batches in 68.28s\n",
      "Done 2900 batches in 70.72s\n",
      "Epoch 2 of 5 took 1667.05s\n",
      "  training loss:\t\t3.440871\n",
      "  validation loss:\t\t3.480820\n",
      "Done 10 batches in 1.27s\ttraining loss:\t3.378155\n",
      "Done 20 batches in 2.78s\ttraining loss:\t3.377094\n",
      "Done 30 batches in 4.04s\ttraining loss:\t3.380248\n",
      "Done 40 batches in 5.65s\ttraining loss:\t3.383857\n",
      "Done 50 batches in 7.13s\ttraining loss:\t3.389118\n",
      "Done 60 batches in 8.57s\ttraining loss:\t3.392558\n",
      "Done 70 batches in 9.67s\ttraining loss:\t3.395482\n",
      "Done 80 batches in 10.95s\ttraining loss:\t3.397348\n",
      "Done 90 batches in 12.45s\ttraining loss:\t3.399840\n",
      "Done 100 batches in 13.71s\ttraining loss:\t3.401088\n",
      "Done 110 batches in 14.93s\ttraining loss:\t3.403341\n",
      "Done 120 batches in 16.26s\ttraining loss:\t3.402329\n",
      "Done 130 batches in 17.50s\ttraining loss:\t3.403879\n",
      "Done 140 batches in 18.95s\ttraining loss:\t3.404615\n",
      "Done 150 batches in 20.50s\ttraining loss:\t3.404869\n",
      "Done 160 batches in 21.97s\ttraining loss:\t3.403127\n",
      "Done 170 batches in 23.23s\ttraining loss:\t3.402269\n",
      "Done 180 batches in 24.84s\ttraining loss:\t3.402325\n",
      "Done 190 batches in 26.08s\ttraining loss:\t3.401093\n",
      "Done 200 batches in 27.69s\ttraining loss:\t3.400786\n",
      "Done 210 batches in 29.29s\ttraining loss:\t3.402752\n",
      "Done 220 batches in 30.74s\ttraining loss:\t3.402720\n",
      "Done 230 batches in 32.00s\ttraining loss:\t3.403709\n",
      "Done 240 batches in 33.06s\ttraining loss:\t3.404305\n",
      "Done 250 batches in 34.42s\ttraining loss:\t3.402871\n",
      "Done 260 batches in 35.74s\ttraining loss:\t3.402472\n",
      "Done 270 batches in 37.00s\ttraining loss:\t3.402011\n",
      "Done 280 batches in 38.11s\ttraining loss:\t3.401295\n",
      "Done 290 batches in 39.60s\ttraining loss:\t3.402644\n",
      "Done 300 batches in 40.97s\ttraining loss:\t3.402974\n",
      "Done 310 batches in 42.26s\ttraining loss:\t3.402974\n",
      "Done 320 batches in 43.62s\ttraining loss:\t3.403371\n",
      "Done 330 batches in 45.17s\ttraining loss:\t3.402538\n",
      "Done 340 batches in 46.65s\ttraining loss:\t3.401707\n",
      "Done 350 batches in 48.07s\ttraining loss:\t3.401757\n",
      "Done 360 batches in 49.62s\ttraining loss:\t3.402669\n",
      "Done 370 batches in 51.06s\ttraining loss:\t3.402259\n",
      "Done 380 batches in 52.48s\ttraining loss:\t3.401452\n",
      "Done 390 batches in 53.86s\ttraining loss:\t3.400690\n",
      "Done 400 batches in 55.23s\ttraining loss:\t3.400531\n",
      "Done 410 batches in 56.48s\ttraining loss:\t3.399546\n",
      "Done 420 batches in 57.95s\ttraining loss:\t3.400382\n",
      "Done 430 batches in 59.38s\ttraining loss:\t3.400072\n",
      "Done 440 batches in 60.71s\ttraining loss:\t3.399746\n",
      "Done 450 batches in 61.89s\ttraining loss:\t3.399371\n",
      "Done 460 batches in 63.03s\ttraining loss:\t3.399152\n",
      "Done 470 batches in 64.27s\ttraining loss:\t3.398852\n",
      "Done 480 batches in 65.39s\ttraining loss:\t3.398715\n",
      "Done 490 batches in 66.75s\ttraining loss:\t3.398579\n",
      "Done 500 batches in 68.19s\ttraining loss:\t3.399756\n",
      "Done 510 batches in 69.46s\ttraining loss:\t3.399850\n",
      "Done 520 batches in 70.59s\ttraining loss:\t3.399325\n",
      "Done 530 batches in 71.87s\ttraining loss:\t3.398614\n",
      "Done 540 batches in 73.38s\ttraining loss:\t3.397804\n",
      "Done 550 batches in 74.77s\ttraining loss:\t3.397767\n",
      "Done 560 batches in 76.10s\ttraining loss:\t3.398186\n",
      "Done 570 batches in 77.48s\ttraining loss:\t3.398985\n",
      "Done 580 batches in 78.92s\ttraining loss:\t3.398778\n",
      "Done 590 batches in 80.21s\ttraining loss:\t3.398634\n",
      "Done 600 batches in 81.60s\ttraining loss:\t3.398897\n",
      "Done 610 batches in 82.89s\ttraining loss:\t3.399138\n",
      "Done 620 batches in 84.08s\ttraining loss:\t3.399192\n",
      "Done 630 batches in 85.34s\ttraining loss:\t3.398344\n",
      "Done 640 batches in 86.84s\ttraining loss:\t3.398111\n",
      "Done 650 batches in 88.85s\ttraining loss:\t3.398770\n",
      "Done 660 batches in 90.08s\ttraining loss:\t3.398621\n",
      "Done 670 batches in 91.40s\ttraining loss:\t3.399038\n",
      "Done 680 batches in 92.61s\ttraining loss:\t3.399035\n",
      "Done 690 batches in 93.90s\ttraining loss:\t3.398903\n",
      "Done 700 batches in 95.00s\ttraining loss:\t3.398981\n",
      "Done 710 batches in 96.19s\ttraining loss:\t3.398654\n",
      "Done 720 batches in 97.61s\ttraining loss:\t3.398330\n",
      "Done 730 batches in 98.80s\ttraining loss:\t3.398723\n",
      "Done 740 batches in 100.33s\ttraining loss:\t3.398905\n",
      "Done 750 batches in 101.87s\ttraining loss:\t3.399694\n",
      "Done 760 batches in 103.27s\ttraining loss:\t3.400108\n",
      "Done 770 batches in 104.78s\ttraining loss:\t3.400073\n",
      "Done 780 batches in 106.12s\ttraining loss:\t3.399386\n",
      "Done 790 batches in 107.25s\ttraining loss:\t3.399570\n",
      "Done 800 batches in 108.67s\ttraining loss:\t3.399742\n",
      "Done 810 batches in 110.29s\ttraining loss:\t3.400097\n",
      "Done 820 batches in 111.55s\ttraining loss:\t3.399789\n",
      "Done 830 batches in 112.77s\ttraining loss:\t3.399791\n",
      "Done 840 batches in 113.94s\ttraining loss:\t3.399436\n",
      "Done 850 batches in 115.47s\ttraining loss:\t3.399028\n",
      "Done 860 batches in 116.84s\ttraining loss:\t3.399153\n",
      "Done 870 batches in 118.07s\ttraining loss:\t3.399317\n",
      "Done 880 batches in 119.48s\ttraining loss:\t3.399496\n",
      "Done 890 batches in 120.91s\ttraining loss:\t3.399079\n",
      "Done 900 batches in 122.20s\ttraining loss:\t3.398805\n",
      "Done 910 batches in 123.39s\ttraining loss:\t3.398686\n",
      "Done 920 batches in 124.69s\ttraining loss:\t3.398685\n",
      "Done 930 batches in 126.12s\ttraining loss:\t3.398562\n",
      "Done 940 batches in 127.55s\ttraining loss:\t3.398001\n",
      "Done 950 batches in 128.90s\ttraining loss:\t3.397781\n",
      "Done 960 batches in 129.99s\ttraining loss:\t3.397928\n",
      "Done 970 batches in 131.38s\ttraining loss:\t3.398058\n",
      "Done 980 batches in 132.56s\ttraining loss:\t3.397922\n",
      "Done 990 batches in 133.86s\ttraining loss:\t3.398128\n",
      "Done 1000 batches in 135.13s\ttraining loss:\t3.398179\n",
      "Done 1010 batches in 136.46s\ttraining loss:\t3.398496\n",
      "Done 1020 batches in 137.79s\ttraining loss:\t3.398648\n",
      "Done 1030 batches in 138.95s\ttraining loss:\t3.398498\n",
      "Done 1040 batches in 140.33s\ttraining loss:\t3.398556\n",
      "Done 1050 batches in 141.79s\ttraining loss:\t3.398670\n",
      "Done 1060 batches in 143.14s\ttraining loss:\t3.398693\n",
      "Done 1070 batches in 144.45s\ttraining loss:\t3.398890\n",
      "Done 1080 batches in 146.06s\ttraining loss:\t3.399185\n",
      "Done 1090 batches in 147.11s\ttraining loss:\t3.399131\n",
      "Done 1100 batches in 148.42s\ttraining loss:\t3.398952\n",
      "Done 1110 batches in 149.80s\ttraining loss:\t3.399337\n",
      "Done 1120 batches in 151.04s\ttraining loss:\t3.399124\n",
      "Done 1130 batches in 152.41s\ttraining loss:\t3.399316\n",
      "Done 1140 batches in 153.55s\ttraining loss:\t3.399324\n",
      "Done 1150 batches in 155.00s\ttraining loss:\t3.399410\n",
      "Done 1160 batches in 156.13s\ttraining loss:\t3.399345\n",
      "Done 1170 batches in 157.33s\ttraining loss:\t3.399287\n",
      "Done 1180 batches in 159.14s\ttraining loss:\t3.399117\n",
      "Done 1190 batches in 160.41s\ttraining loss:\t3.399192\n",
      "Done 1200 batches in 161.69s\ttraining loss:\t3.399159\n",
      "Done 1210 batches in 162.96s\ttraining loss:\t3.399040\n",
      "Done 1220 batches in 164.35s\ttraining loss:\t3.398840\n",
      "Done 1230 batches in 165.59s\ttraining loss:\t3.398872\n",
      "Done 1240 batches in 166.97s\ttraining loss:\t3.398732\n",
      "Done 1250 batches in 168.25s\ttraining loss:\t3.398240\n",
      "Done 1260 batches in 169.83s\ttraining loss:\t3.398469\n",
      "Done 1270 batches in 171.05s\ttraining loss:\t3.398439\n",
      "Done 1280 batches in 172.36s\ttraining loss:\t3.398494\n",
      "Done 1290 batches in 173.73s\ttraining loss:\t3.398614\n",
      "Done 1300 batches in 175.05s\ttraining loss:\t3.398496\n",
      "Done 1310 batches in 176.56s\ttraining loss:\t3.398311\n",
      "Done 1320 batches in 178.16s\ttraining loss:\t3.397821\n",
      "Done 1330 batches in 179.31s\ttraining loss:\t3.397611\n",
      "Done 1340 batches in 180.78s\ttraining loss:\t3.397349\n",
      "Done 1350 batches in 182.13s\ttraining loss:\t3.397306\n",
      "Done 1360 batches in 183.29s\ttraining loss:\t3.396983\n",
      "Done 1370 batches in 184.51s\ttraining loss:\t3.396968\n",
      "Done 1380 batches in 186.00s\ttraining loss:\t3.396998\n",
      "Done 1390 batches in 187.38s\ttraining loss:\t3.396892\n",
      "Done 1400 batches in 188.75s\ttraining loss:\t3.397069\n",
      "Done 1410 batches in 190.45s\ttraining loss:\t3.397183\n",
      "Done 1420 batches in 191.65s\ttraining loss:\t3.397109\n",
      "Done 1430 batches in 193.00s\ttraining loss:\t3.397079\n",
      "Done 1440 batches in 194.58s\ttraining loss:\t3.397202\n",
      "Done 1450 batches in 195.88s\ttraining loss:\t3.397139\n",
      "Done 1460 batches in 196.98s\ttraining loss:\t3.397156\n",
      "Done 1470 batches in 198.29s\ttraining loss:\t3.397307\n",
      "Done 1480 batches in 199.51s\ttraining loss:\t3.397111\n",
      "Done 1490 batches in 200.72s\ttraining loss:\t3.396982\n",
      "Done 1500 batches in 202.20s\ttraining loss:\t3.396764\n",
      "Done 1510 batches in 203.42s\ttraining loss:\t3.396465\n",
      "Done 1520 batches in 204.73s\ttraining loss:\t3.396368\n",
      "Done 1530 batches in 206.00s\ttraining loss:\t3.396346\n",
      "Done 1540 batches in 207.10s\ttraining loss:\t3.396112\n",
      "Done 1550 batches in 208.42s\ttraining loss:\t3.396039\n",
      "Done 1560 batches in 209.90s\ttraining loss:\t3.396051\n",
      "Done 1570 batches in 211.44s\ttraining loss:\t3.396133\n",
      "Done 1580 batches in 212.79s\ttraining loss:\t3.396135\n",
      "Done 1590 batches in 214.14s\ttraining loss:\t3.396137\n",
      "Done 1600 batches in 215.49s\ttraining loss:\t3.396330\n",
      "Done 1610 batches in 216.39s\ttraining loss:\t3.396074\n",
      "Done 1620 batches in 218.02s\ttraining loss:\t3.395967\n",
      "Done 1630 batches in 219.48s\ttraining loss:\t3.396138\n",
      "Done 1640 batches in 220.75s\ttraining loss:\t3.396137\n",
      "Done 1650 batches in 222.06s\ttraining loss:\t3.396226\n",
      "Done 1660 batches in 223.48s\ttraining loss:\t3.396260\n",
      "Done 1670 batches in 224.71s\ttraining loss:\t3.396275\n",
      "Done 1680 batches in 226.61s\ttraining loss:\t3.396527\n",
      "Done 1690 batches in 227.91s\ttraining loss:\t3.396525\n",
      "Done 1700 batches in 229.27s\ttraining loss:\t3.396521\n",
      "Done 1710 batches in 230.45s\ttraining loss:\t3.396328\n",
      "Done 1720 batches in 231.96s\ttraining loss:\t3.396427\n",
      "Done 1730 batches in 233.09s\ttraining loss:\t3.396267\n",
      "Done 1740 batches in 234.28s\ttraining loss:\t3.396285\n",
      "Done 1750 batches in 236.00s\ttraining loss:\t3.396400\n",
      "Done 1760 batches in 237.22s\ttraining loss:\t3.396514\n",
      "Done 1770 batches in 238.74s\ttraining loss:\t3.396319\n",
      "Done 1780 batches in 239.95s\ttraining loss:\t3.396328\n",
      "Done 1790 batches in 241.18s\ttraining loss:\t3.396080\n",
      "Done 1800 batches in 242.52s\ttraining loss:\t3.396197\n",
      "Done 1810 batches in 244.15s\ttraining loss:\t3.396258\n",
      "Done 1820 batches in 245.44s\ttraining loss:\t3.396092\n",
      "Done 1830 batches in 246.90s\ttraining loss:\t3.396226\n",
      "Done 1840 batches in 248.10s\ttraining loss:\t3.396163\n",
      "Done 1850 batches in 249.48s\ttraining loss:\t3.395901\n",
      "Done 1860 batches in 250.80s\ttraining loss:\t3.395839\n",
      "Done 1870 batches in 252.24s\ttraining loss:\t3.395652\n",
      "Done 1880 batches in 253.56s\ttraining loss:\t3.395736\n",
      "Done 1890 batches in 254.72s\ttraining loss:\t3.395666\n",
      "Done 1900 batches in 256.04s\ttraining loss:\t3.395477\n",
      "Done 1910 batches in 257.35s\ttraining loss:\t3.395416\n",
      "Done 1920 batches in 258.77s\ttraining loss:\t3.395430\n",
      "Done 1930 batches in 260.01s\ttraining loss:\t3.395428\n",
      "Done 1940 batches in 261.46s\ttraining loss:\t3.395318\n",
      "Done 1950 batches in 262.95s\ttraining loss:\t3.395067\n",
      "Done 1960 batches in 264.07s\ttraining loss:\t3.394951\n",
      "Done 1970 batches in 265.37s\ttraining loss:\t3.395105\n",
      "Done 1980 batches in 266.93s\ttraining loss:\t3.395030\n",
      "Done 1990 batches in 268.14s\ttraining loss:\t3.394883\n",
      "Done 2000 batches in 269.55s\ttraining loss:\t3.395092\n",
      "Done 2010 batches in 270.89s\ttraining loss:\t3.395424\n",
      "Done 2020 batches in 272.11s\ttraining loss:\t3.395347\n",
      "Done 2030 batches in 273.50s\ttraining loss:\t3.395295\n",
      "Done 2040 batches in 274.86s\ttraining loss:\t3.395305\n",
      "Done 2050 batches in 275.95s\ttraining loss:\t3.395507\n",
      "Done 2060 batches in 277.38s\ttraining loss:\t3.395524\n",
      "Done 2070 batches in 278.72s\ttraining loss:\t3.395527\n",
      "Done 2080 batches in 280.17s\ttraining loss:\t3.395370\n",
      "Done 2090 batches in 281.47s\ttraining loss:\t3.395208\n",
      "Done 2100 batches in 282.92s\ttraining loss:\t3.395077\n",
      "Done 2110 batches in 284.24s\ttraining loss:\t3.395041\n",
      "Done 2120 batches in 285.68s\ttraining loss:\t3.395172\n",
      "Done 2130 batches in 286.85s\ttraining loss:\t3.395464\n",
      "Done 2140 batches in 288.23s\ttraining loss:\t3.395267\n",
      "Done 2150 batches in 289.66s\ttraining loss:\t3.395282\n",
      "Done 2160 batches in 290.87s\ttraining loss:\t3.395308\n",
      "Done 2170 batches in 292.32s\ttraining loss:\t3.395186\n",
      "Done 2180 batches in 293.60s\ttraining loss:\t3.395123\n",
      "Done 2190 batches in 294.94s\ttraining loss:\t3.395157\n",
      "Done 2200 batches in 296.08s\ttraining loss:\t3.394915\n",
      "Done 2210 batches in 297.19s\ttraining loss:\t3.394696\n",
      "Done 2220 batches in 298.94s\ttraining loss:\t3.394808\n",
      "Done 2230 batches in 300.53s\ttraining loss:\t3.394773\n",
      "Done 2240 batches in 301.84s\ttraining loss:\t3.394765\n",
      "Done 2250 batches in 303.10s\ttraining loss:\t3.394664\n",
      "Done 2260 batches in 304.40s\ttraining loss:\t3.394647\n",
      "Done 2270 batches in 305.82s\ttraining loss:\t3.394681\n",
      "Done 2280 batches in 306.94s\ttraining loss:\t3.394624\n",
      "Done 2290 batches in 308.28s\ttraining loss:\t3.394563\n",
      "Done 2300 batches in 309.53s\ttraining loss:\t3.394645\n",
      "Done 2310 batches in 311.11s\ttraining loss:\t3.394880\n",
      "Done 2320 batches in 312.42s\ttraining loss:\t3.394985\n",
      "Done 2330 batches in 313.72s\ttraining loss:\t3.394817\n",
      "Done 2340 batches in 315.33s\ttraining loss:\t3.394764\n",
      "Done 2350 batches in 316.60s\ttraining loss:\t3.394721\n",
      "Done 2360 batches in 317.91s\ttraining loss:\t3.394705\n",
      "Done 2370 batches in 319.19s\ttraining loss:\t3.394624\n",
      "Done 2380 batches in 320.47s\ttraining loss:\t3.394605\n",
      "Done 2390 batches in 322.05s\ttraining loss:\t3.394455\n",
      "Done 2400 batches in 323.35s\ttraining loss:\t3.394376\n",
      "Done 2410 batches in 324.80s\ttraining loss:\t3.394348\n",
      "Done 2420 batches in 325.99s\ttraining loss:\t3.394165\n",
      "Done 2430 batches in 327.08s\ttraining loss:\t3.393960\n",
      "Done 2440 batches in 328.59s\ttraining loss:\t3.394067\n",
      "Done 2450 batches in 329.87s\ttraining loss:\t3.393981\n",
      "Done 2460 batches in 331.13s\ttraining loss:\t3.393801\n",
      "Done 2470 batches in 332.50s\ttraining loss:\t3.393707\n",
      "Done 2480 batches in 334.19s\ttraining loss:\t3.393700\n",
      "Done 2490 batches in 335.62s\ttraining loss:\t3.393799\n",
      "Done 2500 batches in 336.78s\ttraining loss:\t3.393789\n",
      "Done 2510 batches in 337.90s\ttraining loss:\t3.393907\n",
      "Done 2520 batches in 339.21s\ttraining loss:\t3.393894\n",
      "Done 2530 batches in 340.75s\ttraining loss:\t3.393851\n",
      "Done 2540 batches in 341.84s\ttraining loss:\t3.393721\n",
      "Done 2550 batches in 343.24s\ttraining loss:\t3.393809\n",
      "Done 2560 batches in 344.62s\ttraining loss:\t3.393663\n",
      "Done 2570 batches in 346.14s\ttraining loss:\t3.393702\n",
      "Done 2580 batches in 347.50s\ttraining loss:\t3.393559\n",
      "Done 2590 batches in 348.65s\ttraining loss:\t3.393554\n",
      "Done 2600 batches in 350.23s\ttraining loss:\t3.393373\n",
      "Done 2610 batches in 351.26s\ttraining loss:\t3.393525\n",
      "Done 2620 batches in 352.85s\ttraining loss:\t3.393530\n",
      "Done 2630 batches in 354.22s\ttraining loss:\t3.393455\n",
      "Done 2640 batches in 355.51s\ttraining loss:\t3.393428\n",
      "Done 2650 batches in 356.90s\ttraining loss:\t3.393439\n",
      "Done 2660 batches in 358.27s\ttraining loss:\t3.393498\n",
      "Done 2670 batches in 359.71s\ttraining loss:\t3.393543\n",
      "Done 2680 batches in 361.17s\ttraining loss:\t3.393592\n",
      "Done 2690 batches in 362.42s\ttraining loss:\t3.393757\n",
      "Done 2700 batches in 363.70s\ttraining loss:\t3.393753\n",
      "Done 2710 batches in 365.24s\ttraining loss:\t3.393879\n",
      "Done 2720 batches in 366.32s\ttraining loss:\t3.393915\n",
      "Done 2730 batches in 367.50s\ttraining loss:\t3.393800\n",
      "Done 2740 batches in 368.62s\ttraining loss:\t3.393700\n",
      "Done 2750 batches in 370.05s\ttraining loss:\t3.393688\n",
      "Done 2760 batches in 371.42s\ttraining loss:\t3.393641\n",
      "Done 2770 batches in 372.81s\ttraining loss:\t3.393726\n",
      "Done 2780 batches in 374.35s\ttraining loss:\t3.393723\n",
      "Done 2790 batches in 375.71s\ttraining loss:\t3.393631\n",
      "Done 2800 batches in 376.90s\ttraining loss:\t3.393716\n",
      "Done 2810 batches in 378.34s\ttraining loss:\t3.393755\n",
      "Done 2820 batches in 379.48s\ttraining loss:\t3.393688\n",
      "Done 2830 batches in 380.68s\ttraining loss:\t3.393546\n",
      "Done 2840 batches in 382.05s\ttraining loss:\t3.393583\n",
      "Done 2850 batches in 383.67s\ttraining loss:\t3.393426\n",
      "Done 2860 batches in 384.96s\ttraining loss:\t3.393448\n",
      "Done 2870 batches in 386.13s\ttraining loss:\t3.393366\n",
      "Done 2880 batches in 387.34s\ttraining loss:\t3.393271\n",
      "Done 2890 batches in 388.76s\ttraining loss:\t3.393213\n",
      "Done 2900 batches in 390.10s\ttraining loss:\t3.393326\n",
      "Done 2910 batches in 391.42s\ttraining loss:\t3.393438\n",
      "Done 2920 batches in 392.64s\ttraining loss:\t3.393365\n",
      "Done 2930 batches in 393.97s\ttraining loss:\t3.393329\n",
      "Done 2940 batches in 395.29s\ttraining loss:\t3.393260\n",
      "Done 2950 batches in 396.58s\ttraining loss:\t3.393176\n",
      "Done 2960 batches in 398.02s\ttraining loss:\t3.393173\n",
      "Done 2970 batches in 399.45s\ttraining loss:\t3.393129\n",
      "Done 2980 batches in 400.56s\ttraining loss:\t3.393072\n",
      "Done 2990 batches in 401.58s\ttraining loss:\t3.392921\n",
      "Done 3000 batches in 402.90s\ttraining loss:\t3.392883\n",
      "Done 3010 batches in 404.20s\ttraining loss:\t3.392871\n",
      "Done 3020 batches in 405.29s\ttraining loss:\t3.392791\n",
      "Done 3030 batches in 406.79s\ttraining loss:\t3.392816\n",
      "Done 3040 batches in 408.08s\ttraining loss:\t3.392818\n",
      "Done 3050 batches in 409.66s\ttraining loss:\t3.392798\n",
      "Done 3060 batches in 410.64s\ttraining loss:\t3.392782\n",
      "Done 3070 batches in 411.82s\ttraining loss:\t3.392780\n",
      "Done 3080 batches in 412.95s\ttraining loss:\t3.392523\n",
      "Done 3090 batches in 414.44s\ttraining loss:\t3.392582\n",
      "Done 3100 batches in 415.72s\ttraining loss:\t3.392467\n",
      "Done 3110 batches in 417.46s\ttraining loss:\t3.392487\n",
      "Done 3120 batches in 418.75s\ttraining loss:\t3.392592\n",
      "Done 3130 batches in 419.99s\ttraining loss:\t3.392504\n",
      "Done 3140 batches in 421.28s\ttraining loss:\t3.392478\n",
      "Done 3150 batches in 422.54s\ttraining loss:\t3.392428\n",
      "Done 3160 batches in 423.69s\ttraining loss:\t3.392416\n",
      "Done 3170 batches in 425.12s\ttraining loss:\t3.392417\n",
      "Done 3180 batches in 426.21s\ttraining loss:\t3.392364\n",
      "Done 3190 batches in 427.47s\ttraining loss:\t3.392346\n",
      "Done 3200 batches in 428.87s\ttraining loss:\t3.392362\n",
      "Done 3210 batches in 430.32s\ttraining loss:\t3.392393\n",
      "Done 3220 batches in 431.54s\ttraining loss:\t3.392187\n",
      "Done 3230 batches in 432.83s\ttraining loss:\t3.392101\n",
      "Done 3240 batches in 434.19s\ttraining loss:\t3.392048\n",
      "Done 3250 batches in 435.38s\ttraining loss:\t3.392079\n",
      "Done 3260 batches in 436.76s\ttraining loss:\t3.392012\n",
      "Done 3270 batches in 438.04s\ttraining loss:\t3.392015\n",
      "Done 3280 batches in 439.53s\ttraining loss:\t3.392051\n",
      "Done 3290 batches in 440.71s\ttraining loss:\t3.392098\n",
      "Done 3300 batches in 441.89s\ttraining loss:\t3.392122\n",
      "Done 3310 batches in 443.23s\ttraining loss:\t3.392060\n",
      "Done 3320 batches in 444.50s\ttraining loss:\t3.391950\n",
      "Done 3330 batches in 445.96s\ttraining loss:\t3.391905\n",
      "Done 3340 batches in 447.20s\ttraining loss:\t3.391880\n",
      "Done 3350 batches in 448.46s\ttraining loss:\t3.391860\n",
      "Done 3360 batches in 450.05s\ttraining loss:\t3.391823\n",
      "Done 3370 batches in 451.51s\ttraining loss:\t3.391749\n",
      "Done 3380 batches in 453.00s\ttraining loss:\t3.391752\n",
      "Done 3390 batches in 454.58s\ttraining loss:\t3.391771\n",
      "Done 3400 batches in 455.76s\ttraining loss:\t3.391624\n",
      "Done 3410 batches in 457.31s\ttraining loss:\t3.391746\n",
      "Done 3420 batches in 458.51s\ttraining loss:\t3.391628\n",
      "Done 3430 batches in 459.79s\ttraining loss:\t3.391499\n",
      "Done 3440 batches in 461.15s\ttraining loss:\t3.391436\n",
      "Done 3450 batches in 462.30s\ttraining loss:\t3.391352\n",
      "Done 3460 batches in 463.57s\ttraining loss:\t3.391437\n",
      "Done 3470 batches in 464.87s\ttraining loss:\t3.391503\n",
      "Done 3480 batches in 466.45s\ttraining loss:\t3.391490\n",
      "Done 3490 batches in 467.84s\ttraining loss:\t3.391393\n",
      "Done 3500 batches in 469.01s\ttraining loss:\t3.391304\n",
      "Done 3510 batches in 470.43s\ttraining loss:\t3.391264\n",
      "Done 3520 batches in 471.87s\ttraining loss:\t3.391213\n",
      "Done 3530 batches in 473.23s\ttraining loss:\t3.391205\n",
      "Done 3540 batches in 474.83s\ttraining loss:\t3.391171\n",
      "Done 3550 batches in 476.22s\ttraining loss:\t3.391193\n",
      "Done 3560 batches in 477.41s\ttraining loss:\t3.391212\n",
      "Done 3570 batches in 478.96s\ttraining loss:\t3.391256\n",
      "Done 3580 batches in 480.70s\ttraining loss:\t3.391203\n",
      "Done 3590 batches in 482.14s\ttraining loss:\t3.391189\n",
      "Done 3600 batches in 483.46s\ttraining loss:\t3.391124\n",
      "Done 3610 batches in 484.89s\ttraining loss:\t3.391175\n",
      "Done 3620 batches in 486.25s\ttraining loss:\t3.391094\n",
      "Done 3630 batches in 487.72s\ttraining loss:\t3.391052\n",
      "Done 3640 batches in 489.39s\ttraining loss:\t3.391083\n",
      "Done 3650 batches in 490.57s\ttraining loss:\t3.391051\n",
      "Done 3660 batches in 491.78s\ttraining loss:\t3.390947\n",
      "Done 3670 batches in 493.15s\ttraining loss:\t3.390953\n",
      "Done 3680 batches in 494.27s\ttraining loss:\t3.390841\n",
      "Done 3690 batches in 495.88s\ttraining loss:\t3.390974\n",
      "Done 3700 batches in 496.88s\ttraining loss:\t3.390826\n",
      "Done 3710 batches in 498.35s\ttraining loss:\t3.390824\n",
      "Done 3720 batches in 499.70s\ttraining loss:\t3.390798\n",
      "Done 3730 batches in 501.04s\ttraining loss:\t3.390748\n",
      "Done 3740 batches in 502.34s\ttraining loss:\t3.390753\n",
      "Done 3750 batches in 503.73s\ttraining loss:\t3.390656\n",
      "Done 3760 batches in 505.20s\ttraining loss:\t3.390675\n",
      "Done 3770 batches in 506.68s\ttraining loss:\t3.390711\n",
      "Done 3780 batches in 508.05s\ttraining loss:\t3.390599\n",
      "Done 3790 batches in 509.45s\ttraining loss:\t3.390575\n",
      "Done 3800 batches in 510.83s\ttraining loss:\t3.390591\n",
      "Done 3810 batches in 511.96s\ttraining loss:\t3.390526\n",
      "Done 3820 batches in 513.30s\ttraining loss:\t3.390511\n",
      "Done 3830 batches in 514.90s\ttraining loss:\t3.390545\n",
      "Done 3840 batches in 516.55s\ttraining loss:\t3.390518\n",
      "Done 3850 batches in 517.69s\ttraining loss:\t3.390406\n",
      "Done 3860 batches in 519.07s\ttraining loss:\t3.390404\n",
      "Done 3870 batches in 520.26s\ttraining loss:\t3.390308\n",
      "Done 3880 batches in 521.55s\ttraining loss:\t3.390271\n",
      "Done 3890 batches in 522.92s\ttraining loss:\t3.390249\n",
      "Done 3900 batches in 524.48s\ttraining loss:\t3.390334\n",
      "Done 3910 batches in 525.74s\ttraining loss:\t3.390321\n",
      "Done 3920 batches in 526.86s\ttraining loss:\t3.390172\n",
      "Done 3930 batches in 528.08s\ttraining loss:\t3.390156\n",
      "Done 3940 batches in 529.53s\ttraining loss:\t3.390188\n",
      "Done 3950 batches in 530.94s\ttraining loss:\t3.390212\n",
      "Done 3960 batches in 532.24s\ttraining loss:\t3.390177\n",
      "Done 3970 batches in 533.57s\ttraining loss:\t3.390166\n",
      "Done 3980 batches in 535.11s\ttraining loss:\t3.390251\n",
      "Done 3990 batches in 536.15s\ttraining loss:\t3.390283\n",
      "Done 4000 batches in 537.37s\ttraining loss:\t3.390236\n",
      "Done 4010 batches in 538.68s\ttraining loss:\t3.390238\n",
      "Done 4020 batches in 539.96s\ttraining loss:\t3.390112\n",
      "Done 4030 batches in 541.09s\ttraining loss:\t3.390015\n",
      "Done 4040 batches in 542.32s\ttraining loss:\t3.389992\n",
      "Done 4050 batches in 543.83s\ttraining loss:\t3.389900\n",
      "Done 4060 batches in 545.17s\ttraining loss:\t3.389852\n",
      "Done 4070 batches in 546.48s\ttraining loss:\t3.389766\n",
      "Done 4080 batches in 548.17s\ttraining loss:\t3.389801\n",
      "Done 4090 batches in 549.68s\ttraining loss:\t3.389741\n",
      "Done 4100 batches in 551.22s\ttraining loss:\t3.389724\n",
      "Done 4110 batches in 552.61s\ttraining loss:\t3.389731\n",
      "Done 4120 batches in 553.80s\ttraining loss:\t3.389623\n",
      "Done 4130 batches in 555.24s\ttraining loss:\t3.389523\n",
      "Done 4140 batches in 556.73s\ttraining loss:\t3.389503\n",
      "Done 4150 batches in 558.22s\ttraining loss:\t3.389499\n",
      "Done 4160 batches in 559.60s\ttraining loss:\t3.389552\n",
      "Done 4170 batches in 561.06s\ttraining loss:\t3.389558\n",
      "Done 4180 batches in 562.57s\ttraining loss:\t3.389536\n",
      "Done 4190 batches in 563.89s\ttraining loss:\t3.389451\n",
      "Done 4200 batches in 565.15s\ttraining loss:\t3.389399\n",
      "Done 4210 batches in 566.44s\ttraining loss:\t3.389339\n",
      "Done 4220 batches in 567.79s\ttraining loss:\t3.389284\n",
      "Done 4230 batches in 568.99s\ttraining loss:\t3.389187\n",
      "Done 4240 batches in 570.34s\ttraining loss:\t3.389247\n",
      "Done 4250 batches in 571.70s\ttraining loss:\t3.389160\n",
      "Done 4260 batches in 573.19s\ttraining loss:\t3.389067\n",
      "Done 4270 batches in 574.44s\ttraining loss:\t3.389014\n",
      "Done 4280 batches in 575.48s\ttraining loss:\t3.388992\n",
      "Done 4290 batches in 576.85s\ttraining loss:\t3.388951\n",
      "Done 4300 batches in 578.35s\ttraining loss:\t3.388924\n",
      "Done 4310 batches in 579.42s\ttraining loss:\t3.388865\n",
      "Done 4320 batches in 581.18s\ttraining loss:\t3.388852\n",
      "Done 4330 batches in 582.65s\ttraining loss:\t3.388791\n",
      "Done 4340 batches in 583.89s\ttraining loss:\t3.388772\n",
      "Done 4350 batches in 585.37s\ttraining loss:\t3.388777\n",
      "Done 4360 batches in 586.58s\ttraining loss:\t3.388783\n",
      "Done 4370 batches in 588.28s\ttraining loss:\t3.388741\n",
      "Done 4380 batches in 589.70s\ttraining loss:\t3.388687\n",
      "Done 4390 batches in 591.11s\ttraining loss:\t3.388600\n",
      "Done 4400 batches in 592.48s\ttraining loss:\t3.388525\n",
      "Done 4410 batches in 593.96s\ttraining loss:\t3.388609\n",
      "Done 4420 batches in 595.06s\ttraining loss:\t3.388612\n",
      "Done 4430 batches in 596.44s\ttraining loss:\t3.388577\n",
      "Done 4440 batches in 597.65s\ttraining loss:\t3.388607\n",
      "Done 4450 batches in 598.93s\ttraining loss:\t3.388585\n",
      "Done 4460 batches in 600.37s\ttraining loss:\t3.388547\n",
      "Done 4470 batches in 601.92s\ttraining loss:\t3.388608\n",
      "Done 4480 batches in 603.18s\ttraining loss:\t3.388624\n",
      "Done 4490 batches in 604.71s\ttraining loss:\t3.388548\n",
      "Done 4500 batches in 605.92s\ttraining loss:\t3.388515\n",
      "Done 4510 batches in 607.18s\ttraining loss:\t3.388490\n",
      "Done 4520 batches in 608.70s\ttraining loss:\t3.388493\n",
      "Done 4530 batches in 610.08s\ttraining loss:\t3.388413\n",
      "Done 4540 batches in 611.58s\ttraining loss:\t3.388407\n",
      "Done 4550 batches in 613.03s\ttraining loss:\t3.388409\n",
      "Done 4560 batches in 614.54s\ttraining loss:\t3.388365\n",
      "Done 4570 batches in 615.90s\ttraining loss:\t3.388325\n",
      "Done 4580 batches in 617.18s\ttraining loss:\t3.388275\n",
      "Done 4590 batches in 618.58s\ttraining loss:\t3.388245\n",
      "Done 4600 batches in 620.09s\ttraining loss:\t3.388275\n",
      "Done 4610 batches in 621.47s\ttraining loss:\t3.388296\n",
      "Done 4620 batches in 622.90s\ttraining loss:\t3.388351\n",
      "Done 4630 batches in 624.07s\ttraining loss:\t3.388283\n",
      "Done 4640 batches in 625.29s\ttraining loss:\t3.388235\n",
      "Done 4650 batches in 626.56s\ttraining loss:\t3.388199\n",
      "Done 4660 batches in 627.75s\ttraining loss:\t3.388190\n",
      "Done 4670 batches in 629.09s\ttraining loss:\t3.388110\n",
      "Done 4680 batches in 630.31s\ttraining loss:\t3.388166\n",
      "Done 4690 batches in 631.89s\ttraining loss:\t3.388168\n",
      "Done 4700 batches in 633.24s\ttraining loss:\t3.388149\n",
      "Done 4710 batches in 634.31s\ttraining loss:\t3.388057\n",
      "Done 4720 batches in 635.74s\ttraining loss:\t3.388068\n",
      "Done 4730 batches in 637.35s\ttraining loss:\t3.388167\n",
      "Done 4740 batches in 638.65s\ttraining loss:\t3.388148\n",
      "Done 4750 batches in 639.85s\ttraining loss:\t3.388140\n",
      "Done 4760 batches in 641.39s\ttraining loss:\t3.388073\n",
      "Done 4770 batches in 642.69s\ttraining loss:\t3.388047\n",
      "Done 4780 batches in 643.95s\ttraining loss:\t3.387936\n",
      "Done 4790 batches in 645.23s\ttraining loss:\t3.387901\n",
      "Done 4800 batches in 646.84s\ttraining loss:\t3.387940\n",
      "Done 4810 batches in 648.01s\ttraining loss:\t3.387873\n",
      "Done 4820 batches in 649.48s\ttraining loss:\t3.387807\n",
      "Done 4830 batches in 650.89s\ttraining loss:\t3.387772\n",
      "Done 4840 batches in 652.00s\ttraining loss:\t3.387796\n",
      "Done 4850 batches in 653.21s\ttraining loss:\t3.387757\n",
      "Done 4860 batches in 654.72s\ttraining loss:\t3.387763\n",
      "Done 4870 batches in 656.10s\ttraining loss:\t3.387653\n",
      "Done 4880 batches in 657.45s\ttraining loss:\t3.387692\n",
      "Done 4890 batches in 658.91s\ttraining loss:\t3.387677\n",
      "Done 4900 batches in 660.20s\ttraining loss:\t3.387569\n",
      "Done 4910 batches in 661.40s\ttraining loss:\t3.387539\n",
      "Done 4920 batches in 662.87s\ttraining loss:\t3.387521\n",
      "Done 4930 batches in 664.19s\ttraining loss:\t3.387533\n",
      "Done 4940 batches in 665.59s\ttraining loss:\t3.387562\n",
      "Done 4950 batches in 667.11s\ttraining loss:\t3.387560\n",
      "Done 4960 batches in 668.71s\ttraining loss:\t3.387561\n",
      "Done 4970 batches in 669.97s\ttraining loss:\t3.387417\n",
      "Done 4980 batches in 671.27s\ttraining loss:\t3.387374\n",
      "Done 4990 batches in 672.74s\ttraining loss:\t3.387385\n",
      "Done 5000 batches in 674.24s\ttraining loss:\t3.387409\n",
      "Done 5010 batches in 675.61s\ttraining loss:\t3.387314\n",
      "Done 5020 batches in 677.06s\ttraining loss:\t3.387287\n",
      "Done 5030 batches in 678.48s\ttraining loss:\t3.387203\n",
      "Done 5040 batches in 679.70s\ttraining loss:\t3.387099\n",
      "Done 5050 batches in 680.86s\ttraining loss:\t3.387122\n",
      "Done 5060 batches in 682.12s\ttraining loss:\t3.387106\n",
      "Done 5070 batches in 683.71s\ttraining loss:\t3.387079\n",
      "Done 5080 batches in 685.16s\ttraining loss:\t3.387081\n",
      "Done 5090 batches in 686.58s\ttraining loss:\t3.387062\n",
      "Done 5100 batches in 688.00s\ttraining loss:\t3.387034\n",
      "Done 5110 batches in 689.24s\ttraining loss:\t3.386953\n",
      "Done 5120 batches in 690.87s\ttraining loss:\t3.386986\n",
      "Done 5130 batches in 692.09s\ttraining loss:\t3.386953\n",
      "Done 5140 batches in 693.59s\ttraining loss:\t3.386865\n",
      "Done 5150 batches in 694.96s\ttraining loss:\t3.386837\n",
      "Done 5160 batches in 696.85s\ttraining loss:\t3.386820\n",
      "Done 5170 batches in 698.09s\ttraining loss:\t3.386787\n",
      "Done 5180 batches in 699.30s\ttraining loss:\t3.386755\n",
      "Done 5190 batches in 700.71s\ttraining loss:\t3.386718\n",
      "Done 5200 batches in 702.32s\ttraining loss:\t3.386700\n",
      "Done 5210 batches in 703.82s\ttraining loss:\t3.386642\n",
      "Done 5220 batches in 705.30s\ttraining loss:\t3.386605\n",
      "Done 5230 batches in 706.61s\ttraining loss:\t3.386633\n",
      "Done 5240 batches in 707.96s\ttraining loss:\t3.386579\n",
      "Done 5250 batches in 709.37s\ttraining loss:\t3.386575\n",
      "Done 5260 batches in 710.71s\ttraining loss:\t3.386553\n",
      "Done 5270 batches in 712.32s\ttraining loss:\t3.386643\n",
      "Done 5280 batches in 713.53s\ttraining loss:\t3.386610\n",
      "Done 5290 batches in 714.98s\ttraining loss:\t3.386660\n",
      "Done 5300 batches in 716.34s\ttraining loss:\t3.386660\n",
      "Done 5310 batches in 717.53s\ttraining loss:\t3.386668\n",
      "Done 5320 batches in 719.04s\ttraining loss:\t3.386680\n",
      "Done 5330 batches in 720.47s\ttraining loss:\t3.386635\n",
      "Done 5340 batches in 721.61s\ttraining loss:\t3.386636\n",
      "Done 5350 batches in 722.85s\ttraining loss:\t3.386622\n",
      "Done 5360 batches in 724.32s\ttraining loss:\t3.386615\n",
      "Done 5370 batches in 725.81s\ttraining loss:\t3.386673\n",
      "Done 5380 batches in 727.22s\ttraining loss:\t3.386686\n",
      "Done 5390 batches in 728.44s\ttraining loss:\t3.386699\n",
      "Done 5400 batches in 729.81s\ttraining loss:\t3.386712\n",
      "Done 5410 batches in 731.18s\ttraining loss:\t3.386718\n",
      "Done 5420 batches in 732.67s\ttraining loss:\t3.386682\n",
      "Done 5430 batches in 733.84s\ttraining loss:\t3.386663\n",
      "Done 5440 batches in 735.17s\ttraining loss:\t3.386616\n",
      "Done 5450 batches in 736.58s\ttraining loss:\t3.386603\n",
      "Done 5460 batches in 737.92s\ttraining loss:\t3.386641\n",
      "Done 5470 batches in 739.30s\ttraining loss:\t3.386561\n",
      "Done 5480 batches in 740.91s\ttraining loss:\t3.386513\n",
      "Done 5490 batches in 742.24s\ttraining loss:\t3.386519\n",
      "Done 5500 batches in 743.70s\ttraining loss:\t3.386513\n",
      "Done 5510 batches in 745.24s\ttraining loss:\t3.386529\n",
      "Done 5520 batches in 746.49s\ttraining loss:\t3.386536\n",
      "Done 5530 batches in 747.88s\ttraining loss:\t3.386536\n",
      "Done 5540 batches in 749.23s\ttraining loss:\t3.386509\n",
      "Done 5550 batches in 751.00s\ttraining loss:\t3.386499\n",
      "Done 5560 batches in 752.47s\ttraining loss:\t3.386580\n",
      "Done 5570 batches in 753.76s\ttraining loss:\t3.386561\n",
      "Done 5580 batches in 755.22s\ttraining loss:\t3.386551\n",
      "Done 5590 batches in 756.47s\ttraining loss:\t3.386533\n",
      "Done 5600 batches in 757.58s\ttraining loss:\t3.386490\n",
      "Done 5610 batches in 758.70s\ttraining loss:\t3.386483\n",
      "Done 5620 batches in 760.21s\ttraining loss:\t3.386440\n",
      "Done 5630 batches in 761.56s\ttraining loss:\t3.386486\n",
      "Done 5640 batches in 762.73s\ttraining loss:\t3.386498\n",
      "Done 5650 batches in 764.08s\ttraining loss:\t3.386442\n",
      "Done 5660 batches in 765.50s\ttraining loss:\t3.386422\n",
      "Done 5670 batches in 766.92s\ttraining loss:\t3.386410\n",
      "Done 5680 batches in 768.09s\ttraining loss:\t3.386454\n",
      "Done 5690 batches in 769.32s\ttraining loss:\t3.386432\n",
      "Done 5700 batches in 770.95s\ttraining loss:\t3.386436\n",
      "Done 5710 batches in 772.16s\ttraining loss:\t3.386464\n",
      "Done 5720 batches in 773.77s\ttraining loss:\t3.386456\n",
      "Done 5730 batches in 775.23s\ttraining loss:\t3.386399\n",
      "Done 5740 batches in 776.47s\ttraining loss:\t3.386422\n",
      "Done 5750 batches in 777.96s\ttraining loss:\t3.386385\n",
      "Done 5760 batches in 779.14s\ttraining loss:\t3.386356\n",
      "Done 5770 batches in 780.58s\ttraining loss:\t3.386289\n",
      "Done 5780 batches in 781.78s\ttraining loss:\t3.386254\n",
      "Done 5790 batches in 783.22s\ttraining loss:\t3.386224\n",
      "Done 5800 batches in 784.33s\ttraining loss:\t3.386221\n",
      "Done 5810 batches in 785.90s\ttraining loss:\t3.386250\n",
      "Done 5820 batches in 787.33s\ttraining loss:\t3.386238\n",
      "Done 5830 batches in 788.89s\ttraining loss:\t3.386136\n",
      "Done 5840 batches in 790.41s\ttraining loss:\t3.386104\n",
      "Done 5850 batches in 791.99s\ttraining loss:\t3.386100\n",
      "Done 5860 batches in 793.32s\ttraining loss:\t3.386124\n",
      "Done 5870 batches in 794.46s\ttraining loss:\t3.386066\n",
      "Done 5880 batches in 795.71s\ttraining loss:\t3.386032\n",
      "Done 5890 batches in 797.32s\ttraining loss:\t3.386013\n",
      "Done 5900 batches in 798.81s\ttraining loss:\t3.385984\n",
      "Done 5910 batches in 800.28s\ttraining loss:\t3.385924\n",
      "Done 5920 batches in 801.73s\ttraining loss:\t3.385953\n",
      "Done 5930 batches in 802.89s\ttraining loss:\t3.385965\n",
      "Done 5940 batches in 803.98s\ttraining loss:\t3.385873\n",
      "Done 5950 batches in 805.18s\ttraining loss:\t3.385840\n",
      "Done 5960 batches in 806.35s\ttraining loss:\t3.385787\n",
      "Done 5970 batches in 807.81s\ttraining loss:\t3.385751\n",
      "Done 5980 batches in 809.24s\ttraining loss:\t3.385740\n",
      "Done 5990 batches in 810.43s\ttraining loss:\t3.385793\n",
      "Done 6000 batches in 811.80s\ttraining loss:\t3.385801\n",
      "Done 6010 batches in 813.17s\ttraining loss:\t3.385751\n",
      "Done 6020 batches in 814.43s\ttraining loss:\t3.385769\n",
      "Done 6030 batches in 815.90s\ttraining loss:\t3.385684\n",
      "Done 6040 batches in 817.23s\ttraining loss:\t3.385643\n",
      "Done 6050 batches in 818.88s\ttraining loss:\t3.385659\n",
      "Done 6060 batches in 820.25s\ttraining loss:\t3.385600\n",
      "Done 6070 batches in 821.67s\ttraining loss:\t3.385523\n",
      "Done 6080 batches in 822.83s\ttraining loss:\t3.385480\n",
      "Done 6090 batches in 824.19s\ttraining loss:\t3.385422\n",
      "Done 6100 batches in 825.68s\ttraining loss:\t3.385358\n",
      "Done 6110 batches in 826.99s\ttraining loss:\t3.385308\n",
      "Done 6120 batches in 828.24s\ttraining loss:\t3.385277\n",
      "Done 6130 batches in 829.48s\ttraining loss:\t3.385244\n",
      "Done 6140 batches in 831.12s\ttraining loss:\t3.385253\n",
      "Done 6150 batches in 832.25s\ttraining loss:\t3.385222\n",
      "Done 6160 batches in 833.73s\ttraining loss:\t3.385211\n",
      "Done 6170 batches in 835.07s\ttraining loss:\t3.385183\n",
      "Done 6180 batches in 836.23s\ttraining loss:\t3.385102\n",
      "Done 6190 batches in 837.64s\ttraining loss:\t3.385137\n",
      "Done 6200 batches in 838.99s\ttraining loss:\t3.385155\n",
      "Done 6210 batches in 840.18s\ttraining loss:\t3.385147\n",
      "Done 6220 batches in 841.42s\ttraining loss:\t3.385129\n",
      "Done 6230 batches in 842.61s\ttraining loss:\t3.385082\n",
      "Done 6240 batches in 844.00s\ttraining loss:\t3.385107\n",
      "Done 6250 batches in 845.20s\ttraining loss:\t3.384972\n",
      "Done 6260 batches in 846.35s\ttraining loss:\t3.384954\n",
      "Done 6270 batches in 847.86s\ttraining loss:\t3.384937\n",
      "Done 6280 batches in 849.43s\ttraining loss:\t3.384872\n",
      "Done 6290 batches in 850.53s\ttraining loss:\t3.384865\n",
      "Done 6300 batches in 851.88s\ttraining loss:\t3.384839\n",
      "Done 6310 batches in 853.25s\ttraining loss:\t3.384833\n",
      "Done 6320 batches in 854.46s\ttraining loss:\t3.384799\n",
      "Done 6330 batches in 855.75s\ttraining loss:\t3.384770\n",
      "Done 6340 batches in 857.28s\ttraining loss:\t3.384716\n",
      "Done 6350 batches in 858.29s\ttraining loss:\t3.384591\n",
      "Done 6360 batches in 859.52s\ttraining loss:\t3.384615\n",
      "Done 6370 batches in 860.69s\ttraining loss:\t3.384609\n",
      "Done 6380 batches in 862.03s\ttraining loss:\t3.384583\n",
      "Done 6390 batches in 863.40s\ttraining loss:\t3.384574\n",
      "Done 6400 batches in 864.50s\ttraining loss:\t3.384532\n",
      "Done 6410 batches in 865.57s\ttraining loss:\t3.384508\n",
      "Done 6420 batches in 866.74s\ttraining loss:\t3.384460\n",
      "Done 6430 batches in 868.04s\ttraining loss:\t3.384423\n",
      "Done 6440 batches in 869.52s\ttraining loss:\t3.384397\n",
      "Done 6450 batches in 870.94s\ttraining loss:\t3.384322\n",
      "Done 6460 batches in 871.98s\ttraining loss:\t3.384279\n",
      "Done 6470 batches in 873.33s\ttraining loss:\t3.384224\n",
      "Done 6480 batches in 874.70s\ttraining loss:\t3.384191\n",
      "Done 6490 batches in 875.80s\ttraining loss:\t3.384148\n",
      "Done 6500 batches in 876.94s\ttraining loss:\t3.384136\n",
      "Done 6510 batches in 878.42s\ttraining loss:\t3.384116\n",
      "Done 6520 batches in 879.76s\ttraining loss:\t3.384072\n",
      "Done 6530 batches in 881.01s\ttraining loss:\t3.384058\n",
      "Done 6540 batches in 882.46s\ttraining loss:\t3.384011\n",
      "Done 6550 batches in 884.13s\ttraining loss:\t3.384015\n",
      "Done 6560 batches in 885.45s\ttraining loss:\t3.383961\n",
      "Done 6570 batches in 886.71s\ttraining loss:\t3.384014\n",
      "Done 6580 batches in 887.99s\ttraining loss:\t3.383977\n",
      "Done 6590 batches in 889.55s\ttraining loss:\t3.384003\n",
      "Done 6600 batches in 890.69s\ttraining loss:\t3.384015\n",
      "Done 6610 batches in 891.82s\ttraining loss:\t3.384027\n",
      "Done 6620 batches in 893.18s\ttraining loss:\t3.383993\n",
      "Done 6630 batches in 894.77s\ttraining loss:\t3.384014\n",
      "Done 6640 batches in 896.11s\ttraining loss:\t3.383927\n",
      "Done 6650 batches in 897.58s\ttraining loss:\t3.383885\n",
      "Done 6660 batches in 898.89s\ttraining loss:\t3.383871\n",
      "Done 6670 batches in 900.27s\ttraining loss:\t3.383871\n",
      "Done 6680 batches in 901.73s\ttraining loss:\t3.383841\n",
      "Done 6690 batches in 903.44s\ttraining loss:\t3.383849\n",
      "Done 6700 batches in 904.95s\ttraining loss:\t3.383851\n",
      "Done 6710 batches in 905.99s\ttraining loss:\t3.383768\n",
      "Done 6720 batches in 907.38s\ttraining loss:\t3.383775\n",
      "Done 6730 batches in 908.83s\ttraining loss:\t3.383776\n",
      "Done 6740 batches in 910.34s\ttraining loss:\t3.383760\n",
      "Done 6750 batches in 911.72s\ttraining loss:\t3.383725\n",
      "Done 6760 batches in 913.00s\ttraining loss:\t3.383729\n",
      "Done 6770 batches in 914.25s\ttraining loss:\t3.383689\n",
      "Done 6780 batches in 915.73s\ttraining loss:\t3.383661\n",
      "Done 6790 batches in 917.12s\ttraining loss:\t3.383613\n",
      "Done 6800 batches in 918.65s\ttraining loss:\t3.383599\n",
      "Done 6810 batches in 920.02s\ttraining loss:\t3.383564\n",
      "Done 6820 batches in 921.46s\ttraining loss:\t3.383540\n",
      "Done 6830 batches in 922.83s\ttraining loss:\t3.383539\n",
      "Done 6840 batches in 924.16s\ttraining loss:\t3.383544\n",
      "Done 6850 batches in 925.14s\ttraining loss:\t3.383514\n",
      "Done 6860 batches in 926.44s\ttraining loss:\t3.383455\n",
      "Done 6870 batches in 927.78s\ttraining loss:\t3.383449\n",
      "Done 6880 batches in 929.18s\ttraining loss:\t3.383473\n",
      "Done 6890 batches in 930.35s\ttraining loss:\t3.383410\n",
      "Done 6900 batches in 931.74s\ttraining loss:\t3.383391\n",
      "Done 6910 batches in 933.27s\ttraining loss:\t3.383432\n",
      "Done 6920 batches in 934.48s\ttraining loss:\t3.383477\n",
      "Done 6930 batches in 935.98s\ttraining loss:\t3.383412\n",
      "Done 6940 batches in 937.62s\ttraining loss:\t3.383417\n",
      "Done 6950 batches in 939.23s\ttraining loss:\t3.383383\n",
      "Done 6960 batches in 940.82s\ttraining loss:\t3.383410\n",
      "Done 6970 batches in 942.38s\ttraining loss:\t3.383345\n",
      "Done 6980 batches in 943.79s\ttraining loss:\t3.383305\n",
      "Done 6990 batches in 945.11s\ttraining loss:\t3.383301\n",
      "Done 7000 batches in 946.44s\ttraining loss:\t3.383259\n",
      "Done 7010 batches in 947.69s\ttraining loss:\t3.383270\n",
      "Done 7020 batches in 948.90s\ttraining loss:\t3.383268\n",
      "Done 7030 batches in 950.58s\ttraining loss:\t3.383317\n",
      "Done 7040 batches in 951.87s\ttraining loss:\t3.383249\n",
      "Done 7050 batches in 953.42s\ttraining loss:\t3.383209\n",
      "Done 7060 batches in 955.03s\ttraining loss:\t3.383183\n",
      "Done 7070 batches in 956.18s\ttraining loss:\t3.383174\n",
      "Done 7080 batches in 957.54s\ttraining loss:\t3.383120\n",
      "Done 7090 batches in 958.93s\ttraining loss:\t3.383113\n",
      "Done 7100 batches in 960.24s\ttraining loss:\t3.383066\n",
      "Done 7110 batches in 961.52s\ttraining loss:\t3.383043\n",
      "Done 7120 batches in 962.67s\ttraining loss:\t3.383085\n",
      "Done 7130 batches in 964.50s\ttraining loss:\t3.383097\n",
      "Done 7140 batches in 965.81s\ttraining loss:\t3.383117\n",
      "Done 7150 batches in 967.25s\ttraining loss:\t3.383096\n",
      "Done 7160 batches in 968.63s\ttraining loss:\t3.383049\n",
      "Done 7170 batches in 969.72s\ttraining loss:\t3.383046\n",
      "Done 7180 batches in 970.85s\ttraining loss:\t3.383061\n",
      "Done 7190 batches in 972.26s\ttraining loss:\t3.383019\n",
      "Done 7200 batches in 973.78s\ttraining loss:\t3.382972\n",
      "Done 7210 batches in 975.00s\ttraining loss:\t3.382972\n",
      "Done 7220 batches in 976.29s\ttraining loss:\t3.383021\n",
      "Done 7230 batches in 977.89s\ttraining loss:\t3.383112\n",
      "Done 7240 batches in 979.08s\ttraining loss:\t3.383095\n",
      "Done 7250 batches in 980.19s\ttraining loss:\t3.383050\n",
      "Done 7260 batches in 981.55s\ttraining loss:\t3.383026\n",
      "Done 7270 batches in 982.85s\ttraining loss:\t3.383011\n",
      "Done 7280 batches in 984.09s\ttraining loss:\t3.383001\n",
      "Done 7290 batches in 985.55s\ttraining loss:\t3.383018\n",
      "Done 7300 batches in 986.80s\ttraining loss:\t3.383025\n",
      "Done 7310 batches in 988.60s\ttraining loss:\t3.383049\n",
      "Done 7320 batches in 989.71s\ttraining loss:\t3.383062\n",
      "Done 7330 batches in 991.09s\ttraining loss:\t3.383067\n",
      "Done 7340 batches in 992.60s\ttraining loss:\t3.383047\n",
      "Done 7350 batches in 994.21s\ttraining loss:\t3.383056\n",
      "Done 7360 batches in 995.37s\ttraining loss:\t3.383022\n",
      "Done 7370 batches in 997.14s\ttraining loss:\t3.383009\n",
      "Done 7380 batches in 998.39s\ttraining loss:\t3.382977\n",
      "Done 7390 batches in 999.57s\ttraining loss:\t3.383028\n",
      "Done 7400 batches in 1000.83s\ttraining loss:\t3.382995\n",
      "Done 7410 batches in 1002.43s\ttraining loss:\t3.383062\n",
      "Done 7420 batches in 1003.66s\ttraining loss:\t3.383016\n",
      "Done 7430 batches in 1004.94s\ttraining loss:\t3.383034\n",
      "Done 7440 batches in 1006.29s\ttraining loss:\t3.383050\n",
      "Done 7450 batches in 1007.61s\ttraining loss:\t3.383057\n",
      "Done 7460 batches in 1008.79s\ttraining loss:\t3.383004\n",
      "Done 7470 batches in 1010.06s\ttraining loss:\t3.382991\n",
      "Done 7480 batches in 1011.35s\ttraining loss:\t3.382941\n",
      "Done 7490 batches in 1012.74s\ttraining loss:\t3.382924\n",
      "Done 7500 batches in 1013.99s\ttraining loss:\t3.382874\n",
      "Done 7510 batches in 1015.40s\ttraining loss:\t3.382838\n",
      "Done 7520 batches in 1016.77s\ttraining loss:\t3.382812\n",
      "Done 7530 batches in 1018.08s\ttraining loss:\t3.382820\n",
      "Done 7540 batches in 1019.37s\ttraining loss:\t3.382820\n",
      "Done 7550 batches in 1020.93s\ttraining loss:\t3.382813\n",
      "Done 7560 batches in 1022.61s\ttraining loss:\t3.382809\n",
      "Done 7570 batches in 1023.96s\ttraining loss:\t3.382777\n",
      "Done 7580 batches in 1025.24s\ttraining loss:\t3.382744\n",
      "Done 7590 batches in 1026.63s\ttraining loss:\t3.382721\n",
      "Done 7600 batches in 1027.99s\ttraining loss:\t3.382713\n",
      "Done 7610 batches in 1029.41s\ttraining loss:\t3.382672\n",
      "Done 7620 batches in 1030.84s\ttraining loss:\t3.382676\n",
      "Done 7630 batches in 1032.36s\ttraining loss:\t3.382674\n",
      "Done 7640 batches in 1033.75s\ttraining loss:\t3.382633\n",
      "Done 7650 batches in 1035.43s\ttraining loss:\t3.382596\n",
      "Done 7660 batches in 1036.66s\ttraining loss:\t3.382613\n",
      "Done 7670 batches in 1038.06s\ttraining loss:\t3.382606\n",
      "Done 7680 batches in 1039.26s\ttraining loss:\t3.382591\n",
      "Done 7690 batches in 1040.55s\ttraining loss:\t3.382563\n",
      "Done 7700 batches in 1042.16s\ttraining loss:\t3.382614\n",
      "Done 7710 batches in 1043.51s\ttraining loss:\t3.382604\n",
      "Done 7720 batches in 1044.75s\ttraining loss:\t3.382608\n",
      "Done 7730 batches in 1046.03s\ttraining loss:\t3.382595\n",
      "Done 7740 batches in 1047.40s\ttraining loss:\t3.382536\n",
      "Done 7750 batches in 1048.84s\ttraining loss:\t3.382504\n",
      "Done 7760 batches in 1050.10s\ttraining loss:\t3.382433\n",
      "Done 7770 batches in 1051.44s\ttraining loss:\t3.382369\n",
      "Done 7780 batches in 1052.96s\ttraining loss:\t3.382358\n",
      "Done 7790 batches in 1054.52s\ttraining loss:\t3.382417\n",
      "Done 7800 batches in 1055.71s\ttraining loss:\t3.382398\n",
      "Done 7810 batches in 1057.06s\ttraining loss:\t3.382374\n",
      "Done 7820 batches in 1058.62s\ttraining loss:\t3.382375\n",
      "Done 7830 batches in 1059.96s\ttraining loss:\t3.382358\n",
      "Done 7840 batches in 1061.61s\ttraining loss:\t3.382344\n",
      "Done 7850 batches in 1062.95s\ttraining loss:\t3.382302\n",
      "Done 7860 batches in 1064.25s\ttraining loss:\t3.382275\n",
      "Done 7870 batches in 1065.55s\ttraining loss:\t3.382244\n",
      "Done 7880 batches in 1067.02s\ttraining loss:\t3.382269\n",
      "Done 7890 batches in 1068.44s\ttraining loss:\t3.382227\n",
      "Done 7900 batches in 1069.70s\ttraining loss:\t3.382185\n",
      "Done 7910 batches in 1071.32s\ttraining loss:\t3.382128\n",
      "Done 7920 batches in 1072.72s\ttraining loss:\t3.382113\n",
      "Done 7930 batches in 1074.15s\ttraining loss:\t3.382128\n",
      "Done 7940 batches in 1075.30s\ttraining loss:\t3.382117\n",
      "Done 7950 batches in 1076.63s\ttraining loss:\t3.382097\n",
      "Done 7960 batches in 1078.46s\ttraining loss:\t3.382077\n",
      "Done 7970 batches in 1080.05s\ttraining loss:\t3.382072\n",
      "Done 7980 batches in 1081.50s\ttraining loss:\t3.382055\n",
      "Done 7990 batches in 1082.87s\ttraining loss:\t3.382003\n",
      "Done 8000 batches in 1084.18s\ttraining loss:\t3.381997\n",
      "Done 8010 batches in 1085.48s\ttraining loss:\t3.381997\n",
      "Done 8020 batches in 1086.69s\ttraining loss:\t3.381961\n",
      "Done 8030 batches in 1088.05s\ttraining loss:\t3.381923\n",
      "Done 8040 batches in 1089.66s\ttraining loss:\t3.381894\n",
      "Done 8050 batches in 1090.92s\ttraining loss:\t3.381816\n",
      "Done 8060 batches in 1092.24s\ttraining loss:\t3.381811\n",
      "Done 8070 batches in 1093.38s\ttraining loss:\t3.381791\n",
      "Done 8080 batches in 1094.97s\ttraining loss:\t3.381778\n",
      "Done 8090 batches in 1096.42s\ttraining loss:\t3.381777\n",
      "Done 8100 batches in 1097.81s\ttraining loss:\t3.381841\n",
      "Done 8110 batches in 1099.19s\ttraining loss:\t3.381847\n",
      "Done 8120 batches in 1100.65s\ttraining loss:\t3.381786\n",
      "Done 8130 batches in 1102.06s\ttraining loss:\t3.381780\n",
      "Done 8140 batches in 1103.30s\ttraining loss:\t3.381708\n",
      "Done 8150 batches in 1104.82s\ttraining loss:\t3.381727\n",
      "Done 8160 batches in 1106.07s\ttraining loss:\t3.381705\n",
      "Done 8170 batches in 1107.39s\ttraining loss:\t3.381700\n",
      "Done 8180 batches in 1108.53s\ttraining loss:\t3.381688\n",
      "Done 8190 batches in 1109.73s\ttraining loss:\t3.381695\n",
      "Done 8200 batches in 1110.75s\ttraining loss:\t3.381709\n",
      "Done 8210 batches in 1112.26s\ttraining loss:\t3.381744\n",
      "Done 8220 batches in 1113.58s\ttraining loss:\t3.381742\n",
      "Done 8230 batches in 1114.99s\ttraining loss:\t3.381703\n",
      "Done 8240 batches in 1116.44s\ttraining loss:\t3.381708\n",
      "Done 8250 batches in 1117.81s\ttraining loss:\t3.381681\n",
      "Done 8260 batches in 1118.87s\ttraining loss:\t3.381665\n",
      "Done 8270 batches in 1120.09s\ttraining loss:\t3.381612\n",
      "Done 8280 batches in 1121.68s\ttraining loss:\t3.381575\n",
      "Done 8290 batches in 1123.39s\ttraining loss:\t3.381586\n",
      "Done 8300 batches in 1124.90s\ttraining loss:\t3.381557\n",
      "Done 8310 batches in 1126.20s\ttraining loss:\t3.381533\n",
      "Done 8320 batches in 1127.53s\ttraining loss:\t3.381515\n",
      "Done 8330 batches in 1129.06s\ttraining loss:\t3.381568\n",
      "Done 8340 batches in 1130.32s\ttraining loss:\t3.381547\n",
      "Done 8350 batches in 1131.73s\ttraining loss:\t3.381578\n",
      "Done 8360 batches in 1132.98s\ttraining loss:\t3.381569\n",
      "Done 8370 batches in 1134.34s\ttraining loss:\t3.381513\n",
      "Done 8380 batches in 1135.51s\ttraining loss:\t3.381502\n",
      "Done 8390 batches in 1136.75s\ttraining loss:\t3.381484\n",
      "Done 8400 batches in 1138.20s\ttraining loss:\t3.381397\n",
      "Done 8410 batches in 1139.92s\ttraining loss:\t3.381385\n",
      "Done 8420 batches in 1140.98s\ttraining loss:\t3.381376\n",
      "Done 8430 batches in 1142.50s\ttraining loss:\t3.381403\n",
      "Done 8440 batches in 1143.84s\ttraining loss:\t3.381373\n",
      "Done 8450 batches in 1144.93s\ttraining loss:\t3.381325\n",
      "Done 8460 batches in 1146.19s\ttraining loss:\t3.381336\n",
      "Done 8470 batches in 1147.50s\ttraining loss:\t3.381359\n",
      "Done 8480 batches in 1148.69s\ttraining loss:\t3.381371\n",
      "Done 8490 batches in 1149.98s\ttraining loss:\t3.381355\n",
      "Done 8500 batches in 1151.49s\ttraining loss:\t3.381289\n",
      "Done 8510 batches in 1152.73s\ttraining loss:\t3.381247\n",
      "Done 8520 batches in 1154.29s\ttraining loss:\t3.381268\n",
      "Done 8530 batches in 1156.10s\ttraining loss:\t3.381202\n",
      "Done 8540 batches in 1157.35s\ttraining loss:\t3.381206\n",
      "Done 8550 batches in 1158.58s\ttraining loss:\t3.381157\n",
      "Done 8560 batches in 1159.88s\ttraining loss:\t3.381133\n",
      "Done 8570 batches in 1161.58s\ttraining loss:\t3.381100\n",
      "Done 8580 batches in 1163.27s\ttraining loss:\t3.381091\n",
      "Done 8590 batches in 1164.72s\ttraining loss:\t3.381048\n",
      "Done 8600 batches in 1165.92s\ttraining loss:\t3.381031\n",
      "Done 8610 batches in 1167.12s\ttraining loss:\t3.380975\n",
      "Done 8620 batches in 1168.68s\ttraining loss:\t3.380974\n",
      "Done 8630 batches in 1170.05s\ttraining loss:\t3.380916\n",
      "Done 8640 batches in 1171.47s\ttraining loss:\t3.380867\n",
      "Done 8650 batches in 1172.79s\ttraining loss:\t3.380845\n",
      "Done 8660 batches in 1174.20s\ttraining loss:\t3.380808\n",
      "Done 8670 batches in 1175.79s\ttraining loss:\t3.380823\n",
      "Done 8680 batches in 1177.13s\ttraining loss:\t3.380821\n",
      "Done 8690 batches in 1178.38s\ttraining loss:\t3.380768\n",
      "Done 8700 batches in 1179.70s\ttraining loss:\t3.380767\n",
      "Done 8710 batches in 1180.92s\ttraining loss:\t3.380702\n",
      "Done 8720 batches in 1182.52s\ttraining loss:\t3.380685\n",
      "Done 8730 batches in 1183.90s\ttraining loss:\t3.380693\n",
      "Done 8740 batches in 1185.37s\ttraining loss:\t3.380683\n",
      "Done 8750 batches in 1186.72s\ttraining loss:\t3.380604\n",
      "Done 8760 batches in 1188.17s\ttraining loss:\t3.380594\n",
      "Done 8770 batches in 1189.58s\ttraining loss:\t3.380566\n",
      "Done 8780 batches in 1190.71s\ttraining loss:\t3.380527\n",
      "Done 8790 batches in 1192.02s\ttraining loss:\t3.380494\n",
      "Done 8800 batches in 1193.45s\ttraining loss:\t3.380485\n",
      "Done 8810 batches in 1194.87s\ttraining loss:\t3.380443\n",
      "Done 8820 batches in 1196.39s\ttraining loss:\t3.380432\n",
      "Done 8830 batches in 1197.68s\ttraining loss:\t3.380395\n",
      "Done 8840 batches in 1198.76s\ttraining loss:\t3.380406\n",
      "Done 8850 batches in 1200.16s\ttraining loss:\t3.380400\n",
      "Done 8860 batches in 1201.27s\ttraining loss:\t3.380361\n",
      "Done 8870 batches in 1202.90s\ttraining loss:\t3.380316\n",
      "Done 8880 batches in 1204.06s\ttraining loss:\t3.380307\n",
      "Done 8890 batches in 1205.50s\ttraining loss:\t3.380290\n",
      "Done 8900 batches in 1206.83s\ttraining loss:\t3.380238\n",
      "Done 8910 batches in 1208.11s\ttraining loss:\t3.380227\n",
      "Done 8920 batches in 1209.48s\ttraining loss:\t3.380191\n",
      "Done 8930 batches in 1210.94s\ttraining loss:\t3.380244\n",
      "Done 8940 batches in 1212.30s\ttraining loss:\t3.380227\n",
      "Done 8950 batches in 1213.56s\ttraining loss:\t3.380208\n",
      "Done 8960 batches in 1215.06s\ttraining loss:\t3.380220\n",
      "Done 8970 batches in 1216.42s\ttraining loss:\t3.380189\n",
      "Done 8980 batches in 1217.88s\ttraining loss:\t3.380190\n",
      "Done 8990 batches in 1219.12s\ttraining loss:\t3.380204\n",
      "Done 9000 batches in 1220.47s\ttraining loss:\t3.380192\n",
      "Done 9010 batches in 1221.94s\ttraining loss:\t3.380180\n",
      "Done 9020 batches in 1223.36s\ttraining loss:\t3.380115\n",
      "Done 9030 batches in 1224.57s\ttraining loss:\t3.380122\n",
      "Done 9040 batches in 1225.79s\ttraining loss:\t3.380055\n",
      "Done 9050 batches in 1227.31s\ttraining loss:\t3.380023\n",
      "Done 9060 batches in 1228.81s\ttraining loss:\t3.380011\n",
      "Done 9070 batches in 1230.28s\ttraining loss:\t3.379990\n",
      "Done 9080 batches in 1231.70s\ttraining loss:\t3.380012\n",
      "Done 9090 batches in 1232.79s\ttraining loss:\t3.379991\n",
      "Done 9100 batches in 1234.49s\ttraining loss:\t3.380003\n",
      "Done 9110 batches in 1235.79s\ttraining loss:\t3.380002\n",
      "Done 9120 batches in 1237.20s\ttraining loss:\t3.379983\n",
      "Done 9130 batches in 1238.22s\ttraining loss:\t3.379991\n",
      "Done 9140 batches in 1239.64s\ttraining loss:\t3.379948\n",
      "Done 9150 batches in 1240.97s\ttraining loss:\t3.379911\n",
      "Done 9160 batches in 1242.50s\ttraining loss:\t3.379919\n",
      "Done 9170 batches in 1243.91s\ttraining loss:\t3.379865\n",
      "Done 9180 batches in 1245.45s\ttraining loss:\t3.379880\n",
      "Done 9190 batches in 1246.93s\ttraining loss:\t3.379875\n",
      "Done 9200 batches in 1248.22s\ttraining loss:\t3.379802\n",
      "Done 9210 batches in 1249.67s\ttraining loss:\t3.379798\n",
      "Done 9220 batches in 1250.87s\ttraining loss:\t3.379766\n",
      "Done 9230 batches in 1252.25s\ttraining loss:\t3.379724\n",
      "Done 9240 batches in 1253.67s\ttraining loss:\t3.379738\n",
      "Done 9250 batches in 1255.13s\ttraining loss:\t3.379724\n",
      "Done 9260 batches in 1256.65s\ttraining loss:\t3.379698\n",
      "Done 9270 batches in 1257.88s\ttraining loss:\t3.379659\n",
      "Done 9280 batches in 1259.26s\ttraining loss:\t3.379649\n",
      "Done 9290 batches in 1260.52s\ttraining loss:\t3.379625\n",
      "Done 9300 batches in 1261.97s\ttraining loss:\t3.379595\n",
      "Done 9310 batches in 1263.47s\ttraining loss:\t3.379539\n",
      "Done 9320 batches in 1264.75s\ttraining loss:\t3.379526\n",
      "Done 9330 batches in 1266.44s\ttraining loss:\t3.379487\n",
      "Done 9340 batches in 1267.82s\ttraining loss:\t3.379468\n",
      "Done 9350 batches in 1269.22s\ttraining loss:\t3.379450\n",
      "Done 9360 batches in 1270.51s\ttraining loss:\t3.379429\n",
      "Done 9370 batches in 1272.00s\ttraining loss:\t3.379433\n",
      "Done 9380 batches in 1273.39s\ttraining loss:\t3.379472\n",
      "Done 9390 batches in 1274.58s\ttraining loss:\t3.379480\n",
      "Done 9400 batches in 1276.02s\ttraining loss:\t3.379458\n",
      "Done 9410 batches in 1277.46s\ttraining loss:\t3.379466\n",
      "Done 9420 batches in 1278.65s\ttraining loss:\t3.379397\n",
      "Done 9430 batches in 1280.13s\ttraining loss:\t3.379367\n",
      "Done 9440 batches in 1281.64s\ttraining loss:\t3.379381\n",
      "Done 9450 batches in 1283.03s\ttraining loss:\t3.379335\n",
      "Done 9460 batches in 1284.33s\ttraining loss:\t3.379295\n",
      "Done 9470 batches in 1285.49s\ttraining loss:\t3.379293\n",
      "Done 9480 batches in 1286.68s\ttraining loss:\t3.379317\n",
      "Done 9490 batches in 1287.78s\ttraining loss:\t3.379290\n",
      "Done 9500 batches in 1289.12s\ttraining loss:\t3.379251\n",
      "Done 9510 batches in 1290.40s\ttraining loss:\t3.379252\n",
      "Done 9520 batches in 1291.73s\ttraining loss:\t3.379243\n",
      "Done 9530 batches in 1293.01s\ttraining loss:\t3.379253\n",
      "Done 9540 batches in 1294.41s\ttraining loss:\t3.379268\n",
      "Done 9550 batches in 1295.58s\ttraining loss:\t3.379210\n",
      "Done 9560 batches in 1296.86s\ttraining loss:\t3.379206\n",
      "Done 9570 batches in 1298.17s\ttraining loss:\t3.379171\n",
      "Done 9580 batches in 1299.60s\ttraining loss:\t3.379170\n",
      "Done 9590 batches in 1300.88s\ttraining loss:\t3.379178\n",
      "Done 9600 batches in 1302.25s\ttraining loss:\t3.379176\n",
      "Done 9610 batches in 1303.64s\ttraining loss:\t3.379198\n",
      "Done 9620 batches in 1305.19s\ttraining loss:\t3.379184\n",
      "Done 9630 batches in 1306.84s\ttraining loss:\t3.379176\n",
      "Done 9640 batches in 1308.11s\ttraining loss:\t3.379162\n",
      "Done 9650 batches in 1309.54s\ttraining loss:\t3.379158\n",
      "Done 9660 batches in 1310.90s\ttraining loss:\t3.379170\n",
      "Done 9670 batches in 1312.14s\ttraining loss:\t3.379173\n",
      "Done 9680 batches in 1313.68s\ttraining loss:\t3.379175\n",
      "Done 9690 batches in 1314.99s\ttraining loss:\t3.379168\n",
      "Done 9700 batches in 1316.28s\ttraining loss:\t3.379170\n",
      "Done 9710 batches in 1317.51s\ttraining loss:\t3.379161\n",
      "Done 9720 batches in 1318.79s\ttraining loss:\t3.379126\n",
      "Done 9730 batches in 1320.37s\ttraining loss:\t3.379125\n",
      "Done 9740 batches in 1321.76s\ttraining loss:\t3.379105\n",
      "Done 9750 batches in 1323.01s\ttraining loss:\t3.379074\n",
      "Done 9760 batches in 1324.40s\ttraining loss:\t3.379054\n",
      "Done 9770 batches in 1325.77s\ttraining loss:\t3.379081\n",
      "Done 9780 batches in 1327.28s\ttraining loss:\t3.379062\n",
      "Done 9790 batches in 1328.81s\ttraining loss:\t3.379082\n",
      "Done 9800 batches in 1330.04s\ttraining loss:\t3.379051\n",
      "Done 9810 batches in 1331.55s\ttraining loss:\t3.379062\n",
      "Done 9820 batches in 1332.90s\ttraining loss:\t3.379069\n",
      "Done 9830 batches in 1334.40s\ttraining loss:\t3.379043\n",
      "Done 9840 batches in 1335.92s\ttraining loss:\t3.378997\n",
      "Done 9850 batches in 1337.35s\ttraining loss:\t3.378987\n",
      "Done 9860 batches in 1338.81s\ttraining loss:\t3.378935\n",
      "Done 9870 batches in 1339.94s\ttraining loss:\t3.378919\n",
      "Done 9880 batches in 1341.43s\ttraining loss:\t3.378884\n",
      "Done 9890 batches in 1342.91s\ttraining loss:\t3.378850\n",
      "Done 9900 batches in 1344.46s\ttraining loss:\t3.378850\n",
      "Done 9910 batches in 1345.49s\ttraining loss:\t3.378846\n",
      "Done 9920 batches in 1347.18s\ttraining loss:\t3.378820\n",
      "Done 9930 batches in 1348.50s\ttraining loss:\t3.378772\n",
      "Done 9940 batches in 1349.88s\ttraining loss:\t3.378735\n",
      "Done 9950 batches in 1351.23s\ttraining loss:\t3.378696\n",
      "Done 9960 batches in 1352.63s\ttraining loss:\t3.378661\n",
      "Done 9970 batches in 1353.89s\ttraining loss:\t3.378646\n",
      "Done 9980 batches in 1355.44s\ttraining loss:\t3.378639\n",
      "Done 9990 batches in 1356.71s\ttraining loss:\t3.378615\n",
      "Done 10000 batches in 1357.94s\ttraining loss:\t3.378614\n",
      "Done 10010 batches in 1359.15s\ttraining loss:\t3.378598\n",
      "Done 10020 batches in 1360.31s\ttraining loss:\t3.378556\n",
      "Done 10030 batches in 1361.57s\ttraining loss:\t3.378507\n",
      "Done 10040 batches in 1362.96s\ttraining loss:\t3.378490\n",
      "Done 10050 batches in 1364.66s\ttraining loss:\t3.378500\n",
      "Done 10060 batches in 1365.92s\ttraining loss:\t3.378482\n",
      "Done 10070 batches in 1367.28s\ttraining loss:\t3.378474\n",
      "Done 10080 batches in 1368.37s\ttraining loss:\t3.378444\n",
      "Done 10090 batches in 1369.74s\ttraining loss:\t3.378421\n",
      "Done 10100 batches in 1371.05s\ttraining loss:\t3.378477\n",
      "Done 10110 batches in 1372.30s\ttraining loss:\t3.378490\n",
      "Done 10120 batches in 1373.68s\ttraining loss:\t3.378499\n",
      "Done 10130 batches in 1375.14s\ttraining loss:\t3.378501\n",
      "Done 10140 batches in 1376.52s\ttraining loss:\t3.378484\n",
      "Done 10150 batches in 1377.72s\ttraining loss:\t3.378446\n",
      "Done 10160 batches in 1379.25s\ttraining loss:\t3.378451\n",
      "Done 10170 batches in 1380.32s\ttraining loss:\t3.378378\n",
      "Done 10180 batches in 1381.79s\ttraining loss:\t3.378385\n",
      "Done 10190 batches in 1382.98s\ttraining loss:\t3.378339\n",
      "Done 10200 batches in 1384.22s\ttraining loss:\t3.378312\n",
      "Done 10210 batches in 1385.53s\ttraining loss:\t3.378307\n",
      "Done 10220 batches in 1386.78s\ttraining loss:\t3.378272\n",
      "Done 10230 batches in 1388.26s\ttraining loss:\t3.378265\n",
      "Done 10240 batches in 1389.53s\ttraining loss:\t3.378243\n",
      "Done 10250 batches in 1391.21s\ttraining loss:\t3.378257\n",
      "Done 10260 batches in 1392.35s\ttraining loss:\t3.378221\n",
      "Done 10270 batches in 1393.70s\ttraining loss:\t3.378217\n",
      "Done 10280 batches in 1394.96s\ttraining loss:\t3.378257\n",
      "Done 10290 batches in 1396.18s\ttraining loss:\t3.378240\n",
      "Done 10300 batches in 1397.48s\ttraining loss:\t3.378227\n",
      "Done 10310 batches in 1398.87s\ttraining loss:\t3.378248\n",
      "Done 10320 batches in 1400.00s\ttraining loss:\t3.378224\n",
      "Done 10330 batches in 1401.34s\ttraining loss:\t3.378181\n",
      "Done 10340 batches in 1402.56s\ttraining loss:\t3.378179\n",
      "Done 10350 batches in 1403.76s\ttraining loss:\t3.378180\n",
      "Done 10360 batches in 1405.25s\ttraining loss:\t3.378162\n",
      "Done 10370 batches in 1406.75s\ttraining loss:\t3.378119\n",
      "Done 10380 batches in 1408.00s\ttraining loss:\t3.378102\n",
      "Done 10390 batches in 1409.20s\ttraining loss:\t3.378118\n",
      "Done 10400 batches in 1410.39s\ttraining loss:\t3.378139\n",
      "Done 10410 batches in 1411.61s\ttraining loss:\t3.378167\n",
      "Done 10420 batches in 1413.08s\ttraining loss:\t3.378191\n",
      "Done 10430 batches in 1414.28s\ttraining loss:\t3.378168\n",
      "Done 10440 batches in 1415.50s\ttraining loss:\t3.378096\n",
      "Done 10450 batches in 1416.71s\ttraining loss:\t3.378091\n",
      "Done 10460 batches in 1417.93s\ttraining loss:\t3.378095\n",
      "Done 10470 batches in 1419.15s\ttraining loss:\t3.378082\n",
      "Done 10480 batches in 1420.46s\ttraining loss:\t3.378056\n",
      "Done 10490 batches in 1421.72s\ttraining loss:\t3.378063\n",
      "Done 10500 batches in 1423.01s\ttraining loss:\t3.378030\n",
      "Done 10510 batches in 1424.61s\ttraining loss:\t3.377980\n",
      "Done 10520 batches in 1425.91s\ttraining loss:\t3.377945\n",
      "Done 10530 batches in 1427.66s\ttraining loss:\t3.377969\n",
      "Done 10540 batches in 1429.09s\ttraining loss:\t3.377991\n",
      "Done 10550 batches in 1430.62s\ttraining loss:\t3.377987\n",
      "Done 10560 batches in 1431.77s\ttraining loss:\t3.377977\n",
      "Done 10570 batches in 1432.97s\ttraining loss:\t3.377938\n",
      "Done 10580 batches in 1434.43s\ttraining loss:\t3.377936\n",
      "Done 10590 batches in 1435.74s\ttraining loss:\t3.377967\n",
      "Done 10600 batches in 1437.04s\ttraining loss:\t3.377934\n",
      "Done 10610 batches in 1438.24s\ttraining loss:\t3.377912\n",
      "Done 10620 batches in 1439.81s\ttraining loss:\t3.377901\n",
      "Done 10630 batches in 1441.32s\ttraining loss:\t3.377911\n",
      "Done 10640 batches in 1442.64s\ttraining loss:\t3.377896\n",
      "Done 10650 batches in 1443.96s\ttraining loss:\t3.377877\n",
      "Done 10660 batches in 1445.19s\ttraining loss:\t3.377868\n",
      "Done 10670 batches in 1446.75s\ttraining loss:\t3.377898\n",
      "Done 10680 batches in 1448.04s\ttraining loss:\t3.377886\n",
      "Done 10690 batches in 1449.27s\ttraining loss:\t3.377804\n",
      "Done 10700 batches in 1450.56s\ttraining loss:\t3.377768\n",
      "Done 10710 batches in 1451.76s\ttraining loss:\t3.377779\n",
      "Done 10720 batches in 1453.29s\ttraining loss:\t3.377758\n",
      "Done 10730 batches in 1454.54s\ttraining loss:\t3.377709\n",
      "Done 10740 batches in 1455.78s\ttraining loss:\t3.377696\n",
      "Done 10750 batches in 1457.23s\ttraining loss:\t3.377692\n",
      "Done 10760 batches in 1458.55s\ttraining loss:\t3.377678\n",
      "Done 10770 batches in 1459.61s\ttraining loss:\t3.377643\n",
      "Done 10780 batches in 1461.13s\ttraining loss:\t3.377646\n",
      "Done 10790 batches in 1462.62s\ttraining loss:\t3.377594\n",
      "Done 10800 batches in 1464.05s\ttraining loss:\t3.377549\n",
      "Done 10810 batches in 1465.46s\ttraining loss:\t3.377521\n",
      "Done 10820 batches in 1467.00s\ttraining loss:\t3.377510\n",
      "Done 10830 batches in 1468.46s\ttraining loss:\t3.377508\n",
      "Done 10840 batches in 1469.91s\ttraining loss:\t3.377494\n",
      "Done 10850 batches in 1471.15s\ttraining loss:\t3.377452\n",
      "Done 10860 batches in 1472.80s\ttraining loss:\t3.377445\n",
      "Done 10870 batches in 1474.31s\ttraining loss:\t3.377429\n",
      "Done 10880 batches in 1475.43s\ttraining loss:\t3.377438\n",
      "Done 10890 batches in 1476.94s\ttraining loss:\t3.377408\n",
      "Done 10900 batches in 1478.76s\ttraining loss:\t3.377400\n",
      "Done 10910 batches in 1480.16s\ttraining loss:\t3.377384\n",
      "Done 10920 batches in 1481.51s\ttraining loss:\t3.377350\n",
      "Done 10930 batches in 1482.63s\ttraining loss:\t3.377327\n",
      "Done 10940 batches in 1484.01s\ttraining loss:\t3.377327\n",
      "Done 10950 batches in 1485.12s\ttraining loss:\t3.377296\n",
      "Done 10960 batches in 1486.54s\ttraining loss:\t3.377237\n",
      "Done 10970 batches in 1488.13s\ttraining loss:\t3.377228\n",
      "Done 10980 batches in 1489.40s\ttraining loss:\t3.377196\n",
      "Done 10990 batches in 1491.00s\ttraining loss:\t3.377160\n",
      "Done 11000 batches in 1492.30s\ttraining loss:\t3.377152\n",
      "Done 11010 batches in 1493.52s\ttraining loss:\t3.377099\n",
      "Done 11020 batches in 1494.98s\ttraining loss:\t3.377075\n",
      "Done 11030 batches in 1496.04s\ttraining loss:\t3.377061\n",
      "Done 11040 batches in 1497.35s\ttraining loss:\t3.377064\n",
      "Done 11050 batches in 1498.59s\ttraining loss:\t3.377069\n",
      "Done 11060 batches in 1499.95s\ttraining loss:\t3.377023\n",
      "Done 11070 batches in 1501.35s\ttraining loss:\t3.377012\n",
      "Done 11080 batches in 1502.52s\ttraining loss:\t3.377009\n",
      "Done 11090 batches in 1504.00s\ttraining loss:\t3.377008\n",
      "Done 11100 batches in 1505.07s\ttraining loss:\t3.376976\n",
      "Done 11110 batches in 1506.42s\ttraining loss:\t3.376932\n",
      "Done 11120 batches in 1507.70s\ttraining loss:\t3.376903\n",
      "Done 11130 batches in 1509.06s\ttraining loss:\t3.376897\n",
      "Done 11140 batches in 1510.34s\ttraining loss:\t3.376844\n",
      "Done 11150 batches in 1511.56s\ttraining loss:\t3.376863\n",
      "Done 11160 batches in 1512.86s\ttraining loss:\t3.376871\n",
      "Done 11170 batches in 1514.45s\ttraining loss:\t3.376853\n",
      "Done 11180 batches in 1515.60s\ttraining loss:\t3.376880\n",
      "Done 11190 batches in 1516.73s\ttraining loss:\t3.376790\n",
      "Done 11200 batches in 1517.71s\ttraining loss:\t3.376763\n",
      "Done 11210 batches in 1518.86s\ttraining loss:\t3.376741\n",
      "Done 11220 batches in 1520.25s\ttraining loss:\t3.376754\n",
      "Done 11230 batches in 1521.63s\ttraining loss:\t3.376750\n",
      "Done 11240 batches in 1523.01s\ttraining loss:\t3.376712\n",
      "Done 11250 batches in 1524.49s\ttraining loss:\t3.376698\n",
      "Done 11260 batches in 1525.72s\ttraining loss:\t3.376675\n",
      "Done 11270 batches in 1526.80s\ttraining loss:\t3.376645\n",
      "Done 11280 batches in 1528.14s\ttraining loss:\t3.376608\n",
      "Done 11290 batches in 1529.40s\ttraining loss:\t3.376588\n",
      "Done 11300 batches in 1530.79s\ttraining loss:\t3.376611\n",
      "Done 11310 batches in 1532.21s\ttraining loss:\t3.376611\n",
      "Done 11320 batches in 1533.55s\ttraining loss:\t3.376626\n",
      "Done 11330 batches in 1534.70s\ttraining loss:\t3.376579\n",
      "Done 11340 batches in 1536.16s\ttraining loss:\t3.376534\n",
      "Done 11350 batches in 1537.55s\ttraining loss:\t3.376502\n",
      "Done 11360 batches in 1538.75s\ttraining loss:\t3.376502\n",
      "Done 11370 batches in 1539.89s\ttraining loss:\t3.376497\n",
      "Done 11380 batches in 1541.32s\ttraining loss:\t3.376491\n",
      "Done 11390 batches in 1542.66s\ttraining loss:\t3.376481\n",
      "Done 11400 batches in 1543.86s\ttraining loss:\t3.376470\n",
      "Done 11410 batches in 1545.20s\ttraining loss:\t3.376444\n",
      "Done 11420 batches in 1546.48s\ttraining loss:\t3.376426\n",
      "Done 11430 batches in 1547.66s\ttraining loss:\t3.376428\n",
      "Done 11440 batches in 1549.18s\ttraining loss:\t3.376455\n",
      "Done 11450 batches in 1550.34s\ttraining loss:\t3.376436\n",
      "Done 11460 batches in 1551.79s\ttraining loss:\t3.376422\n",
      "Done 11470 batches in 1553.05s\ttraining loss:\t3.376412\n",
      "Done 11480 batches in 1554.22s\ttraining loss:\t3.376368\n",
      "Done 11490 batches in 1555.49s\ttraining loss:\t3.376375\n",
      "Done 11500 batches in 1556.77s\ttraining loss:\t3.376376\n",
      "Done 11510 batches in 1558.30s\ttraining loss:\t3.376370\n",
      "Done 11520 batches in 1559.67s\ttraining loss:\t3.376340\n",
      "Done 11530 batches in 1560.98s\ttraining loss:\t3.376324\n",
      "Done 11540 batches in 1562.71s\ttraining loss:\t3.376296\n",
      "Done 11550 batches in 1563.93s\ttraining loss:\t3.376255\n",
      "Done 11560 batches in 1565.30s\ttraining loss:\t3.376233\n",
      "Done 11570 batches in 1566.78s\ttraining loss:\t3.376238\n",
      "Done 11580 batches in 1568.09s\ttraining loss:\t3.376200\n",
      "Done 11590 batches in 1569.64s\ttraining loss:\t3.376168\n",
      "Done 11600 batches in 1571.18s\ttraining loss:\t3.376141\n",
      "Done 11610 batches in 1572.74s\ttraining loss:\t3.376114\n",
      "Done 11620 batches in 1574.05s\ttraining loss:\t3.376100\n",
      "Done 11630 batches in 1575.47s\ttraining loss:\t3.376114\n",
      "Done 11640 batches in 1577.04s\ttraining loss:\t3.376122\n",
      "Done 11650 batches in 1578.42s\ttraining loss:\t3.376106\n",
      "Done 11660 batches in 1579.82s\ttraining loss:\t3.376074\n",
      "Done 11670 batches in 1581.17s\ttraining loss:\t3.376049\n",
      "Done 11680 batches in 1582.63s\ttraining loss:\t3.376053\n",
      "Done 11690 batches in 1584.02s\ttraining loss:\t3.376015\n",
      "Done 11700 batches in 1585.26s\ttraining loss:\t3.376031\n",
      "Done 11710 batches in 1586.52s\ttraining loss:\t3.376007\n",
      "Done 11720 batches in 1587.81s\ttraining loss:\t3.375989\n",
      "Done 11730 batches in 1589.01s\ttraining loss:\t3.375980\n",
      "Done 11740 batches in 1590.17s\ttraining loss:\t3.375970\n",
      "Done 11750 batches in 1591.47s\ttraining loss:\t3.375978\n",
      "Done 11760 batches in 1592.88s\ttraining loss:\t3.375986\n",
      "Done 100 batches in 2.32s\n",
      "Done 200 batches in 4.91s\n",
      "Done 300 batches in 7.46s\n",
      "Done 400 batches in 10.03s\n",
      "Done 500 batches in 12.36s\n",
      "Done 600 batches in 14.77s\n",
      "Done 700 batches in 17.08s\n",
      "Done 800 batches in 19.46s\n",
      "Done 900 batches in 21.76s\n",
      "Done 1000 batches in 24.01s\n",
      "Done 1100 batches in 26.63s\n",
      "Done 1200 batches in 29.25s\n",
      "Done 1300 batches in 31.77s\n",
      "Done 1400 batches in 34.39s\n",
      "Done 1500 batches in 36.98s\n",
      "Done 1600 batches in 39.61s\n",
      "Done 1700 batches in 41.85s\n",
      "Done 1800 batches in 44.20s\n",
      "Done 1900 batches in 46.62s\n",
      "Done 2000 batches in 49.00s\n",
      "Done 2100 batches in 51.51s\n",
      "Done 2200 batches in 54.06s\n",
      "Done 2300 batches in 56.62s\n",
      "Done 2400 batches in 58.95s\n",
      "Done 2500 batches in 61.40s\n",
      "Done 2600 batches in 63.87s\n",
      "Done 2700 batches in 66.47s\n",
      "Done 2800 batches in 69.07s\n",
      "Done 2900 batches in 71.53s\n",
      "Epoch 3 of 5 took 1667.35s\n",
      "  training loss:\t\t3.375984\n",
      "  validation loss:\t\t3.447041\n",
      "Done 10 batches in 1.27s\ttraining loss:\t3.327945\n",
      "Done 20 batches in 2.78s\ttraining loss:\t3.334639\n",
      "Done 30 batches in 4.04s\ttraining loss:\t3.329531\n",
      "Done 40 batches in 5.65s\ttraining loss:\t3.336987\n",
      "Done 50 batches in 7.12s\ttraining loss:\t3.342704\n",
      "Done 60 batches in 8.57s\ttraining loss:\t3.343155\n",
      "Done 70 batches in 9.67s\ttraining loss:\t3.344142\n",
      "Done 80 batches in 10.95s\ttraining loss:\t3.347192\n",
      "Done 90 batches in 12.45s\ttraining loss:\t3.351798\n",
      "Done 100 batches in 13.72s\ttraining loss:\t3.355079\n",
      "Done 110 batches in 14.94s\ttraining loss:\t3.356684\n",
      "Done 120 batches in 16.28s\ttraining loss:\t3.356473\n",
      "Done 130 batches in 17.51s\ttraining loss:\t3.357877\n",
      "Done 140 batches in 18.96s\ttraining loss:\t3.357987\n",
      "Done 150 batches in 20.50s\ttraining loss:\t3.357710\n",
      "Done 160 batches in 21.98s\ttraining loss:\t3.356406\n",
      "Done 170 batches in 23.24s\ttraining loss:\t3.355928\n",
      "Done 180 batches in 24.85s\ttraining loss:\t3.356528\n",
      "Done 190 batches in 26.10s\ttraining loss:\t3.355635\n",
      "Done 200 batches in 27.70s\ttraining loss:\t3.354938\n",
      "Done 210 batches in 29.30s\ttraining loss:\t3.356083\n",
      "Done 220 batches in 30.76s\ttraining loss:\t3.355656\n",
      "Done 230 batches in 32.02s\ttraining loss:\t3.356498\n",
      "Done 240 batches in 33.08s\ttraining loss:\t3.356368\n",
      "Done 250 batches in 34.45s\ttraining loss:\t3.355345\n",
      "Done 260 batches in 35.77s\ttraining loss:\t3.354858\n",
      "Done 270 batches in 37.03s\ttraining loss:\t3.354695\n",
      "Done 280 batches in 38.14s\ttraining loss:\t3.353776\n",
      "Done 290 batches in 39.62s\ttraining loss:\t3.354838\n",
      "Done 300 batches in 41.00s\ttraining loss:\t3.355033\n",
      "Done 310 batches in 42.29s\ttraining loss:\t3.355035\n",
      "Done 320 batches in 43.65s\ttraining loss:\t3.355180\n",
      "Done 330 batches in 45.20s\ttraining loss:\t3.354573\n",
      "Done 340 batches in 46.68s\ttraining loss:\t3.354063\n",
      "Done 350 batches in 48.10s\ttraining loss:\t3.353694\n",
      "Done 360 batches in 49.66s\ttraining loss:\t3.354975\n",
      "Done 370 batches in 51.10s\ttraining loss:\t3.355070\n",
      "Done 380 batches in 52.52s\ttraining loss:\t3.354624\n",
      "Done 390 batches in 53.89s\ttraining loss:\t3.353851\n",
      "Done 400 batches in 55.26s\ttraining loss:\t3.353496\n",
      "Done 410 batches in 56.52s\ttraining loss:\t3.352352\n",
      "Done 420 batches in 57.99s\ttraining loss:\t3.352993\n",
      "Done 430 batches in 59.42s\ttraining loss:\t3.352529\n",
      "Done 440 batches in 60.76s\ttraining loss:\t3.352362\n",
      "Done 450 batches in 61.94s\ttraining loss:\t3.352030\n",
      "Done 460 batches in 63.08s\ttraining loss:\t3.351796\n",
      "Done 470 batches in 64.32s\ttraining loss:\t3.351631\n",
      "Done 480 batches in 65.45s\ttraining loss:\t3.351356\n",
      "Done 490 batches in 66.81s\ttraining loss:\t3.351245\n",
      "Done 500 batches in 68.24s\ttraining loss:\t3.352272\n",
      "Done 510 batches in 69.51s\ttraining loss:\t3.352534\n",
      "Done 520 batches in 70.65s\ttraining loss:\t3.351974\n",
      "Done 530 batches in 71.93s\ttraining loss:\t3.351423\n",
      "Done 540 batches in 73.44s\ttraining loss:\t3.350899\n",
      "Done 550 batches in 74.83s\ttraining loss:\t3.350825\n",
      "Done 560 batches in 76.16s\ttraining loss:\t3.350936\n",
      "Done 570 batches in 77.54s\ttraining loss:\t3.351908\n",
      "Done 580 batches in 78.98s\ttraining loss:\t3.351575\n",
      "Done 590 batches in 80.27s\ttraining loss:\t3.351733\n",
      "Done 600 batches in 81.66s\ttraining loss:\t3.352092\n",
      "Done 610 batches in 82.96s\ttraining loss:\t3.352456\n",
      "Done 620 batches in 84.15s\ttraining loss:\t3.352524\n",
      "Done 630 batches in 85.40s\ttraining loss:\t3.352006\n",
      "Done 640 batches in 86.91s\ttraining loss:\t3.351866\n",
      "Done 650 batches in 88.92s\ttraining loss:\t3.352582\n",
      "Done 660 batches in 90.15s\ttraining loss:\t3.352130\n",
      "Done 670 batches in 91.47s\ttraining loss:\t3.352512\n",
      "Done 680 batches in 92.68s\ttraining loss:\t3.352715\n",
      "Done 690 batches in 93.97s\ttraining loss:\t3.352643\n",
      "Done 700 batches in 95.08s\ttraining loss:\t3.352573\n",
      "Done 710 batches in 96.27s\ttraining loss:\t3.352392\n",
      "Done 720 batches in 97.69s\ttraining loss:\t3.352092\n",
      "Done 730 batches in 98.88s\ttraining loss:\t3.352431\n",
      "Done 740 batches in 100.41s\ttraining loss:\t3.352420\n",
      "Done 750 batches in 101.95s\ttraining loss:\t3.352990\n",
      "Done 760 batches in 103.35s\ttraining loss:\t3.353091\n",
      "Done 770 batches in 104.86s\ttraining loss:\t3.353224\n",
      "Done 780 batches in 106.19s\ttraining loss:\t3.352566\n",
      "Done 790 batches in 107.33s\ttraining loss:\t3.352751\n",
      "Done 800 batches in 108.75s\ttraining loss:\t3.353069\n",
      "Done 810 batches in 110.38s\ttraining loss:\t3.353125\n",
      "Done 820 batches in 111.64s\ttraining loss:\t3.352776\n",
      "Done 830 batches in 112.86s\ttraining loss:\t3.352922\n",
      "Done 840 batches in 114.03s\ttraining loss:\t3.352633\n",
      "Done 850 batches in 115.56s\ttraining loss:\t3.352230\n",
      "Done 860 batches in 116.91s\ttraining loss:\t3.352527\n",
      "Done 870 batches in 118.15s\ttraining loss:\t3.352647\n",
      "Done 880 batches in 119.57s\ttraining loss:\t3.352853\n",
      "Done 890 batches in 120.98s\ttraining loss:\t3.352550\n",
      "Done 900 batches in 122.28s\ttraining loss:\t3.352236\n",
      "Done 910 batches in 123.46s\ttraining loss:\t3.352052\n",
      "Done 920 batches in 124.77s\ttraining loss:\t3.352060\n",
      "Done 930 batches in 126.20s\ttraining loss:\t3.351981\n",
      "Done 940 batches in 127.64s\ttraining loss:\t3.351659\n",
      "Done 950 batches in 128.98s\ttraining loss:\t3.351387\n",
      "Done 960 batches in 130.07s\ttraining loss:\t3.351530\n",
      "Done 970 batches in 131.46s\ttraining loss:\t3.351612\n",
      "Done 980 batches in 132.64s\ttraining loss:\t3.351601\n",
      "Done 990 batches in 133.95s\ttraining loss:\t3.351762\n",
      "Done 1000 batches in 135.22s\ttraining loss:\t3.351763\n",
      "Done 1010 batches in 136.54s\ttraining loss:\t3.352150\n",
      "Done 1020 batches in 137.88s\ttraining loss:\t3.352406\n",
      "Done 1030 batches in 139.04s\ttraining loss:\t3.352462\n",
      "Done 1040 batches in 140.42s\ttraining loss:\t3.352429\n",
      "Done 1050 batches in 141.88s\ttraining loss:\t3.352521\n",
      "Done 1060 batches in 143.24s\ttraining loss:\t3.352526\n",
      "Done 1070 batches in 144.54s\ttraining loss:\t3.352601\n",
      "Done 1080 batches in 146.15s\ttraining loss:\t3.352772\n",
      "Done 1090 batches in 147.21s\ttraining loss:\t3.352829\n",
      "Done 1100 batches in 148.52s\ttraining loss:\t3.352780\n",
      "Done 1110 batches in 149.90s\ttraining loss:\t3.353138\n",
      "Done 1120 batches in 151.14s\ttraining loss:\t3.352916\n",
      "Done 1130 batches in 152.51s\ttraining loss:\t3.353169\n",
      "Done 1140 batches in 153.66s\ttraining loss:\t3.353259\n",
      "Done 1150 batches in 155.11s\ttraining loss:\t3.353286\n",
      "Done 1160 batches in 156.24s\ttraining loss:\t3.353172\n",
      "Done 1170 batches in 157.45s\ttraining loss:\t3.353225\n",
      "Done 1180 batches in 159.26s\ttraining loss:\t3.353153\n",
      "Done 1190 batches in 160.53s\ttraining loss:\t3.353137\n",
      "Done 1200 batches in 161.81s\ttraining loss:\t3.353175\n",
      "Done 1210 batches in 163.08s\ttraining loss:\t3.353069\n",
      "Done 1220 batches in 164.48s\ttraining loss:\t3.352872\n",
      "Done 1230 batches in 165.72s\ttraining loss:\t3.352838\n",
      "Done 1240 batches in 167.09s\ttraining loss:\t3.352734\n",
      "Done 1250 batches in 168.37s\ttraining loss:\t3.352288\n",
      "Done 1260 batches in 169.95s\ttraining loss:\t3.352516\n",
      "Done 1270 batches in 171.17s\ttraining loss:\t3.352402\n",
      "Done 1280 batches in 172.48s\ttraining loss:\t3.352445\n",
      "Done 1290 batches in 173.85s\ttraining loss:\t3.352631\n",
      "Done 1300 batches in 175.17s\ttraining loss:\t3.352515\n",
      "Done 1310 batches in 176.68s\ttraining loss:\t3.352536\n",
      "Done 1320 batches in 178.30s\ttraining loss:\t3.352105\n",
      "Done 1330 batches in 179.45s\ttraining loss:\t3.351860\n",
      "Done 1340 batches in 180.92s\ttraining loss:\t3.351621\n",
      "Done 1350 batches in 182.27s\ttraining loss:\t3.351575\n",
      "Done 1360 batches in 183.44s\ttraining loss:\t3.351436\n",
      "Done 1370 batches in 184.66s\ttraining loss:\t3.351344\n",
      "Done 1380 batches in 186.16s\ttraining loss:\t3.351474\n",
      "Done 1390 batches in 187.54s\ttraining loss:\t3.351429\n",
      "Done 1400 batches in 188.91s\ttraining loss:\t3.351688\n",
      "Done 1410 batches in 190.61s\ttraining loss:\t3.351761\n",
      "Done 1420 batches in 191.82s\ttraining loss:\t3.351748\n",
      "Done 1430 batches in 193.18s\ttraining loss:\t3.351743\n",
      "Done 1440 batches in 194.75s\ttraining loss:\t3.351865\n",
      "Done 1450 batches in 196.06s\ttraining loss:\t3.351780\n",
      "Done 1460 batches in 197.17s\ttraining loss:\t3.351721\n",
      "Done 1470 batches in 198.48s\ttraining loss:\t3.351792\n",
      "Done 1480 batches in 199.69s\ttraining loss:\t3.351653\n",
      "Done 1490 batches in 200.91s\ttraining loss:\t3.351550\n",
      "Done 1500 batches in 202.38s\ttraining loss:\t3.351348\n",
      "Done 1510 batches in 203.59s\ttraining loss:\t3.351025\n",
      "Done 1520 batches in 204.91s\ttraining loss:\t3.351071\n",
      "Done 1530 batches in 206.18s\ttraining loss:\t3.351052\n",
      "Done 1540 batches in 207.28s\ttraining loss:\t3.350790\n",
      "Done 1550 batches in 208.60s\ttraining loss:\t3.350633\n",
      "Done 1560 batches in 210.08s\ttraining loss:\t3.350703\n",
      "Done 1570 batches in 211.62s\ttraining loss:\t3.350766\n",
      "Done 1580 batches in 212.98s\ttraining loss:\t3.350911\n",
      "Done 1590 batches in 214.32s\ttraining loss:\t3.350778\n",
      "Done 1600 batches in 215.67s\ttraining loss:\t3.350944\n",
      "Done 1610 batches in 216.57s\ttraining loss:\t3.350715\n",
      "Done 1620 batches in 218.20s\ttraining loss:\t3.350633\n",
      "Done 1630 batches in 219.66s\ttraining loss:\t3.350780\n",
      "Done 1640 batches in 220.93s\ttraining loss:\t3.350779\n",
      "Done 1650 batches in 222.24s\ttraining loss:\t3.350849\n",
      "Done 1660 batches in 223.66s\ttraining loss:\t3.350916\n",
      "Done 1670 batches in 224.89s\ttraining loss:\t3.350898\n",
      "Done 1680 batches in 226.79s\ttraining loss:\t3.351174\n",
      "Done 1690 batches in 228.09s\ttraining loss:\t3.351226\n",
      "Done 1700 batches in 229.45s\ttraining loss:\t3.351263\n",
      "Done 1710 batches in 230.64s\ttraining loss:\t3.351046\n",
      "Done 1720 batches in 232.15s\ttraining loss:\t3.351140\n",
      "Done 1730 batches in 233.28s\ttraining loss:\t3.350820\n",
      "Done 1740 batches in 234.46s\ttraining loss:\t3.350802\n",
      "Done 1750 batches in 236.18s\ttraining loss:\t3.350895\n",
      "Done 1760 batches in 237.41s\ttraining loss:\t3.350980\n",
      "Done 1770 batches in 238.93s\ttraining loss:\t3.350709\n",
      "Done 1780 batches in 240.14s\ttraining loss:\t3.350714\n",
      "Done 1790 batches in 241.37s\ttraining loss:\t3.350475\n",
      "Done 1800 batches in 242.72s\ttraining loss:\t3.350519\n",
      "Done 1810 batches in 244.35s\ttraining loss:\t3.350496\n",
      "Done 1820 batches in 245.65s\ttraining loss:\t3.350346\n",
      "Done 1830 batches in 247.11s\ttraining loss:\t3.350372\n",
      "Done 1840 batches in 248.30s\ttraining loss:\t3.350215\n",
      "Done 1850 batches in 249.68s\ttraining loss:\t3.350079\n",
      "Done 1860 batches in 251.00s\ttraining loss:\t3.349991\n",
      "Done 1870 batches in 252.45s\ttraining loss:\t3.349798\n",
      "Done 1880 batches in 253.76s\ttraining loss:\t3.349831\n",
      "Done 1890 batches in 254.93s\ttraining loss:\t3.349741\n",
      "Done 1900 batches in 256.26s\ttraining loss:\t3.349557\n",
      "Done 1910 batches in 257.56s\ttraining loss:\t3.349483\n",
      "Done 1920 batches in 258.98s\ttraining loss:\t3.349491\n",
      "Done 1930 batches in 260.22s\ttraining loss:\t3.349478\n",
      "Done 1940 batches in 261.68s\ttraining loss:\t3.349431\n",
      "Done 1950 batches in 263.17s\ttraining loss:\t3.349157\n",
      "Done 1960 batches in 264.28s\ttraining loss:\t3.349058\n",
      "Done 1970 batches in 265.59s\ttraining loss:\t3.349273\n",
      "Done 1980 batches in 267.14s\ttraining loss:\t3.349172\n",
      "Done 1990 batches in 268.36s\ttraining loss:\t3.349036\n",
      "Done 2000 batches in 269.76s\ttraining loss:\t3.349227\n",
      "Done 2010 batches in 271.10s\ttraining loss:\t3.349339\n",
      "Done 2020 batches in 272.32s\ttraining loss:\t3.349293\n",
      "Done 2030 batches in 273.71s\ttraining loss:\t3.349165\n",
      "Done 2040 batches in 275.07s\ttraining loss:\t3.349279\n",
      "Done 2050 batches in 276.16s\ttraining loss:\t3.349494\n",
      "Done 2060 batches in 277.59s\ttraining loss:\t3.349544\n",
      "Done 2070 batches in 278.93s\ttraining loss:\t3.349554\n",
      "Done 2080 batches in 280.37s\ttraining loss:\t3.349499\n",
      "Done 2090 batches in 281.68s\ttraining loss:\t3.349374\n",
      "Done 2100 batches in 283.13s\ttraining loss:\t3.349171\n",
      "Done 2110 batches in 284.44s\ttraining loss:\t3.349063\n",
      "Done 2120 batches in 285.88s\ttraining loss:\t3.349146\n",
      "Done 2130 batches in 287.05s\ttraining loss:\t3.349421\n",
      "Done 2140 batches in 288.43s\ttraining loss:\t3.349196\n",
      "Done 2150 batches in 289.86s\ttraining loss:\t3.349189\n",
      "Done 2160 batches in 291.07s\ttraining loss:\t3.349203\n",
      "Done 2170 batches in 292.51s\ttraining loss:\t3.349155\n",
      "Done 2180 batches in 293.79s\ttraining loss:\t3.349104\n",
      "Done 2190 batches in 295.12s\ttraining loss:\t3.349118\n",
      "Done 2200 batches in 296.26s\ttraining loss:\t3.348973\n",
      "Done 2210 batches in 297.37s\ttraining loss:\t3.348807\n",
      "Done 2220 batches in 299.13s\ttraining loss:\t3.348816\n",
      "Done 2230 batches in 300.72s\ttraining loss:\t3.348822\n",
      "Done 2240 batches in 302.04s\ttraining loss:\t3.348790\n",
      "Done 2250 batches in 303.30s\ttraining loss:\t3.348614\n",
      "Done 2260 batches in 304.60s\ttraining loss:\t3.348579\n",
      "Done 2270 batches in 306.03s\ttraining loss:\t3.348602\n",
      "Done 2280 batches in 307.15s\ttraining loss:\t3.348566\n",
      "Done 2290 batches in 308.50s\ttraining loss:\t3.348547\n",
      "Done 2300 batches in 309.74s\ttraining loss:\t3.348671\n",
      "Done 2310 batches in 311.32s\ttraining loss:\t3.348917\n",
      "Done 2320 batches in 312.63s\ttraining loss:\t3.348992\n",
      "Done 2330 batches in 313.93s\ttraining loss:\t3.348727\n",
      "Done 2340 batches in 315.53s\ttraining loss:\t3.348591\n",
      "Done 2350 batches in 316.80s\ttraining loss:\t3.348526\n",
      "Done 2360 batches in 318.11s\ttraining loss:\t3.348454\n",
      "Done 2370 batches in 319.40s\ttraining loss:\t3.348408\n",
      "Done 2380 batches in 320.68s\ttraining loss:\t3.348403\n",
      "Done 2390 batches in 322.26s\ttraining loss:\t3.348288\n",
      "Done 2400 batches in 323.56s\ttraining loss:\t3.348250\n",
      "Done 2410 batches in 325.00s\ttraining loss:\t3.348230\n",
      "Done 2420 batches in 326.19s\ttraining loss:\t3.348121\n",
      "Done 2430 batches in 327.27s\ttraining loss:\t3.347952\n",
      "Done 2440 batches in 328.78s\ttraining loss:\t3.348047\n",
      "Done 2450 batches in 330.07s\ttraining loss:\t3.347945\n",
      "Done 2460 batches in 331.33s\ttraining loss:\t3.347855\n",
      "Done 2470 batches in 332.70s\ttraining loss:\t3.347731\n",
      "Done 2480 batches in 334.38s\ttraining loss:\t3.347723\n",
      "Done 2490 batches in 335.81s\ttraining loss:\t3.347849\n",
      "Done 2500 batches in 336.97s\ttraining loss:\t3.347855\n",
      "Done 2510 batches in 338.09s\ttraining loss:\t3.348004\n",
      "Done 2520 batches in 339.40s\ttraining loss:\t3.348044\n",
      "Done 2530 batches in 340.94s\ttraining loss:\t3.348027\n",
      "Done 2540 batches in 342.02s\ttraining loss:\t3.348005\n",
      "Done 2550 batches in 343.42s\ttraining loss:\t3.348130\n",
      "Done 2560 batches in 344.80s\ttraining loss:\t3.347973\n",
      "Done 2570 batches in 346.32s\ttraining loss:\t3.348046\n",
      "Done 2580 batches in 347.70s\ttraining loss:\t3.347931\n",
      "Done 2590 batches in 348.84s\ttraining loss:\t3.347902\n",
      "Done 2600 batches in 350.42s\ttraining loss:\t3.347768\n",
      "Done 2610 batches in 351.45s\ttraining loss:\t3.347903\n",
      "Done 2620 batches in 353.05s\ttraining loss:\t3.347937\n",
      "Done 2630 batches in 354.42s\ttraining loss:\t3.347864\n",
      "Done 2640 batches in 355.70s\ttraining loss:\t3.347825\n",
      "Done 2650 batches in 357.09s\ttraining loss:\t3.347805\n",
      "Done 2660 batches in 358.46s\ttraining loss:\t3.347802\n",
      "Done 2670 batches in 359.90s\ttraining loss:\t3.347903\n",
      "Done 2680 batches in 361.37s\ttraining loss:\t3.347890\n",
      "Done 2690 batches in 362.62s\ttraining loss:\t3.348038\n",
      "Done 2700 batches in 363.90s\ttraining loss:\t3.348015\n",
      "Done 2710 batches in 365.44s\ttraining loss:\t3.348169\n",
      "Done 2720 batches in 366.52s\ttraining loss:\t3.348185\n",
      "Done 2730 batches in 367.70s\ttraining loss:\t3.348082\n",
      "Done 2740 batches in 368.83s\ttraining loss:\t3.347968\n",
      "Done 2750 batches in 370.25s\ttraining loss:\t3.347967\n",
      "Done 2760 batches in 371.62s\ttraining loss:\t3.347914\n",
      "Done 2770 batches in 373.01s\ttraining loss:\t3.347993\n",
      "Done 2780 batches in 374.55s\ttraining loss:\t3.347938\n",
      "Done 2790 batches in 375.91s\ttraining loss:\t3.347872\n",
      "Done 2800 batches in 377.10s\ttraining loss:\t3.347942\n",
      "Done 2810 batches in 378.53s\ttraining loss:\t3.347995\n",
      "Done 2820 batches in 379.67s\ttraining loss:\t3.347964\n",
      "Done 2830 batches in 380.86s\ttraining loss:\t3.347859\n",
      "Done 2840 batches in 382.24s\ttraining loss:\t3.347826\n",
      "Done 2850 batches in 383.86s\ttraining loss:\t3.347662\n",
      "Done 2860 batches in 385.15s\ttraining loss:\t3.347712\n",
      "Done 2870 batches in 386.32s\ttraining loss:\t3.347680\n",
      "Done 2880 batches in 387.53s\ttraining loss:\t3.347627\n",
      "Done 2890 batches in 388.94s\ttraining loss:\t3.347592\n",
      "Done 2900 batches in 390.28s\ttraining loss:\t3.347716\n",
      "Done 2910 batches in 391.60s\ttraining loss:\t3.347819\n",
      "Done 2920 batches in 392.83s\ttraining loss:\t3.347736\n",
      "Done 2930 batches in 394.16s\ttraining loss:\t3.347634\n",
      "Done 2940 batches in 395.48s\ttraining loss:\t3.347580\n",
      "Done 2950 batches in 396.77s\ttraining loss:\t3.347481\n",
      "Done 2960 batches in 398.21s\ttraining loss:\t3.347526\n",
      "Done 2970 batches in 399.64s\ttraining loss:\t3.347419\n",
      "Done 2980 batches in 400.74s\ttraining loss:\t3.347340\n",
      "Done 2990 batches in 401.76s\ttraining loss:\t3.347260\n",
      "Done 3000 batches in 403.08s\ttraining loss:\t3.347226\n",
      "Done 3010 batches in 404.38s\ttraining loss:\t3.347164\n",
      "Done 3020 batches in 405.47s\ttraining loss:\t3.347079\n",
      "Done 3030 batches in 406.97s\ttraining loss:\t3.347095\n",
      "Done 3040 batches in 408.25s\ttraining loss:\t3.347113\n",
      "Done 3050 batches in 409.83s\ttraining loss:\t3.347132\n",
      "Done 3060 batches in 410.81s\ttraining loss:\t3.347090\n",
      "Done 3070 batches in 411.99s\ttraining loss:\t3.347056\n",
      "Done 3080 batches in 413.11s\ttraining loss:\t3.346765\n",
      "Done 3090 batches in 414.61s\ttraining loss:\t3.346819\n",
      "Done 3100 batches in 415.89s\ttraining loss:\t3.346696\n",
      "Done 3110 batches in 417.63s\ttraining loss:\t3.346710\n",
      "Done 3120 batches in 418.92s\ttraining loss:\t3.346782\n",
      "Done 3130 batches in 420.16s\ttraining loss:\t3.346786\n",
      "Done 3140 batches in 421.45s\ttraining loss:\t3.346765\n",
      "Done 3150 batches in 422.71s\ttraining loss:\t3.346652\n",
      "Done 3160 batches in 423.87s\ttraining loss:\t3.346643\n",
      "Done 3170 batches in 425.31s\ttraining loss:\t3.346669\n",
      "Done 3180 batches in 426.40s\ttraining loss:\t3.346624\n",
      "Done 3190 batches in 427.66s\ttraining loss:\t3.346579\n",
      "Done 3200 batches in 429.06s\ttraining loss:\t3.346544\n",
      "Done 3210 batches in 430.51s\ttraining loss:\t3.346590\n",
      "Done 3220 batches in 431.74s\ttraining loss:\t3.346451\n",
      "Done 3230 batches in 433.02s\ttraining loss:\t3.346375\n",
      "Done 3240 batches in 434.38s\ttraining loss:\t3.346303\n",
      "Done 3250 batches in 435.57s\ttraining loss:\t3.346337\n",
      "Done 3260 batches in 436.96s\ttraining loss:\t3.346301\n",
      "Done 3270 batches in 438.23s\ttraining loss:\t3.346326\n",
      "Done 3280 batches in 439.72s\ttraining loss:\t3.346356\n",
      "Done 3290 batches in 440.90s\ttraining loss:\t3.346413\n",
      "Done 3300 batches in 442.08s\ttraining loss:\t3.346489\n",
      "Done 3310 batches in 443.42s\ttraining loss:\t3.346402\n",
      "Done 3320 batches in 444.69s\ttraining loss:\t3.346338\n",
      "Done 3330 batches in 446.15s\ttraining loss:\t3.346312\n",
      "Done 3340 batches in 447.39s\ttraining loss:\t3.346314\n",
      "Done 3350 batches in 448.65s\ttraining loss:\t3.346357\n",
      "Done 3360 batches in 450.23s\ttraining loss:\t3.346263\n",
      "Done 3370 batches in 451.70s\ttraining loss:\t3.346187\n",
      "Done 3380 batches in 453.18s\ttraining loss:\t3.346179\n",
      "Done 3390 batches in 454.76s\ttraining loss:\t3.346148\n",
      "Done 3400 batches in 455.95s\ttraining loss:\t3.346015\n",
      "Done 3410 batches in 457.49s\ttraining loss:\t3.346110\n",
      "Done 3420 batches in 458.69s\ttraining loss:\t3.346010\n",
      "Done 3430 batches in 459.97s\ttraining loss:\t3.345856\n",
      "Done 3440 batches in 461.33s\ttraining loss:\t3.345810\n",
      "Done 3450 batches in 462.48s\ttraining loss:\t3.345774\n",
      "Done 3460 batches in 463.75s\ttraining loss:\t3.345848\n",
      "Done 3470 batches in 465.05s\ttraining loss:\t3.345865\n",
      "Done 3480 batches in 466.63s\ttraining loss:\t3.345843\n",
      "Done 3490 batches in 468.02s\ttraining loss:\t3.345733\n",
      "Done 3500 batches in 469.20s\ttraining loss:\t3.345618\n",
      "Done 3510 batches in 470.61s\ttraining loss:\t3.345635\n",
      "Done 3520 batches in 472.05s\ttraining loss:\t3.345589\n",
      "Done 3530 batches in 473.40s\ttraining loss:\t3.345570\n",
      "Done 3540 batches in 475.01s\ttraining loss:\t3.345548\n",
      "Done 3550 batches in 476.39s\ttraining loss:\t3.345619\n",
      "Done 3560 batches in 477.59s\ttraining loss:\t3.345655\n",
      "Done 3570 batches in 479.14s\ttraining loss:\t3.345749\n",
      "Done 3580 batches in 480.87s\ttraining loss:\t3.345693\n",
      "Done 3590 batches in 482.31s\ttraining loss:\t3.345670\n",
      "Done 3600 batches in 483.64s\ttraining loss:\t3.345618\n",
      "Done 3610 batches in 485.06s\ttraining loss:\t3.345676\n",
      "Done 3620 batches in 486.43s\ttraining loss:\t3.345577\n",
      "Done 3630 batches in 487.90s\ttraining loss:\t3.345518\n",
      "Done 3640 batches in 489.57s\ttraining loss:\t3.345562\n",
      "Done 3650 batches in 490.75s\ttraining loss:\t3.345502\n",
      "Done 3660 batches in 491.96s\ttraining loss:\t3.345355\n",
      "Done 3670 batches in 493.33s\ttraining loss:\t3.345332\n",
      "Done 3680 batches in 494.45s\ttraining loss:\t3.345260\n",
      "Done 3690 batches in 496.07s\ttraining loss:\t3.345394\n",
      "Done 3700 batches in 497.06s\ttraining loss:\t3.345235\n",
      "Done 3710 batches in 498.53s\ttraining loss:\t3.345239\n",
      "Done 3720 batches in 499.88s\ttraining loss:\t3.345241\n",
      "Done 3730 batches in 501.23s\ttraining loss:\t3.345182\n",
      "Done 3740 batches in 502.52s\ttraining loss:\t3.345255\n",
      "Done 3750 batches in 503.91s\ttraining loss:\t3.345111\n",
      "Done 3760 batches in 505.39s\ttraining loss:\t3.345109\n",
      "Done 3770 batches in 506.86s\ttraining loss:\t3.345141\n",
      "Done 3780 batches in 508.24s\ttraining loss:\t3.345065\n",
      "Done 3790 batches in 509.64s\ttraining loss:\t3.345062\n",
      "Done 3800 batches in 511.02s\ttraining loss:\t3.345086\n",
      "Done 3810 batches in 512.14s\ttraining loss:\t3.345006\n",
      "Done 3820 batches in 513.49s\ttraining loss:\t3.345008\n",
      "Done 3830 batches in 515.08s\ttraining loss:\t3.345058\n",
      "Done 3840 batches in 516.74s\ttraining loss:\t3.345033\n",
      "Done 3850 batches in 517.87s\ttraining loss:\t3.344843\n",
      "Done 3860 batches in 519.25s\ttraining loss:\t3.344827\n",
      "Done 3870 batches in 520.45s\ttraining loss:\t3.344768\n",
      "Done 3880 batches in 521.73s\ttraining loss:\t3.344720\n",
      "Done 3890 batches in 523.11s\ttraining loss:\t3.344665\n",
      "Done 3900 batches in 524.68s\ttraining loss:\t3.344803\n",
      "Done 3910 batches in 525.92s\ttraining loss:\t3.344779\n",
      "Done 3920 batches in 527.05s\ttraining loss:\t3.344639\n",
      "Done 3930 batches in 528.27s\ttraining loss:\t3.344651\n",
      "Done 3940 batches in 529.71s\ttraining loss:\t3.344725\n",
      "Done 3950 batches in 531.11s\ttraining loss:\t3.344784\n",
      "Done 3960 batches in 532.41s\ttraining loss:\t3.344734\n",
      "Done 3970 batches in 533.74s\ttraining loss:\t3.344726\n",
      "Done 3980 batches in 535.28s\ttraining loss:\t3.344802\n",
      "Done 3990 batches in 536.32s\ttraining loss:\t3.344818\n",
      "Done 4000 batches in 537.53s\ttraining loss:\t3.344773\n",
      "Done 4010 batches in 538.85s\ttraining loss:\t3.344786\n",
      "Done 4020 batches in 540.13s\ttraining loss:\t3.344689\n",
      "Done 4030 batches in 541.26s\ttraining loss:\t3.344656\n",
      "Done 4040 batches in 542.51s\ttraining loss:\t3.344600\n",
      "Done 4050 batches in 544.01s\ttraining loss:\t3.344505\n",
      "Done 4060 batches in 545.36s\ttraining loss:\t3.344438\n",
      "Done 4070 batches in 546.66s\ttraining loss:\t3.344367\n",
      "Done 4080 batches in 548.36s\ttraining loss:\t3.344390\n",
      "Done 4090 batches in 549.87s\ttraining loss:\t3.344324\n",
      "Done 4100 batches in 551.41s\ttraining loss:\t3.344302\n",
      "Done 4110 batches in 552.81s\ttraining loss:\t3.344303\n",
      "Done 4120 batches in 553.99s\ttraining loss:\t3.344184\n",
      "Done 4130 batches in 555.43s\ttraining loss:\t3.344111\n",
      "Done 4140 batches in 556.93s\ttraining loss:\t3.344036\n",
      "Done 4150 batches in 558.42s\ttraining loss:\t3.343997\n",
      "Done 4160 batches in 559.81s\ttraining loss:\t3.344063\n",
      "Done 4170 batches in 561.26s\ttraining loss:\t3.344081\n",
      "Done 4180 batches in 562.77s\ttraining loss:\t3.344048\n",
      "Done 4190 batches in 564.09s\ttraining loss:\t3.344002\n",
      "Done 4200 batches in 565.35s\ttraining loss:\t3.343957\n",
      "Done 4210 batches in 566.65s\ttraining loss:\t3.343899\n",
      "Done 4220 batches in 568.00s\ttraining loss:\t3.343883\n",
      "Done 4230 batches in 569.21s\ttraining loss:\t3.343776\n",
      "Done 4240 batches in 570.55s\ttraining loss:\t3.343854\n",
      "Done 4250 batches in 571.92s\ttraining loss:\t3.343797\n",
      "Done 4260 batches in 573.41s\ttraining loss:\t3.343694\n",
      "Done 4270 batches in 574.66s\ttraining loss:\t3.343625\n",
      "Done 4280 batches in 575.71s\ttraining loss:\t3.343624\n",
      "Done 4290 batches in 577.08s\ttraining loss:\t3.343568\n",
      "Done 4300 batches in 578.58s\ttraining loss:\t3.343520\n",
      "Done 4310 batches in 579.65s\ttraining loss:\t3.343454\n",
      "Done 4320 batches in 581.41s\ttraining loss:\t3.343453\n",
      "Done 4330 batches in 582.88s\ttraining loss:\t3.343396\n",
      "Done 4340 batches in 584.12s\ttraining loss:\t3.343397\n",
      "Done 4350 batches in 585.60s\ttraining loss:\t3.343433\n",
      "Done 4360 batches in 586.81s\ttraining loss:\t3.343408\n",
      "Done 4370 batches in 588.51s\ttraining loss:\t3.343401\n",
      "Done 4380 batches in 589.93s\ttraining loss:\t3.343350\n",
      "Done 4390 batches in 591.33s\ttraining loss:\t3.343267\n",
      "Done 4400 batches in 592.71s\ttraining loss:\t3.343237\n",
      "Done 4410 batches in 594.18s\ttraining loss:\t3.343280\n",
      "Done 4420 batches in 595.29s\ttraining loss:\t3.343280\n",
      "Done 4430 batches in 596.68s\ttraining loss:\t3.343227\n",
      "Done 4440 batches in 597.89s\ttraining loss:\t3.343226\n",
      "Done 4450 batches in 599.17s\ttraining loss:\t3.343202\n",
      "Done 4460 batches in 600.61s\ttraining loss:\t3.343163\n",
      "Done 4470 batches in 602.16s\ttraining loss:\t3.343191\n",
      "Done 4480 batches in 603.42s\ttraining loss:\t3.343225\n",
      "Done 4490 batches in 604.95s\ttraining loss:\t3.343174\n",
      "Done 4500 batches in 606.17s\ttraining loss:\t3.343144\n",
      "Done 4510 batches in 607.43s\ttraining loss:\t3.343125\n",
      "Done 4520 batches in 608.95s\ttraining loss:\t3.343138\n",
      "Done 4530 batches in 610.33s\ttraining loss:\t3.343074\n",
      "Done 4540 batches in 611.84s\ttraining loss:\t3.343105\n",
      "Done 4550 batches in 613.29s\ttraining loss:\t3.343094\n",
      "Done 4560 batches in 614.81s\ttraining loss:\t3.343053\n",
      "Done 4570 batches in 616.17s\ttraining loss:\t3.343041\n",
      "Done 4580 batches in 617.45s\ttraining loss:\t3.343013\n",
      "Done 4590 batches in 618.84s\ttraining loss:\t3.342998\n",
      "Done 4600 batches in 620.36s\ttraining loss:\t3.343015\n",
      "Done 4610 batches in 621.74s\ttraining loss:\t3.343052\n",
      "Done 4620 batches in 623.17s\ttraining loss:\t3.343089\n",
      "Done 4630 batches in 624.34s\ttraining loss:\t3.343019\n",
      "Done 4640 batches in 625.56s\ttraining loss:\t3.342999\n",
      "Done 4650 batches in 626.83s\ttraining loss:\t3.342982\n",
      "Done 4660 batches in 628.02s\ttraining loss:\t3.342952\n",
      "Done 4670 batches in 629.36s\ttraining loss:\t3.342875\n",
      "Done 4680 batches in 630.58s\ttraining loss:\t3.342927\n",
      "Done 4690 batches in 632.16s\ttraining loss:\t3.342964\n",
      "Done 4700 batches in 633.52s\ttraining loss:\t3.342933\n",
      "Done 4710 batches in 634.58s\ttraining loss:\t3.342839\n",
      "Done 4720 batches in 636.02s\ttraining loss:\t3.342856\n",
      "Done 4730 batches in 637.63s\ttraining loss:\t3.342942\n",
      "Done 4740 batches in 638.94s\ttraining loss:\t3.342964\n",
      "Done 4750 batches in 640.14s\ttraining loss:\t3.342943\n",
      "Done 4760 batches in 641.68s\ttraining loss:\t3.342871\n",
      "Done 4770 batches in 642.98s\ttraining loss:\t3.342841\n",
      "Done 4780 batches in 644.23s\ttraining loss:\t3.342737\n",
      "Done 4790 batches in 645.52s\ttraining loss:\t3.342701\n",
      "Done 4800 batches in 647.15s\ttraining loss:\t3.342767\n",
      "Done 4810 batches in 648.31s\ttraining loss:\t3.342697\n",
      "Done 4820 batches in 649.78s\ttraining loss:\t3.342641\n",
      "Done 4830 batches in 651.17s\ttraining loss:\t3.342604\n",
      "Done 4840 batches in 652.27s\ttraining loss:\t3.342603\n",
      "Done 4850 batches in 653.48s\ttraining loss:\t3.342577\n",
      "Done 4860 batches in 655.00s\ttraining loss:\t3.342594\n",
      "Done 4870 batches in 656.38s\ttraining loss:\t3.342554\n",
      "Done 4880 batches in 657.74s\ttraining loss:\t3.342577\n",
      "Done 4890 batches in 659.19s\ttraining loss:\t3.342534\n",
      "Done 4900 batches in 660.48s\ttraining loss:\t3.342449\n",
      "Done 4910 batches in 661.68s\ttraining loss:\t3.342422\n",
      "Done 4920 batches in 663.16s\ttraining loss:\t3.342420\n",
      "Done 4930 batches in 664.47s\ttraining loss:\t3.342415\n",
      "Done 4940 batches in 665.88s\ttraining loss:\t3.342435\n",
      "Done 4950 batches in 667.41s\ttraining loss:\t3.342477\n",
      "Done 4960 batches in 669.01s\ttraining loss:\t3.342484\n",
      "Done 4970 batches in 670.28s\ttraining loss:\t3.342390\n",
      "Done 4980 batches in 671.58s\ttraining loss:\t3.342377\n",
      "Done 4990 batches in 673.05s\ttraining loss:\t3.342373\n",
      "Done 5000 batches in 674.55s\ttraining loss:\t3.342440\n",
      "Done 5010 batches in 675.92s\ttraining loss:\t3.342366\n",
      "Done 5020 batches in 677.37s\ttraining loss:\t3.342361\n",
      "Done 5030 batches in 678.78s\ttraining loss:\t3.342244\n",
      "Done 5040 batches in 680.00s\ttraining loss:\t3.342129\n",
      "Done 5050 batches in 681.17s\ttraining loss:\t3.342149\n",
      "Done 5060 batches in 682.43s\ttraining loss:\t3.342138\n",
      "Done 5070 batches in 684.01s\ttraining loss:\t3.342113\n",
      "Done 5080 batches in 685.46s\ttraining loss:\t3.342123\n",
      "Done 5090 batches in 686.88s\ttraining loss:\t3.342127\n",
      "Done 5100 batches in 688.30s\ttraining loss:\t3.342112\n",
      "Done 5110 batches in 689.53s\ttraining loss:\t3.342042\n",
      "Done 5120 batches in 691.17s\ttraining loss:\t3.342075\n",
      "Done 5130 batches in 692.39s\ttraining loss:\t3.342065\n",
      "Done 5140 batches in 693.88s\ttraining loss:\t3.341988\n",
      "Done 5150 batches in 695.26s\ttraining loss:\t3.341987\n",
      "Done 5160 batches in 697.14s\ttraining loss:\t3.341947\n",
      "Done 5170 batches in 698.38s\ttraining loss:\t3.341920\n",
      "Done 5180 batches in 699.59s\ttraining loss:\t3.341882\n",
      "Done 5190 batches in 701.00s\ttraining loss:\t3.341861\n",
      "Done 5200 batches in 702.61s\ttraining loss:\t3.341847\n",
      "Done 5210 batches in 704.11s\ttraining loss:\t3.341830\n",
      "Done 5220 batches in 705.59s\ttraining loss:\t3.341820\n",
      "Done 5230 batches in 706.91s\ttraining loss:\t3.341870\n",
      "Done 5240 batches in 708.26s\ttraining loss:\t3.341804\n",
      "Done 5250 batches in 709.67s\ttraining loss:\t3.341797\n",
      "Done 5260 batches in 711.01s\ttraining loss:\t3.341785\n",
      "Done 5270 batches in 712.63s\ttraining loss:\t3.341826\n",
      "Done 5280 batches in 713.84s\ttraining loss:\t3.341794\n",
      "Done 5290 batches in 715.29s\ttraining loss:\t3.341839\n",
      "Done 5300 batches in 716.65s\ttraining loss:\t3.341828\n",
      "Done 5310 batches in 717.84s\ttraining loss:\t3.341806\n",
      "Done 5320 batches in 719.35s\ttraining loss:\t3.341821\n",
      "Done 5330 batches in 720.78s\ttraining loss:\t3.341820\n",
      "Done 5340 batches in 721.92s\ttraining loss:\t3.341848\n",
      "Done 5350 batches in 723.15s\ttraining loss:\t3.341820\n",
      "Done 5360 batches in 724.63s\ttraining loss:\t3.341837\n",
      "Done 5370 batches in 726.12s\ttraining loss:\t3.341885\n",
      "Done 5380 batches in 727.54s\ttraining loss:\t3.341870\n",
      "Done 5390 batches in 728.75s\ttraining loss:\t3.341879\n",
      "Done 5400 batches in 730.13s\ttraining loss:\t3.341892\n",
      "Done 5410 batches in 731.50s\ttraining loss:\t3.341901\n",
      "Done 5420 batches in 732.98s\ttraining loss:\t3.341873\n",
      "Done 5430 batches in 734.15s\ttraining loss:\t3.341853\n",
      "Done 5440 batches in 735.48s\ttraining loss:\t3.341784\n",
      "Done 5450 batches in 736.89s\ttraining loss:\t3.341807\n",
      "Done 5460 batches in 738.23s\ttraining loss:\t3.341844\n",
      "Done 5470 batches in 739.60s\ttraining loss:\t3.341781\n",
      "Done 5480 batches in 741.21s\ttraining loss:\t3.341723\n",
      "Done 5490 batches in 742.54s\ttraining loss:\t3.341721\n",
      "Done 5500 batches in 744.00s\ttraining loss:\t3.341743\n",
      "Done 5510 batches in 745.55s\ttraining loss:\t3.341768\n",
      "Done 5520 batches in 746.80s\ttraining loss:\t3.341758\n",
      "Done 5530 batches in 748.19s\ttraining loss:\t3.341783\n",
      "Done 5540 batches in 749.55s\ttraining loss:\t3.341771\n",
      "Done 5550 batches in 751.32s\ttraining loss:\t3.341762\n",
      "Done 5560 batches in 752.79s\ttraining loss:\t3.341839\n",
      "Done 5570 batches in 754.08s\ttraining loss:\t3.341819\n",
      "Done 5580 batches in 755.54s\ttraining loss:\t3.341813\n",
      "Done 5590 batches in 756.80s\ttraining loss:\t3.341789\n",
      "Done 5600 batches in 757.90s\ttraining loss:\t3.341747\n",
      "Done 5610 batches in 759.03s\ttraining loss:\t3.341735\n",
      "Done 5620 batches in 760.54s\ttraining loss:\t3.341718\n",
      "Done 5630 batches in 761.89s\ttraining loss:\t3.341735\n",
      "Done 5640 batches in 763.06s\ttraining loss:\t3.341765\n",
      "Done 5650 batches in 764.41s\ttraining loss:\t3.341707\n",
      "Done 5660 batches in 765.82s\ttraining loss:\t3.341701\n",
      "Done 5670 batches in 767.25s\ttraining loss:\t3.341679\n",
      "Done 5680 batches in 768.41s\ttraining loss:\t3.341716\n",
      "Done 5690 batches in 769.64s\ttraining loss:\t3.341674\n",
      "Done 5700 batches in 771.28s\ttraining loss:\t3.341693\n",
      "Done 5710 batches in 772.48s\ttraining loss:\t3.341704\n",
      "Done 5720 batches in 774.10s\ttraining loss:\t3.341689\n",
      "Done 5730 batches in 775.56s\ttraining loss:\t3.341626\n",
      "Done 5740 batches in 776.80s\ttraining loss:\t3.341653\n",
      "Done 5750 batches in 778.29s\ttraining loss:\t3.341639\n",
      "Done 5760 batches in 779.47s\ttraining loss:\t3.341625\n",
      "Done 5770 batches in 780.92s\ttraining loss:\t3.341603\n",
      "Done 5780 batches in 782.12s\ttraining loss:\t3.341559\n",
      "Done 5790 batches in 783.56s\ttraining loss:\t3.341553\n",
      "Done 5800 batches in 784.67s\ttraining loss:\t3.341548\n",
      "Done 5810 batches in 786.24s\ttraining loss:\t3.341578\n",
      "Done 5820 batches in 787.68s\ttraining loss:\t3.341562\n",
      "Done 5830 batches in 789.25s\ttraining loss:\t3.341484\n",
      "Done 5840 batches in 790.77s\ttraining loss:\t3.341483\n",
      "Done 5850 batches in 792.35s\ttraining loss:\t3.341468\n",
      "Done 5860 batches in 793.68s\ttraining loss:\t3.341486\n",
      "Done 5870 batches in 794.82s\ttraining loss:\t3.341446\n",
      "Done 5880 batches in 796.07s\ttraining loss:\t3.341420\n",
      "Done 5890 batches in 797.68s\ttraining loss:\t3.341370\n",
      "Done 5900 batches in 799.16s\ttraining loss:\t3.341387\n",
      "Done 5910 batches in 800.64s\ttraining loss:\t3.341338\n",
      "Done 5920 batches in 802.09s\ttraining loss:\t3.341376\n",
      "Done 5930 batches in 803.25s\ttraining loss:\t3.341387\n",
      "Done 5940 batches in 804.34s\ttraining loss:\t3.341292\n",
      "Done 5950 batches in 805.54s\ttraining loss:\t3.341254\n",
      "Done 5960 batches in 806.71s\ttraining loss:\t3.341221\n",
      "Done 5970 batches in 808.17s\ttraining loss:\t3.341182\n",
      "Done 5980 batches in 809.60s\ttraining loss:\t3.341181\n",
      "Done 5990 batches in 810.80s\ttraining loss:\t3.341195\n",
      "Done 6000 batches in 812.18s\ttraining loss:\t3.341194\n",
      "Done 6010 batches in 813.55s\ttraining loss:\t3.341135\n",
      "Done 6020 batches in 814.79s\ttraining loss:\t3.341164\n",
      "Done 6030 batches in 816.26s\ttraining loss:\t3.341087\n",
      "Done 6040 batches in 817.59s\ttraining loss:\t3.341075\n",
      "Done 6050 batches in 819.25s\ttraining loss:\t3.341093\n",
      "Done 6060 batches in 820.62s\ttraining loss:\t3.341041\n",
      "Done 6070 batches in 822.03s\ttraining loss:\t3.340971\n",
      "Done 6080 batches in 823.19s\ttraining loss:\t3.340937\n",
      "Done 6090 batches in 824.55s\ttraining loss:\t3.340904\n",
      "Done 6100 batches in 826.04s\ttraining loss:\t3.340847\n",
      "Done 6110 batches in 827.35s\ttraining loss:\t3.340811\n",
      "Done 6120 batches in 828.60s\ttraining loss:\t3.340789\n",
      "Done 6130 batches in 829.84s\ttraining loss:\t3.340758\n",
      "Done 6140 batches in 831.48s\ttraining loss:\t3.340753\n",
      "Done 6150 batches in 832.61s\ttraining loss:\t3.340752\n",
      "Done 6160 batches in 834.08s\ttraining loss:\t3.340745\n",
      "Done 6170 batches in 835.43s\ttraining loss:\t3.340722\n",
      "Done 6180 batches in 836.59s\ttraining loss:\t3.340634\n",
      "Done 6190 batches in 838.00s\ttraining loss:\t3.340662\n",
      "Done 6200 batches in 839.34s\ttraining loss:\t3.340665\n",
      "Done 6210 batches in 840.53s\ttraining loss:\t3.340673\n",
      "Done 6220 batches in 841.78s\ttraining loss:\t3.340680\n",
      "Done 6230 batches in 842.97s\ttraining loss:\t3.340647\n",
      "Done 6240 batches in 844.36s\ttraining loss:\t3.340659\n",
      "Done 6250 batches in 845.56s\ttraining loss:\t3.340526\n",
      "Done 6260 batches in 846.72s\ttraining loss:\t3.340529\n",
      "Done 6270 batches in 848.23s\ttraining loss:\t3.340510\n",
      "Done 6280 batches in 849.81s\ttraining loss:\t3.340463\n",
      "Done 6290 batches in 850.91s\ttraining loss:\t3.340466\n",
      "Done 6300 batches in 852.27s\ttraining loss:\t3.340425\n",
      "Done 6310 batches in 853.63s\ttraining loss:\t3.340425\n",
      "Done 6320 batches in 854.85s\ttraining loss:\t3.340392\n",
      "Done 6330 batches in 856.13s\ttraining loss:\t3.340393\n",
      "Done 6340 batches in 857.67s\ttraining loss:\t3.340324\n",
      "Done 6350 batches in 858.68s\ttraining loss:\t3.340242\n",
      "Done 6360 batches in 859.91s\ttraining loss:\t3.340289\n",
      "Done 6370 batches in 861.08s\ttraining loss:\t3.340251\n",
      "Done 6380 batches in 862.43s\ttraining loss:\t3.340261\n",
      "Done 6390 batches in 863.79s\ttraining loss:\t3.340266\n",
      "Done 6400 batches in 864.89s\ttraining loss:\t3.340244\n",
      "Done 6410 batches in 865.96s\ttraining loss:\t3.340227\n",
      "Done 6420 batches in 867.14s\ttraining loss:\t3.340181\n",
      "Done 6430 batches in 868.44s\ttraining loss:\t3.340150\n",
      "Done 6440 batches in 869.91s\ttraining loss:\t3.340123\n",
      "Done 6450 batches in 871.33s\ttraining loss:\t3.340046\n",
      "Done 6460 batches in 872.37s\ttraining loss:\t3.339981\n",
      "Done 6470 batches in 873.72s\ttraining loss:\t3.339942\n",
      "Done 6480 batches in 875.10s\ttraining loss:\t3.339908\n",
      "Done 6490 batches in 876.19s\ttraining loss:\t3.339879\n",
      "Done 6500 batches in 877.33s\ttraining loss:\t3.339880\n",
      "Done 6510 batches in 878.81s\ttraining loss:\t3.339846\n",
      "Done 6520 batches in 880.16s\ttraining loss:\t3.339797\n",
      "Done 6530 batches in 881.40s\ttraining loss:\t3.339795\n",
      "Done 6540 batches in 882.86s\ttraining loss:\t3.339767\n",
      "Done 6550 batches in 884.52s\ttraining loss:\t3.339777\n",
      "Done 6560 batches in 885.85s\ttraining loss:\t3.339753\n",
      "Done 6570 batches in 887.11s\ttraining loss:\t3.339834\n",
      "Done 6580 batches in 888.39s\ttraining loss:\t3.339804\n",
      "Done 6590 batches in 889.94s\ttraining loss:\t3.339822\n",
      "Done 6600 batches in 891.08s\ttraining loss:\t3.339826\n",
      "Done 6610 batches in 892.22s\ttraining loss:\t3.339839\n",
      "Done 6620 batches in 893.57s\ttraining loss:\t3.339834\n",
      "Done 6630 batches in 895.17s\ttraining loss:\t3.339859\n",
      "Done 6640 batches in 896.51s\ttraining loss:\t3.339766\n",
      "Done 6650 batches in 897.98s\ttraining loss:\t3.339737\n",
      "Done 6660 batches in 899.29s\ttraining loss:\t3.339733\n",
      "Done 6670 batches in 900.68s\ttraining loss:\t3.339734\n",
      "Done 6680 batches in 902.14s\ttraining loss:\t3.339724\n",
      "Done 6690 batches in 903.87s\ttraining loss:\t3.339744\n",
      "Done 6700 batches in 905.38s\ttraining loss:\t3.339747\n",
      "Done 6710 batches in 906.43s\ttraining loss:\t3.339686\n",
      "Done 6720 batches in 907.82s\ttraining loss:\t3.339684\n",
      "Done 6730 batches in 909.27s\ttraining loss:\t3.339683\n",
      "Done 6740 batches in 910.79s\ttraining loss:\t3.339662\n",
      "Done 6750 batches in 912.17s\ttraining loss:\t3.339662\n",
      "Done 6760 batches in 913.46s\ttraining loss:\t3.339665\n",
      "Done 6770 batches in 914.70s\ttraining loss:\t3.339616\n",
      "Done 6780 batches in 916.18s\ttraining loss:\t3.339568\n",
      "Done 6790 batches in 917.57s\ttraining loss:\t3.339520\n",
      "Done 6800 batches in 919.10s\ttraining loss:\t3.339504\n",
      "Done 6810 batches in 920.48s\ttraining loss:\t3.339480\n",
      "Done 6820 batches in 921.92s\ttraining loss:\t3.339437\n",
      "Done 6830 batches in 923.29s\ttraining loss:\t3.339460\n",
      "Done 6840 batches in 924.62s\ttraining loss:\t3.339472\n",
      "Done 6850 batches in 925.60s\ttraining loss:\t3.339453\n",
      "Done 6860 batches in 926.90s\ttraining loss:\t3.339415\n",
      "Done 6870 batches in 928.24s\ttraining loss:\t3.339407\n",
      "Done 6880 batches in 929.64s\ttraining loss:\t3.339435\n",
      "Done 6890 batches in 930.81s\ttraining loss:\t3.339399\n",
      "Done 6900 batches in 932.20s\ttraining loss:\t3.339386\n",
      "Done 6910 batches in 933.73s\ttraining loss:\t3.339454\n",
      "Done 6920 batches in 934.95s\ttraining loss:\t3.339505\n",
      "Done 6930 batches in 936.45s\ttraining loss:\t3.339442\n",
      "Done 6940 batches in 938.09s\ttraining loss:\t3.339443\n",
      "Done 6950 batches in 939.70s\ttraining loss:\t3.339392\n",
      "Done 6960 batches in 941.29s\ttraining loss:\t3.339394\n",
      "Done 6970 batches in 942.85s\ttraining loss:\t3.339341\n",
      "Done 6980 batches in 944.26s\ttraining loss:\t3.339318\n",
      "Done 6990 batches in 945.59s\ttraining loss:\t3.339316\n",
      "Done 7000 batches in 946.92s\ttraining loss:\t3.339289\n",
      "Done 7010 batches in 948.18s\ttraining loss:\t3.339320\n",
      "Done 7020 batches in 949.39s\ttraining loss:\t3.339324\n",
      "Done 7030 batches in 951.07s\ttraining loss:\t3.339385\n",
      "Done 7040 batches in 952.35s\ttraining loss:\t3.339343\n",
      "Done 7050 batches in 953.90s\ttraining loss:\t3.339310\n",
      "Done 7060 batches in 955.51s\ttraining loss:\t3.339287\n",
      "Done 7070 batches in 956.67s\ttraining loss:\t3.339277\n",
      "Done 7080 batches in 958.03s\ttraining loss:\t3.339214\n",
      "Done 7090 batches in 959.41s\ttraining loss:\t3.339211\n",
      "Done 7100 batches in 960.72s\ttraining loss:\t3.339151\n",
      "Done 7110 batches in 962.00s\ttraining loss:\t3.339149\n",
      "Done 7120 batches in 963.15s\ttraining loss:\t3.339182\n",
      "Done 7130 batches in 964.99s\ttraining loss:\t3.339234\n",
      "Done 7140 batches in 966.30s\ttraining loss:\t3.339249\n",
      "Done 7150 batches in 967.73s\ttraining loss:\t3.339246\n",
      "Done 7160 batches in 969.11s\ttraining loss:\t3.339215\n",
      "Done 7170 batches in 970.21s\ttraining loss:\t3.339205\n",
      "Done 7180 batches in 971.34s\ttraining loss:\t3.339198\n",
      "Done 7190 batches in 972.75s\ttraining loss:\t3.339155\n",
      "Done 7200 batches in 974.27s\ttraining loss:\t3.339108\n",
      "Done 7210 batches in 975.49s\ttraining loss:\t3.339123\n",
      "Done 7220 batches in 976.78s\ttraining loss:\t3.339166\n",
      "Done 7230 batches in 978.37s\ttraining loss:\t3.339262\n",
      "Done 7240 batches in 979.56s\ttraining loss:\t3.339253\n",
      "Done 7250 batches in 980.66s\ttraining loss:\t3.339224\n",
      "Done 7260 batches in 982.03s\ttraining loss:\t3.339203\n",
      "Done 7270 batches in 983.33s\ttraining loss:\t3.339167\n",
      "Done 7280 batches in 984.57s\ttraining loss:\t3.339158\n",
      "Done 7290 batches in 986.04s\ttraining loss:\t3.339186\n",
      "Done 7300 batches in 987.29s\ttraining loss:\t3.339198\n",
      "Done 7310 batches in 989.09s\ttraining loss:\t3.339234\n",
      "Done 7320 batches in 990.19s\ttraining loss:\t3.339239\n",
      "Done 7330 batches in 991.57s\ttraining loss:\t3.339260\n",
      "Done 7340 batches in 993.09s\ttraining loss:\t3.339269\n",
      "Done 7350 batches in 994.69s\ttraining loss:\t3.339268\n",
      "Done 7360 batches in 995.85s\ttraining loss:\t3.339224\n",
      "Done 7370 batches in 997.62s\ttraining loss:\t3.339213\n",
      "Done 7380 batches in 998.86s\ttraining loss:\t3.339184\n",
      "Done 7390 batches in 1000.05s\ttraining loss:\t3.339235\n",
      "Done 7400 batches in 1001.31s\ttraining loss:\t3.339203\n",
      "Done 7410 batches in 1002.91s\ttraining loss:\t3.339276\n",
      "Done 7420 batches in 1004.13s\ttraining loss:\t3.339248\n",
      "Done 7430 batches in 1005.41s\ttraining loss:\t3.339262\n",
      "Done 7440 batches in 1006.77s\ttraining loss:\t3.339273\n",
      "Done 7450 batches in 1008.09s\ttraining loss:\t3.339292\n",
      "Done 7460 batches in 1009.27s\ttraining loss:\t3.339226\n",
      "Done 7470 batches in 1010.54s\ttraining loss:\t3.339244\n",
      "Done 7480 batches in 1011.83s\ttraining loss:\t3.339202\n",
      "Done 7490 batches in 1013.21s\ttraining loss:\t3.339200\n",
      "Done 7500 batches in 1014.46s\ttraining loss:\t3.339174\n",
      "Done 7510 batches in 1015.87s\ttraining loss:\t3.339143\n",
      "Done 7520 batches in 1017.24s\ttraining loss:\t3.339109\n",
      "Done 7530 batches in 1018.54s\ttraining loss:\t3.339128\n",
      "Done 7540 batches in 1019.84s\ttraining loss:\t3.339134\n",
      "Done 7550 batches in 1021.40s\ttraining loss:\t3.339134\n",
      "Done 7560 batches in 1023.07s\ttraining loss:\t3.339102\n",
      "Done 7570 batches in 1024.43s\ttraining loss:\t3.339087\n",
      "Done 7580 batches in 1025.72s\ttraining loss:\t3.339069\n",
      "Done 7590 batches in 1027.10s\ttraining loss:\t3.339050\n",
      "Done 7600 batches in 1028.46s\ttraining loss:\t3.339047\n",
      "Done 7610 batches in 1029.89s\ttraining loss:\t3.339006\n",
      "Done 7620 batches in 1031.31s\ttraining loss:\t3.339004\n",
      "Done 7630 batches in 1032.84s\ttraining loss:\t3.338985\n",
      "Done 7640 batches in 1034.23s\ttraining loss:\t3.338945\n",
      "Done 7650 batches in 1035.90s\ttraining loss:\t3.338900\n",
      "Done 7660 batches in 1037.13s\ttraining loss:\t3.338907\n",
      "Done 7670 batches in 1038.53s\ttraining loss:\t3.338909\n",
      "Done 7680 batches in 1039.74s\ttraining loss:\t3.338912\n",
      "Done 7690 batches in 1041.02s\ttraining loss:\t3.338879\n",
      "Done 7700 batches in 1042.63s\ttraining loss:\t3.338944\n",
      "Done 7710 batches in 1043.99s\ttraining loss:\t3.338930\n",
      "Done 7720 batches in 1045.23s\ttraining loss:\t3.338930\n",
      "Done 7730 batches in 1046.51s\ttraining loss:\t3.338937\n",
      "Done 7740 batches in 1047.88s\ttraining loss:\t3.338882\n",
      "Done 7750 batches in 1049.32s\ttraining loss:\t3.338883\n",
      "Done 7760 batches in 1050.58s\ttraining loss:\t3.338815\n",
      "Done 7770 batches in 1051.92s\ttraining loss:\t3.338765\n",
      "Done 7780 batches in 1053.44s\ttraining loss:\t3.338745\n",
      "Done 7790 batches in 1055.00s\ttraining loss:\t3.338808\n",
      "Done 7800 batches in 1056.19s\ttraining loss:\t3.338789\n",
      "Done 7810 batches in 1057.54s\ttraining loss:\t3.338764\n",
      "Done 7820 batches in 1059.10s\ttraining loss:\t3.338785\n",
      "Done 7830 batches in 1060.44s\ttraining loss:\t3.338770\n",
      "Done 7840 batches in 1062.10s\ttraining loss:\t3.338751\n",
      "Done 7850 batches in 1063.43s\ttraining loss:\t3.338711\n",
      "Done 7860 batches in 1064.73s\ttraining loss:\t3.338687\n",
      "Done 7870 batches in 1066.04s\ttraining loss:\t3.338673\n",
      "Done 7880 batches in 1067.51s\ttraining loss:\t3.338709\n",
      "Done 7890 batches in 1068.92s\ttraining loss:\t3.338678\n",
      "Done 7900 batches in 1070.18s\ttraining loss:\t3.338640\n",
      "Done 7910 batches in 1071.80s\ttraining loss:\t3.338591\n",
      "Done 7920 batches in 1073.19s\ttraining loss:\t3.338553\n",
      "Done 7930 batches in 1074.63s\ttraining loss:\t3.338603\n",
      "Done 7940 batches in 1075.78s\ttraining loss:\t3.338586\n",
      "Done 7950 batches in 1077.11s\ttraining loss:\t3.338559\n",
      "Done 7960 batches in 1078.94s\ttraining loss:\t3.338548\n",
      "Done 7970 batches in 1080.53s\ttraining loss:\t3.338556\n",
      "Done 7980 batches in 1081.97s\ttraining loss:\t3.338558\n",
      "Done 7990 batches in 1083.35s\ttraining loss:\t3.338533\n",
      "Done 8000 batches in 1084.66s\ttraining loss:\t3.338518\n",
      "Done 8010 batches in 1085.95s\ttraining loss:\t3.338528\n",
      "Done 8020 batches in 1087.17s\ttraining loss:\t3.338495\n",
      "Done 8030 batches in 1088.53s\ttraining loss:\t3.338474\n",
      "Done 8040 batches in 1090.14s\ttraining loss:\t3.338442\n",
      "Done 8050 batches in 1091.39s\ttraining loss:\t3.338370\n",
      "Done 8060 batches in 1092.72s\ttraining loss:\t3.338366\n",
      "Done 8070 batches in 1093.86s\ttraining loss:\t3.338359\n",
      "Done 8080 batches in 1095.45s\ttraining loss:\t3.338333\n",
      "Done 8090 batches in 1096.90s\ttraining loss:\t3.338345\n",
      "Done 8100 batches in 1098.29s\ttraining loss:\t3.338427\n",
      "Done 8110 batches in 1099.67s\ttraining loss:\t3.338434\n",
      "Done 8120 batches in 1101.14s\ttraining loss:\t3.338368\n",
      "Done 8130 batches in 1102.55s\ttraining loss:\t3.338364\n",
      "Done 8140 batches in 1103.78s\ttraining loss:\t3.338299\n",
      "Done 8150 batches in 1105.31s\ttraining loss:\t3.338323\n",
      "Done 8160 batches in 1106.56s\ttraining loss:\t3.338317\n",
      "Done 8170 batches in 1107.88s\ttraining loss:\t3.338320\n",
      "Done 8180 batches in 1109.02s\ttraining loss:\t3.338336\n",
      "Done 8190 batches in 1110.22s\ttraining loss:\t3.338353\n",
      "Done 8200 batches in 1111.24s\ttraining loss:\t3.338375\n",
      "Done 8210 batches in 1112.76s\ttraining loss:\t3.338387\n",
      "Done 8220 batches in 1114.09s\ttraining loss:\t3.338397\n",
      "Done 8230 batches in 1115.50s\ttraining loss:\t3.338348\n",
      "Done 8240 batches in 1116.95s\ttraining loss:\t3.338348\n",
      "Done 8250 batches in 1118.31s\ttraining loss:\t3.338310\n",
      "Done 8260 batches in 1119.38s\ttraining loss:\t3.338317\n",
      "Done 8270 batches in 1120.60s\ttraining loss:\t3.338280\n",
      "Done 8280 batches in 1122.19s\ttraining loss:\t3.338238\n",
      "Done 8290 batches in 1123.90s\ttraining loss:\t3.338271\n",
      "Done 8300 batches in 1125.40s\ttraining loss:\t3.338221\n",
      "Done 8310 batches in 1126.71s\ttraining loss:\t3.338207\n",
      "Done 8320 batches in 1128.04s\ttraining loss:\t3.338194\n",
      "Done 8330 batches in 1129.58s\ttraining loss:\t3.338251\n",
      "Done 8340 batches in 1130.83s\ttraining loss:\t3.338240\n",
      "Done 8350 batches in 1132.24s\ttraining loss:\t3.338283\n",
      "Done 8360 batches in 1133.49s\ttraining loss:\t3.338286\n",
      "Done 8370 batches in 1134.85s\ttraining loss:\t3.338229\n",
      "Done 8380 batches in 1136.02s\ttraining loss:\t3.338242\n",
      "Done 8390 batches in 1137.26s\ttraining loss:\t3.338227\n",
      "Done 8400 batches in 1138.71s\ttraining loss:\t3.338166\n",
      "Done 8410 batches in 1140.43s\ttraining loss:\t3.338144\n",
      "Done 8420 batches in 1141.50s\ttraining loss:\t3.338127\n",
      "Done 8430 batches in 1143.02s\ttraining loss:\t3.338180\n",
      "Done 8440 batches in 1144.37s\ttraining loss:\t3.338156\n",
      "Done 8450 batches in 1145.47s\ttraining loss:\t3.338122\n",
      "Done 8460 batches in 1146.73s\ttraining loss:\t3.338131\n",
      "Done 8470 batches in 1148.04s\ttraining loss:\t3.338155\n",
      "Done 8480 batches in 1149.23s\ttraining loss:\t3.338169\n",
      "Done 8490 batches in 1150.52s\ttraining loss:\t3.338191\n",
      "Done 8500 batches in 1152.04s\ttraining loss:\t3.338140\n",
      "Done 8510 batches in 1153.27s\ttraining loss:\t3.338128\n",
      "Done 8520 batches in 1154.84s\ttraining loss:\t3.338163\n",
      "Done 8530 batches in 1156.64s\ttraining loss:\t3.338133\n",
      "Done 8540 batches in 1157.90s\ttraining loss:\t3.338157\n",
      "Done 8550 batches in 1159.14s\ttraining loss:\t3.338115\n",
      "Done 8560 batches in 1160.44s\ttraining loss:\t3.338092\n",
      "Done 8570 batches in 1162.14s\ttraining loss:\t3.338070\n",
      "Done 8580 batches in 1163.83s\ttraining loss:\t3.338072\n",
      "Done 8590 batches in 1165.28s\ttraining loss:\t3.338059\n",
      "Done 8600 batches in 1166.48s\ttraining loss:\t3.338060\n",
      "Done 8610 batches in 1167.69s\ttraining loss:\t3.338031\n",
      "Done 8620 batches in 1169.25s\ttraining loss:\t3.338008\n",
      "Done 8630 batches in 1170.63s\ttraining loss:\t3.337953\n",
      "Done 8640 batches in 1172.05s\ttraining loss:\t3.337905\n",
      "Done 8650 batches in 1173.37s\ttraining loss:\t3.337897\n",
      "Done 8660 batches in 1174.78s\ttraining loss:\t3.337859\n",
      "Done 8670 batches in 1176.37s\ttraining loss:\t3.337887\n",
      "Done 8680 batches in 1177.71s\ttraining loss:\t3.337887\n",
      "Done 8690 batches in 1178.95s\ttraining loss:\t3.337842\n",
      "Done 8700 batches in 1180.28s\ttraining loss:\t3.337829\n",
      "Done 8710 batches in 1181.50s\ttraining loss:\t3.337773\n",
      "Done 8720 batches in 1183.09s\ttraining loss:\t3.337751\n",
      "Done 8730 batches in 1184.48s\ttraining loss:\t3.337750\n",
      "Done 8740 batches in 1185.94s\ttraining loss:\t3.337724\n",
      "Done 8750 batches in 1187.30s\ttraining loss:\t3.337643\n",
      "Done 8760 batches in 1188.75s\ttraining loss:\t3.337628\n",
      "Done 8770 batches in 1190.15s\ttraining loss:\t3.337608\n",
      "Done 8780 batches in 1191.28s\ttraining loss:\t3.337586\n",
      "Done 8790 batches in 1192.59s\ttraining loss:\t3.337565\n",
      "Done 8800 batches in 1194.02s\ttraining loss:\t3.337556\n",
      "Done 8810 batches in 1195.43s\ttraining loss:\t3.337508\n",
      "Done 8820 batches in 1196.96s\ttraining loss:\t3.337505\n",
      "Done 8830 batches in 1198.24s\ttraining loss:\t3.337475\n",
      "Done 8840 batches in 1199.32s\ttraining loss:\t3.337466\n",
      "Done 8850 batches in 1200.73s\ttraining loss:\t3.337463\n",
      "Done 8860 batches in 1201.84s\ttraining loss:\t3.337434\n",
      "Done 8870 batches in 1203.46s\ttraining loss:\t3.337412\n",
      "Done 8880 batches in 1204.63s\ttraining loss:\t3.337397\n",
      "Done 8890 batches in 1206.08s\ttraining loss:\t3.337390\n",
      "Done 8900 batches in 1207.41s\ttraining loss:\t3.337344\n",
      "Done 8910 batches in 1208.69s\ttraining loss:\t3.337330\n",
      "Done 8920 batches in 1210.06s\ttraining loss:\t3.337299\n",
      "Done 8930 batches in 1211.52s\ttraining loss:\t3.337352\n",
      "Done 8940 batches in 1212.88s\ttraining loss:\t3.337349\n",
      "Done 8950 batches in 1214.15s\ttraining loss:\t3.337329\n",
      "Done 8960 batches in 1215.64s\ttraining loss:\t3.337325\n",
      "Done 8970 batches in 1217.00s\ttraining loss:\t3.337309\n",
      "Done 8980 batches in 1218.46s\ttraining loss:\t3.337333\n",
      "Done 8990 batches in 1219.70s\ttraining loss:\t3.337343\n",
      "Done 9000 batches in 1221.06s\ttraining loss:\t3.337335\n",
      "Done 9010 batches in 1222.53s\ttraining loss:\t3.337325\n",
      "Done 9020 batches in 1223.95s\ttraining loss:\t3.337269\n",
      "Done 9030 batches in 1225.16s\ttraining loss:\t3.337283\n",
      "Done 9040 batches in 1226.38s\ttraining loss:\t3.337223\n",
      "Done 9050 batches in 1227.90s\ttraining loss:\t3.337206\n",
      "Done 9060 batches in 1229.40s\ttraining loss:\t3.337189\n",
      "Done 9070 batches in 1230.87s\ttraining loss:\t3.337169\n",
      "Done 9080 batches in 1232.28s\ttraining loss:\t3.337202\n",
      "Done 9090 batches in 1233.37s\ttraining loss:\t3.337207\n",
      "Done 9100 batches in 1235.07s\ttraining loss:\t3.337222\n",
      "Done 9110 batches in 1236.37s\ttraining loss:\t3.337231\n",
      "Done 9120 batches in 1237.79s\ttraining loss:\t3.337217\n",
      "Done 9130 batches in 1238.81s\ttraining loss:\t3.337230\n",
      "Done 9140 batches in 1240.23s\ttraining loss:\t3.337181\n",
      "Done 9150 batches in 1241.56s\ttraining loss:\t3.337144\n",
      "Done 9160 batches in 1243.09s\ttraining loss:\t3.337169\n",
      "Done 9170 batches in 1244.51s\ttraining loss:\t3.337117\n",
      "Done 9180 batches in 1246.06s\ttraining loss:\t3.337133\n",
      "Done 9190 batches in 1247.54s\ttraining loss:\t3.337130\n",
      "Done 9200 batches in 1248.83s\ttraining loss:\t3.337076\n",
      "Done 9210 batches in 1250.28s\ttraining loss:\t3.337081\n",
      "Done 9220 batches in 1251.48s\ttraining loss:\t3.337040\n",
      "Done 9230 batches in 1252.85s\ttraining loss:\t3.336999\n",
      "Done 9240 batches in 1254.28s\ttraining loss:\t3.337003\n",
      "Done 9250 batches in 1255.74s\ttraining loss:\t3.336997\n",
      "Done 9260 batches in 1257.26s\ttraining loss:\t3.336985\n",
      "Done 9270 batches in 1258.50s\ttraining loss:\t3.336953\n",
      "Done 9280 batches in 1259.88s\ttraining loss:\t3.336960\n",
      "Done 9290 batches in 1261.14s\ttraining loss:\t3.336939\n",
      "Done 9300 batches in 1262.59s\ttraining loss:\t3.336923\n",
      "Done 9310 batches in 1264.09s\ttraining loss:\t3.336866\n",
      "Done 9320 batches in 1265.37s\ttraining loss:\t3.336870\n",
      "Done 9330 batches in 1267.06s\ttraining loss:\t3.336845\n",
      "Done 9340 batches in 1268.44s\ttraining loss:\t3.336844\n",
      "Done 9350 batches in 1269.85s\ttraining loss:\t3.336851\n",
      "Done 9360 batches in 1271.14s\ttraining loss:\t3.336821\n",
      "Done 9370 batches in 1272.63s\ttraining loss:\t3.336836\n",
      "Done 9380 batches in 1274.02s\ttraining loss:\t3.336869\n",
      "Done 9390 batches in 1275.21s\ttraining loss:\t3.336885\n",
      "Done 9400 batches in 1276.65s\ttraining loss:\t3.336876\n",
      "Done 9410 batches in 1278.10s\ttraining loss:\t3.336873\n",
      "Done 9420 batches in 1279.29s\ttraining loss:\t3.336803\n",
      "Done 9430 batches in 1280.77s\ttraining loss:\t3.336771\n",
      "Done 9440 batches in 1282.28s\ttraining loss:\t3.336792\n",
      "Done 9450 batches in 1283.68s\ttraining loss:\t3.336753\n",
      "Done 9460 batches in 1284.97s\ttraining loss:\t3.336719\n",
      "Done 9470 batches in 1286.13s\ttraining loss:\t3.336714\n",
      "Done 9480 batches in 1287.32s\ttraining loss:\t3.336745\n",
      "Done 9490 batches in 1288.42s\ttraining loss:\t3.336722\n",
      "Done 9500 batches in 1289.76s\ttraining loss:\t3.336703\n",
      "Done 9510 batches in 1291.05s\ttraining loss:\t3.336720\n",
      "Done 9520 batches in 1292.37s\ttraining loss:\t3.336719\n",
      "Done 9530 batches in 1293.65s\ttraining loss:\t3.336729\n",
      "Done 9540 batches in 1295.05s\ttraining loss:\t3.336770\n",
      "Done 9550 batches in 1296.22s\ttraining loss:\t3.336703\n",
      "Done 9560 batches in 1297.50s\ttraining loss:\t3.336698\n",
      "Done 9570 batches in 1298.82s\ttraining loss:\t3.336667\n",
      "Done 9580 batches in 1300.26s\ttraining loss:\t3.336690\n",
      "Done 9590 batches in 1301.55s\ttraining loss:\t3.336712\n",
      "Done 9600 batches in 1302.91s\ttraining loss:\t3.336711\n",
      "Done 9610 batches in 1304.31s\ttraining loss:\t3.336737\n",
      "Done 9620 batches in 1305.86s\ttraining loss:\t3.336724\n",
      "Done 9630 batches in 1307.51s\ttraining loss:\t3.336710\n",
      "Done 9640 batches in 1308.78s\ttraining loss:\t3.336707\n",
      "Done 9650 batches in 1310.21s\ttraining loss:\t3.336715\n",
      "Done 9660 batches in 1311.58s\ttraining loss:\t3.336731\n",
      "Done 9670 batches in 1312.82s\ttraining loss:\t3.336739\n",
      "Done 9680 batches in 1314.37s\ttraining loss:\t3.336763\n",
      "Done 9690 batches in 1315.68s\ttraining loss:\t3.336762\n",
      "Done 9700 batches in 1316.97s\ttraining loss:\t3.336782\n",
      "Done 9710 batches in 1318.20s\ttraining loss:\t3.336774\n",
      "Done 9720 batches in 1319.48s\ttraining loss:\t3.336745\n",
      "Done 9730 batches in 1321.07s\ttraining loss:\t3.336751\n",
      "Done 9740 batches in 1322.46s\ttraining loss:\t3.336730\n",
      "Done 9750 batches in 1323.71s\ttraining loss:\t3.336695\n",
      "Done 9760 batches in 1325.09s\ttraining loss:\t3.336662\n",
      "Done 9770 batches in 1326.47s\ttraining loss:\t3.336672\n",
      "Done 9780 batches in 1327.98s\ttraining loss:\t3.336659\n",
      "Done 9790 batches in 1329.51s\ttraining loss:\t3.336692\n",
      "Done 9800 batches in 1330.75s\ttraining loss:\t3.336685\n",
      "Done 9810 batches in 1332.26s\ttraining loss:\t3.336704\n",
      "Done 9820 batches in 1333.61s\ttraining loss:\t3.336702\n",
      "Done 9830 batches in 1335.11s\ttraining loss:\t3.336682\n",
      "Done 9840 batches in 1336.64s\ttraining loss:\t3.336644\n",
      "Done 9850 batches in 1338.06s\ttraining loss:\t3.336648\n",
      "Done 9860 batches in 1339.52s\ttraining loss:\t3.336599\n",
      "Done 9870 batches in 1340.65s\ttraining loss:\t3.336573\n",
      "Done 9880 batches in 1342.14s\ttraining loss:\t3.336544\n",
      "Done 9890 batches in 1343.62s\ttraining loss:\t3.336525\n",
      "Done 9900 batches in 1345.17s\ttraining loss:\t3.336531\n",
      "Done 9910 batches in 1346.20s\ttraining loss:\t3.336534\n",
      "Done 9920 batches in 1347.89s\ttraining loss:\t3.336510\n",
      "Done 9930 batches in 1349.21s\ttraining loss:\t3.336478\n",
      "Done 9940 batches in 1350.60s\ttraining loss:\t3.336459\n",
      "Done 9950 batches in 1351.95s\ttraining loss:\t3.336433\n",
      "Done 9960 batches in 1353.35s\ttraining loss:\t3.336400\n",
      "Done 9970 batches in 1354.61s\ttraining loss:\t3.336391\n",
      "Done 9980 batches in 1356.15s\ttraining loss:\t3.336395\n",
      "Done 9990 batches in 1357.42s\ttraining loss:\t3.336377\n",
      "Done 10000 batches in 1358.65s\ttraining loss:\t3.336381\n",
      "Done 10010 batches in 1359.86s\ttraining loss:\t3.336385\n",
      "Done 10020 batches in 1361.03s\ttraining loss:\t3.336366\n",
      "Done 10030 batches in 1362.28s\ttraining loss:\t3.336314\n",
      "Done 10040 batches in 1363.67s\ttraining loss:\t3.336308\n",
      "Done 10050 batches in 1365.37s\ttraining loss:\t3.336320\n",
      "Done 10060 batches in 1366.63s\ttraining loss:\t3.336315\n",
      "Done 10070 batches in 1368.00s\ttraining loss:\t3.336311\n",
      "Done 10080 batches in 1369.09s\ttraining loss:\t3.336278\n",
      "Done 10090 batches in 1370.45s\ttraining loss:\t3.336274\n",
      "Done 10100 batches in 1371.76s\ttraining loss:\t3.336331\n",
      "Done 10110 batches in 1373.01s\ttraining loss:\t3.336349\n",
      "Done 10120 batches in 1374.41s\ttraining loss:\t3.336356\n",
      "Done 10130 batches in 1375.86s\ttraining loss:\t3.336360\n",
      "Done 10140 batches in 1377.24s\ttraining loss:\t3.336337\n",
      "Done 10150 batches in 1378.44s\ttraining loss:\t3.336314\n",
      "Done 10160 batches in 1379.97s\ttraining loss:\t3.336338\n",
      "Done 10170 batches in 1381.05s\ttraining loss:\t3.336275\n",
      "Done 10180 batches in 1382.53s\ttraining loss:\t3.336297\n",
      "Done 10190 batches in 1383.71s\ttraining loss:\t3.336267\n",
      "Done 10200 batches in 1384.96s\ttraining loss:\t3.336244\n",
      "Done 10210 batches in 1386.28s\ttraining loss:\t3.336243\n",
      "Done 10220 batches in 1387.53s\ttraining loss:\t3.336204\n",
      "Done 10230 batches in 1389.01s\ttraining loss:\t3.336205\n",
      "Done 10240 batches in 1390.28s\ttraining loss:\t3.336203\n",
      "Done 10250 batches in 1391.95s\ttraining loss:\t3.336213\n",
      "Done 10260 batches in 1393.10s\ttraining loss:\t3.336177\n",
      "Done 10270 batches in 1394.45s\ttraining loss:\t3.336163\n",
      "Done 10280 batches in 1395.72s\ttraining loss:\t3.336193\n",
      "Done 10290 batches in 1396.94s\ttraining loss:\t3.336174\n",
      "Done 10300 batches in 1398.23s\ttraining loss:\t3.336162\n",
      "Done 10310 batches in 1399.62s\ttraining loss:\t3.336184\n",
      "Done 10320 batches in 1400.75s\ttraining loss:\t3.336167\n",
      "Done 10330 batches in 1402.10s\ttraining loss:\t3.336146\n",
      "Done 10340 batches in 1403.31s\ttraining loss:\t3.336167\n",
      "Done 10350 batches in 1404.52s\ttraining loss:\t3.336181\n",
      "Done 10360 batches in 1406.00s\ttraining loss:\t3.336180\n",
      "Done 10370 batches in 1407.50s\ttraining loss:\t3.336144\n",
      "Done 10380 batches in 1408.76s\ttraining loss:\t3.336132\n",
      "Done 10390 batches in 1409.96s\ttraining loss:\t3.336160\n",
      "Done 10400 batches in 1411.15s\ttraining loss:\t3.336178\n",
      "Done 10410 batches in 1412.37s\ttraining loss:\t3.336211\n",
      "Done 10420 batches in 1413.84s\ttraining loss:\t3.336219\n",
      "Done 10430 batches in 1415.03s\ttraining loss:\t3.336188\n",
      "Done 10440 batches in 1416.24s\ttraining loss:\t3.336133\n",
      "Done 10450 batches in 1417.45s\ttraining loss:\t3.336143\n",
      "Done 10460 batches in 1418.68s\ttraining loss:\t3.336157\n",
      "Done 10470 batches in 1419.91s\ttraining loss:\t3.336160\n",
      "Done 10480 batches in 1421.21s\ttraining loss:\t3.336143\n",
      "Done 10490 batches in 1422.47s\ttraining loss:\t3.336169\n",
      "Done 10500 batches in 1423.76s\ttraining loss:\t3.336143\n",
      "Done 10510 batches in 1425.36s\ttraining loss:\t3.336115\n",
      "Done 10520 batches in 1426.67s\ttraining loss:\t3.336085\n",
      "Done 10530 batches in 1428.42s\ttraining loss:\t3.336098\n",
      "Done 10540 batches in 1429.85s\ttraining loss:\t3.336120\n",
      "Done 10550 batches in 1431.38s\ttraining loss:\t3.336131\n",
      "Done 10560 batches in 1432.53s\ttraining loss:\t3.336114\n",
      "Done 10570 batches in 1433.74s\ttraining loss:\t3.336091\n",
      "Done 10580 batches in 1435.20s\ttraining loss:\t3.336093\n",
      "Done 10590 batches in 1436.52s\ttraining loss:\t3.336134\n",
      "Done 10600 batches in 1437.82s\ttraining loss:\t3.336124\n",
      "Done 10610 batches in 1439.02s\ttraining loss:\t3.336100\n",
      "Done 10620 batches in 1440.59s\ttraining loss:\t3.336098\n",
      "Done 10630 batches in 1442.10s\ttraining loss:\t3.336102\n",
      "Done 10640 batches in 1443.42s\ttraining loss:\t3.336094\n",
      "Done 10650 batches in 1444.74s\ttraining loss:\t3.336072\n",
      "Done 10660 batches in 1445.97s\ttraining loss:\t3.336078\n",
      "Done 10670 batches in 1447.53s\ttraining loss:\t3.336126\n",
      "Done 10680 batches in 1448.83s\ttraining loss:\t3.336102\n",
      "Done 10690 batches in 1450.06s\ttraining loss:\t3.336036\n",
      "Done 10700 batches in 1451.35s\ttraining loss:\t3.336005\n",
      "Done 10710 batches in 1452.55s\ttraining loss:\t3.336006\n",
      "Done 10720 batches in 1454.08s\ttraining loss:\t3.335979\n",
      "Done 10730 batches in 1455.32s\ttraining loss:\t3.335949\n",
      "Done 10740 batches in 1456.57s\ttraining loss:\t3.335949\n",
      "Done 10750 batches in 1458.02s\ttraining loss:\t3.335963\n",
      "Done 10760 batches in 1459.34s\ttraining loss:\t3.335965\n",
      "Done 10770 batches in 1460.41s\ttraining loss:\t3.335935\n",
      "Done 10780 batches in 1461.92s\ttraining loss:\t3.335933\n",
      "Done 10790 batches in 1463.42s\ttraining loss:\t3.335901\n",
      "Done 10800 batches in 1464.85s\ttraining loss:\t3.335857\n",
      "Done 10810 batches in 1466.26s\ttraining loss:\t3.335832\n",
      "Done 10820 batches in 1467.80s\ttraining loss:\t3.335829\n",
      "Done 10830 batches in 1469.26s\ttraining loss:\t3.335841\n",
      "Done 10840 batches in 1470.71s\ttraining loss:\t3.335843\n",
      "Done 10850 batches in 1471.96s\ttraining loss:\t3.335808\n",
      "Done 10860 batches in 1473.60s\ttraining loss:\t3.335827\n",
      "Done 10870 batches in 1475.11s\ttraining loss:\t3.335817\n",
      "Done 10880 batches in 1476.24s\ttraining loss:\t3.335839\n",
      "Done 10890 batches in 1477.75s\ttraining loss:\t3.335802\n",
      "Done 10900 batches in 1479.56s\ttraining loss:\t3.335779\n",
      "Done 10910 batches in 1480.97s\ttraining loss:\t3.335763\n",
      "Done 10920 batches in 1482.31s\ttraining loss:\t3.335757\n",
      "Done 10930 batches in 1483.44s\ttraining loss:\t3.335736\n",
      "Done 10940 batches in 1484.82s\ttraining loss:\t3.335736\n",
      "Done 10950 batches in 1485.93s\ttraining loss:\t3.335718\n",
      "Done 10960 batches in 1487.34s\ttraining loss:\t3.335671\n",
      "Done 10970 batches in 1488.94s\ttraining loss:\t3.335657\n",
      "Done 10980 batches in 1490.21s\ttraining loss:\t3.335621\n",
      "Done 10990 batches in 1491.80s\ttraining loss:\t3.335584\n",
      "Done 11000 batches in 1493.09s\ttraining loss:\t3.335568\n",
      "Done 11010 batches in 1494.32s\ttraining loss:\t3.335534\n",
      "Done 11020 batches in 1495.78s\ttraining loss:\t3.335523\n",
      "Done 11030 batches in 1496.85s\ttraining loss:\t3.335510\n",
      "Done 11040 batches in 1498.16s\ttraining loss:\t3.335502\n",
      "Done 11050 batches in 1499.40s\ttraining loss:\t3.335508\n",
      "Done 11060 batches in 1500.76s\ttraining loss:\t3.335483\n",
      "Done 11070 batches in 1502.17s\ttraining loss:\t3.335465\n",
      "Done 11080 batches in 1503.34s\ttraining loss:\t3.335465\n",
      "Done 11090 batches in 1504.83s\ttraining loss:\t3.335453\n",
      "Done 11100 batches in 1505.90s\ttraining loss:\t3.335427\n",
      "Done 11110 batches in 1507.25s\ttraining loss:\t3.335397\n",
      "Done 11120 batches in 1508.53s\ttraining loss:\t3.335361\n",
      "Done 11130 batches in 1509.89s\ttraining loss:\t3.335367\n",
      "Done 11140 batches in 1511.17s\ttraining loss:\t3.335342\n",
      "Done 11150 batches in 1512.39s\ttraining loss:\t3.335365\n",
      "Done 11160 batches in 1513.69s\ttraining loss:\t3.335382\n",
      "Done 11170 batches in 1515.28s\ttraining loss:\t3.335367\n",
      "Done 11180 batches in 1516.43s\ttraining loss:\t3.335395\n",
      "Done 11190 batches in 1517.56s\ttraining loss:\t3.335329\n",
      "Done 11200 batches in 1518.54s\ttraining loss:\t3.335310\n",
      "Done 11210 batches in 1519.69s\ttraining loss:\t3.335298\n",
      "Done 11220 batches in 1521.08s\ttraining loss:\t3.335315\n",
      "Done 11230 batches in 1522.45s\ttraining loss:\t3.335320\n",
      "Done 11240 batches in 1523.84s\ttraining loss:\t3.335286\n",
      "Done 11250 batches in 1525.33s\ttraining loss:\t3.335301\n",
      "Done 11260 batches in 1526.55s\ttraining loss:\t3.335254\n",
      "Done 11270 batches in 1527.63s\ttraining loss:\t3.335225\n",
      "Done 11280 batches in 1528.97s\ttraining loss:\t3.335206\n",
      "Done 11290 batches in 1530.23s\ttraining loss:\t3.335185\n",
      "Done 11300 batches in 1531.63s\ttraining loss:\t3.335214\n",
      "Done 11310 batches in 1533.04s\ttraining loss:\t3.335224\n",
      "Done 11320 batches in 1534.38s\ttraining loss:\t3.335238\n",
      "Done 11330 batches in 1535.53s\ttraining loss:\t3.335205\n",
      "Done 11340 batches in 1537.00s\ttraining loss:\t3.335170\n",
      "Done 11350 batches in 1538.39s\ttraining loss:\t3.335152\n",
      "Done 11360 batches in 1539.58s\ttraining loss:\t3.335160\n",
      "Done 11370 batches in 1540.73s\ttraining loss:\t3.335159\n",
      "Done 11380 batches in 1542.16s\ttraining loss:\t3.335157\n",
      "Done 11390 batches in 1543.49s\ttraining loss:\t3.335135\n",
      "Done 11400 batches in 1544.69s\ttraining loss:\t3.335135\n",
      "Done 11410 batches in 1546.03s\ttraining loss:\t3.335111\n",
      "Done 11420 batches in 1547.32s\ttraining loss:\t3.335108\n",
      "Done 11430 batches in 1548.51s\ttraining loss:\t3.335114\n",
      "Done 11440 batches in 1550.03s\ttraining loss:\t3.335157\n",
      "Done 11450 batches in 1551.19s\ttraining loss:\t3.335129\n",
      "Done 11460 batches in 1552.64s\ttraining loss:\t3.335120\n",
      "Done 11470 batches in 1553.90s\ttraining loss:\t3.335133\n",
      "Done 11480 batches in 1555.07s\ttraining loss:\t3.335093\n",
      "Done 11490 batches in 1556.34s\ttraining loss:\t3.335088\n",
      "Done 11500 batches in 1557.62s\ttraining loss:\t3.335088\n",
      "Done 11510 batches in 1559.15s\ttraining loss:\t3.335091\n",
      "Done 11520 batches in 1560.52s\ttraining loss:\t3.335059\n",
      "Done 11530 batches in 1561.83s\ttraining loss:\t3.335060\n",
      "Done 11540 batches in 1563.56s\ttraining loss:\t3.335042\n",
      "Done 11550 batches in 1564.78s\ttraining loss:\t3.335021\n",
      "Done 11560 batches in 1566.14s\ttraining loss:\t3.335013\n",
      "Done 11570 batches in 1567.63s\ttraining loss:\t3.335027\n",
      "Done 11580 batches in 1568.95s\ttraining loss:\t3.334987\n",
      "Done 11590 batches in 1570.50s\ttraining loss:\t3.334973\n",
      "Done 11600 batches in 1572.04s\ttraining loss:\t3.334958\n",
      "Done 11610 batches in 1573.59s\ttraining loss:\t3.334952\n",
      "Done 11620 batches in 1574.89s\ttraining loss:\t3.334944\n",
      "Done 11630 batches in 1576.32s\ttraining loss:\t3.334952\n",
      "Done 11640 batches in 1577.88s\ttraining loss:\t3.334965\n",
      "Done 11650 batches in 1579.26s\ttraining loss:\t3.334971\n",
      "Done 11660 batches in 1580.66s\ttraining loss:\t3.334948\n",
      "Done 11670 batches in 1582.01s\ttraining loss:\t3.334936\n",
      "Done 11680 batches in 1583.47s\ttraining loss:\t3.334935\n",
      "Done 11690 batches in 1584.86s\ttraining loss:\t3.334913\n",
      "Done 11700 batches in 1586.11s\ttraining loss:\t3.334934\n",
      "Done 11710 batches in 1587.36s\ttraining loss:\t3.334920\n",
      "Done 11720 batches in 1588.66s\ttraining loss:\t3.334912\n",
      "Done 11730 batches in 1589.86s\ttraining loss:\t3.334900\n",
      "Done 11740 batches in 1591.02s\ttraining loss:\t3.334883\n",
      "Done 11750 batches in 1592.31s\ttraining loss:\t3.334909\n",
      "Done 11760 batches in 1593.73s\ttraining loss:\t3.334936\n",
      "Done 100 batches in 2.31s\n",
      "Done 200 batches in 4.88s\n",
      "Done 300 batches in 7.40s\n",
      "Done 400 batches in 9.95s\n",
      "Done 500 batches in 12.26s\n",
      "Done 600 batches in 14.64s\n",
      "Done 700 batches in 16.93s\n",
      "Done 800 batches in 19.27s\n",
      "Done 900 batches in 21.56s\n",
      "Done 1000 batches in 23.80s\n",
      "Done 1100 batches in 26.41s\n",
      "Done 1200 batches in 29.02s\n",
      "Done 1300 batches in 31.52s\n",
      "Done 1400 batches in 34.13s\n",
      "Done 1500 batches in 36.69s\n",
      "Done 1600 batches in 39.31s\n",
      "Done 1700 batches in 41.54s\n",
      "Done 1800 batches in 43.87s\n",
      "Done 1900 batches in 46.28s\n",
      "Done 2000 batches in 48.64s\n",
      "Done 2100 batches in 51.13s\n",
      "Done 2200 batches in 53.66s\n",
      "Done 2300 batches in 56.20s\n",
      "Done 2400 batches in 58.52s\n",
      "Done 2500 batches in 60.94s\n",
      "Done 2600 batches in 63.40s\n",
      "Done 2700 batches in 65.98s\n",
      "Done 2800 batches in 68.57s\n",
      "Done 2900 batches in 71.01s\n",
      "Epoch 4 of 5 took 1667.67s\n",
      "  training loss:\t\t3.334928\n",
      "  validation loss:\t\t3.429394\n",
      "Done 10 batches in 1.28s\ttraining loss:\t3.297761\n",
      "Done 20 batches in 2.78s\ttraining loss:\t3.295344\n",
      "Done 30 batches in 4.05s\ttraining loss:\t3.289445\n",
      "Done 40 batches in 5.66s\ttraining loss:\t3.300320\n",
      "Done 50 batches in 7.14s\ttraining loss:\t3.307878\n",
      "Done 60 batches in 8.59s\ttraining loss:\t3.309133\n",
      "Done 70 batches in 9.69s\ttraining loss:\t3.311798\n",
      "Done 80 batches in 10.97s\ttraining loss:\t3.315092\n",
      "Done 90 batches in 12.47s\ttraining loss:\t3.317936\n",
      "Done 100 batches in 13.74s\ttraining loss:\t3.320503\n",
      "Done 110 batches in 14.95s\ttraining loss:\t3.321785\n",
      "Done 120 batches in 16.29s\ttraining loss:\t3.321852\n",
      "Done 130 batches in 17.53s\ttraining loss:\t3.322738\n",
      "Done 140 batches in 18.98s\ttraining loss:\t3.324491\n",
      "Done 150 batches in 20.52s\ttraining loss:\t3.325008\n",
      "Done 160 batches in 22.00s\ttraining loss:\t3.323458\n",
      "Done 170 batches in 23.27s\ttraining loss:\t3.322149\n",
      "Done 180 batches in 24.87s\ttraining loss:\t3.321793\n",
      "Done 190 batches in 26.12s\ttraining loss:\t3.320522\n",
      "Done 200 batches in 27.73s\ttraining loss:\t3.320002\n",
      "Done 210 batches in 29.34s\ttraining loss:\t3.322139\n",
      "Done 220 batches in 30.79s\ttraining loss:\t3.322447\n",
      "Done 230 batches in 32.05s\ttraining loss:\t3.323493\n",
      "Done 240 batches in 33.11s\ttraining loss:\t3.324075\n",
      "Done 250 batches in 34.48s\ttraining loss:\t3.322847\n",
      "Done 260 batches in 35.80s\ttraining loss:\t3.322665\n",
      "Done 270 batches in 37.06s\ttraining loss:\t3.322542\n",
      "Done 280 batches in 38.18s\ttraining loss:\t3.321339\n",
      "Done 290 batches in 39.67s\ttraining loss:\t3.321984\n",
      "Done 300 batches in 41.04s\ttraining loss:\t3.321772\n",
      "Done 310 batches in 42.33s\ttraining loss:\t3.321587\n",
      "Done 320 batches in 43.69s\ttraining loss:\t3.321967\n",
      "Done 330 batches in 45.25s\ttraining loss:\t3.321457\n",
      "Done 340 batches in 46.73s\ttraining loss:\t3.320754\n",
      "Done 350 batches in 48.15s\ttraining loss:\t3.320497\n",
      "Done 360 batches in 49.70s\ttraining loss:\t3.321889\n",
      "Done 370 batches in 51.14s\ttraining loss:\t3.322245\n",
      "Done 380 batches in 52.57s\ttraining loss:\t3.322088\n",
      "Done 390 batches in 53.95s\ttraining loss:\t3.321631\n",
      "Done 400 batches in 55.32s\ttraining loss:\t3.321517\n",
      "Done 410 batches in 56.57s\ttraining loss:\t3.320092\n",
      "Done 420 batches in 58.04s\ttraining loss:\t3.320732\n",
      "Done 430 batches in 59.48s\ttraining loss:\t3.320812\n",
      "Done 440 batches in 60.81s\ttraining loss:\t3.320408\n",
      "Done 450 batches in 61.99s\ttraining loss:\t3.319960\n",
      "Done 460 batches in 63.13s\ttraining loss:\t3.319576\n",
      "Done 470 batches in 64.37s\ttraining loss:\t3.319265\n",
      "Done 480 batches in 65.49s\ttraining loss:\t3.318863\n",
      "Done 490 batches in 66.85s\ttraining loss:\t3.318728\n",
      "Done 500 batches in 68.28s\ttraining loss:\t3.319863\n",
      "Done 510 batches in 69.55s\ttraining loss:\t3.320062\n",
      "Done 520 batches in 70.68s\ttraining loss:\t3.319336\n",
      "Done 530 batches in 71.96s\ttraining loss:\t3.318591\n",
      "Done 540 batches in 73.48s\ttraining loss:\t3.318172\n",
      "Done 550 batches in 74.88s\ttraining loss:\t3.317777\n",
      "Done 560 batches in 76.22s\ttraining loss:\t3.318011\n",
      "Done 570 batches in 77.60s\ttraining loss:\t3.318712\n",
      "Done 580 batches in 79.04s\ttraining loss:\t3.318446\n",
      "Done 590 batches in 80.33s\ttraining loss:\t3.318544\n",
      "Done 600 batches in 81.71s\ttraining loss:\t3.318773\n",
      "Done 610 batches in 83.01s\ttraining loss:\t3.319103\n",
      "Done 620 batches in 84.20s\ttraining loss:\t3.319170\n",
      "Done 630 batches in 85.45s\ttraining loss:\t3.318575\n",
      "Done 640 batches in 86.96s\ttraining loss:\t3.318554\n",
      "Done 650 batches in 88.97s\ttraining loss:\t3.319138\n",
      "Done 660 batches in 90.20s\ttraining loss:\t3.318912\n",
      "Done 670 batches in 91.52s\ttraining loss:\t3.319717\n",
      "Done 680 batches in 92.73s\ttraining loss:\t3.319683\n",
      "Done 690 batches in 94.02s\ttraining loss:\t3.319580\n",
      "Done 700 batches in 95.13s\ttraining loss:\t3.319638\n",
      "Done 710 batches in 96.32s\ttraining loss:\t3.319394\n",
      "Done 720 batches in 97.74s\ttraining loss:\t3.318975\n",
      "Done 730 batches in 98.93s\ttraining loss:\t3.319332\n",
      "Done 740 batches in 100.47s\ttraining loss:\t3.319267\n",
      "Done 750 batches in 102.01s\ttraining loss:\t3.319994\n",
      "Done 760 batches in 103.40s\ttraining loss:\t3.320244\n",
      "Done 770 batches in 104.91s\ttraining loss:\t3.320304\n",
      "Done 780 batches in 106.25s\ttraining loss:\t3.319684\n",
      "Done 790 batches in 107.38s\ttraining loss:\t3.319815\n",
      "Done 800 batches in 108.81s\ttraining loss:\t3.319713\n",
      "Done 810 batches in 110.42s\ttraining loss:\t3.319808\n",
      "Done 820 batches in 111.69s\ttraining loss:\t3.319422\n",
      "Done 830 batches in 112.91s\ttraining loss:\t3.319454\n",
      "Done 840 batches in 114.08s\ttraining loss:\t3.318938\n",
      "Done 850 batches in 115.61s\ttraining loss:\t3.318582\n",
      "Done 860 batches in 116.97s\ttraining loss:\t3.318786\n",
      "Done 870 batches in 118.21s\ttraining loss:\t3.318906\n",
      "Done 880 batches in 119.62s\ttraining loss:\t3.318951\n",
      "Done 890 batches in 121.04s\ttraining loss:\t3.318622\n",
      "Done 900 batches in 122.34s\ttraining loss:\t3.318246\n",
      "Done 910 batches in 123.53s\ttraining loss:\t3.318103\n",
      "Done 920 batches in 124.83s\ttraining loss:\t3.317957\n",
      "Done 930 batches in 126.26s\ttraining loss:\t3.318017\n",
      "Done 940 batches in 127.70s\ttraining loss:\t3.317720\n",
      "Done 950 batches in 129.05s\ttraining loss:\t3.317436\n",
      "Done 960 batches in 130.13s\ttraining loss:\t3.317657\n",
      "Done 970 batches in 131.52s\ttraining loss:\t3.317767\n",
      "Done 980 batches in 132.70s\ttraining loss:\t3.317566\n",
      "Done 990 batches in 134.01s\ttraining loss:\t3.317642\n",
      "Done 1000 batches in 135.28s\ttraining loss:\t3.317780\n",
      "Done 1010 batches in 136.61s\ttraining loss:\t3.318214\n",
      "Done 1020 batches in 137.95s\ttraining loss:\t3.318483\n",
      "Done 1030 batches in 139.11s\ttraining loss:\t3.318401\n",
      "Done 1040 batches in 140.49s\ttraining loss:\t3.318581\n",
      "Done 1050 batches in 141.94s\ttraining loss:\t3.318728\n",
      "Done 1060 batches in 143.30s\ttraining loss:\t3.318729\n",
      "Done 1070 batches in 144.61s\ttraining loss:\t3.318961\n",
      "Done 1080 batches in 146.22s\ttraining loss:\t3.319092\n",
      "Done 1090 batches in 147.28s\ttraining loss:\t3.319099\n",
      "Done 1100 batches in 148.58s\ttraining loss:\t3.318983\n",
      "Done 1110 batches in 149.96s\ttraining loss:\t3.319458\n",
      "Done 1120 batches in 151.20s\ttraining loss:\t3.319321\n",
      "Done 1130 batches in 152.57s\ttraining loss:\t3.319606\n",
      "Done 1140 batches in 153.72s\ttraining loss:\t3.319590\n",
      "Done 1150 batches in 155.16s\ttraining loss:\t3.319542\n",
      "Done 1160 batches in 156.30s\ttraining loss:\t3.319465\n",
      "Done 1170 batches in 157.50s\ttraining loss:\t3.319382\n",
      "Done 1180 batches in 159.31s\ttraining loss:\t3.319388\n",
      "Done 1190 batches in 160.58s\ttraining loss:\t3.319357\n",
      "Done 1200 batches in 161.86s\ttraining loss:\t3.319270\n",
      "Done 1210 batches in 163.13s\ttraining loss:\t3.319049\n",
      "Done 1220 batches in 164.52s\ttraining loss:\t3.318750\n",
      "Done 1230 batches in 165.77s\ttraining loss:\t3.318685\n",
      "Done 1240 batches in 167.14s\ttraining loss:\t3.318672\n",
      "Done 1250 batches in 168.42s\ttraining loss:\t3.318246\n",
      "Done 1260 batches in 170.00s\ttraining loss:\t3.318456\n",
      "Done 1270 batches in 171.22s\ttraining loss:\t3.318318\n",
      "Done 1280 batches in 172.53s\ttraining loss:\t3.318171\n",
      "Done 1290 batches in 173.90s\ttraining loss:\t3.318275\n",
      "Done 1300 batches in 175.23s\ttraining loss:\t3.318035\n",
      "Done 1310 batches in 176.73s\ttraining loss:\t3.318074\n",
      "Done 1320 batches in 178.34s\ttraining loss:\t3.317617\n",
      "Done 1330 batches in 179.50s\ttraining loss:\t3.317535\n",
      "Done 1340 batches in 180.97s\ttraining loss:\t3.317298\n",
      "Done 1350 batches in 182.32s\ttraining loss:\t3.317235\n",
      "Done 1360 batches in 183.48s\ttraining loss:\t3.316977\n",
      "Done 1370 batches in 184.71s\ttraining loss:\t3.316957\n",
      "Done 1380 batches in 186.19s\ttraining loss:\t3.317016\n",
      "Done 1390 batches in 187.58s\ttraining loss:\t3.316874\n",
      "Done 1400 batches in 188.95s\ttraining loss:\t3.317081\n",
      "Done 1410 batches in 190.65s\ttraining loss:\t3.317255\n",
      "Done 1420 batches in 191.85s\ttraining loss:\t3.317174\n",
      "Done 1430 batches in 193.21s\ttraining loss:\t3.317108\n",
      "Done 1440 batches in 194.78s\ttraining loss:\t3.317202\n",
      "Done 1450 batches in 196.09s\ttraining loss:\t3.317133\n",
      "Done 1460 batches in 197.21s\ttraining loss:\t3.317114\n",
      "Done 1470 batches in 198.52s\ttraining loss:\t3.317260\n",
      "Done 1480 batches in 199.74s\ttraining loss:\t3.317106\n",
      "Done 1490 batches in 200.95s\ttraining loss:\t3.316939\n",
      "Done 1500 batches in 202.43s\ttraining loss:\t3.316826\n",
      "Done 1510 batches in 203.65s\ttraining loss:\t3.316493\n",
      "Done 1520 batches in 204.97s\ttraining loss:\t3.316506\n",
      "Done 1530 batches in 206.23s\ttraining loss:\t3.316581\n",
      "Done 1540 batches in 207.33s\ttraining loss:\t3.316416\n",
      "Done 1550 batches in 208.65s\ttraining loss:\t3.316282\n",
      "Done 1560 batches in 210.13s\ttraining loss:\t3.316364\n",
      "Done 1570 batches in 211.68s\ttraining loss:\t3.316387\n",
      "Done 1580 batches in 213.03s\ttraining loss:\t3.316478\n",
      "Done 1590 batches in 214.38s\ttraining loss:\t3.316344\n",
      "Done 1600 batches in 215.72s\ttraining loss:\t3.316512\n",
      "Done 1610 batches in 216.62s\ttraining loss:\t3.316212\n",
      "Done 1620 batches in 218.25s\ttraining loss:\t3.316140\n",
      "Done 1630 batches in 219.71s\ttraining loss:\t3.316203\n",
      "Done 1640 batches in 220.98s\ttraining loss:\t3.316136\n",
      "Done 1650 batches in 222.29s\ttraining loss:\t3.316209\n",
      "Done 1660 batches in 223.70s\ttraining loss:\t3.316208\n",
      "Done 1670 batches in 224.94s\ttraining loss:\t3.316223\n",
      "Done 1680 batches in 226.84s\ttraining loss:\t3.316482\n",
      "Done 1690 batches in 228.14s\ttraining loss:\t3.316482\n",
      "Done 1700 batches in 229.50s\ttraining loss:\t3.316468\n",
      "Done 1710 batches in 230.69s\ttraining loss:\t3.316339\n",
      "Done 1720 batches in 232.20s\ttraining loss:\t3.316372\n",
      "Done 1730 batches in 233.33s\ttraining loss:\t3.316084\n",
      "Done 1740 batches in 234.51s\ttraining loss:\t3.316079\n",
      "Done 1750 batches in 236.23s\ttraining loss:\t3.316190\n",
      "Done 1760 batches in 237.46s\ttraining loss:\t3.316266\n",
      "Done 1770 batches in 238.97s\ttraining loss:\t3.316010\n",
      "Done 1780 batches in 240.19s\ttraining loss:\t3.316082\n",
      "Done 1790 batches in 241.42s\ttraining loss:\t3.315907\n",
      "Done 1800 batches in 242.76s\ttraining loss:\t3.316002\n",
      "Done 1810 batches in 244.39s\ttraining loss:\t3.316092\n",
      "Done 1820 batches in 245.68s\ttraining loss:\t3.316014\n",
      "Done 1830 batches in 247.14s\ttraining loss:\t3.316083\n",
      "Done 1840 batches in 248.34s\ttraining loss:\t3.316013\n",
      "Done 1850 batches in 249.72s\ttraining loss:\t3.315801\n",
      "Done 1860 batches in 251.04s\ttraining loss:\t3.315641\n",
      "Done 1870 batches in 252.49s\ttraining loss:\t3.315456\n",
      "Done 1880 batches in 253.80s\ttraining loss:\t3.315567\n",
      "Done 1890 batches in 254.97s\ttraining loss:\t3.315525\n",
      "Done 1900 batches in 256.29s\ttraining loss:\t3.315304\n",
      "Done 1910 batches in 257.60s\ttraining loss:\t3.315241\n",
      "Done 1920 batches in 259.02s\ttraining loss:\t3.315239\n",
      "Done 1930 batches in 260.26s\ttraining loss:\t3.315275\n",
      "Done 1940 batches in 261.71s\ttraining loss:\t3.315206\n",
      "Done 1950 batches in 263.20s\ttraining loss:\t3.314921\n",
      "Done 1960 batches in 264.32s\ttraining loss:\t3.314845\n",
      "Done 1970 batches in 265.62s\ttraining loss:\t3.315029\n",
      "Done 1980 batches in 267.17s\ttraining loss:\t3.314939\n",
      "Done 1990 batches in 268.39s\ttraining loss:\t3.314784\n",
      "Done 2000 batches in 269.79s\ttraining loss:\t3.314968\n",
      "Done 2010 batches in 271.14s\ttraining loss:\t3.315148\n",
      "Done 2020 batches in 272.36s\ttraining loss:\t3.315113\n",
      "Done 2030 batches in 273.75s\ttraining loss:\t3.315040\n",
      "Done 2040 batches in 275.11s\ttraining loss:\t3.315147\n",
      "Done 2050 batches in 276.20s\ttraining loss:\t3.315326\n",
      "Done 2060 batches in 277.63s\ttraining loss:\t3.315359\n",
      "Done 2070 batches in 278.97s\ttraining loss:\t3.315363\n",
      "Done 2080 batches in 280.42s\ttraining loss:\t3.315345\n",
      "Done 2090 batches in 281.72s\ttraining loss:\t3.315211\n",
      "Done 2100 batches in 283.18s\ttraining loss:\t3.315144\n",
      "Done 2110 batches in 284.49s\ttraining loss:\t3.315105\n",
      "Done 2120 batches in 285.93s\ttraining loss:\t3.315150\n",
      "Done 2130 batches in 287.10s\ttraining loss:\t3.315374\n",
      "Done 2140 batches in 288.48s\ttraining loss:\t3.315220\n",
      "Done 2150 batches in 289.92s\ttraining loss:\t3.315288\n",
      "Done 2160 batches in 291.13s\ttraining loss:\t3.315280\n",
      "Done 2170 batches in 292.57s\ttraining loss:\t3.315231\n",
      "Done 2180 batches in 293.85s\ttraining loss:\t3.315251\n",
      "Done 2190 batches in 295.18s\ttraining loss:\t3.315303\n",
      "Done 2200 batches in 296.32s\ttraining loss:\t3.315145\n",
      "Done 2210 batches in 297.43s\ttraining loss:\t3.315007\n",
      "Done 2220 batches in 299.18s\ttraining loss:\t3.314989\n",
      "Done 2230 batches in 300.77s\ttraining loss:\t3.314930\n",
      "Done 2240 batches in 302.08s\ttraining loss:\t3.314909\n",
      "Done 2250 batches in 303.34s\ttraining loss:\t3.314778\n",
      "Done 2260 batches in 304.65s\ttraining loss:\t3.314755\n",
      "Done 2270 batches in 306.07s\ttraining loss:\t3.314812\n",
      "Done 2280 batches in 307.19s\ttraining loss:\t3.314760\n",
      "Done 2290 batches in 308.53s\ttraining loss:\t3.314659\n",
      "Done 2300 batches in 309.77s\ttraining loss:\t3.314730\n",
      "Done 2310 batches in 311.36s\ttraining loss:\t3.314975\n",
      "Done 2320 batches in 312.66s\ttraining loss:\t3.315086\n",
      "Done 2330 batches in 313.97s\ttraining loss:\t3.314898\n",
      "Done 2340 batches in 315.58s\ttraining loss:\t3.314844\n",
      "Done 2350 batches in 316.86s\ttraining loss:\t3.314812\n",
      "Done 2360 batches in 318.17s\ttraining loss:\t3.314702\n",
      "Done 2370 batches in 319.46s\ttraining loss:\t3.314624\n",
      "Done 2380 batches in 320.74s\ttraining loss:\t3.314598\n",
      "Done 2390 batches in 322.32s\ttraining loss:\t3.314527\n",
      "Done 2400 batches in 323.62s\ttraining loss:\t3.314546\n",
      "Done 2410 batches in 325.07s\ttraining loss:\t3.314534\n",
      "Done 2420 batches in 326.25s\ttraining loss:\t3.314440\n",
      "Done 2430 batches in 327.34s\ttraining loss:\t3.314261\n",
      "Done 2440 batches in 328.84s\ttraining loss:\t3.314361\n",
      "Done 2450 batches in 330.13s\ttraining loss:\t3.314236\n",
      "Done 2460 batches in 331.39s\ttraining loss:\t3.314102\n",
      "Done 2470 batches in 332.76s\ttraining loss:\t3.314005\n",
      "Done 2480 batches in 334.45s\ttraining loss:\t3.314001\n",
      "Done 2490 batches in 335.87s\ttraining loss:\t3.314103\n",
      "Done 2500 batches in 337.04s\ttraining loss:\t3.314095\n",
      "Done 2510 batches in 338.16s\ttraining loss:\t3.314228\n",
      "Done 2520 batches in 339.47s\ttraining loss:\t3.314267\n",
      "Done 2530 batches in 341.01s\ttraining loss:\t3.314244\n",
      "Done 2540 batches in 342.09s\ttraining loss:\t3.314149\n",
      "Done 2550 batches in 343.49s\ttraining loss:\t3.314233\n",
      "Done 2560 batches in 344.87s\ttraining loss:\t3.314090\n",
      "Done 2570 batches in 346.39s\ttraining loss:\t3.314193\n",
      "Done 2580 batches in 347.76s\ttraining loss:\t3.314033\n",
      "Done 2590 batches in 348.91s\ttraining loss:\t3.314041\n",
      "Done 2600 batches in 350.50s\ttraining loss:\t3.313844\n",
      "Done 2610 batches in 351.53s\ttraining loss:\t3.313965\n",
      "Done 2620 batches in 353.12s\ttraining loss:\t3.314027\n",
      "Done 2630 batches in 354.49s\ttraining loss:\t3.313912\n",
      "Done 2640 batches in 355.78s\ttraining loss:\t3.313847\n",
      "Done 2650 batches in 357.17s\ttraining loss:\t3.313856\n",
      "Done 2660 batches in 358.54s\ttraining loss:\t3.313877\n",
      "Done 2670 batches in 359.98s\ttraining loss:\t3.314014\n",
      "Done 2680 batches in 361.44s\ttraining loss:\t3.313996\n",
      "Done 2690 batches in 362.69s\ttraining loss:\t3.314156\n",
      "Done 2700 batches in 363.98s\ttraining loss:\t3.314117\n",
      "Done 2710 batches in 365.52s\ttraining loss:\t3.314227\n",
      "Done 2720 batches in 366.60s\ttraining loss:\t3.314248\n",
      "Done 2730 batches in 367.79s\ttraining loss:\t3.314101\n",
      "Done 2740 batches in 368.91s\ttraining loss:\t3.314043\n",
      "Done 2750 batches in 370.34s\ttraining loss:\t3.314016\n",
      "Done 2760 batches in 371.70s\ttraining loss:\t3.313966\n",
      "Done 2770 batches in 373.09s\ttraining loss:\t3.314023\n",
      "Done 2780 batches in 374.64s\ttraining loss:\t3.313971\n",
      "Done 2790 batches in 376.00s\ttraining loss:\t3.313915\n",
      "Done 2800 batches in 377.19s\ttraining loss:\t3.313972\n",
      "Done 2810 batches in 378.62s\ttraining loss:\t3.313993\n",
      "Done 2820 batches in 379.77s\ttraining loss:\t3.313924\n",
      "Done 2830 batches in 380.96s\ttraining loss:\t3.313794\n",
      "Done 2840 batches in 382.34s\ttraining loss:\t3.313799\n",
      "Done 2850 batches in 383.96s\ttraining loss:\t3.313639\n",
      "Done 2860 batches in 385.26s\ttraining loss:\t3.313688\n",
      "Done 2870 batches in 386.42s\ttraining loss:\t3.313630\n",
      "Done 2880 batches in 387.63s\ttraining loss:\t3.313573\n",
      "Done 2890 batches in 389.05s\ttraining loss:\t3.313530\n",
      "Done 2900 batches in 390.39s\ttraining loss:\t3.313707\n",
      "Done 2910 batches in 391.71s\ttraining loss:\t3.313793\n",
      "Done 2920 batches in 392.93s\ttraining loss:\t3.313757\n",
      "Done 2930 batches in 394.27s\ttraining loss:\t3.313702\n",
      "Done 2940 batches in 395.59s\ttraining loss:\t3.313604\n",
      "Done 2950 batches in 396.88s\ttraining loss:\t3.313463\n",
      "Done 2960 batches in 398.32s\ttraining loss:\t3.313518\n",
      "Done 2970 batches in 399.74s\ttraining loss:\t3.313413\n",
      "Done 2980 batches in 400.85s\ttraining loss:\t3.313367\n",
      "Done 2990 batches in 401.87s\ttraining loss:\t3.313258\n",
      "Done 3000 batches in 403.19s\ttraining loss:\t3.313219\n",
      "Done 3010 batches in 404.49s\ttraining loss:\t3.313211\n",
      "Done 3020 batches in 405.58s\ttraining loss:\t3.313159\n",
      "Done 3030 batches in 407.07s\ttraining loss:\t3.313173\n",
      "Done 3040 batches in 408.36s\ttraining loss:\t3.313193\n",
      "Done 3050 batches in 409.95s\ttraining loss:\t3.313195\n",
      "Done 3060 batches in 410.93s\ttraining loss:\t3.313145\n",
      "Done 3070 batches in 412.11s\ttraining loss:\t3.313098\n",
      "Done 3080 batches in 413.23s\ttraining loss:\t3.312816\n",
      "Done 3090 batches in 414.73s\ttraining loss:\t3.312876\n",
      "Done 3100 batches in 416.00s\ttraining loss:\t3.312746\n",
      "Done 3110 batches in 417.74s\ttraining loss:\t3.312779\n",
      "Done 3120 batches in 419.04s\ttraining loss:\t3.312873\n",
      "Done 3130 batches in 420.27s\ttraining loss:\t3.312864\n",
      "Done 3140 batches in 421.57s\ttraining loss:\t3.312933\n",
      "Done 3150 batches in 422.83s\ttraining loss:\t3.312843\n",
      "Done 3160 batches in 423.98s\ttraining loss:\t3.312869\n",
      "Done 3170 batches in 425.42s\ttraining loss:\t3.312890\n",
      "Done 3180 batches in 426.51s\ttraining loss:\t3.312815\n",
      "Done 3190 batches in 427.77s\ttraining loss:\t3.312788\n",
      "Done 3200 batches in 429.18s\ttraining loss:\t3.312778\n",
      "Done 3210 batches in 430.63s\ttraining loss:\t3.312832\n",
      "Done 3220 batches in 431.85s\ttraining loss:\t3.312652\n",
      "Done 3230 batches in 433.14s\ttraining loss:\t3.312613\n",
      "Done 3240 batches in 434.51s\ttraining loss:\t3.312529\n",
      "Done 3250 batches in 435.70s\ttraining loss:\t3.312541\n",
      "Done 3260 batches in 437.09s\ttraining loss:\t3.312486\n",
      "Done 3270 batches in 438.37s\ttraining loss:\t3.312511\n",
      "Done 3280 batches in 439.86s\ttraining loss:\t3.312586\n",
      "Done 3290 batches in 441.04s\ttraining loss:\t3.312666\n",
      "Done 3300 batches in 442.22s\ttraining loss:\t3.312721\n",
      "Done 3310 batches in 443.56s\ttraining loss:\t3.312664\n",
      "Done 3320 batches in 444.83s\ttraining loss:\t3.312614\n",
      "Done 3330 batches in 446.29s\ttraining loss:\t3.312584\n",
      "Done 3340 batches in 447.54s\ttraining loss:\t3.312580\n",
      "Done 3350 batches in 448.79s\ttraining loss:\t3.312585\n",
      "Done 3360 batches in 450.37s\ttraining loss:\t3.312520\n",
      "Done 3370 batches in 451.83s\ttraining loss:\t3.312451\n",
      "Done 3380 batches in 453.32s\ttraining loss:\t3.312477\n",
      "Done 3390 batches in 454.90s\ttraining loss:\t3.312483\n",
      "Done 3400 batches in 456.09s\ttraining loss:\t3.312322\n",
      "Done 3410 batches in 457.63s\ttraining loss:\t3.312423\n",
      "Done 3420 batches in 458.84s\ttraining loss:\t3.312326\n",
      "Done 3430 batches in 460.11s\ttraining loss:\t3.312178\n",
      "Done 3440 batches in 461.48s\ttraining loss:\t3.312105\n",
      "Done 3450 batches in 462.63s\ttraining loss:\t3.312079\n",
      "Done 3460 batches in 463.90s\ttraining loss:\t3.312186\n",
      "Done 3470 batches in 465.20s\ttraining loss:\t3.312250\n",
      "Done 3480 batches in 466.77s\ttraining loss:\t3.312269\n",
      "Done 3490 batches in 468.17s\ttraining loss:\t3.312212\n",
      "Done 3500 batches in 469.34s\ttraining loss:\t3.312113\n",
      "Done 3510 batches in 470.76s\ttraining loss:\t3.312065\n",
      "Done 3520 batches in 472.20s\ttraining loss:\t3.312016\n",
      "Done 3530 batches in 473.56s\ttraining loss:\t3.312011\n",
      "Done 3540 batches in 475.16s\ttraining loss:\t3.311995\n",
      "Done 3550 batches in 476.55s\ttraining loss:\t3.312024\n",
      "Done 3560 batches in 477.74s\ttraining loss:\t3.312110\n",
      "Done 3570 batches in 479.29s\ttraining loss:\t3.312180\n",
      "Done 3580 batches in 481.04s\ttraining loss:\t3.312134\n",
      "Done 3590 batches in 482.48s\ttraining loss:\t3.312151\n",
      "Done 3600 batches in 483.81s\ttraining loss:\t3.312110\n",
      "Done 3610 batches in 485.23s\ttraining loss:\t3.312175\n",
      "Done 3620 batches in 486.59s\ttraining loss:\t3.312054\n",
      "Done 3630 batches in 488.07s\ttraining loss:\t3.311995\n",
      "Done 3640 batches in 489.75s\ttraining loss:\t3.312039\n",
      "Done 3650 batches in 490.93s\ttraining loss:\t3.311984\n",
      "Done 3660 batches in 492.22s\ttraining loss:\t3.311893\n",
      "Done 3670 batches in 493.60s\ttraining loss:\t3.311918\n",
      "Done 3680 batches in 494.71s\ttraining loss:\t3.311869\n",
      "Done 3690 batches in 496.33s\ttraining loss:\t3.312031\n",
      "Done 3700 batches in 497.33s\ttraining loss:\t3.311884\n",
      "Done 3710 batches in 498.80s\ttraining loss:\t3.311888\n",
      "Done 3720 batches in 500.16s\ttraining loss:\t3.311913\n",
      "Done 3730 batches in 501.50s\ttraining loss:\t3.311870\n",
      "Done 3740 batches in 502.86s\ttraining loss:\t3.311891\n",
      "Done 3750 batches in 504.38s\ttraining loss:\t3.311783\n",
      "Done 3760 batches in 505.91s\ttraining loss:\t3.311759\n",
      "Done 3770 batches in 507.43s\ttraining loss:\t3.311762\n",
      "Done 3780 batches in 508.88s\ttraining loss:\t3.311707\n",
      "Done 3790 batches in 510.33s\ttraining loss:\t3.311684\n",
      "Done 3800 batches in 511.77s\ttraining loss:\t3.311729\n",
      "Done 3810 batches in 512.92s\ttraining loss:\t3.311649\n",
      "Done 3820 batches in 514.28s\ttraining loss:\t3.311585\n",
      "Done 3830 batches in 515.94s\ttraining loss:\t3.311627\n",
      "Done 3840 batches in 517.62s\ttraining loss:\t3.311638\n",
      "Done 3850 batches in 518.78s\ttraining loss:\t3.311477\n",
      "Done 3860 batches in 520.19s\ttraining loss:\t3.311486\n",
      "Done 3870 batches in 521.40s\ttraining loss:\t3.311435\n",
      "Done 3880 batches in 522.71s\ttraining loss:\t3.311389\n",
      "Done 3890 batches in 524.12s\ttraining loss:\t3.311359\n",
      "Done 3900 batches in 525.70s\ttraining loss:\t3.311477\n",
      "Done 3910 batches in 526.99s\ttraining loss:\t3.311472\n",
      "Done 3920 batches in 528.15s\ttraining loss:\t3.311368\n",
      "Done 3930 batches in 529.39s\ttraining loss:\t3.311377\n",
      "Done 3940 batches in 530.90s\ttraining loss:\t3.311416\n",
      "Done 3950 batches in 532.36s\ttraining loss:\t3.311436\n",
      "Done 3960 batches in 533.73s\ttraining loss:\t3.311390\n",
      "Done 3970 batches in 535.13s\ttraining loss:\t3.311387\n",
      "Done 3980 batches in 536.69s\ttraining loss:\t3.311500\n",
      "Done 3990 batches in 537.78s\ttraining loss:\t3.311537\n",
      "Done 4000 batches in 539.00s\ttraining loss:\t3.311527\n",
      "Done 4010 batches in 540.31s\ttraining loss:\t3.311546\n",
      "Done 4020 batches in 541.60s\ttraining loss:\t3.311475\n",
      "Done 4030 batches in 542.73s\ttraining loss:\t3.311421\n",
      "Done 4040 batches in 543.97s\ttraining loss:\t3.311370\n",
      "Done 4050 batches in 545.48s\ttraining loss:\t3.311287\n",
      "Done 4060 batches in 546.82s\ttraining loss:\t3.311191\n",
      "Done 4070 batches in 548.13s\ttraining loss:\t3.311123\n",
      "Done 4080 batches in 549.83s\ttraining loss:\t3.311178\n",
      "Done 4090 batches in 551.34s\ttraining loss:\t3.311120\n",
      "Done 4100 batches in 552.89s\ttraining loss:\t3.311102\n",
      "Done 4110 batches in 554.29s\ttraining loss:\t3.311113\n",
      "Done 4120 batches in 555.49s\ttraining loss:\t3.311054\n",
      "Done 4130 batches in 556.93s\ttraining loss:\t3.310982\n",
      "Done 4140 batches in 558.44s\ttraining loss:\t3.310919\n",
      "Done 4150 batches in 559.93s\ttraining loss:\t3.310914\n",
      "Done 4160 batches in 561.32s\ttraining loss:\t3.310992\n",
      "Done 4170 batches in 562.79s\ttraining loss:\t3.311014\n",
      "Done 4180 batches in 564.29s\ttraining loss:\t3.310967\n",
      "Done 4190 batches in 565.62s\ttraining loss:\t3.310923\n",
      "Done 4200 batches in 566.88s\ttraining loss:\t3.310883\n",
      "Done 4210 batches in 568.18s\ttraining loss:\t3.310830\n",
      "Done 4220 batches in 569.53s\ttraining loss:\t3.310826\n",
      "Done 4230 batches in 570.74s\ttraining loss:\t3.310722\n",
      "Done 4240 batches in 572.09s\ttraining loss:\t3.310788\n",
      "Done 4250 batches in 573.46s\ttraining loss:\t3.310737\n",
      "Done 4260 batches in 574.95s\ttraining loss:\t3.310660\n",
      "Done 4270 batches in 576.20s\ttraining loss:\t3.310605\n",
      "Done 4280 batches in 577.25s\ttraining loss:\t3.310580\n",
      "Done 4290 batches in 578.67s\ttraining loss:\t3.310546\n",
      "Done 4300 batches in 580.24s\ttraining loss:\t3.310539\n",
      "Done 4310 batches in 581.32s\ttraining loss:\t3.310480\n",
      "Done 4320 batches in 583.11s\ttraining loss:\t3.310507\n",
      "Done 4330 batches in 584.60s\ttraining loss:\t3.310457\n",
      "Done 4340 batches in 585.91s\ttraining loss:\t3.310463\n",
      "Done 4350 batches in 587.42s\ttraining loss:\t3.310480\n",
      "Done 4360 batches in 588.67s\ttraining loss:\t3.310461\n",
      "Done 4370 batches in 590.53s\ttraining loss:\t3.310451\n",
      "Done 4380 batches in 592.03s\ttraining loss:\t3.310408\n",
      "Done 4390 batches in 593.47s\ttraining loss:\t3.310321\n",
      "Done 4400 batches in 594.85s\ttraining loss:\t3.310302\n",
      "Done 4410 batches in 596.33s\ttraining loss:\t3.310389\n",
      "Done 4420 batches in 597.46s\ttraining loss:\t3.310394\n",
      "Done 4430 batches in 598.85s\ttraining loss:\t3.310384\n",
      "Done 4440 batches in 600.05s\ttraining loss:\t3.310381\n",
      "Done 4450 batches in 601.33s\ttraining loss:\t3.310367\n",
      "Done 4460 batches in 602.79s\ttraining loss:\t3.310298\n",
      "Done 4470 batches in 604.36s\ttraining loss:\t3.310349\n",
      "Done 4480 batches in 605.62s\ttraining loss:\t3.310379\n",
      "Done 4490 batches in 607.15s\ttraining loss:\t3.310323\n",
      "Done 4500 batches in 608.38s\ttraining loss:\t3.310292\n",
      "Done 4510 batches in 609.66s\ttraining loss:\t3.310269\n",
      "Done 4520 batches in 611.20s\ttraining loss:\t3.310299\n",
      "Done 4530 batches in 612.60s\ttraining loss:\t3.310206\n",
      "Done 4540 batches in 614.15s\ttraining loss:\t3.310228\n",
      "Done 4550 batches in 615.62s\ttraining loss:\t3.310238\n",
      "Done 4560 batches in 617.16s\ttraining loss:\t3.310197\n",
      "Done 4570 batches in 618.56s\ttraining loss:\t3.310164\n",
      "Done 4580 batches in 619.87s\ttraining loss:\t3.310134\n",
      "Done 4590 batches in 621.28s\ttraining loss:\t3.310122\n",
      "Done 4600 batches in 622.83s\ttraining loss:\t3.310122\n",
      "Done 4610 batches in 624.25s\ttraining loss:\t3.310167\n",
      "Done 4620 batches in 625.70s\ttraining loss:\t3.310224\n",
      "Done 4630 batches in 626.87s\ttraining loss:\t3.310137\n",
      "Done 4640 batches in 628.09s\ttraining loss:\t3.310115\n",
      "Done 4650 batches in 629.37s\ttraining loss:\t3.310114\n",
      "Done 4660 batches in 630.57s\ttraining loss:\t3.310083\n",
      "Done 4670 batches in 631.91s\ttraining loss:\t3.310023\n",
      "Done 4680 batches in 633.13s\ttraining loss:\t3.310094\n",
      "Done 4690 batches in 634.71s\ttraining loss:\t3.310085\n",
      "Done 4700 batches in 636.07s\ttraining loss:\t3.310059\n",
      "Done 4710 batches in 637.14s\ttraining loss:\t3.309946\n",
      "Done 4720 batches in 638.57s\ttraining loss:\t3.309974\n",
      "Done 4730 batches in 640.20s\ttraining loss:\t3.310094\n",
      "Done 4740 batches in 641.50s\ttraining loss:\t3.310089\n",
      "Done 4750 batches in 642.70s\ttraining loss:\t3.310086\n",
      "Done 4760 batches in 644.25s\ttraining loss:\t3.310011\n",
      "Done 4770 batches in 645.56s\ttraining loss:\t3.310003\n",
      "Done 4780 batches in 646.82s\ttraining loss:\t3.309925\n",
      "Done 4790 batches in 648.11s\ttraining loss:\t3.309901\n",
      "Done 4800 batches in 649.72s\ttraining loss:\t3.309952\n",
      "Done 4810 batches in 650.90s\ttraining loss:\t3.309935\n",
      "Done 4820 batches in 652.38s\ttraining loss:\t3.309893\n",
      "Done 4830 batches in 653.78s\ttraining loss:\t3.309894\n",
      "Done 4840 batches in 654.88s\ttraining loss:\t3.309883\n",
      "Done 4850 batches in 656.10s\ttraining loss:\t3.309863\n",
      "Done 4860 batches in 657.63s\ttraining loss:\t3.309856\n",
      "Done 4870 batches in 659.01s\ttraining loss:\t3.309787\n",
      "Done 4880 batches in 660.36s\ttraining loss:\t3.309800\n",
      "Done 4890 batches in 661.84s\ttraining loss:\t3.309802\n",
      "Done 4900 batches in 663.13s\ttraining loss:\t3.309707\n",
      "Done 4910 batches in 664.33s\ttraining loss:\t3.309694\n",
      "Done 4920 batches in 665.81s\ttraining loss:\t3.309679\n",
      "Done 4930 batches in 667.15s\ttraining loss:\t3.309678\n",
      "Done 4940 batches in 668.55s\ttraining loss:\t3.309701\n",
      "Done 4950 batches in 670.07s\ttraining loss:\t3.309736\n",
      "Done 4960 batches in 671.67s\ttraining loss:\t3.309685\n",
      "Done 4970 batches in 672.97s\ttraining loss:\t3.309613\n",
      "Done 4980 batches in 674.27s\ttraining loss:\t3.309609\n",
      "Done 4990 batches in 675.74s\ttraining loss:\t3.309600\n",
      "Done 5000 batches in 677.25s\ttraining loss:\t3.309648\n",
      "Done 5010 batches in 678.64s\ttraining loss:\t3.309587\n",
      "Done 5020 batches in 680.09s\ttraining loss:\t3.309612\n",
      "Done 5030 batches in 681.52s\ttraining loss:\t3.309500\n",
      "Done 5040 batches in 682.73s\ttraining loss:\t3.309408\n",
      "Done 5050 batches in 683.92s\ttraining loss:\t3.309431\n",
      "Done 5060 batches in 685.18s\ttraining loss:\t3.309435\n",
      "Done 5070 batches in 686.76s\ttraining loss:\t3.309415\n",
      "Done 5080 batches in 688.22s\ttraining loss:\t3.309425\n",
      "Done 5090 batches in 689.67s\ttraining loss:\t3.309418\n",
      "Done 5100 batches in 691.08s\ttraining loss:\t3.309437\n",
      "Done 5110 batches in 692.31s\ttraining loss:\t3.309368\n",
      "Done 5120 batches in 693.96s\ttraining loss:\t3.309411\n",
      "Done 5130 batches in 695.19s\ttraining loss:\t3.309392\n",
      "Done 5140 batches in 696.69s\ttraining loss:\t3.309302\n",
      "Done 5150 batches in 698.06s\ttraining loss:\t3.309300\n",
      "Done 5160 batches in 699.97s\ttraining loss:\t3.309274\n",
      "Done 5170 batches in 701.20s\ttraining loss:\t3.309224\n",
      "Done 5180 batches in 702.42s\ttraining loss:\t3.309169\n",
      "Done 5190 batches in 703.83s\ttraining loss:\t3.309128\n",
      "Done 5200 batches in 705.45s\ttraining loss:\t3.309108\n",
      "Done 5210 batches in 706.95s\ttraining loss:\t3.309107\n",
      "Done 5220 batches in 708.44s\ttraining loss:\t3.309101\n",
      "Done 5230 batches in 709.75s\ttraining loss:\t3.309180\n",
      "Done 5240 batches in 711.12s\ttraining loss:\t3.309128\n",
      "Done 5250 batches in 712.53s\ttraining loss:\t3.309091\n",
      "Done 5260 batches in 713.87s\ttraining loss:\t3.309091\n",
      "Done 5270 batches in 715.50s\ttraining loss:\t3.309168\n",
      "Done 5280 batches in 716.71s\ttraining loss:\t3.309145\n",
      "Done 5290 batches in 718.16s\ttraining loss:\t3.309215\n",
      "Done 5300 batches in 719.52s\ttraining loss:\t3.309216\n",
      "Done 5310 batches in 720.72s\ttraining loss:\t3.309238\n",
      "Done 5320 batches in 722.24s\ttraining loss:\t3.309260\n",
      "Done 5330 batches in 723.67s\ttraining loss:\t3.309244\n",
      "Done 5340 batches in 724.81s\ttraining loss:\t3.309287\n",
      "Done 5350 batches in 726.06s\ttraining loss:\t3.309269\n",
      "Done 5360 batches in 727.55s\ttraining loss:\t3.309310\n",
      "Done 5370 batches in 729.04s\ttraining loss:\t3.309368\n",
      "Done 5380 batches in 730.46s\ttraining loss:\t3.309370\n",
      "Done 5390 batches in 731.69s\ttraining loss:\t3.309372\n",
      "Done 5400 batches in 733.07s\ttraining loss:\t3.309398\n",
      "Done 5410 batches in 734.44s\ttraining loss:\t3.309407\n",
      "Done 5420 batches in 735.93s\ttraining loss:\t3.309402\n",
      "Done 5430 batches in 737.12s\ttraining loss:\t3.309397\n",
      "Done 5440 batches in 738.45s\ttraining loss:\t3.309378\n",
      "Done 5450 batches in 739.86s\ttraining loss:\t3.309381\n",
      "Done 5460 batches in 741.20s\ttraining loss:\t3.309446\n",
      "Done 5470 batches in 742.60s\ttraining loss:\t3.309407\n",
      "Done 5480 batches in 744.20s\ttraining loss:\t3.309352\n",
      "Done 5490 batches in 745.53s\ttraining loss:\t3.309381\n",
      "Done 5500 batches in 747.00s\ttraining loss:\t3.309416\n",
      "Done 5510 batches in 748.56s\ttraining loss:\t3.309435\n",
      "Done 5520 batches in 749.81s\ttraining loss:\t3.309431\n",
      "Done 5530 batches in 751.20s\ttraining loss:\t3.309442\n",
      "Done 5540 batches in 752.56s\ttraining loss:\t3.309449\n",
      "Done 5550 batches in 754.34s\ttraining loss:\t3.309455\n",
      "Done 5560 batches in 755.81s\ttraining loss:\t3.309525\n",
      "Done 5570 batches in 757.10s\ttraining loss:\t3.309536\n",
      "Done 5580 batches in 758.58s\ttraining loss:\t3.309493\n",
      "Done 5590 batches in 759.84s\ttraining loss:\t3.309486\n",
      "Done 5600 batches in 760.93s\ttraining loss:\t3.309422\n",
      "Done 5610 batches in 762.06s\ttraining loss:\t3.309411\n",
      "Done 5620 batches in 763.57s\ttraining loss:\t3.309395\n",
      "Done 5630 batches in 764.95s\ttraining loss:\t3.309407\n",
      "Done 5640 batches in 766.11s\ttraining loss:\t3.309413\n",
      "Done 5650 batches in 767.46s\ttraining loss:\t3.309327\n",
      "Done 5660 batches in 768.88s\ttraining loss:\t3.309321\n",
      "Done 5670 batches in 770.32s\ttraining loss:\t3.309293\n",
      "Done 5680 batches in 771.48s\ttraining loss:\t3.309313\n",
      "Done 5690 batches in 772.72s\ttraining loss:\t3.309295\n",
      "Done 5700 batches in 774.35s\ttraining loss:\t3.309334\n",
      "Done 5710 batches in 775.57s\ttraining loss:\t3.309364\n",
      "Done 5720 batches in 777.19s\ttraining loss:\t3.309332\n",
      "Done 5730 batches in 778.65s\ttraining loss:\t3.309279\n",
      "Done 5740 batches in 779.91s\ttraining loss:\t3.309308\n",
      "Done 5750 batches in 781.41s\ttraining loss:\t3.309295\n",
      "Done 5760 batches in 782.60s\ttraining loss:\t3.309304\n",
      "Done 5770 batches in 784.03s\ttraining loss:\t3.309265\n",
      "Done 5780 batches in 785.24s\ttraining loss:\t3.309219\n",
      "Done 5790 batches in 786.70s\ttraining loss:\t3.309205\n",
      "Done 5800 batches in 787.81s\ttraining loss:\t3.309215\n",
      "Done 5810 batches in 789.38s\ttraining loss:\t3.309248\n",
      "Done 5820 batches in 790.83s\ttraining loss:\t3.309234\n",
      "Done 5830 batches in 792.39s\ttraining loss:\t3.309161\n",
      "Done 5840 batches in 793.91s\ttraining loss:\t3.309181\n",
      "Done 5850 batches in 795.49s\ttraining loss:\t3.309211\n",
      "Done 5860 batches in 796.84s\ttraining loss:\t3.309267\n",
      "Done 5870 batches in 797.98s\ttraining loss:\t3.309243\n",
      "Done 5880 batches in 799.25s\ttraining loss:\t3.309194\n",
      "Done 5890 batches in 800.90s\ttraining loss:\t3.309167\n",
      "Done 5900 batches in 802.42s\ttraining loss:\t3.309186\n",
      "Done 5910 batches in 803.92s\ttraining loss:\t3.309154\n",
      "Done 5920 batches in 805.37s\ttraining loss:\t3.309197\n",
      "Done 5930 batches in 806.53s\ttraining loss:\t3.309202\n",
      "Done 5940 batches in 807.63s\ttraining loss:\t3.309120\n",
      "Done 5950 batches in 808.86s\ttraining loss:\t3.309098\n",
      "Done 5960 batches in 810.04s\ttraining loss:\t3.309068\n",
      "Done 5970 batches in 811.53s\ttraining loss:\t3.309015\n",
      "Done 5980 batches in 812.98s\ttraining loss:\t3.309017\n",
      "Done 5990 batches in 814.19s\ttraining loss:\t3.309048\n",
      "Done 6000 batches in 815.56s\ttraining loss:\t3.309059\n",
      "Done 6010 batches in 816.94s\ttraining loss:\t3.309025\n",
      "Done 6020 batches in 818.19s\ttraining loss:\t3.309068\n",
      "Done 6030 batches in 819.67s\ttraining loss:\t3.308982\n",
      "Done 6040 batches in 821.04s\ttraining loss:\t3.308952\n",
      "Done 6050 batches in 822.72s\ttraining loss:\t3.308988\n",
      "Done 6060 batches in 824.11s\ttraining loss:\t3.308934\n",
      "Done 6070 batches in 825.56s\ttraining loss:\t3.308892\n",
      "Done 6080 batches in 826.72s\ttraining loss:\t3.308841\n",
      "Done 6090 batches in 828.08s\ttraining loss:\t3.308807\n",
      "Done 6100 batches in 829.58s\ttraining loss:\t3.308743\n",
      "Done 6110 batches in 830.90s\ttraining loss:\t3.308702\n",
      "Done 6120 batches in 832.15s\ttraining loss:\t3.308695\n",
      "Done 6130 batches in 833.40s\ttraining loss:\t3.308664\n",
      "Done 6140 batches in 835.07s\ttraining loss:\t3.308704\n",
      "Done 6150 batches in 836.21s\ttraining loss:\t3.308714\n",
      "Done 6160 batches in 837.70s\ttraining loss:\t3.308714\n",
      "Done 6170 batches in 839.04s\ttraining loss:\t3.308706\n",
      "Done 6180 batches in 840.21s\ttraining loss:\t3.308620\n",
      "Done 6190 batches in 841.62s\ttraining loss:\t3.308641\n",
      "Done 6200 batches in 842.97s\ttraining loss:\t3.308662\n",
      "Done 6210 batches in 844.17s\ttraining loss:\t3.308684\n",
      "Done 6220 batches in 845.42s\ttraining loss:\t3.308691\n",
      "Done 6230 batches in 846.61s\ttraining loss:\t3.308652\n",
      "Done 6240 batches in 848.00s\ttraining loss:\t3.308663\n",
      "Done 6250 batches in 849.20s\ttraining loss:\t3.308552\n",
      "Done 6260 batches in 850.36s\ttraining loss:\t3.308583\n",
      "Done 6270 batches in 851.87s\ttraining loss:\t3.308546\n",
      "Done 6280 batches in 853.45s\ttraining loss:\t3.308494\n",
      "Done 6290 batches in 854.54s\ttraining loss:\t3.308520\n",
      "Done 6300 batches in 855.91s\ttraining loss:\t3.308523\n",
      "Done 6310 batches in 857.32s\ttraining loss:\t3.308554\n",
      "Done 6320 batches in 858.56s\ttraining loss:\t3.308528\n",
      "Done 6330 batches in 859.86s\ttraining loss:\t3.308559\n",
      "Done 6340 batches in 861.40s\ttraining loss:\t3.308486\n",
      "Done 6350 batches in 862.41s\ttraining loss:\t3.308399\n",
      "Done 6360 batches in 863.63s\ttraining loss:\t3.308431\n",
      "Done 6370 batches in 864.83s\ttraining loss:\t3.308423\n",
      "Done 6380 batches in 866.20s\ttraining loss:\t3.308428\n",
      "Done 6390 batches in 867.58s\ttraining loss:\t3.308434\n",
      "Done 6400 batches in 868.68s\ttraining loss:\t3.308410\n",
      "Done 6410 batches in 869.77s\ttraining loss:\t3.308400\n",
      "Done 6420 batches in 870.96s\ttraining loss:\t3.308359\n",
      "Done 6430 batches in 872.26s\ttraining loss:\t3.308321\n",
      "Done 6440 batches in 873.75s\ttraining loss:\t3.308337\n",
      "Done 6450 batches in 875.18s\ttraining loss:\t3.308263\n",
      "Done 6460 batches in 876.22s\ttraining loss:\t3.308238\n",
      "Done 6470 batches in 877.62s\ttraining loss:\t3.308185\n",
      "Done 6480 batches in 879.03s\ttraining loss:\t3.308168\n",
      "Done 6490 batches in 880.15s\ttraining loss:\t3.308143\n",
      "Done 6500 batches in 881.30s\ttraining loss:\t3.308145\n",
      "Done 6510 batches in 882.78s\ttraining loss:\t3.308123\n",
      "Done 6520 batches in 884.13s\ttraining loss:\t3.308087\n",
      "Done 6530 batches in 885.38s\ttraining loss:\t3.308086\n",
      "Done 6540 batches in 886.85s\ttraining loss:\t3.308082\n",
      "Done 6550 batches in 888.53s\ttraining loss:\t3.308116\n",
      "Done 6560 batches in 889.89s\ttraining loss:\t3.308089\n",
      "Done 6570 batches in 891.17s\ttraining loss:\t3.308166\n",
      "Done 6580 batches in 892.46s\ttraining loss:\t3.308119\n",
      "Done 6590 batches in 894.03s\ttraining loss:\t3.308126\n",
      "Done 6600 batches in 895.19s\ttraining loss:\t3.308133\n",
      "Done 6610 batches in 896.34s\ttraining loss:\t3.308153\n",
      "Done 6620 batches in 897.72s\ttraining loss:\t3.308133\n",
      "Done 6630 batches in 899.31s\ttraining loss:\t3.308183\n",
      "Done 6640 batches in 900.65s\ttraining loss:\t3.308080\n",
      "Done 6650 batches in 902.15s\ttraining loss:\t3.308071\n",
      "Done 6660 batches in 903.47s\ttraining loss:\t3.308066\n",
      "Done 6670 batches in 904.89s\ttraining loss:\t3.308055\n",
      "Done 6680 batches in 906.36s\ttraining loss:\t3.308050\n",
      "Done 6690 batches in 908.08s\ttraining loss:\t3.308089\n",
      "Done 6700 batches in 909.61s\ttraining loss:\t3.308087\n",
      "Done 6710 batches in 910.66s\ttraining loss:\t3.308041\n",
      "Done 6720 batches in 912.07s\ttraining loss:\t3.308055\n",
      "Done 6730 batches in 913.53s\ttraining loss:\t3.308017\n",
      "Done 6740 batches in 915.09s\ttraining loss:\t3.307997\n",
      "Done 6750 batches in 916.49s\ttraining loss:\t3.307961\n",
      "Done 6760 batches in 917.82s\ttraining loss:\t3.307971\n",
      "Done 6770 batches in 919.08s\ttraining loss:\t3.307950\n",
      "Done 6780 batches in 920.58s\ttraining loss:\t3.307917\n",
      "Done 6790 batches in 921.97s\ttraining loss:\t3.307868\n",
      "Done 6800 batches in 923.53s\ttraining loss:\t3.307870\n",
      "Done 6810 batches in 924.91s\ttraining loss:\t3.307866\n",
      "Done 6820 batches in 926.35s\ttraining loss:\t3.307846\n",
      "Done 6830 batches in 927.74s\ttraining loss:\t3.307844\n",
      "Done 6840 batches in 929.10s\ttraining loss:\t3.307855\n",
      "Done 6850 batches in 930.10s\ttraining loss:\t3.307822\n",
      "Done 6860 batches in 931.41s\ttraining loss:\t3.307778\n",
      "Done 6870 batches in 932.76s\ttraining loss:\t3.307781\n",
      "Done 6880 batches in 934.20s\ttraining loss:\t3.307795\n",
      "Done 6890 batches in 935.40s\ttraining loss:\t3.307763\n",
      "Done 6900 batches in 936.82s\ttraining loss:\t3.307742\n",
      "Done 6910 batches in 938.37s\ttraining loss:\t3.307808\n",
      "Done 6920 batches in 939.58s\ttraining loss:\t3.307883\n",
      "Done 6930 batches in 941.08s\ttraining loss:\t3.307839\n",
      "Done 6940 batches in 942.72s\ttraining loss:\t3.307869\n",
      "Done 6950 batches in 944.35s\ttraining loss:\t3.307826\n",
      "Done 6960 batches in 945.98s\ttraining loss:\t3.307819\n",
      "Done 6970 batches in 947.56s\ttraining loss:\t3.307797\n",
      "Done 6980 batches in 949.01s\ttraining loss:\t3.307750\n",
      "Done 6990 batches in 950.36s\ttraining loss:\t3.307761\n",
      "Done 7000 batches in 951.73s\ttraining loss:\t3.307746\n",
      "Done 7010 batches in 953.00s\ttraining loss:\t3.307780\n",
      "Done 7020 batches in 954.24s\ttraining loss:\t3.307790\n",
      "Done 7030 batches in 955.96s\ttraining loss:\t3.307849\n",
      "Done 7040 batches in 957.24s\ttraining loss:\t3.307801\n",
      "Done 7050 batches in 958.80s\ttraining loss:\t3.307780\n",
      "Done 7060 batches in 960.45s\ttraining loss:\t3.307771\n",
      "Done 7070 batches in 961.64s\ttraining loss:\t3.307766\n",
      "Done 7080 batches in 963.02s\ttraining loss:\t3.307706\n",
      "Done 7090 batches in 964.41s\ttraining loss:\t3.307728\n",
      "Done 7100 batches in 965.72s\ttraining loss:\t3.307687\n",
      "Done 7110 batches in 967.00s\ttraining loss:\t3.307669\n",
      "Done 7120 batches in 968.15s\ttraining loss:\t3.307711\n",
      "Done 7130 batches in 969.99s\ttraining loss:\t3.307750\n",
      "Done 7140 batches in 971.32s\ttraining loss:\t3.307753\n",
      "Done 7150 batches in 972.77s\ttraining loss:\t3.307751\n",
      "Done 7160 batches in 974.20s\ttraining loss:\t3.307715\n",
      "Done 7170 batches in 975.29s\ttraining loss:\t3.307714\n",
      "Done 7180 batches in 976.42s\ttraining loss:\t3.307721\n",
      "Done 7190 batches in 977.82s\ttraining loss:\t3.307681\n",
      "Done 7200 batches in 979.38s\ttraining loss:\t3.307617\n",
      "Done 7210 batches in 980.60s\ttraining loss:\t3.307637\n",
      "Done 7220 batches in 981.90s\ttraining loss:\t3.307701\n",
      "Done 7230 batches in 983.50s\ttraining loss:\t3.307795\n",
      "Done 7240 batches in 984.72s\ttraining loss:\t3.307773\n",
      "Done 7250 batches in 985.85s\ttraining loss:\t3.307736\n",
      "Done 7260 batches in 987.23s\ttraining loss:\t3.307710\n",
      "Done 7270 batches in 988.56s\ttraining loss:\t3.307686\n",
      "Done 7280 batches in 989.81s\ttraining loss:\t3.307692\n",
      "Done 7290 batches in 991.30s\ttraining loss:\t3.307708\n",
      "Done 7300 batches in 992.57s\ttraining loss:\t3.307721\n",
      "Done 7310 batches in 994.40s\ttraining loss:\t3.307748\n",
      "Done 7320 batches in 995.51s\ttraining loss:\t3.307739\n",
      "Done 7330 batches in 996.92s\ttraining loss:\t3.307753\n",
      "Done 7340 batches in 998.46s\ttraining loss:\t3.307754\n",
      "Done 7350 batches in 1000.06s\ttraining loss:\t3.307765\n",
      "Done 7360 batches in 1001.23s\ttraining loss:\t3.307710\n",
      "Done 7370 batches in 1003.05s\ttraining loss:\t3.307701\n",
      "Done 7380 batches in 1004.31s\ttraining loss:\t3.307701\n",
      "Done 7390 batches in 1005.49s\ttraining loss:\t3.307740\n",
      "Done 7400 batches in 1006.77s\ttraining loss:\t3.307703\n",
      "Done 7410 batches in 1008.41s\ttraining loss:\t3.307773\n",
      "Done 7420 batches in 1009.64s\ttraining loss:\t3.307733\n",
      "Done 7430 batches in 1010.92s\ttraining loss:\t3.307754\n",
      "Done 7440 batches in 1012.28s\ttraining loss:\t3.307772\n",
      "Done 7450 batches in 1013.61s\ttraining loss:\t3.307781\n",
      "Done 7460 batches in 1014.79s\ttraining loss:\t3.307714\n",
      "Done 7470 batches in 1016.06s\ttraining loss:\t3.307728\n",
      "Done 7480 batches in 1017.36s\ttraining loss:\t3.307709\n",
      "Done 7490 batches in 1018.74s\ttraining loss:\t3.307702\n",
      "Done 7500 batches in 1020.02s\ttraining loss:\t3.307695\n",
      "Done 7510 batches in 1021.47s\ttraining loss:\t3.307666\n",
      "Done 7520 batches in 1022.88s\ttraining loss:\t3.307629\n",
      "Done 7530 batches in 1024.20s\ttraining loss:\t3.307666\n",
      "Done 7540 batches in 1025.52s\ttraining loss:\t3.307670\n",
      "Done 7550 batches in 1027.08s\ttraining loss:\t3.307663\n",
      "Done 7560 batches in 1028.78s\ttraining loss:\t3.307654\n",
      "Done 7570 batches in 1030.14s\ttraining loss:\t3.307629\n",
      "Done 7580 batches in 1031.43s\ttraining loss:\t3.307613\n",
      "Done 7590 batches in 1032.83s\ttraining loss:\t3.307597\n",
      "Done 7600 batches in 1034.21s\ttraining loss:\t3.307592\n",
      "Done 7610 batches in 1035.65s\ttraining loss:\t3.307558\n",
      "Done 7620 batches in 1037.09s\ttraining loss:\t3.307547\n",
      "Done 7630 batches in 1038.62s\ttraining loss:\t3.307531\n",
      "Done 7640 batches in 1040.03s\ttraining loss:\t3.307499\n",
      "Done 7650 batches in 1041.72s\ttraining loss:\t3.307463\n",
      "Done 7660 batches in 1042.96s\ttraining loss:\t3.307485\n",
      "Done 7670 batches in 1044.35s\ttraining loss:\t3.307482\n",
      "Done 7680 batches in 1045.55s\ttraining loss:\t3.307473\n",
      "Done 7690 batches in 1046.84s\ttraining loss:\t3.307449\n",
      "Done 7700 batches in 1048.45s\ttraining loss:\t3.307511\n",
      "Done 7710 batches in 1049.81s\ttraining loss:\t3.307504\n",
      "Done 7720 batches in 1051.06s\ttraining loss:\t3.307501\n",
      "Done 7730 batches in 1052.33s\ttraining loss:\t3.307523\n",
      "Done 7740 batches in 1053.71s\ttraining loss:\t3.307470\n",
      "Done 7750 batches in 1055.15s\ttraining loss:\t3.307469\n",
      "Done 7760 batches in 1056.41s\ttraining loss:\t3.307395\n",
      "Done 7770 batches in 1057.76s\ttraining loss:\t3.307335\n",
      "Done 7780 batches in 1059.28s\ttraining loss:\t3.307347\n",
      "Done 7790 batches in 1060.88s\ttraining loss:\t3.307407\n",
      "Done 7800 batches in 1062.09s\ttraining loss:\t3.307388\n",
      "Done 7810 batches in 1063.46s\ttraining loss:\t3.307359\n",
      "Done 7820 batches in 1065.11s\ttraining loss:\t3.307365\n",
      "Done 7830 batches in 1066.48s\ttraining loss:\t3.307364\n",
      "Done 7840 batches in 1068.14s\ttraining loss:\t3.307354\n",
      "Done 7850 batches in 1069.51s\ttraining loss:\t3.307328\n",
      "Done 7860 batches in 1070.84s\ttraining loss:\t3.307323\n",
      "Done 7870 batches in 1072.18s\ttraining loss:\t3.307301\n",
      "Done 7880 batches in 1073.77s\ttraining loss:\t3.307341\n",
      "Done 7890 batches in 1075.19s\ttraining loss:\t3.307317\n",
      "Done 7900 batches in 1076.45s\ttraining loss:\t3.307300\n",
      "Done 7910 batches in 1078.09s\ttraining loss:\t3.307254\n",
      "Done 7920 batches in 1079.52s\ttraining loss:\t3.307224\n",
      "Done 7930 batches in 1080.97s\ttraining loss:\t3.307272\n",
      "Done 7940 batches in 1082.14s\ttraining loss:\t3.307272\n",
      "Done 7950 batches in 1083.54s\ttraining loss:\t3.307260\n",
      "Done 7960 batches in 1085.49s\ttraining loss:\t3.307248\n",
      "Done 7970 batches in 1087.17s\ttraining loss:\t3.307262\n",
      "Done 7980 batches in 1088.63s\ttraining loss:\t3.307265\n",
      "Done 7990 batches in 1090.02s\ttraining loss:\t3.307247\n",
      "Done 8000 batches in 1091.38s\ttraining loss:\t3.307242\n",
      "Done 8010 batches in 1092.73s\ttraining loss:\t3.307250\n",
      "Done 8020 batches in 1093.95s\ttraining loss:\t3.307217\n",
      "Done 8030 batches in 1095.31s\ttraining loss:\t3.307203\n",
      "Done 8040 batches in 1096.93s\ttraining loss:\t3.307201\n",
      "Done 8050 batches in 1098.20s\ttraining loss:\t3.307142\n",
      "Done 8060 batches in 1099.54s\ttraining loss:\t3.307135\n",
      "Done 8070 batches in 1100.68s\ttraining loss:\t3.307110\n",
      "Done 8080 batches in 1102.27s\ttraining loss:\t3.307091\n",
      "Done 8090 batches in 1103.75s\ttraining loss:\t3.307109\n",
      "Done 8100 batches in 1105.26s\ttraining loss:\t3.307176\n",
      "Done 8110 batches in 1106.69s\ttraining loss:\t3.307185\n",
      "Done 8120 batches in 1108.17s\ttraining loss:\t3.307134\n",
      "Done 8130 batches in 1109.59s\ttraining loss:\t3.307115\n",
      "Done 8140 batches in 1110.82s\ttraining loss:\t3.307046\n",
      "Done 8150 batches in 1112.37s\ttraining loss:\t3.307084\n",
      "Done 8160 batches in 1113.62s\ttraining loss:\t3.307086\n",
      "Done 8170 batches in 1114.96s\ttraining loss:\t3.307080\n",
      "Done 8180 batches in 1116.16s\ttraining loss:\t3.307069\n",
      "Done 8190 batches in 1117.39s\ttraining loss:\t3.307081\n",
      "Done 8200 batches in 1118.46s\ttraining loss:\t3.307087\n",
      "Done 8210 batches in 1120.02s\ttraining loss:\t3.307113\n",
      "Done 8220 batches in 1121.40s\ttraining loss:\t3.307119\n",
      "Done 8230 batches in 1122.88s\ttraining loss:\t3.307076\n",
      "Done 8240 batches in 1124.38s\ttraining loss:\t3.307098\n",
      "Done 8250 batches in 1125.75s\ttraining loss:\t3.307061\n",
      "Done 8260 batches in 1126.82s\ttraining loss:\t3.307053\n",
      "Done 8270 batches in 1128.04s\ttraining loss:\t3.307024\n",
      "Done 8280 batches in 1129.63s\ttraining loss:\t3.306999\n",
      "Done 8290 batches in 1131.34s\ttraining loss:\t3.307023\n",
      "Done 8300 batches in 1132.85s\ttraining loss:\t3.306976\n",
      "Done 8310 batches in 1134.18s\ttraining loss:\t3.306974\n",
      "Done 8320 batches in 1135.53s\ttraining loss:\t3.306975\n",
      "Done 8330 batches in 1137.10s\ttraining loss:\t3.307037\n",
      "Done 8340 batches in 1138.36s\ttraining loss:\t3.307024\n",
      "Done 8350 batches in 1139.77s\ttraining loss:\t3.307061\n",
      "Done 8360 batches in 1141.03s\ttraining loss:\t3.307056\n",
      "Done 8370 batches in 1142.40s\ttraining loss:\t3.307009\n",
      "Done 8380 batches in 1143.57s\ttraining loss:\t3.307021\n",
      "Done 8390 batches in 1144.81s\ttraining loss:\t3.307009\n",
      "Done 8400 batches in 1146.25s\ttraining loss:\t3.306940\n",
      "Done 8410 batches in 1147.98s\ttraining loss:\t3.306924\n",
      "Done 8420 batches in 1149.04s\ttraining loss:\t3.306938\n",
      "Done 8430 batches in 1150.56s\ttraining loss:\t3.306996\n",
      "Done 8440 batches in 1151.90s\ttraining loss:\t3.306973\n",
      "Done 8450 batches in 1153.01s\ttraining loss:\t3.306936\n",
      "Done 8460 batches in 1154.27s\ttraining loss:\t3.306941\n",
      "Done 8470 batches in 1155.58s\ttraining loss:\t3.306964\n",
      "Done 8480 batches in 1156.78s\ttraining loss:\t3.307001\n",
      "Done 8490 batches in 1158.07s\ttraining loss:\t3.307003\n",
      "Done 8500 batches in 1159.58s\ttraining loss:\t3.306955\n",
      "Done 8510 batches in 1160.81s\ttraining loss:\t3.306968\n",
      "Done 8520 batches in 1162.37s\ttraining loss:\t3.306991\n",
      "Done 8530 batches in 1164.21s\ttraining loss:\t3.306954\n",
      "Done 8540 batches in 1165.47s\ttraining loss:\t3.306980\n",
      "Done 8550 batches in 1166.75s\ttraining loss:\t3.306940\n",
      "Done 8560 batches in 1168.12s\ttraining loss:\t3.306921\n",
      "Done 8570 batches in 1169.85s\ttraining loss:\t3.306895\n",
      "Done 8580 batches in 1171.64s\ttraining loss:\t3.306892\n",
      "Done 8590 batches in 1173.14s\ttraining loss:\t3.306858\n",
      "Done 8600 batches in 1174.34s\ttraining loss:\t3.306865\n",
      "Done 8610 batches in 1175.57s\ttraining loss:\t3.306834\n",
      "Done 8620 batches in 1177.15s\ttraining loss:\t3.306821\n",
      "Done 8630 batches in 1178.54s\ttraining loss:\t3.306750\n",
      "Done 8640 batches in 1179.97s\ttraining loss:\t3.306712\n",
      "Done 8650 batches in 1181.29s\ttraining loss:\t3.306696\n",
      "Done 8660 batches in 1182.70s\ttraining loss:\t3.306664\n",
      "Done 8670 batches in 1184.31s\ttraining loss:\t3.306701\n",
      "Done 8680 batches in 1185.66s\ttraining loss:\t3.306715\n",
      "Done 8690 batches in 1186.98s\ttraining loss:\t3.306670\n",
      "Done 8700 batches in 1188.34s\ttraining loss:\t3.306670\n",
      "Done 8710 batches in 1189.59s\ttraining loss:\t3.306618\n",
      "Done 8720 batches in 1191.18s\ttraining loss:\t3.306588\n",
      "Done 8730 batches in 1192.56s\ttraining loss:\t3.306604\n",
      "Done 8740 batches in 1194.04s\ttraining loss:\t3.306584\n",
      "Done 8750 batches in 1195.39s\ttraining loss:\t3.306522\n",
      "Done 8760 batches in 1196.85s\ttraining loss:\t3.306514\n",
      "Done 8770 batches in 1198.25s\ttraining loss:\t3.306502\n",
      "Done 8780 batches in 1199.38s\ttraining loss:\t3.306496\n",
      "Done 8790 batches in 1200.70s\ttraining loss:\t3.306486\n",
      "Done 8800 batches in 1202.13s\ttraining loss:\t3.306478\n",
      "Done 8810 batches in 1203.54s\ttraining loss:\t3.306440\n",
      "Done 8820 batches in 1205.07s\ttraining loss:\t3.306452\n",
      "Done 8830 batches in 1206.36s\ttraining loss:\t3.306425\n",
      "Done 8840 batches in 1207.44s\ttraining loss:\t3.306434\n",
      "Done 8850 batches in 1208.84s\ttraining loss:\t3.306425\n",
      "Done 8860 batches in 1209.96s\ttraining loss:\t3.306397\n",
      "Done 8870 batches in 1211.58s\ttraining loss:\t3.306381\n",
      "Done 8880 batches in 1212.75s\ttraining loss:\t3.306373\n",
      "Done 8890 batches in 1214.20s\ttraining loss:\t3.306372\n",
      "Done 8900 batches in 1215.53s\ttraining loss:\t3.306340\n",
      "Done 8910 batches in 1216.83s\ttraining loss:\t3.306343\n",
      "Done 8920 batches in 1218.26s\ttraining loss:\t3.306326\n",
      "Done 8930 batches in 1219.80s\ttraining loss:\t3.306377\n",
      "Done 8940 batches in 1221.20s\ttraining loss:\t3.306381\n",
      "Done 8950 batches in 1222.48s\ttraining loss:\t3.306374\n",
      "Done 8960 batches in 1224.00s\ttraining loss:\t3.306379\n",
      "Done 8970 batches in 1225.41s\ttraining loss:\t3.306366\n",
      "Done 8980 batches in 1226.96s\ttraining loss:\t3.306405\n",
      "Done 8990 batches in 1228.26s\ttraining loss:\t3.306408\n",
      "Done 9000 batches in 1229.68s\ttraining loss:\t3.306380\n",
      "Done 9010 batches in 1231.26s\ttraining loss:\t3.306374\n",
      "Done 9020 batches in 1232.71s\ttraining loss:\t3.306324\n",
      "Done 9030 batches in 1233.93s\ttraining loss:\t3.306341\n",
      "Done 9040 batches in 1235.16s\ttraining loss:\t3.306263\n",
      "Done 9050 batches in 1236.71s\ttraining loss:\t3.306251\n",
      "Done 9060 batches in 1238.26s\ttraining loss:\t3.306241\n",
      "Done 9070 batches in 1239.73s\ttraining loss:\t3.306239\n",
      "Done 9080 batches in 1241.17s\ttraining loss:\t3.306276\n",
      "Done 9090 batches in 1242.38s\ttraining loss:\t3.306270\n",
      "Done 9100 batches in 1244.10s\ttraining loss:\t3.306282\n",
      "Done 9110 batches in 1245.40s\ttraining loss:\t3.306270\n",
      "Done 9120 batches in 1246.90s\ttraining loss:\t3.306262\n",
      "Done 9130 batches in 1247.92s\ttraining loss:\t3.306287\n",
      "Done 9140 batches in 1249.38s\ttraining loss:\t3.306245\n",
      "Done 9150 batches in 1250.80s\ttraining loss:\t3.306208\n",
      "Done 9160 batches in 1252.36s\ttraining loss:\t3.306218\n",
      "Done 9170 batches in 1253.85s\ttraining loss:\t3.306172\n",
      "Done 9180 batches in 1255.45s\ttraining loss:\t3.306216\n",
      "Done 9190 batches in 1256.97s\ttraining loss:\t3.306233\n",
      "Done 9200 batches in 1258.43s\ttraining loss:\t3.306185\n",
      "Done 9210 batches in 1259.93s\ttraining loss:\t3.306188\n",
      "Done 9220 batches in 1261.22s\ttraining loss:\t3.306173\n",
      "Done 9230 batches in 1262.61s\ttraining loss:\t3.306124\n",
      "Done 9240 batches in 1264.06s\ttraining loss:\t3.306137\n",
      "Done 9250 batches in 1265.55s\ttraining loss:\t3.306138\n",
      "Done 9260 batches in 1267.09s\ttraining loss:\t3.306124\n",
      "Done 9270 batches in 1268.48s\ttraining loss:\t3.306097\n",
      "Done 9280 batches in 1270.16s\ttraining loss:\t3.306107\n",
      "Done 9290 batches in 1271.53s\ttraining loss:\t3.306085\n",
      "Done 9300 batches in 1273.08s\ttraining loss:\t3.306053\n",
      "Done 9310 batches in 1274.69s\ttraining loss:\t3.305999\n",
      "Done 9320 batches in 1276.07s\ttraining loss:\t3.306008\n",
      "Done 9330 batches in 1277.85s\ttraining loss:\t3.305968\n",
      "Done 9340 batches in 1279.34s\ttraining loss:\t3.305956\n",
      "Done 9350 batches in 1280.84s\ttraining loss:\t3.305962\n",
      "Done 9360 batches in 1282.14s\ttraining loss:\t3.305952\n",
      "Done 9370 batches in 1283.63s\ttraining loss:\t3.305967\n",
      "Done 9380 batches in 1285.05s\ttraining loss:\t3.306007\n",
      "Done 9390 batches in 1286.27s\ttraining loss:\t3.306031\n",
      "Done 9400 batches in 1287.81s\ttraining loss:\t3.306018\n",
      "Done 9410 batches in 1289.34s\ttraining loss:\t3.306029\n",
      "Done 9420 batches in 1290.55s\ttraining loss:\t3.305954\n",
      "Done 9430 batches in 1292.07s\ttraining loss:\t3.305935\n",
      "Done 9440 batches in 1293.59s\ttraining loss:\t3.305961\n",
      "Done 9450 batches in 1295.01s\ttraining loss:\t3.305930\n",
      "Done 9460 batches in 1296.38s\ttraining loss:\t3.305898\n",
      "Done 9470 batches in 1297.60s\ttraining loss:\t3.305900\n",
      "Done 9480 batches in 1298.82s\ttraining loss:\t3.305928\n",
      "Done 9490 batches in 1299.93s\ttraining loss:\t3.305914\n",
      "Done 9500 batches in 1301.31s\ttraining loss:\t3.305896\n",
      "Done 9510 batches in 1302.61s\ttraining loss:\t3.305916\n",
      "Done 9520 batches in 1303.95s\ttraining loss:\t3.305920\n",
      "Done 9530 batches in 1305.26s\ttraining loss:\t3.305929\n",
      "Done 9540 batches in 1306.70s\ttraining loss:\t3.305950\n",
      "Done 9550 batches in 1307.91s\ttraining loss:\t3.305897\n",
      "Done 9560 batches in 1309.26s\ttraining loss:\t3.305889\n",
      "Done 9570 batches in 1310.62s\ttraining loss:\t3.305870\n",
      "Done 9580 batches in 1312.11s\ttraining loss:\t3.305896\n",
      "Done 9590 batches in 1313.42s\ttraining loss:\t3.305908\n",
      "Done 9600 batches in 1314.79s\ttraining loss:\t3.305910\n",
      "Done 9610 batches in 1316.20s\ttraining loss:\t3.305956\n",
      "Done 9620 batches in 1317.78s\ttraining loss:\t3.305946\n",
      "Done 9630 batches in 1319.43s\ttraining loss:\t3.305943\n",
      "Done 9640 batches in 1320.70s\ttraining loss:\t3.305948\n",
      "Done 9650 batches in 1322.13s\ttraining loss:\t3.305961\n",
      "Done 9660 batches in 1323.51s\ttraining loss:\t3.305982\n",
      "Done 9670 batches in 1324.75s\ttraining loss:\t3.305999\n",
      "Done 9680 batches in 1326.29s\ttraining loss:\t3.306025\n",
      "Done 9690 batches in 1327.64s\ttraining loss:\t3.306046\n",
      "Done 9700 batches in 1328.97s\ttraining loss:\t3.306058\n",
      "Done 9710 batches in 1330.23s\ttraining loss:\t3.306059\n",
      "Done 9720 batches in 1331.53s\ttraining loss:\t3.306038\n",
      "Done 9730 batches in 1333.11s\ttraining loss:\t3.306041\n",
      "Done 9740 batches in 1334.53s\ttraining loss:\t3.306026\n",
      "Done 9750 batches in 1335.80s\ttraining loss:\t3.306012\n",
      "Done 9760 batches in 1337.20s\ttraining loss:\t3.305994\n",
      "Done 9770 batches in 1338.66s\ttraining loss:\t3.306033\n",
      "Done 9780 batches in 1340.23s\ttraining loss:\t3.306023\n",
      "Done 9790 batches in 1341.83s\ttraining loss:\t3.306054\n",
      "Done 9800 batches in 1343.11s\ttraining loss:\t3.306045\n",
      "Done 9810 batches in 1344.69s\ttraining loss:\t3.306071\n",
      "Done 9820 batches in 1346.09s\ttraining loss:\t3.306060\n",
      "Done 9830 batches in 1347.62s\ttraining loss:\t3.306047\n",
      "Done 9840 batches in 1349.23s\ttraining loss:\t3.306005\n",
      "Done 9850 batches in 1350.78s\ttraining loss:\t3.306006\n",
      "Done 9860 batches in 1352.30s\ttraining loss:\t3.305971\n",
      "Done 9870 batches in 1353.47s\ttraining loss:\t3.305973\n",
      "Done 9880 batches in 1355.02s\ttraining loss:\t3.305932\n",
      "Done 9890 batches in 1356.52s\ttraining loss:\t3.305915\n",
      "Done 9900 batches in 1358.07s\ttraining loss:\t3.305915\n",
      "Done 9910 batches in 1359.12s\ttraining loss:\t3.305930\n",
      "Done 9920 batches in 1360.83s\ttraining loss:\t3.305910\n",
      "Done 9930 batches in 1362.20s\ttraining loss:\t3.305879\n",
      "Done 9940 batches in 1363.62s\ttraining loss:\t3.305867\n",
      "Done 9950 batches in 1365.01s\ttraining loss:\t3.305831\n",
      "Done 9960 batches in 1366.47s\ttraining loss:\t3.305807\n",
      "Done 9970 batches in 1367.74s\ttraining loss:\t3.305821\n",
      "Done 9980 batches in 1369.32s\ttraining loss:\t3.305818\n",
      "Done 9990 batches in 1370.61s\ttraining loss:\t3.305808\n",
      "Done 10000 batches in 1371.86s\ttraining loss:\t3.305824\n",
      "Done 10010 batches in 1373.13s\ttraining loss:\t3.305827\n",
      "Done 10020 batches in 1374.34s\ttraining loss:\t3.305822\n",
      "Done 10030 batches in 1375.65s\ttraining loss:\t3.305792\n",
      "Done 10040 batches in 1377.11s\ttraining loss:\t3.305784\n",
      "Done 10050 batches in 1378.86s\ttraining loss:\t3.305797\n",
      "Done 10060 batches in 1380.15s\ttraining loss:\t3.305781\n",
      "Done 10070 batches in 1381.54s\ttraining loss:\t3.305785\n",
      "Done 10080 batches in 1382.64s\ttraining loss:\t3.305761\n",
      "Done 10090 batches in 1384.03s\ttraining loss:\t3.305763\n",
      "Done 10100 batches in 1385.36s\ttraining loss:\t3.305808\n",
      "Done 10110 batches in 1386.65s\ttraining loss:\t3.305827\n",
      "Done 10120 batches in 1388.06s\ttraining loss:\t3.305843\n",
      "Done 10130 batches in 1389.53s\ttraining loss:\t3.305851\n",
      "Done 10140 batches in 1390.94s\ttraining loss:\t3.305843\n",
      "Done 10150 batches in 1392.21s\ttraining loss:\t3.305807\n",
      "Done 10160 batches in 1393.75s\ttraining loss:\t3.305826\n",
      "Done 10170 batches in 1394.84s\ttraining loss:\t3.305772\n",
      "Done 10180 batches in 1396.32s\ttraining loss:\t3.305781\n",
      "Done 10190 batches in 1397.53s\ttraining loss:\t3.305759\n",
      "Done 10200 batches in 1398.83s\ttraining loss:\t3.305745\n",
      "Done 10210 batches in 1400.19s\ttraining loss:\t3.305756\n",
      "Done 10220 batches in 1401.44s\ttraining loss:\t3.305724\n",
      "Done 10230 batches in 1402.94s\ttraining loss:\t3.305723\n",
      "Done 10240 batches in 1404.26s\ttraining loss:\t3.305715\n",
      "Done 10250 batches in 1405.96s\ttraining loss:\t3.305730\n",
      "Done 10260 batches in 1407.14s\ttraining loss:\t3.305703\n",
      "Done 10270 batches in 1408.51s\ttraining loss:\t3.305710\n",
      "Done 10280 batches in 1409.80s\ttraining loss:\t3.305747\n",
      "Done 10290 batches in 1411.02s\ttraining loss:\t3.305734\n",
      "Done 10300 batches in 1412.35s\ttraining loss:\t3.305731\n",
      "Done 10310 batches in 1413.75s\ttraining loss:\t3.305763\n",
      "Done 10320 batches in 1414.89s\ttraining loss:\t3.305740\n",
      "Done 10330 batches in 1416.27s\ttraining loss:\t3.305715\n",
      "Done 10340 batches in 1417.49s\ttraining loss:\t3.305746\n",
      "Done 10350 batches in 1418.73s\ttraining loss:\t3.305764\n",
      "Done 10360 batches in 1420.27s\ttraining loss:\t3.305770\n",
      "Done 10370 batches in 1421.82s\ttraining loss:\t3.305745\n",
      "Done 10380 batches in 1423.16s\ttraining loss:\t3.305735\n",
      "Done 10390 batches in 1424.45s\ttraining loss:\t3.305759\n",
      "Done 10400 batches in 1425.66s\ttraining loss:\t3.305771\n",
      "Done 10410 batches in 1426.88s\ttraining loss:\t3.305792\n",
      "Done 10420 batches in 1428.35s\ttraining loss:\t3.305817\n",
      "Done 10430 batches in 1429.59s\ttraining loss:\t3.305796\n",
      "Done 10440 batches in 1430.87s\ttraining loss:\t3.305741\n",
      "Done 10450 batches in 1432.11s\ttraining loss:\t3.305749\n",
      "Done 10460 batches in 1433.39s\ttraining loss:\t3.305760\n",
      "Done 10470 batches in 1434.64s\ttraining loss:\t3.305767\n",
      "Done 10480 batches in 1435.96s\ttraining loss:\t3.305754\n",
      "Done 10490 batches in 1437.26s\ttraining loss:\t3.305790\n",
      "Done 10500 batches in 1438.56s\ttraining loss:\t3.305758\n",
      "Done 10510 batches in 1440.20s\ttraining loss:\t3.305729\n",
      "Done 10520 batches in 1441.51s\ttraining loss:\t3.305691\n",
      "Done 10530 batches in 1443.29s\ttraining loss:\t3.305701\n",
      "Done 10540 batches in 1444.80s\ttraining loss:\t3.305712\n",
      "Done 10550 batches in 1446.36s\ttraining loss:\t3.305742\n",
      "Done 10560 batches in 1447.53s\ttraining loss:\t3.305744\n",
      "Done 10570 batches in 1448.74s\ttraining loss:\t3.305735\n",
      "Done 10580 batches in 1450.20s\ttraining loss:\t3.305729\n",
      "Done 10590 batches in 1451.52s\ttraining loss:\t3.305769\n",
      "Done 10600 batches in 1452.82s\ttraining loss:\t3.305746\n",
      "Done 10610 batches in 1454.03s\ttraining loss:\t3.305722\n",
      "Done 10620 batches in 1455.60s\ttraining loss:\t3.305729\n",
      "Done 10630 batches in 1457.11s\ttraining loss:\t3.305746\n",
      "Done 10640 batches in 1458.43s\ttraining loss:\t3.305747\n",
      "Done 10650 batches in 1459.76s\ttraining loss:\t3.305733\n",
      "Done 10660 batches in 1461.00s\ttraining loss:\t3.305734\n",
      "Done 10670 batches in 1462.56s\ttraining loss:\t3.305772\n",
      "Done 10680 batches in 1463.86s\ttraining loss:\t3.305763\n",
      "Done 10690 batches in 1465.10s\ttraining loss:\t3.305702\n",
      "Done 10700 batches in 1466.39s\ttraining loss:\t3.305669\n",
      "Done 10710 batches in 1467.60s\ttraining loss:\t3.305687\n",
      "Done 10720 batches in 1469.16s\ttraining loss:\t3.305674\n",
      "Done 10730 batches in 1470.44s\ttraining loss:\t3.305639\n",
      "Done 10740 batches in 1471.73s\ttraining loss:\t3.305644\n",
      "Done 10750 batches in 1473.28s\ttraining loss:\t3.305664\n",
      "Done 10760 batches in 1474.65s\ttraining loss:\t3.305664\n",
      "Done 10770 batches in 1475.74s\ttraining loss:\t3.305634\n",
      "Done 10780 batches in 1477.27s\ttraining loss:\t3.305639\n",
      "Done 10790 batches in 1478.80s\ttraining loss:\t3.305598\n",
      "Done 10800 batches in 1480.23s\ttraining loss:\t3.305557\n",
      "Done 10810 batches in 1481.71s\ttraining loss:\t3.305535\n",
      "Done 10820 batches in 1483.33s\ttraining loss:\t3.305533\n",
      "Done 10830 batches in 1484.84s\ttraining loss:\t3.305542\n",
      "Done 10840 batches in 1486.35s\ttraining loss:\t3.305538\n",
      "Done 10850 batches in 1487.65s\ttraining loss:\t3.305490\n",
      "Done 10860 batches in 1489.39s\ttraining loss:\t3.305504\n",
      "Done 10870 batches in 1491.01s\ttraining loss:\t3.305506\n",
      "Done 10880 batches in 1492.19s\ttraining loss:\t3.305512\n",
      "Done 10890 batches in 1493.71s\ttraining loss:\t3.305488\n",
      "Done 10900 batches in 1495.56s\ttraining loss:\t3.305481\n",
      "Done 10910 batches in 1496.99s\ttraining loss:\t3.305463\n",
      "Done 10920 batches in 1498.35s\ttraining loss:\t3.305464\n",
      "Done 10930 batches in 1499.48s\ttraining loss:\t3.305442\n",
      "Done 10940 batches in 1500.89s\ttraining loss:\t3.305449\n",
      "Done 10950 batches in 1502.06s\ttraining loss:\t3.305438\n",
      "Done 10960 batches in 1503.57s\ttraining loss:\t3.305395\n",
      "Done 10970 batches in 1505.18s\ttraining loss:\t3.305390\n",
      "Done 10980 batches in 1506.45s\ttraining loss:\t3.305352\n",
      "Done 10990 batches in 1508.06s\ttraining loss:\t3.305318\n",
      "Done 11000 batches in 1509.38s\ttraining loss:\t3.305305\n",
      "Done 11010 batches in 1510.64s\ttraining loss:\t3.305272\n",
      "Done 11020 batches in 1512.11s\ttraining loss:\t3.305280\n",
      "Done 11030 batches in 1513.23s\ttraining loss:\t3.305273\n",
      "Done 11040 batches in 1514.56s\ttraining loss:\t3.305279\n",
      "Done 11050 batches in 1515.83s\ttraining loss:\t3.305292\n",
      "Done 11060 batches in 1517.22s\ttraining loss:\t3.305265\n",
      "Done 11070 batches in 1518.64s\ttraining loss:\t3.305262\n",
      "Done 11080 batches in 1519.82s\ttraining loss:\t3.305264\n",
      "Done 11090 batches in 1521.30s\ttraining loss:\t3.305260\n",
      "Done 11100 batches in 1522.38s\ttraining loss:\t3.305251\n",
      "Done 11110 batches in 1523.80s\ttraining loss:\t3.305215\n",
      "Done 11120 batches in 1525.12s\ttraining loss:\t3.305201\n",
      "Done 11130 batches in 1526.49s\ttraining loss:\t3.305191\n",
      "Done 11140 batches in 1527.80s\ttraining loss:\t3.305156\n",
      "Done 11150 batches in 1529.10s\ttraining loss:\t3.305173\n",
      "Done 11160 batches in 1530.42s\ttraining loss:\t3.305187\n",
      "Done 11170 batches in 1532.02s\ttraining loss:\t3.305168\n",
      "Done 11180 batches in 1533.19s\ttraining loss:\t3.305197\n",
      "Done 11190 batches in 1534.37s\ttraining loss:\t3.305134\n",
      "Done 11200 batches in 1535.41s\ttraining loss:\t3.305122\n",
      "Done 11210 batches in 1536.58s\ttraining loss:\t3.305098\n",
      "Done 11220 batches in 1537.98s\ttraining loss:\t3.305126\n",
      "Done 11230 batches in 1539.36s\ttraining loss:\t3.305126\n",
      "Done 11240 batches in 1540.75s\ttraining loss:\t3.305081\n",
      "Done 11250 batches in 1542.28s\ttraining loss:\t3.305097\n",
      "Done 11260 batches in 1543.51s\ttraining loss:\t3.305069\n",
      "Done 11270 batches in 1544.59s\ttraining loss:\t3.305041\n",
      "Done 11280 batches in 1545.97s\ttraining loss:\t3.305026\n",
      "Done 11290 batches in 1547.27s\ttraining loss:\t3.305005\n",
      "Done 11300 batches in 1548.69s\ttraining loss:\t3.305033\n",
      "Done 11310 batches in 1550.11s\ttraining loss:\t3.305052\n",
      "Done 11320 batches in 1551.47s\ttraining loss:\t3.305058\n",
      "Done 11330 batches in 1552.64s\ttraining loss:\t3.305034\n",
      "Done 11340 batches in 1554.14s\ttraining loss:\t3.304991\n",
      "Done 11350 batches in 1555.55s\ttraining loss:\t3.304970\n",
      "Done 11360 batches in 1556.76s\ttraining loss:\t3.304976\n",
      "Done 11370 batches in 1557.93s\ttraining loss:\t3.304982\n",
      "Done 11380 batches in 1559.38s\ttraining loss:\t3.304987\n",
      "Done 11390 batches in 1560.72s\ttraining loss:\t3.304968\n",
      "Done 11400 batches in 1561.94s\ttraining loss:\t3.304986\n",
      "Done 11410 batches in 1563.31s\ttraining loss:\t3.304957\n",
      "Done 11420 batches in 1564.64s\ttraining loss:\t3.304941\n",
      "Done 11430 batches in 1565.84s\ttraining loss:\t3.304944\n",
      "Done 11440 batches in 1567.37s\ttraining loss:\t3.304976\n",
      "Done 11450 batches in 1568.55s\ttraining loss:\t3.304964\n",
      "Done 11460 batches in 1570.01s\ttraining loss:\t3.304971\n",
      "Done 11470 batches in 1571.27s\ttraining loss:\t3.304968\n",
      "Done 11480 batches in 1572.44s\ttraining loss:\t3.304933\n",
      "Done 11490 batches in 1573.71s\ttraining loss:\t3.304936\n",
      "Done 11500 batches in 1575.00s\ttraining loss:\t3.304952\n",
      "Done 11510 batches in 1576.57s\ttraining loss:\t3.304949\n",
      "Done 11520 batches in 1577.96s\ttraining loss:\t3.304931\n",
      "Done 11530 batches in 1579.31s\ttraining loss:\t3.304926\n",
      "Done 11540 batches in 1581.06s\ttraining loss:\t3.304912\n",
      "Done 11550 batches in 1582.28s\ttraining loss:\t3.304878\n",
      "Done 11560 batches in 1583.66s\ttraining loss:\t3.304866\n",
      "Done 11570 batches in 1585.16s\ttraining loss:\t3.304861\n",
      "Done 11580 batches in 1586.47s\ttraining loss:\t3.304833\n",
      "Done 11590 batches in 1588.03s\ttraining loss:\t3.304818\n",
      "Done 11600 batches in 1589.57s\ttraining loss:\t3.304796\n",
      "Done 11610 batches in 1591.13s\ttraining loss:\t3.304795\n",
      "Done 11620 batches in 1592.47s\ttraining loss:\t3.304787\n",
      "Done 11630 batches in 1594.00s\ttraining loss:\t3.304796\n",
      "Done 11640 batches in 1595.62s\ttraining loss:\t3.304811\n",
      "Done 11650 batches in 1597.04s\ttraining loss:\t3.304808\n",
      "Done 11660 batches in 1598.48s\ttraining loss:\t3.304783\n",
      "Done 11670 batches in 1599.89s\ttraining loss:\t3.304777\n",
      "Done 11680 batches in 1601.41s\ttraining loss:\t3.304788\n",
      "Done 11690 batches in 1602.88s\ttraining loss:\t3.304764\n",
      "Done 11700 batches in 1604.16s\ttraining loss:\t3.304788\n",
      "Done 11710 batches in 1605.43s\ttraining loss:\t3.304771\n",
      "Done 11720 batches in 1606.75s\ttraining loss:\t3.304775\n",
      "Done 11730 batches in 1607.97s\ttraining loss:\t3.304768\n",
      "Done 11740 batches in 1609.16s\ttraining loss:\t3.304758\n",
      "Done 11750 batches in 1610.45s\ttraining loss:\t3.304788\n",
      "Done 11760 batches in 1611.89s\ttraining loss:\t3.304801\n",
      "Done 100 batches in 2.33s\n",
      "Done 200 batches in 4.94s\n",
      "Done 300 batches in 7.48s\n",
      "Done 400 batches in 10.11s\n",
      "Done 500 batches in 12.44s\n",
      "Done 600 batches in 14.85s\n",
      "Done 700 batches in 17.17s\n",
      "Done 800 batches in 19.55s\n",
      "Done 900 batches in 21.86s\n",
      "Done 1000 batches in 24.16s\n",
      "Done 1100 batches in 26.82s\n",
      "Done 1200 batches in 29.53s\n",
      "Done 1300 batches in 32.17s\n",
      "Done 1400 batches in 35.04s\n",
      "Done 1500 batches in 37.75s\n",
      "Done 1600 batches in 40.62s\n",
      "Done 1700 batches in 42.88s\n",
      "Done 1800 batches in 45.33s\n",
      "Done 1900 batches in 47.83s\n",
      "Done 2000 batches in 50.32s\n",
      "Done 2100 batches in 52.92s\n",
      "Done 2200 batches in 55.50s\n",
      "Done 2300 batches in 58.10s\n",
      "Done 2400 batches in 60.48s\n",
      "Done 2500 batches in 62.95s\n",
      "Done 2600 batches in 65.47s\n",
      "Done 2700 batches in 68.18s\n",
      "Done 2800 batches in 70.97s\n",
      "Done 2900 batches in 73.52s\n",
      "Epoch 5 of 5 took 1688.42s\n",
      "  training loss:\t\t3.304804\n",
      "  validation loss:\t\t3.417077\n"
     ]
    }
   ],
   "source": [
    "net.train_model(num_epochs=5,\n",
    "                path='sentences_5ep_w2vInit_300_300_ssoft(uni,200,non-unique)_bs50_cut200.npz',\n",
    "                save_params=True,\n",
    "                train_batch_size=50,\n",
    "                train_data=train,\n",
    "                val_batch_size=25,\n",
    "                val_data=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnd_next_word(probs, size=1):\n",
    "    return np.random.choice(np.append(np.arange(probs.shape[0]-1), -1).astype(np.int32), \n",
    "                            size=size, p=probs)\n",
    "\n",
    "def beam_search(get_probs_fun, beam=10, init_seq='', mode='rr'):\n",
    "    utt = map(lambda w: w_to_idx.get(w, w_to_idx['<unk>']), init_seq.split())\n",
    "    if len(utt) == 0 or utt[0] != 1:\n",
    "        utt = [1] + utt\n",
    "    utt = np.asarray(utt, dtype=np.int32)[np.newaxis]\n",
    "    \n",
    "    if mode[0] == 's':\n",
    "        words = get_probs_fun(utt)[0].argpartition(-beam)[-beam:].astype(np.int32)\n",
    "        words[words==voc_size-1] = pad_value\n",
    "    elif mode[0] == 'r':\n",
    "        words = rnd_next_word(get_probs_fun(utt)[0], beam)\n",
    "    \n",
    "    candidates = utt.repeat(beam, axis=0)\n",
    "    candidates = np.hstack([candidates, words[np.newaxis].T])\n",
    "    scores = np.zeros(beam)\n",
    "    \n",
    "#     print candidates\n",
    "    \n",
    "    while candidates.shape[1] < 100 and pad_value not in candidates[:,-1]:\n",
    "        \n",
    "        if mode[1] == 's':\n",
    "            log_probs = np.log(get_probs_fun(candidates))\n",
    "            tot_scores = log_probs + scores[np.newaxis].T\n",
    "\n",
    "            idx = tot_scores.ravel().argpartition(-beam)[-beam:]\n",
    "            i,j = divmod(idx, tot_scores.shape[1])\n",
    "            j[j==voc_size-1] = pad_value\n",
    "            \n",
    "            scores = tot_scores[i,j]\n",
    "\n",
    "            candidates = np.hstack([candidates[i], j[np.newaxis].T.astype(np.int32)])\n",
    "            \n",
    "        elif mode[1] == 'r':\n",
    "            probs = get_probs_fun(candidates)\n",
    "            words = []\n",
    "            for k in xrange(beam):\n",
    "                words.append(rnd_next_word(probs[k], beam)) # this doesn't have to be exactly 'beam'\n",
    "            words = np.array(words)\n",
    "            idx = np.indices((beam, words.shape[1]))[0]\n",
    "            tot_scores = scores[np.newaxis].T + np.log(probs)[idx, words]\n",
    "                \n",
    "            idx = tot_scores.ravel().argpartition(-beam)[-beam:]\n",
    "            i,j = divmod(idx, tot_scores.shape[1])\n",
    "\n",
    "            scores = tot_scores[i,j]\n",
    "\n",
    "            candidates = np.hstack([candidates[i], words[i,j][np.newaxis].T])\n",
    "            \n",
    "#     print candidates[:,:10]\n",
    "#     print scores[:10]\n",
    "        \n",
    "    cands = candidates[candidates[:,-1] == 0]\n",
    "    if cands.size > 0:\n",
    "        return candidates[candidates[:,-1] == 0][0]\n",
    "    return candidates[scores.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"that ' s what i ' m saying .\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt = beam_search(net.get_probs_fn, init_seq='', beam=2, mode='rr')\n",
    "\n",
    "text = map(lambda i: idx_to_w[i], list(utt))\n",
    "' '.join([t for t in text if t not in ['<s>', '</s>', '<utt_end>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<person> <unk> ? got some help ! !'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_seq = ''\n",
    "utt = [1] + map(lambda w: w_to_idx.get(w, w_to_idx['<unk>']), init_seq.split())\n",
    "utt = np.asarray(utt, dtype=np.int32)[np.newaxis]\n",
    "\n",
    "i = 0\n",
    "while utt[0,-1] != -1 and i < 100:\n",
    "    word_probs = net.get_probs_fn(utt)[0]\n",
    "    next_idx = rnd_next_word(word_probs)\n",
    "    utt = np.append(utt, next_idx)[np.newaxis].astype(np.int32)\n",
    "    i += 1\n",
    "    \n",
    "text = map(lambda i: idx_to_w[i], list(utt[0]))\n",
    "' '.join([t for t in text if t not in ['<s>', '</s>', '<utt_end>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
