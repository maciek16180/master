{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 4007)\n",
      "/home/i258346/.local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "from itertools import chain\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "from SimpleRNNLM import SimpleRNNLM, iterate_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remember, now the pad value is the same as the <utt_end> token\n",
    "\n",
    "pad_value = -1 # <utt_end>'s vector is the last one\n",
    "\n",
    "def split_utt(utt):\n",
    "    u1, u2, u3 = [i for i,j in enumerate(utt) if j == 1]\n",
    "    return [utt[:u2], utt[u2:u3], utt[u3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "# mt_path = \"/home/maciek/Desktop/mgr/DATA/MovieTriples_Dataset/\"\n",
    "\n",
    "def load_mt(path=mt_path):\n",
    "    tr = np.load(mt_path + 'Training.triples.pkl')\n",
    "    vl = np.load(mt_path + 'Validation.triples.pkl')\n",
    "    ts = np.load(mt_path + 'Test.triples.pkl')\n",
    "    \n",
    "#     tr = chain(*map(split_utt, tr))\n",
    "#     vl = chain(*map(split_utt, vl))\n",
    "#     ts = chain(*map(split_utt, ts))\n",
    "    \n",
    "    return tr, vl, ts\n",
    "\n",
    "train, valid, test = load_mt()\n",
    "\n",
    "train = [utt for utt in train if len(utt) < 200]\n",
    "valid = [utt for utt in valid if len(utt) < 200]\n",
    "test  = [utt for utt in test  if len(utt) < 200]\n",
    "\n",
    "\n",
    "def get_mt_voc(mt_path=mt_path, train_len=len(train)):\n",
    "    word_list = np.load(mt_path + 'Training.dict.pkl')\n",
    "    word_list.sort(key=lambda x: x[1])\n",
    "    freqs = np.array(map(lambda x: x[2], word_list) + [train_len])\n",
    "    total_count = float(sum(freqs))\n",
    "    \n",
    "    words = map(lambda x: x[:2], word_list)\n",
    "    \n",
    "    w_to_idx = dict(words)\n",
    "    w_to_idx['<utt_end>'] = pad_value\n",
    "    idx_to_w = {v : k for (k,v) in w_to_idx.items()}\n",
    "    \n",
    "    return idx_to_w, w_to_idx, len(w_to_idx), freqs / total_count\n",
    "\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_mt_voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_embs, word2vec_embs_mask = np.load(mt_path + 'Word2Vec_WordEmb.pkl')\n",
    "word2vec_embs = np.vstack([word2vec_embs, L.init.GlorotUniform()((1,300))]).astype(np.float32)\n",
    "word2vec_embs_mask = np.vstack([word2vec_embs_mask, np.ones((1,300))])\n",
    "\n",
    "w2v_train_mask = np.where(word2vec_embs_mask[:,0] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "Building a network for generation...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "net = SimpleRNNLM(voc_size=voc_size,\n",
    "                  emb_size=300,\n",
    "                  rec_size=300,\n",
    "                  mode='nce',\n",
    "                  num_sampled=200,\n",
    "                  emb_init=word2vec_embs,\n",
    "                  noise_probs=freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.load_params(fname='5ep_w2vInit_300_300_ssoft(uni,200,non-unique)_bs50_cut200.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 batches in 0.58s\ttraining loss:\tnan\n",
      "Done 20 batches in 1.05s\ttraining loss:\tnan\n",
      "Done 30 batches in 1.54s\ttraining loss:\tnan\n",
      "Done 40 batches in 2.05s\ttraining loss:\tnan\n",
      "Done 50 batches in 2.51s\ttraining loss:\tnan\n",
      "Done 60 batches in 3.08s\ttraining loss:\tnan\n",
      "Done 70 batches in 3.62s\ttraining loss:\tnan\n",
      "Done 80 batches in 4.09s\ttraining loss:\tnan\n",
      "Done 90 batches in 4.57s\ttraining loss:\tnan\n",
      "Done 100 batches in 5.11s\ttraining loss:\tnan\n",
      "Done 110 batches in 5.57s\ttraining loss:\tnan\n",
      "Done 120 batches in 6.06s\ttraining loss:\tnan\n",
      "Done 130 batches in 6.46s\ttraining loss:\tnan\n",
      "Done 140 batches in 7.05s\ttraining loss:\tnan\n",
      "Done 150 batches in 7.63s\ttraining loss:\tnan\n",
      "Done 160 batches in 8.09s\ttraining loss:\tnan\n",
      "Done 170 batches in 8.54s\ttraining loss:\tnan\n",
      "Done 180 batches in 9.06s\ttraining loss:\tnan\n",
      "Done 190 batches in 9.60s\ttraining loss:\tnan\n",
      "Done 200 batches in 10.06s\ttraining loss:\tnan\n",
      "Done 210 batches in 10.57s\ttraining loss:\tnan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-60dc78ae0b52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mval_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 val_data=valid)\n\u001b[0m",
      "\u001b[1;32m/home/i258346/Desktop/mgr/rnn_ex/SimpleRNNLM.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, train_data, val_data, train_batch_size, val_batch_size, num_epochs, save_params, path)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[0mtrain_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             \u001b[0mval_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/Desktop/mgr/rnn_ex/SimpleRNNLM.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, train_data, batch_size)\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 951\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    941\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train_model(num_epochs=1,\n",
    "                path=None,\n",
    "                save_params=False,\n",
    "                train_batch_size=1,\n",
    "                train_data=train,\n",
    "                val_batch_size=25,\n",
    "                val_data=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnd_next_word(probs, size=1):\n",
    "    return np.random.choice(np.append(np.arange(probs.shape[0]-1), -1).astype(np.int32), \n",
    "                            size=size, p=probs)\n",
    "\n",
    "def beam_search(get_probs_fun, beam=10, init_seq='', mode='rr'):\n",
    "    utt = map(lambda w: w_to_idx.get(w, w_to_idx['<unk>']), init_seq.split())\n",
    "    if len(utt) == 0 or utt[0] != 1:\n",
    "        utt = [1] + utt\n",
    "    utt = np.asarray(utt, dtype=np.int32)[np.newaxis]\n",
    "    \n",
    "    if mode[0] == 's':\n",
    "        words = get_probs_fun(utt)[0].argpartition(-beam)[-beam:].astype(np.int32)\n",
    "        words[words==voc_size-1] = pad_value\n",
    "    elif mode[0] == 'r':\n",
    "        words = rnd_next_word(get_probs_fun(utt)[0], beam)\n",
    "    \n",
    "    candidates = utt.repeat(beam, axis=0)\n",
    "    candidates = np.hstack([candidates, words[np.newaxis].T])\n",
    "    scores = np.zeros(beam)\n",
    "    \n",
    "#     print candidates\n",
    "    \n",
    "    while candidates.shape[1] < 100 and pad_value not in candidates[:,-1]:\n",
    "        \n",
    "        if mode[1] == 's':\n",
    "            log_probs = np.log(get_probs_fun(candidates))\n",
    "            tot_scores = log_probs + scores[np.newaxis].T\n",
    "\n",
    "            idx = tot_scores.ravel().argpartition(-beam)[-beam:]\n",
    "            i,j = divmod(idx, tot_scores.shape[1])\n",
    "            j[j==voc_size-1] = pad_value\n",
    "            \n",
    "            scores = tot_scores[i,j]\n",
    "\n",
    "            candidates = np.hstack([candidates[i], j[np.newaxis].T.astype(np.int32)])\n",
    "            \n",
    "        elif mode[1] == 'r':\n",
    "            probs = get_probs_fun(candidates)\n",
    "            words = []\n",
    "            for k in xrange(beam):\n",
    "                words.append(rnd_next_word(probs[k], beam)) # this doesn't have to be exactly 'beam'\n",
    "            words = np.array(words)\n",
    "            idx = np.indices((beam, words.shape[1]))[0]\n",
    "            tot_scores = scores[np.newaxis].T + np.log(probs)[idx, words]\n",
    "                \n",
    "            idx = tot_scores.ravel().argpartition(-beam)[-beam:]\n",
    "            i,j = divmod(idx, tot_scores.shape[1])\n",
    "\n",
    "            scores = tot_scores[i,j]\n",
    "\n",
    "            candidates = np.hstack([candidates[i], words[i,j][np.newaxis].T])\n",
    "            \n",
    "#     print candidates[:,:10]\n",
    "#     print scores[:10]\n",
    "        \n",
    "    cands = candidates[candidates[:,-1] == 0]\n",
    "    if cands.size > 0:\n",
    "        return candidates[candidates[:,-1] == 0][0]\n",
    "    return candidates[scores.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"really ? i ' m okay . <person> . <person> ' s about to tell me .\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt = beam_search(net.get_probs_fn, init_seq='', beam=2, mode='rr')\n",
    "\n",
    "text = map(lambda i: idx_to_w[i], list(utt))\n",
    "' '.join([t for t in text if t not in ['<s>', '</s>', '<utt_end>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<person> <unk> ? got some help ! !'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_seq = ''\n",
    "utt = [1] + map(lambda w: w_to_idx.get(w, w_to_idx['<unk>']), init_seq.split())\n",
    "utt = np.asarray(utt, dtype=np.int32)[np.newaxis]\n",
    "\n",
    "i = 0\n",
    "while utt[0,-1] != -1 and i < 100:\n",
    "    word_probs = net.get_probs_fn(utt)[0]\n",
    "    next_idx = rnd_next_word(word_probs)\n",
    "    utt = np.append(utt, next_idx)[np.newaxis].astype(np.int32)\n",
    "    i += 1\n",
    "    \n",
    "text = map(lambda i: idx_to_w[i], list(utt[0]))\n",
    "' '.join([t for t in text if t not in ['<s>', '</s>', '<utt_end>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
