{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../rnn_ex/')\n",
    "\n",
    "from HRED import HRED\n",
    "from mt_load import load_mt, get_mt_voc, get_w2v_embs\n",
    "from load_subtle import load_subtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember, now the pad value is the same as the <utt_end> token\n",
    "\n",
    "pad_value = -1 # <utt_end>'s vector is the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Failed to interpret file '/pio/data/data/mtriples/Subtle_Dataset.triples.pkl' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a96cd8c94280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msubtle_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/pio/data/data/mtriples/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_subtle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_subtle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtle_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/Desktop/masters_thesis/HRED/load_subtle.pyc\u001b[0m in \u001b[0;36mload_subtle\u001b[1;34m(path, split, trim)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_subtle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Subtle_Dataset.triples.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m                 raise IOError(\n\u001b[1;32m--> 429\u001b[1;33m                     \"Failed to interpret file %s as a pickle\" % repr(file))\n\u001b[0m\u001b[0;32m    430\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: Failed to interpret file '/pio/data/data/mtriples/Subtle_Dataset.triples.pkl' as a pickle"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "subtle_path = \"/pio/data/data/mtriples/\"\n",
    "\n",
    "train_subtle = load_subtle(subtle_path, split=True, trim=200)\n",
    "print time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "# mt_path = \"/home/maciek/Desktop/mgr/DATA/MovieTriples_Dataset/\"\n",
    "\n",
    "train, valid, test = load_mt(path=mt_path, split=True, trim=200)\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_mt_voc(path=mt_path, train_len=len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_embs, word2vec_embs_mask = get_w2v_embs(path=mt_path)\n",
    "\n",
    "w2v_train_mask = np.where(word2vec_embs_mask[:,0] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "Building a network for generating...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hred_net = HRED(voc_size=voc_size,\n",
    "                emb_size=300,\n",
    "                lv1_rec_size=300, \n",
    "                lv2_rec_size=300, \n",
    "                out_emb_size=300, \n",
    "                num_sampled=200,\n",
    "                ssoft_probs=freqs,\n",
    "                emb_init=word2vec_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hred_net.load_params('trained_models/subtleFixed_300_300_300_300_ssoft200unigr_bs30_cut200_early5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_utt(utt):\n",
    "    print ' '.join([idx_to_w[x] if x != voc_size-1 else '<utt_end>' for x in utt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnd_next_word(probs, size=1):\n",
    "    return np.random.choice(np.append(np.arange(probs.shape[0]-1), -1).astype(np.int32), \n",
    "                            size=size, p=probs)\n",
    "\n",
    "def beam_search(beam, dec_init, gamma=-.1, init_seq=np.array([[1]])):\n",
    "    seq = np.repeat(init_seq.astype(np.int32), beam, axis=0)\n",
    "#     seq = np.ones((beam, 1), dtype=np.int32)\n",
    "    probs, dec_init = hred_net.get_probs_and_new_dec_init_fn(seq, dec_init)\n",
    "    \n",
    "    words = probs[0].argpartition(-beam)[-beam:].astype(np.int32)\n",
    "    words[words==voc_size-1] = pad_value\n",
    "    scores = np.log(probs[0][words])\n",
    "    seq = np.hstack([seq, words[:, np.newaxis]])\n",
    "    \n",
    "    ends = np.zeros(beam)\n",
    "    \n",
    "    while not all(ends) and seq.shape[1] < 50:\n",
    "        probs, dec_init = hred_net.get_probs_and_new_dec_init_fn(seq[:,-1:], dec_init)\n",
    "        words = probs.argpartition(-beam, axis=1)[:, -beam:].astype(np.int32)\n",
    "        new_scores = (np.log(probs[np.indices((beam, beam))[0], words]) + scores[:, np.newaxis])\n",
    "        ###\n",
    "        new_scores += (new_scores.argsort(axis=1) + 1) * gamma\n",
    "        ###\n",
    "        new_scores = new_scores.ravel()\n",
    "        best = new_scores.argpartition(-beam)[-beam:].astype(np.int32)\n",
    "        new_seq = []\n",
    "        new_ends = []\n",
    "        new_dec_inits = []\n",
    "        \n",
    "        for idx in best:\n",
    "            i,j = divmod(idx, beam)\n",
    "            new_seq.append(np.concatenate([seq[i], np.array([words[i,j]])]))\n",
    "            new_dec_inits.append(dec_init[i])\n",
    "            \n",
    "            if ends[i]:\n",
    "                new_ends.append(ends[i])\n",
    "            elif words[i,j] == w_to_idx['</s>']:\n",
    "                new_ends.append(seq[i].size)\n",
    "            else:\n",
    "                new_ends.append(0)\n",
    "                \n",
    "        seq = np.vstack(new_seq)\n",
    "        ends = np.array(new_ends)\n",
    "        scores = new_scores[best]\n",
    "        dec_init = np.vstack(new_dec_inits)\n",
    "    \n",
    "    return seq[np.argsort(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def utt_to_array(utt):\n",
    "    arr = np.array([w_to_idx[w] for w in utt])[np.newaxis].astype(np.int32)\n",
    "    arr[arr == -voc_size] = -1\n",
    "    return arr\n",
    "\n",
    "def context_summary(context, lookup=True):\n",
    "    con_init = np.zeros((1, hred_net.lv2_rec_size), dtype=np.float32)\n",
    "    for utt in context:\n",
    "        con_init = hred_net.get_new_con_init_fn(utt_to_array(utt) if lookup else utt, con_init)\n",
    "    return con_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context = map(lambda x: np.array(x, dtype=np.int32)[np.newaxis], train[9:11])\n",
    "lookup = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> why do you look so satisfied ? </s>\n"
     ]
    }
   ],
   "source": [
    "print_utt(train[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ['<s> hi . </s>'.split(), '<s> hello , what \\' s up ? </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ['<s> yeah , okay . </s>'.split(), '<s> well , i guess i \\' ll be going now . </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> check turns goes start checks holidays holidays helps reflect helps reflect helps reflect happening stays happening shuts rushes television stays mention strain strain happens asks verge tv holidays checks strain supplies helps explode messes supplies junction checks apologized verge motions asks cheer stops strain checks apologized fails weekends bother\n",
      "\n",
      "<s> who called checks start bugging supplies strain strain happening stops strain stays happening television stays stays helps weekends strain supplies helps explode messes supplies junction checks strain mention supplies junction sneak weekends strain verge rips rushes shuts cleaners asks sneak verge sacramento messes respond strain stays drift catches weekends\n",
      "\n",
      "<s> you ought yelled stops coming checks explode respond tv helps bother bother verge stays forth fails helps verge checks apologized fails helps verge checks apologized fails helps verge checks apologized fails weekends bother bother bother bother bother bother investigate checks sneak investigate television investigate extent fails junction supplies explode\n",
      "\n",
      "<s> <person> turns television rips stays forth fails junction investigate assembly strain helps verge tv fails verge goes television apologized stays helps bother bother bother investigate publishing airlock verge stays asks news stays helps verge sacramento junction fails helps explode drift asks helps cheer stops thanksgiving schedule apologized fails verge\n",
      "\n",
      "<s> uh works worry comes happens monday mention assembly stays stays stays happening messes mention assembly supplies junction shuts rushes rushes rushes mention asks cheer stops strain strain stays helps bother bother verge stays asks extent bother verge sacramento stops thanksgiving strain fails weekends strain supplies weekends strain stays drift\n",
      "\n",
      "<s> show news sacramento happens asks strain strain happens asks happens goes respond tv junction respond holidays apologized messes messes helps verge sacramento stays asks news stays forth strain stays helps bother investigate helps cheer stops thanksgiving helps cheer stops respond strain stays drift sacramento weekends verge rips motions stays\n",
      "\n",
      "<s> he wants better reach start junction investigate investigate checks drift stays drift asks helps reflect helps reflect helps reflect happening stays happening shuts rushes drift messes respond messes mention strain mention respond weekends checks weekends investigate checks weekends helps explode junction shuts helps explode messes helps explode junction supplies\n",
      "\n",
      "<s> tv shows he talks sacramento stops helps tend helps tend weekends helps tend television messes television strain stays helps verge stays forth strain fails weekends bother bother bother verge stays asks news strain stays forth strain fails weekends messes messes verge sacramento junction fails helps verge sacramento junction shuts\n",
      "\n",
      "<s> look sees messes helps movies strain happening stops worry mention asks yuh happened thanksgiving apologized weekends checks holidays sneak strain happened thanksgiving helps weekends weekends messes messes supplies junction checks weekends bother sneak apologized verge sacramento stops thanksgiving schedule checks strain mention respond weekends strain fails junction supplies weekends\n",
      "\n",
      "<s> well ask tells appreciate bother respond strain fails television worry fails junction checks strain fails weekends strain stays helps verge tv verge sacramento respond asks cheer stops respond fails weekends messes respond strain stays drift checks apologized fails junction shuts rushes drift tv weekends ought disappeared asks cheer yuh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_size = 10\n",
    "con_init = context_summary(context, lookup)\n",
    "W = L.layers.get_all_param_values(hred_net.train_net)[31]\n",
    "b = L.layers.get_all_param_values(hred_net.train_net)[32]\n",
    "dec_init = np.repeat(con_init.dot(W) + b, beam_size, axis=0)\n",
    "\n",
    "for utt in beam_search(beam_size, dec_init, gamma=-10, init_seq=utt_to_array('<s> '.split())):\n",
    "    print_utt(utt)\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 batches in 0.86s\ttraining loss:\t7.176166\n",
      "Done 20 batches in 1.69s\ttraining loss:\t6.175796\n",
      "Done 30 batches in 2.44s\ttraining loss:\t5.697121\n",
      "Done 40 batches in 3.47s\ttraining loss:\t5.374195\n",
      "Done 50 batches in 4.27s\ttraining loss:\t5.207509\n",
      "Done 60 batches in 5.11s\ttraining loss:\t5.063584\n",
      "Done 70 batches in 5.92s\ttraining loss:\t4.934647\n",
      "Done 80 batches in 6.69s\ttraining loss:\t4.840843\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e0bc5d556518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhred_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_subtle2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/i258346/Desktop/masters_thesis/rnn_ex/SimpleRNNLM.pyc\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, train_data, batch_size, log_interval)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mnum_batch_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mnum_training_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hred_net.train_one_epoch(train_subtle2, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100 batches in 4.56s\n",
      "Done 200 batches in 9.25s\n",
      "Done 300 batches in 14.05s\n",
      "Done 400 batches in 18.29s\n",
      "Done 500 batches in 22.79s\n",
      "Done 600 batches in 27.11s\n",
      "Done 700 batches in 31.47s\n",
      "Done 800 batches in 35.77s\n",
      "Done 900 batches in 40.50s\n",
      "Done 1000 batches in 45.42s\n",
      "Done 1100 batches in 50.12s\n",
      "Done 1200 batches in 54.98s\n",
      "Done 1300 batches in 59.86s\n",
      "Done 1400 batches in 64.20s\n",
      "Done 1500 batches in 68.60s\n",
      "Done 1600 batches in 73.03s\n",
      "Done 1700 batches in 77.50s\n",
      "Done 1800 batches in 82.20s\n",
      "Done 1900 batches in 87.06s\n",
      "Done 2000 batches in 91.32s\n",
      "Done 2100 batches in 96.01s\n",
      "Done 2200 batches in 100.76s\n",
      "Done 2300 batches in 105.59s\n",
      "Done 2400 batches in 110.10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2955217842403752"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hred_net.validate(valid, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''full softmax, bs=30'''\n",
    "# train, 1 dir, 1 epoch: 3.485554076321884\n",
    "# val: 3.455356876018342\n",
    "\n",
    "# train, 2 dir, concat, 1 epoch: 3.4864403798772239\n",
    "# val: 3.4579001751897063\n",
    "\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.4881669768474675\n",
    "# val: 3.4584704095551695\n",
    "# training time: ~4700s\n",
    "\n",
    "'''sampled softmax'''\n",
    "# bs=30\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.486180601246621\n",
    "# val: 3.4811877499289308\n",
    "# training time: ~2300s\n",
    "\n",
    "# bs=60\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.5235153449672456\n",
    "# val: 3.5063306987542759\n",
    "# training time: ~1900s"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
