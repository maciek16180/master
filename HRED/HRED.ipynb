{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../rnn_ex/')\n",
    "\n",
    "from HRED import HRED\n",
    "from mt_load import load_mt, get_mt_voc, get_w2v_embs\n",
    "from load_subtle import load_subtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember, now the pad value is the same as the <utt_end> token\n",
    "\n",
    "pad_value = -1 # <utt_end>'s vector is the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.3778378963\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "subtle_path = \"/pio/data/data/mtriples/\"\n",
    "\n",
    "train_subtle = load_subtle(subtle_path, split=True, trim=200)\n",
    "print time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "# mt_path = \"/home/maciek/Desktop/mgr/DATA/MovieTriples_Dataset/\"\n",
    "\n",
    "train, valid, test = load_mt(path=mt_path, split=True, trim=200)\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_mt_voc(path=mt_path, train_len=len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_embs, word2vec_embs_mask = get_w2v_embs(path=mt_path)\n",
    "\n",
    "w2v_train_mask = np.where(word2vec_embs_mask[:,0] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "Building a network for generating...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hred_net = HRED(voc_size=voc_size,\n",
    "                emb_size=300,\n",
    "                lv1_rec_size=300, \n",
    "                lv2_rec_size=300, \n",
    "                out_emb_size=300, \n",
    "                num_sampled=200,\n",
    "                ssoft_probs=freqs,\n",
    "                emb_init=word2vec_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hred_net.load_params('trained_models/w2vInit_300_300_300_300_ssoft200unigr_bs30_cut200_early5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_utt(utt):\n",
    "    print ' '.join([idx_to_w[x] if x != voc_size-1 else '<utt_end>' for x in utt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnd_next_word(probs, size=1):\n",
    "    return np.random.choice(np.append(np.arange(probs.shape[0]-1), -1).astype(np.int32), \n",
    "                            size=size, p=probs)\n",
    "\n",
    "def beam_search(beam, dec_init, gamma=-.1, init_seq=np.array([[1]])):\n",
    "    seq = np.repeat(init_seq.astype(np.int32), beam, axis=0)\n",
    "#     seq = np.ones((beam, 1), dtype=np.int32)\n",
    "    probs, dec_init = hred_net.get_probs_and_new_dec_init_fn(seq, dec_init)\n",
    "    \n",
    "    words = probs[0].argpartition(-beam)[-beam:].astype(np.int32)\n",
    "    words[words==voc_size-1] = pad_value\n",
    "    scores = np.log(probs[0][words])\n",
    "    seq = np.hstack([seq, words[:, np.newaxis]])\n",
    "    \n",
    "    ends = np.zeros(beam)\n",
    "    \n",
    "    while not all(ends) and seq.shape[1] < 50:\n",
    "        probs, dec_init = hred_net.get_probs_and_new_dec_init_fn(seq[:,-1:], dec_init)\n",
    "        words = probs.argpartition(-beam, axis=1)[:, -beam:].astype(np.int32)\n",
    "        new_scores = (np.log(probs[np.indices((beam, beam))[0], words]) + scores[:, np.newaxis])\n",
    "        ###\n",
    "        new_scores += (new_scores.argsort(axis=1) + 1) * gamma\n",
    "        ###\n",
    "        new_scores = new_scores.ravel()\n",
    "        best = new_scores.argpartition(-beam)[-beam:].astype(np.int32)\n",
    "        new_seq = []\n",
    "        new_ends = []\n",
    "        new_dec_inits = []\n",
    "        \n",
    "        for idx in best:\n",
    "            i,j = divmod(idx, beam)\n",
    "            new_seq.append(np.concatenate([seq[i], np.array([words[i,j]])]))\n",
    "            new_dec_inits.append(dec_init[i])\n",
    "            \n",
    "            if ends[i]:\n",
    "                new_ends.append(ends[i])\n",
    "            elif words[i,j] == w_to_idx['</s>']:\n",
    "                new_ends.append(seq[i].size)\n",
    "            else:\n",
    "                new_ends.append(0)\n",
    "                \n",
    "        seq = np.vstack(new_seq)\n",
    "        ends = np.array(new_ends)\n",
    "        scores = new_scores[best]\n",
    "        dec_init = np.vstack(new_dec_inits)\n",
    "    \n",
    "    return seq[np.argsort(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def utt_to_array(utt):\n",
    "    arr = np.array([w_to_idx[w] for w in utt])[np.newaxis].astype(np.int32)\n",
    "    arr[arr == -voc_size] = -1\n",
    "    return arr\n",
    "\n",
    "def context_summary(context):\n",
    "    con_init = np.zeros((1, hred_net.lv2_rec_size), dtype=np.float32)\n",
    "    for utt in context:\n",
    "        con_init = hred_net.get_new_con_init_fn(utt_to_array(utt), con_init)\n",
    "    return con_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ['<s> hi . </s>'.split(), '<s> hello , what \\' s up ? </s>'.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> what way you really expect the answer like an ad in <unk> work security record work evening nights like sending somebody <number> pounds time $ twenty-nine other option investigating file clerk can handle this whole new life <unk> on impact sales record advance on hold care where his work\n",
      "\n",
      "<s> what way you really expect the answer like an ad in <unk> work security record work evening nights like sending somebody <number> pounds time $ twenty-nine other time doorway floor rear trunk coming through t like new meaning much less well excuse us hope life story in spite things\n",
      "\n",
      "<s> t of all sorts kinds other end look vaguely dangerous silence living under surveillance shift ward kind kind <number> p still missing blue t ring raise the big hole time worrying right arm around $ cash <unk> work well put way the probe phone records and fifty quid of\n",
      "\n",
      "<s> well work on tv set hands in progress t sleep with no longer be <unk> time <unk> like large <unk> on top <unk> like twenty miles hence hell yeah talking <unk> well known ways life normally eat dripping trigger like big nutshell ' like spies just looks rather interesting\n",
      "\n",
      "<s> why does have time care where ' work mornings weekend anchor news like big storms planned night ' clock t have just walk out t like shoe eat squash coke bottle eat red wine champagne wine eat red tights filled water boil amounts sorta sick peoples well preserved distance\n",
      "\n",
      "<s> oh jesus walk around night night <unk> time marches into tears just another year sentence before asking his hands pocket just call his time sunrise outside jersey home in new life left <unk> and a good <unk> looks <unk> way out there other weekend internship at care where the\n",
      "\n",
      "<s> yeah whoa got punched up tears face <number> minutes outside have time bomb kit plays bingo pot bread can work mornings care other time experimenting coke sell some iced chocolate dish dinner drive a great cover day work evening long silence . just call like he hit time <unk>\n",
      "\n",
      "<s> just been <unk> time marches back work at best <unk> like large well way way be heard noises at t of just answer . no excuse he handles the sink water tanks pump pressure on earth perspective system can way back he got a t stand between two grand\n",
      "\n",
      "<s> get lost five minute care for <unk> ? a pretty stiff wind looks rather way way way round two other kind kind time bomb calls he hit the probe killed five blocks waiting till looks well known a very least really bad dream dream hole going on vacation room\n",
      "\n",
      "<s> what way you really expect the answer like an ad in <unk> work security record work evening nights like sending somebody <number> pounds time $ twenty-nine other option investigating file clerk can handle this whole new life <unk> on impact sales record advance on hold care where his blood\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_size = 10\n",
    "con_init = context_summary(context)\n",
    "W = L.layers.get_all_param_values(hred_net.train_net)[31]\n",
    "b = L.layers.get_all_param_values(hred_net.train_net)[32]\n",
    "dec_init = np.repeat(con_init.dot(W) + b, beam_size, axis=0)\n",
    "\n",
    "for utt in beam_search(beam_size, dec_init, gamma=-10, init_seq=utt_to_array('<s>'.split())):\n",
    "    print_utt(utt)\n",
    "    print ''\n",
    "\n",
    "# hred_net.get_probs_and_new_dec_init_fn(utt_to_array('<s> this is it'.split()), dec_init)[0][0].argpartition(-10)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 batches in 0.86s\ttraining loss:\t7.176166\n",
      "Done 20 batches in 1.69s\ttraining loss:\t6.175796\n",
      "Done 30 batches in 2.44s\ttraining loss:\t5.697121\n",
      "Done 40 batches in 3.47s\ttraining loss:\t5.374195\n",
      "Done 50 batches in 4.27s\ttraining loss:\t5.207509\n",
      "Done 60 batches in 5.11s\ttraining loss:\t5.063584\n",
      "Done 70 batches in 5.92s\ttraining loss:\t4.934647\n",
      "Done 80 batches in 6.69s\ttraining loss:\t4.840843\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e0bc5d556518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhred_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_subtle2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/i258346/Desktop/masters_thesis/rnn_ex/SimpleRNNLM.pyc\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, train_data, batch_size, log_interval)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mnum_batch_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mnum_training_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hred_net.train_one_epoch(train_subtle2, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100 batches in 4.67s\n",
      "Done 200 batches in 9.55s\n",
      "Done 300 batches in 14.64s\n",
      "Done 400 batches in 19.10s\n",
      "Done 500 batches in 23.70s\n",
      "Done 600 batches in 28.16s\n",
      "Done 700 batches in 32.69s\n",
      "Done 800 batches in 37.18s\n",
      "Done 900 batches in 42.03s\n",
      "Done 1000 batches in 47.11s\n",
      "Done 1100 batches in 52.00s\n",
      "Done 1200 batches in 57.01s\n",
      "Done 1300 batches in 62.08s\n",
      "Done 1400 batches in 66.66s\n",
      "Done 1500 batches in 71.25s\n",
      "Done 1600 batches in 75.86s\n",
      "Done 1700 batches in 80.38s\n",
      "Done 1800 batches in 85.46s\n",
      "Done 1900 batches in 90.48s\n",
      "Done 2000 batches in 94.94s\n",
      "Done 2100 batches in 99.86s\n",
      "Done 2200 batches in 104.77s\n",
      "Done 2300 batches in 109.84s\n",
      "Done 2400 batches in 114.53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.410280048104148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hred_net.validate(valid, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''full softmax, bs=30'''\n",
    "# train, 1 dir, 1 epoch: 3.485554076321884\n",
    "# val: 3.455356876018342\n",
    "\n",
    "# train, 2 dir, concat, 1 epoch: 3.4864403798772239\n",
    "# val: 3.4579001751897063\n",
    "\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.4881669768474675\n",
    "# val: 3.4584704095551695\n",
    "# training time: ~4700s\n",
    "\n",
    "'''sampled softmax'''\n",
    "# bs=30\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.486180601246621\n",
    "# val: 3.4811877499289308\n",
    "# training time: ~2300s\n",
    "\n",
    "# bs=60\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.5235153449672456\n",
    "# val: 3.5063306987542759\n",
    "# training time: ~1900s"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
