{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../rnn_ex/')\n",
    "\n",
    "from HRED import HRED\n",
    "from mt_load import load_mt, get_mt_voc, get_w2v_embs\n",
    "from load_subtle import load_subtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember, now the pad value is the same as the <utt_end> token\n",
    "\n",
    "pad_value = -1 # <utt_end>'s vector is the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Failed to interpret file '/pio/data/data/mtriples/Subtle_Dataset.triples.pkl' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a96cd8c94280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msubtle_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/pio/data/data/mtriples/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_subtle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_subtle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtle_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/Desktop/masters_thesis/HRED/load_subtle.pyc\u001b[0m in \u001b[0;36mload_subtle\u001b[1;34m(path, split, trim)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_subtle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Subtle_Dataset.triples.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m                 raise IOError(\n\u001b[1;32m--> 429\u001b[1;33m                     \"Failed to interpret file %s as a pickle\" % repr(file))\n\u001b[0m\u001b[0;32m    430\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: Failed to interpret file '/pio/data/data/mtriples/Subtle_Dataset.triples.pkl' as a pickle"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "subtle_path = \"/pio/data/data/mtriples/\"\n",
    "\n",
    "train_subtle = load_subtle(subtle_path, split=True, trim=200)\n",
    "print time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "# mt_path = \"/home/maciek/Desktop/mgr/DATA/MovieTriples_Dataset/\"\n",
    "\n",
    "train, valid, test = load_mt(path=mt_path, split=True, trim=200)\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_mt_voc(path=mt_path, train_len=len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_embs, word2vec_embs_mask = get_w2v_embs(path=mt_path)\n",
    "\n",
    "w2v_train_mask = np.where(word2vec_embs_mask[:,0] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "Building a network for generating...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hred_net = HRED(voc_size=voc_size,\n",
    "                emb_size=300,\n",
    "                lv1_rec_size=300, \n",
    "                lv2_rec_size=300, \n",
    "                out_emb_size=300, \n",
    "                num_sampled=200,\n",
    "                ssoft_probs=freqs,\n",
    "                emb_init=word2vec_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hred_net.load_params('trained_models/subtleFixed_300_300_300_300_ssoft200unigr_bs30_cut200_early5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_utt(utt):\n",
    "    return ' '.join([idx_to_w[x] if x != voc_size-1 else '<utt_end>' for x in utt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnd_next_word(probs, size=1):\n",
    "    return np.random.choice(np.append(np.arange(probs.shape[0]-1), -1).astype(np.int32), \n",
    "                            size=size, p=probs)\n",
    "\n",
    "def beam_search(beam, dec_init, gamma=0, init_seq=np.array([[1]]), mean=False, keep_penalty=True):\n",
    "    seq = np.repeat(init_seq.astype(np.int32), beam, axis=0)\n",
    "    probs, dec_init = hred_net.get_probs_and_new_dec_init_fn(seq, dec_init)\n",
    "    \n",
    "    words = probs[0].argpartition(-beam)[-beam:].astype(np.int32)\n",
    "    words[words==voc_size-1] = pad_value\n",
    "    scores = np.log(probs[0][words])\n",
    "    seq = np.hstack([seq, words[:, np.newaxis]])\n",
    "    \n",
    "    ends = np.zeros(beam)\n",
    "    \n",
    "    while not all(ends) and seq.shape[1] < 50:\n",
    "        probs, dec_init = hred_net.get_probs_and_new_dec_init_fn(seq[:,-1:], dec_init)\n",
    "        words = probs.argpartition(-beam, axis=1)[:, -beam:].astype(np.int32)\n",
    "        next_word_scores = np.log(probs[np.indices((beam, beam))[0], words])\n",
    "        \n",
    "        if mean:\n",
    "            next_word_scores *= (ends == 0)[:, np.newaxis]\n",
    "            new_scores = np.zeros_like(next_word_scores)\n",
    "            new_scores[ends > 0] = np.repeat(scores[ends > 0][:, np.newaxis], beam, axis=1)\n",
    "            new_scores[ends == 0] = (scores[ends == 0][:, np.newaxis] * seq.shape[1] + next_word_scores[ends == 0]) / \\\n",
    "                                    (seq.shape[1] + 1)\n",
    "        else:\n",
    "            new_scores = next_word_scores + scores[:, np.newaxis]\n",
    "        \n",
    "        # this line is for implementing https://arxiv.org/abs/1611.08562\n",
    "        new_scores_penalized = (new_scores + (new_scores.argsort(axis=1) + 1) * gamma).ravel()\n",
    "        \n",
    "        new_scores = new_scores.ravel()\n",
    "        \n",
    "        order = (-new_scores_penalized).argsort().astype(np.int32)\n",
    "#         best = new_scores.argpartition(-beam)[-beam:].astype(np.int32)\n",
    "        new_seq = []\n",
    "        new_ends = []\n",
    "        new_dec_inits = []\n",
    "        \n",
    "        continued = []\n",
    "        best = []\n",
    "        \n",
    "        for idx in order:\n",
    "            if len(continued) == beam:\n",
    "                break\n",
    "            \n",
    "            i,j = divmod(idx, beam)\n",
    "            \n",
    "            if ends[i] and i in continued:\n",
    "                continue\n",
    "                \n",
    "            continued.append(i)\n",
    "            best.append(idx)\n",
    "            \n",
    "            new_seq.append(np.concatenate([seq[i], np.array([words[i,j]])]))\n",
    "            new_dec_inits.append(dec_init[i])\n",
    "            \n",
    "            if ends[i]:\n",
    "                new_ends.append(ends[i])\n",
    "            elif words[i,j] == w_to_idx['</s>']:\n",
    "                new_ends.append(seq[i].size)\n",
    "            else:\n",
    "                new_ends.append(0)\n",
    "                \n",
    "#         print len(continued)\n",
    "                \n",
    "        seq = np.vstack(new_seq)\n",
    "        ends = np.array(new_ends)\n",
    "        scores = new_scores[best] if not keep_penalty else new_scores_penalized[best]\n",
    "        dec_init = np.vstack(new_dec_inits)\n",
    "    \n",
    "#     for utt, s in zip(seq, scores):\n",
    "#         print '{:.4f} {}'.format(s, print_utt(utt))\n",
    "#         print ''\n",
    "#     print '#########################################\\n'\n",
    "    \n",
    "    return seq[0][:ends[0] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def utt_to_array(utt):\n",
    "    arr = np.array([w_to_idx[w] for w in utt])[np.newaxis].astype(np.int32)\n",
    "    arr[arr == -voc_size] = -1\n",
    "    return arr\n",
    "\n",
    "def context_summary(context, lookup=True):\n",
    "    con_init = np.zeros((1, hred_net.lv2_rec_size), dtype=np.float32)\n",
    "    for utt in context:\n",
    "        con_init = hred_net.get_new_con_init_fn(utt_to_array(utt) if lookup else utt, con_init)\n",
    "    return con_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> i couldn ' t say . </s>\n",
      "<s> you were a prosecutor . </s>\n"
     ]
    }
   ],
   "source": [
    "context = map(lambda x: np.array(x, dtype=np.int32)[np.newaxis], train[99:101])\n",
    "lookup = False\n",
    "for u in context:\n",
    "    print print_utt(u[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> this place has great drugs . <person> . i should ' ve <unk> my leg long ago . <continued_utterance> they ' re all dead ? </s>\n"
     ]
    }
   ],
   "source": [
    "print print_utt(train[992])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ['<s> hi . </s>'.split(), '<s> hello , what \\' s up ? </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ['<s> yeah , okay . </s>'.split(), '<s> well , i guess i \\' ll be going now . </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context= ['<s> what would the table think about if it could think ? </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> i had to talk to a police and ask me if you don ' t come over and have a boyfriend . </s>\n"
     ]
    }
   ],
   "source": [
    "beam_size = 10\n",
    "con_init = context_summary(context, lookup)\n",
    "W = L.layers.get_all_param_values(hred_net.train_net)[31]\n",
    "b = L.layers.get_all_param_values(hred_net.train_net)[32]\n",
    "dec_init = np.repeat(con_init.dot(W) + b, beam_size, axis=0)\n",
    "\n",
    "beamsearch = beam_search(beam_size, dec_init, gamma=-.5, init_seq=utt_to_array('<s> '.split()), \n",
    "                         keep_penalty=True, mean=False)\n",
    "\n",
    "print print_utt(beamsearch)\n",
    "\n",
    "# for utt in beamsearch:\n",
    "#     print_utt(utt)\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> you lied to me so many times -- </s>\n",
      "<s> reggie -- trust me once more -- please . </s>\n",
      "<s> no , i have no idea how things i ' d been talking about . maybe you could be . </s>\n",
      "\n",
      "\n",
      "<s> even by modern male standards you ' re a <unk> immature little shit . <unk> with the kind of money you have access to , that ' s deadly . <person> may not have a four hour stand up routine about the <unk> building , but she ' s a solid girl who will look after you . </s>\n",
      "<s> i have you for that . </s>\n",
      "<s> i ' ll tell you , <person> . if they ' re coming out , i ' ll just sit down and find my place . <continued_utterance> hey , we ' re gon na see ya . <person> . <continued_utterance> hey , how are you guys doing ? </s>\n",
      "\n",
      "\n",
      "<s> is that what you think i was thinking ? </s>\n",
      "<s> no -- that ' s what i know you were thinking . <continued_utterance> how often do you make love to your wife , <person> ? once a week ? sometimes twice ? there once was passion , wasn ' t there ? but now it ' s <unk> , predictable . tell me , when you do it -- do you always think of her ? or do you wonder what it would be like to be with someone else ? someone wild . someone who would force you to lose control . <continued_utterance> there ' s nothing wrong in admitting that you want me , <person> . </s>\n",
      "<s> i ' ll give you anything but i need you . i want you to come up on me . that ' s what i like to do . what ' s so weird about this ? i don ' t mean i ' m so bad . </s>\n",
      "\n",
      "\n",
      "<s> i have been waiting for you . </s>\n",
      "<s> <person> me . i was detained for a few moments . because i revealed my <unk> to you , i ' m in retreat . it ' s your move . </s>\n",
      "<s> <person> ' t i ever miss you ? how long since we ' ve been on it ? </s>\n",
      "\n",
      "\n",
      "<s> it ' s a <number> <person> . <person> . <person> ' , except for the mess inside . about twenty minutes . nobody who ' ll be missed . you ' re a good man , <person> . see ya soon . how we comin ' , <person> ? </s>\n",
      "<s> mr . <person> , you got ta understand somethin ' </s>\n",
      "<s> yeah , what are you gon na tell me , that ' s not what i ' m talking about . he ' s <unk> ' me . </s>\n",
      "\n",
      "\n",
      "<s> it ' s just a very hard move to explain . people are going to think you ' ve lost your mind . </s>\n",
      "<s> why ' s that a problem <person> ? </s>\n",
      "<s> that ' s him . that ' s him , isn ' t it . what did you want to talk about it ? why ' d you leave it in the room ? it ' s not gon na be all right , just like him . </s>\n",
      "\n",
      "\n",
      "<s> <person> is the case . <person> , there ' s `` evidence '' down in that hole . you understand evidence ? little things that are `` clues . `` clues can be very helpful to a fella when he ' s trying to solve a crime . </s>\n",
      "<s> i understand that . </s>\n",
      "<s> well , they say , but that ' s it , <person> , it ' s what we did . what ' s wrong with ? </s>\n",
      "\n",
      "\n",
      "<s> there was no sex . she was very traditional . we were waiting until we were married . </s>\n",
      "<s> you ' re kidding . no sex ? nothing ? no mu-shu ? </s>\n",
      "<s> no . she ' s a girl , i ' m so scared . why are you still at work ? </s>\n",
      "\n",
      "\n",
      "<s> what ? </s>\n",
      "<s> i want you to come in till i get the lights on . </s>\n",
      "<s> you can ' t , uh . you ' re going to take us over to the station . </s>\n",
      "\n",
      "\n",
      "<s> no i haven ' t . </s>\n",
      "<s> babe it ' s me . i won ' t let you get away . </s>\n",
      "<s> i didn ' t think you ' d know i wasn ' t expecting you to get you any of my feelings . </s>\n",
      "\n",
      "\n",
      "<s> well what ? </s>\n",
      "<s> this saturday - you coming to call or what ? </s>\n",
      "<s> oh , i . um . yeah . what kind of person you could get into . </s>\n",
      "\n",
      "\n",
      "<s> what do you mean , `` no '' ? </s>\n",
      "<s> no . </s>\n",
      "<s> no . what happened to my father ? </s>\n",
      "\n",
      "\n",
      "<s> absolutely nothing . </s>\n",
      "<s> <person> . </s>\n",
      "<s> <person> , you don ' t want to say ? </s>\n",
      "\n",
      "\n",
      "<s> . in <unk> <unk> , the nine members of the asian dawn movement . </s>\n",
      "<s> ' asian dawn movement ? ' </s>\n",
      "<s> ' like `` ' <person> '' ' . ' </s>\n",
      "\n",
      "\n",
      "<s> what am i going to do ? </s>\n",
      "<s> it ' s okay . it ' s alright . </s>\n",
      "<s> <person> . it ' s okay . <person> ' ll be late . we ' ll do a nice little bit <unk> . </s>\n",
      "\n",
      "\n",
      "<s> it ' s okay . </s>\n",
      "<s> i have an idea . if you ' re interested . </s>\n",
      "<s> you said we ' re still in trouble . </s>\n",
      "\n",
      "\n",
      "<s> <person> , dad . i ' m seventeen now . i ' m driving . i ' ve got a girlfriend . well , actually , we broke up . but you guys treat me like a kid . is it too much to ask for to be a normal teenager with a normal life ? </s>\n",
      "<s> you broke up with <person> ? </s>\n",
      "<s> she didn ' t want to say you said i couldn ' t get her right . </s>\n",
      "\n",
      "\n",
      "<s> <unk> . </s>\n",
      "<s> that gag ' s got <unk> on it ! </s>\n",
      "<s> i said i didn ' t <unk> it . </s>\n",
      "\n",
      "\n",
      "<s> [ well . we ' re surrounded by the police and we have no way out . what are we going to do ? ] <person> slaps him across the face . </s>\n",
      "<s> [ what are you doing <person> ? talking of all this false doubt . what do you think we ' re going to do ? ] </s>\n",
      "<s> we ' re doing something . we ' ll get out of here -- we ' ll see where we can get some food . it ' s too early . i ' ll tell you what to say , `` hey . `` what are you ? </s>\n",
      "\n",
      "\n",
      "<s> excuse me ? what ? this is a mistake . i ' ve lived here since <number> . i ' m applying for <unk> . </s>\n",
      "<s> you need <unk> now ? after the big promotion ? </s>\n",
      "<s> no , no . i didn ' t want to know it . we should leave in the house . the house is over . <continued_utterance> it ' s going to be in there . and we want to meet you . </s>\n",
      "\n",
      "\n",
      "<s> <person> , just apologize . </s>\n",
      "<s> <person> here was on the <continued_utterance> shut the fuck up . </s>\n",
      "<s> <person> . it ' s what you did . and now they ' re going to need to know why . </s>\n",
      "\n",
      "\n",
      "<s> you sing like a bird . </s>\n",
      "<s> a bird with <unk> . a <unk> bird . that hasn ' t long to live . </s>\n",
      "<s> and we ' ll just like to live for a little more time . </s>\n",
      "\n",
      "\n",
      "<s> the streets are getting full of guys you ' ve <unk> . </s>\n",
      "<s> been thinking about <person> . there ' s nothing to keep me here . </s>\n",
      "<s> it ' s only my fault . and when you see him , <person> ' ll kill ' em . we are gon na die . we ' re getting to <person> . we ' re here to get to you . </s>\n",
      "\n",
      "\n",
      "<s> <person> ' numbers without i know about it is both illegal and <unk> . you remember that . <continued_utterance> <person> , son . you ' re not finished . pour his . </s>\n",
      "<s> i prefer it in the bottle -- </s>\n",
      "<s> i don ' t wan na have to see it all this time , but if it ' s good , that ' s right . </s>\n",
      "\n",
      "\n",
      "<s> <person> ' t tell me you ' re jealous ? </s>\n",
      "<s> yeah , jealous . a little bit like <person> . lem me , lem me <unk> i show you something , lady ? what i have here . i found this in the apartment . <person> soap . she used to wash her face eight hundred times a day with black soap . <person> ' t ask me why . </s>\n",
      "<s> you don ' t remember , <person> ? that ' s great . what happened to your mother that night ? how old is it ? how old is it ? <person> ? you ' re going to need this . <continued_utterance> this is <unk> . </s>\n",
      "\n",
      "\n",
      "<s> that ' s a good one . </s>\n",
      "<s> i ' m serious , dude . you always seem to be on top of things , even when you ' re <unk> ' . </s>\n",
      "<s> yeah . <continued_utterance> . well , there ' s something i ' ve gotten away from you , that i don ' t care what it is . if this is , <person> , you want to come over and get some help . </s>\n",
      "\n",
      "\n",
      "<s> we have a new site in montana . at least until the money runs out . </s>\n",
      "<s> anything good ? </s>\n",
      "<s> no , that ' s it . there ' s got there . </s>\n",
      "\n",
      "\n",
      "<s> oh boy ! </s>\n",
      "<s> now , <person> , we ' re leaving on the electronic collar . i don ' t think we ' ll need to shock you , but just in case . </s>\n",
      "<s> <person> , okay , <person> ! it ' s gon na do us both and if we want to know what happens to this thing about our people . </s>\n",
      "\n",
      "\n",
      "<s> well , they ' ll go along with anything . </s>\n",
      "<s> sure . but eventually , even the more <unk> birds began to listen . `` why should humans rule ? '' they asked themselves . </s>\n",
      "<s>\n",
      "\n",
      "\n",
      "<s> see that up there ? your mother thought i was crazy for wanting to buy this place , middle of nowhere . but i just knew this was what i was supposed to do . told your mom , `` just wait . `` told her when they finally ran the freeway through here like they were <unk> ' on , this place would be like <person> . <continued_utterance> but i was wrong . the freeway never came and now the only people who ever stop here are the ones who are lost . <continued_utterance> and your mom ? well she got tired of waitin ' . </s>\n",
      "<s> c ' mon dad . you can ' t blame yourself for what she did -- </s>\n",
      "<s> she ' s my dad . she got me pregnant . she didn ' t kill me either . i never heard of this . she got a boyfriend . she ' s never in touch . <continued_utterance> you see him , and you ' re right . </s>\n",
      "\n",
      "\n",
      "<s> <person> . </s>\n",
      "<s> i ' m sorry . i shouldn ' t have fucked this kid last night . i should have slept . now i ' ve got all this stuff to do , and i ' m tired , i ' m <unk> up , i ' m in a fuckin ' mood . </s>\n",
      "<s>\n",
      "\n",
      "\n",
      "<s> you have kids , <person> ? </s>\n",
      "<s> uh . actually , yes . two . good ones . </s>\n",
      "<s> so do you guys come with me at my dad ' s place ? </s>\n",
      "\n",
      "\n",
      "<s> i don ' t want to go out with some who wears <unk> pants . </s>\n",
      "<s> well , there we go . i could go <unk> , but i don ' t think that ' s acceptable in government . </s>\n",
      "<s> no , no , it ' s no problem . but i don ' t believe how long i ' ll be doing it to the party , but i just think it might be a bit <unk> . you want me to put that back ? </s>\n",
      "\n",
      "\n",
      "<s> i couldn ' t say . </s>\n",
      "<s> you were a prosecutor . </s>\n",
      "<s> i had to talk to a police and ask me if you don ' t come over and have a boyfriend . </s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_size = 10\n",
    "\n",
    "for i in xrange(0, 100, 3):\n",
    "    context = map(lambda x: np.array(x, dtype=np.int32)[np.newaxis], train[i:i+2])\n",
    "    lookup = False\n",
    "    for u in context:\n",
    "        print print_utt(u[0])\n",
    "        \n",
    "    con_init = context_summary(context, lookup)\n",
    "    W = L.layers.get_all_param_values(hred_net.train_net)[31]\n",
    "    b = L.layers.get_all_param_values(hred_net.train_net)[32]\n",
    "    dec_init = np.repeat(con_init.dot(W) + b, beam_size, axis=0)\n",
    "\n",
    "    beamsearch = beam_search(beam_size, dec_init, gamma=-.5, init_seq=utt_to_array('<s> '.split()), \n",
    "                             keep_penalty=True, mean=False)\n",
    "\n",
    "    print print_utt(beamsearch)\n",
    "\n",
    "    print '\\n'\n",
    "\n",
    "# for utt in beamsearch:\n",
    "#     print_utt(utt)\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 batches in 0.86s\ttraining loss:\t7.176166\n",
      "Done 20 batches in 1.69s\ttraining loss:\t6.175796\n",
      "Done 30 batches in 2.44s\ttraining loss:\t5.697121\n",
      "Done 40 batches in 3.47s\ttraining loss:\t5.374195\n",
      "Done 50 batches in 4.27s\ttraining loss:\t5.207509\n",
      "Done 60 batches in 5.11s\ttraining loss:\t5.063584\n",
      "Done 70 batches in 5.92s\ttraining loss:\t4.934647\n",
      "Done 80 batches in 6.69s\ttraining loss:\t4.840843\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e0bc5d556518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhred_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_subtle2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/i258346/Desktop/masters_thesis/rnn_ex/SimpleRNNLM.pyc\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, train_data, batch_size, log_interval)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mnum_batch_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mnum_training_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnum_batch_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hred_net.train_one_epoch(train_subtle2, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100 batches in 4.56s\n",
      "Done 200 batches in 9.25s\n",
      "Done 300 batches in 14.05s\n",
      "Done 400 batches in 18.29s\n",
      "Done 500 batches in 22.79s\n",
      "Done 600 batches in 27.11s\n",
      "Done 700 batches in 31.47s\n",
      "Done 800 batches in 35.77s\n",
      "Done 900 batches in 40.50s\n",
      "Done 1000 batches in 45.42s\n",
      "Done 1100 batches in 50.12s\n",
      "Done 1200 batches in 54.98s\n",
      "Done 1300 batches in 59.86s\n",
      "Done 1400 batches in 64.20s\n",
      "Done 1500 batches in 68.60s\n",
      "Done 1600 batches in 73.03s\n",
      "Done 1700 batches in 77.50s\n",
      "Done 1800 batches in 82.20s\n",
      "Done 1900 batches in 87.06s\n",
      "Done 2000 batches in 91.32s\n",
      "Done 2100 batches in 96.01s\n",
      "Done 2200 batches in 100.76s\n",
      "Done 2300 batches in 105.59s\n",
      "Done 2400 batches in 110.10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2955217842403752"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hred_net.validate(valid, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''full softmax, bs=30'''\n",
    "# train, 1 dir, 1 epoch: 3.485554076321884\n",
    "# val: 3.455356876018342\n",
    "\n",
    "# train, 2 dir, concat, 1 epoch: 3.4864403798772239\n",
    "# val: 3.4579001751897063\n",
    "\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.4881669768474675\n",
    "# val: 3.4584704095551695\n",
    "# training time: ~4700s\n",
    "\n",
    "'''sampled softmax'''\n",
    "# bs=30\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.486180601246621\n",
    "# val: 3.4811877499289308\n",
    "# training time: ~2300s\n",
    "\n",
    "# bs=60\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.5235153449672456\n",
    "# val: 3.5063306987542759\n",
    "# training time: ~1900s"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
