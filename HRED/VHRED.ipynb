{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "\n",
    "import lasagne as L\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../SimpleRNNLM/')\n",
    "\n",
    "%aimport VHRED\n",
    "from mt_load import load_mt, get_mt_voc, get_w2v_embs\n",
    "from load_subtle import load_subtle\n",
    "from diverse_beam_search import diverse_beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember, now the pad value is the same as the <utt_end> token\n",
    "\n",
    "pad_value = -1 # <utt_end>'s vector is the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "subtle_path = \"/pio/data/data/mtriples/\"\n",
    "\n",
    "train_subtle = load_subtle(subtle_path, split=True, trim=200)\n",
    "print time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt_path = \"/pio/data/data/mtriples/\"\n",
    "# mt_path = \"../DATA/MovieTriples_Dataset/\"\n",
    "\n",
    "train, valid, test = load_mt(path=mt_path, split=True, trim=200)\n",
    "idx_to_w, w_to_idx, voc_size, freqs = get_mt_voc(path=mt_path, train_len=len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_embs, word2vec_embs_mask = get_w2v_embs(path=mt_path)\n",
    "\n",
    "w2v_train_mask = np.where(word2vec_embs_mask[:,0] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Compiling theano functions...\n",
      "Building a network for generating...\n",
      "Done\n",
      "CPU times: user 51 s, sys: 787 ms, total: 51.8 s\n",
      "Wall time: 51.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vhred_net = VHRED.VHRED(voc_size=voc_size,\n",
    "                        emb_size=300,\n",
    "                        lv1_rec_size=300, \n",
    "                        lv2_rec_size=300, \n",
    "                        out_emb_size=300,\n",
    "                        latent_size=20,\n",
    "                        num_sampled=200,\n",
    "                        ssoft_probs=freqs,\n",
    "                        train_emb=False,\n",
    "                        kl_annealing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with KL annealing, some information is put into prior and posterior\n",
    "# avg KL div per word on valid: 0.049\n",
    "vhred_net.load_params('trained_models/vhred_hredEmbFixed_300_300_300_300_20_Anneal2M_drop25_ssoft200unigr_bs30_cut200_early5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this has no KL annealing, the prior and posterior are very close, because there is no information coded there\n",
    "# avg KL div per word on valid: 7e-6\n",
    "vhred_net.load_params('trained_models/vhred_hredEmbFixed_300_300_300_300_10_noAnneal_drop25_ssoft200unigr_bs30_cut200_early5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04151616809414882"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vhred_net.validate(valid[:30], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vhred_net.load_params_from_HRED('trained_models/subtleFixed_300_300_300_300_ssoft200unigr_bs30_cut200_early5.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10 batches in 1.15s\ttraining loss:\t5.675020\n",
      "0.00654025608674\n",
      "Done 20 batches in 2.75s\ttraining loss:\t5.616165\n",
      "0.00714027928188\n",
      "Done 30 batches in 4.19s\ttraining loss:\t5.584745\n",
      "0.00774030247703\n",
      "Done 40 batches in 5.70s\ttraining loss:\t5.560396\n",
      "0.00834032613784\n",
      "Done 50 batches in 7.03s\ttraining loss:\t5.550236\n",
      "0.00894034933299\n",
      "Done 60 batches in 8.68s\ttraining loss:\t5.530466\n",
      "0.00954037252814\n",
      "Done 70 batches in 9.84s\ttraining loss:\t5.516066\n",
      "0.0101403957233\n",
      "Done 80 batches in 11.20s\ttraining loss:\t5.507935\n",
      "0.0107404189184\n",
      "Done 90 batches in 12.65s\ttraining loss:\t5.498226\n",
      "0.0113404421136\n",
      "Done 100 batches in 14.03s\ttraining loss:\t5.490364\n",
      "0.0119404653087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.49036352239"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vhred_net.train_one_epoch(train[3000:6000], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.012000467628240585, dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.layers.get_all_param_values(vhred_net.train_net)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vhred_net.save_params('trained_models/vhred_ep1_dropAll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00268026])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu0 = np.zeros((1,10))\n",
    "mu1 = np.zeros((1,10))\n",
    "sig0 = np.array([[.1,.1,.2,.02,.5,.006,.7,.0009,.004,.1]])\n",
    "sig1 = np.array([[.1,.1,.2,.02,.5,.006,.7,.001,.004,.1]])\n",
    "        \n",
    "res = (sig0 / sig1).sum(axis=1) + ((mu1 - mu0) / sig1 * (mu1 - mu0)).sum(axis=1) - \\\n",
    "      mu0.shape[1] + np.log(sig1.prod(axis=1) / sig0.prod(axis=1))\n",
    "res *= .5\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_utt(utt):\n",
    "    return ' '.join([idx_to_w[x] for x in utt])\n",
    "\n",
    "def rnd_next_word(probs, size=1):\n",
    "    return np.random.choice(np.append(np.arange(probs.shape[0]-1), -1).astype(np.int32), \n",
    "                            size=size, p=probs)\n",
    "\n",
    "def utt_to_array(utt):\n",
    "    arr = np.array([w_to_idx.get(w, w_to_idx['<unk>']) for w in utt])[np.newaxis].astype(np.int32)\n",
    "    arr[arr == -voc_size] = -1\n",
    "    return arr\n",
    "\n",
    "def context_summary(context, lookup=True):\n",
    "    con_init = np.zeros((1, vhred_net.lv2_rec_size), dtype=np.float32)\n",
    "    for utt in context:\n",
    "        con_init, z = vhred_net.get_new_con_init_fn(utt_to_array(utt) if lookup else utt, con_init)\n",
    "    return con_init, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> i couldn ' t say . </s>\n",
      "<s> you were a prosecutor . </s>\n"
     ]
    }
   ],
   "source": [
    "context = map(lambda x: np.array(x, dtype=np.int32)[np.newaxis], train[99:101])\n",
    "lookup = False\n",
    "for u in context:\n",
    "    print print_utt(u[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ['<s> hi . </s>'.split(), '<s> hello , what \\' s up ? </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = ['<s> yeah , okay . </s>'.split(), '<s> well , i guess i \\' ll be going now . </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context= ['<s> what would the table think about if it could think ? </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context= ['<s> i saw a pretty good movie yesterday . </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context= ['<s> hi . </s>'.split()]\n",
    "lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.692   yes .\n",
      "\n",
      "-0.921   no .\n",
      "\n",
      "-1.319   no . i ' d like to ask you something .\n",
      "\n",
      "-1.319   no . i ' m not .\n",
      "\n",
      "-1.321   no . i ' d like to see you .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.359   yes .\n",
      "\n",
      "-1.377   yes , sir .\n",
      "\n",
      "-1.411   yes , but i ' m not .\n",
      "\n",
      "-1.545   yes , but i ' m not sure .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.587   no .\n",
      "\n",
      "-1.628   no . i ' d like to ask you something . i was thinking about it .\n",
      "\n",
      "-1.636   no . i ' d like to ask you something . i was thinking about it , but i didn ' t know what happened to me .\n",
      "\n",
      "-1.655   no . i ' d like to ask you something . i was thinking about it , but i didn ' t know what happened to him .\n",
      "\n",
      "-1.659   no . i didn ' t know what happened to me .\n",
      "\n",
      "-1.666   no . i ' d like to ask you something . i was thinking about it , but i didn ' t know what happened .\n",
      "\n",
      "-1.706   no . i didn ' t know what happened to you .\n",
      "\n",
      "-1.719   no . i didn ' t .\n",
      "\n",
      "-1.729   no . i ' ve been thinking about it , but i don ' t know what to do .\n",
      "\n",
      "-1.731   yes , but i ' m not . i ' ve been thinking about you . i ' ve got a lot of money to do with it . i don ' t know what i mean .\n",
      "\n",
      "-1.738   yes , but i ' m not . i ' ve been thinking about it .\n",
      "\n",
      "-1.739   yes , but i ' m not . i ' ve been thinking about you . i ' ve got a lot of money to do with it . i don ' t know what to do .\n",
      "\n",
      "-1.745   yes , but i ' m not . i ' ve been thinking about you .\n",
      "\n",
      "-1.757   yes , but i ' m not . i ' ve been thinking about you . i ' ve got a lot of money to do .\n",
      "\n",
      "-1.763   yes , but i ' m not . i ' ve been thinking about you . i ' ve got a lot of money to do with it .\n",
      "\n",
      "-1.769   no . i ' ve been thinking about it , but i don ' t know what to do with you .\n",
      "\n",
      "-1.771   no . i ' d like to ask you something . i was thinking about it , but i didn ' t know what happened to me . i thought i was going to tell you .\n",
      "\n",
      "-1.784   yes , but i ' m not . i ' ve been thinking about you . i ' ve got a lot of money to do with it . i don ' t know what i mean . i just want to see you .\n",
      "\n",
      "-1.786   no . i didn ' t know what happened to me . i was thinking about it , but i don ' t know what you ' re talking about .\n",
      "\n",
      "-1.789   no . i didn ' t know what happened to me . i was thinking about it .\n",
      "\n",
      "-1.794   no . i ' d like to ask you something . i was thinking about it , but i didn ' t know what happened to me . i thought i was going to tell you . i ' m sorry .\n",
      "\n",
      "-1.810   yes , but i ' m not . i ' ve been thinking about you . i ' ve got a lot of money to do with my friends .\n",
      "\n",
      "-1.822   no . i ' ve been thinking about it , but i don ' t know what to do with you . i ' m not going to tell you anything .\n",
      "\n",
      "-1.830   no . i didn ' t know what happened to me . i was thinking about it , but i don ' t know what you ' re talking about . i ' m not going to tell you anything .\n",
      "\n",
      "-1.833   no . i ' ve been thinking about it , but i don ' t know what to do with you . i ' m not going to tell you that .\n",
      "\n",
      "-1.840   no . i didn ' t know what happened to me . i was thinking about it , but i don ' t know what you ' re talking about . i ' m not going to tell you .\n",
      "\n",
      "-1.854   no . i didn ' t know what happened to me . i was thinking about it , but i don ' t know what you ' re saying .\n",
      "\n",
      "-1.876   no . i didn ' t know what happened to me . i was thinking about it , but i don ' t know .\n",
      "\n",
      "-1.887   no . i ' ve been thinking about it , but i don ' t know what to do with you . i ' m not going to tell you anything . i ' m just a little confused .\n",
      "\n",
      "-1.890   no . i ' m sorry , but i don ' t .\n",
      "\n",
      "-1.897   no . i ' m sorry , but i didn ' t .\n",
      "\n",
      "-1.901   no . i ' ve been thinking about it , but i don ' t know what to do with you . i ' m not going to tell you anything . i ' m just saying that .\n",
      "\n",
      "-1.946   no . i ' m not sure you have a problem with this , but i ' ve been thinking about it . i don ' t know what to do .\n",
      "\n",
      "-1.950   no . i ' ve been thinking about it , but i don ' t know what to do with you . i ' m not going to tell you anything . i ' m just a little confused and i ' d like to see you .\n",
      "\n",
      "-1.955   no . i ' ve been thinking about it .\n",
      "\n",
      "-1.957   no . i ' m not sure you have a problem with this , but i ' ve been thinking about it . i don ' t know what to do anymore .\n",
      "\n",
      "-1.970   no . i ' d like to know what happened to me , but i didn ' t want to talk to you about it .\n",
      "\n",
      "-1.980   no . i ' m sorry , but i didn ' t . i was thinking about it .\n",
      "\n",
      "-2.011   no . i ' m not sure you have a problem with this , but i ' ve been thinking about it . i don ' t know what to do . i can ' t help you .\n",
      "\n",
      "-2.015   no . i ' m not sure you have a problem with this , but i ' ve been thinking about it . i don ' t know what to do . i can ' t tell you that .\n",
      "\n",
      "-2.018   no . i ' m sorry , but i didn ' t . i was thinking about the last night . i thought you were going to have to do something wrong with me .\n",
      "\n",
      "-2.024   no . i ' m not sure you have a problem with this , but i ' ve been thinking about it . i don ' t know what to do . i can ' t help you . i ' m not going anywhere .\n",
      "\n",
      "-2.031   no . i ' d like to know what happened to me , but i didn ' t want to talk to you .\n",
      "\n",
      "-2.033   no . i ' m sorry , but i didn ' t . i was thinking about the last night .\n",
      "\n",
      "-2.039   no . i ' m sorry , but i didn ' t . i was thinking about the last night . i thought you were going to have to do something wrong .\n",
      "\n",
      "-2.059   no . i ' d like to know what happened to me .\n",
      "\n",
      "-2.063   no . i ' m sorry , but i didn ' t . i was thinking about the last night . i thought you were going to have to do it .\n",
      "\n",
      "-2.070   no . i ' m sorry , but i didn ' t . i was thinking about the last time .\n",
      "\n",
      "-2.081   no . i ' d like to know what happened to me , but i didn ' t want to talk to you about it . i was just thinking about that .\n",
      "\n",
      "-2.081   no . i ' m not sure you have a problem with this , but i ' ve been thinking about it .\n",
      "\n",
      "-2.091   no . i ' d like to know what happened to me , but i didn ' t want to talk to you about it . i was just thinking about the other night .\n",
      "\n",
      "-2.099   no . i ' d like to know what happened to me , but i didn ' t want to talk to you about it . i was just thinking about the other day .\n",
      "\n",
      "-2.127   no . i ' m sorry .\n",
      "\n",
      "-2.128   no . i ' d like to know what happened to me , but i didn ' t want to talk to you about it . i was just thinking about the other night . and i ' m not going anywhere else to do that .\n",
      "\n",
      "-2.128   no . i ' d like to know what happened to me , but i didn ' t want to talk to you about it . i was just thinking about the other night . and i ' m not going anywhere else to do anymore .\n",
      "\n",
      "-2.132   no . i ' d like to know what happened to me , but i didn ' t want to talk to you about it . i was just thinking about the other night . and i ' m sorry .\n",
      "\n",
      "-2.157   no . i ' m fine .\n",
      "\n",
      "-2.161   no . i ' d rather not be surprised if it was me . i ' d like to ask you a question .\n",
      "\n",
      "-2.163   no . i ' d like to have a good idea . it would be difficult for me to do that , but if you don ' t mind , i will not .\n",
      "\n",
      "-2.165   no . i ' d like to have a good idea . it would be difficult for me to do that , but if you don ' t mind , i can ' t .\n",
      "\n",
      "-2.170   no . i ' m sorry , sir .\n",
      "\n",
      "-2.175   no . i ' m just a little confused .\n",
      "\n",
      "-2.179   no . i ' d like to have a good idea . it would be difficult for me to do that , but if you don ' t mind , i can ' t help you .\n",
      "\n",
      "-2.181   no . i ' d like to have a good idea . it would be difficult for me to do that , but if you don ' t mind , i can ' t help him .\n",
      "\n",
      "-2.187   no . i ' d like to have a good idea . it would be difficult for me to do that , but if you don ' t mind , i can ' t help you . i ' ll take care of myself .\n",
      "\n",
      "-2.188   no . i ' d like to have a good idea . it would be difficult for me to do that , but if you don ' t mind , i can ' t help you . i ' ll take care of it .\n",
      "\n",
      "-2.190   no . i ' m not sure you have a problem with this .\n",
      "\n",
      "-2.194   no . i ' m not .\n",
      "\n",
      "-2.194   no . i ' m not .\n",
      "\n",
      "-2.194   no . i ' m not .\n",
      "\n",
      "-2.194   no . i ' m not .\n",
      "\n",
      "-2.198   no . i ' d like to have a good idea . it would be difficult for me .\n",
      "\n",
      "-2.201   no . i ' d like to have a good idea .\n",
      "\n",
      "-2.201   no . i ' d rather not .\n",
      "\n",
      "-2.206   no . i ' d rather not be surprised if it was me . i ' d like to ask you something .\n",
      "\n",
      "-2.211   no . i ' d like to have a good time .\n",
      "\n",
      "-2.215   no . i ' d rather not be surprised if it was me . i ' d like to ask you a question , but it would be difficult for me to do . i ' ve been thinking about this before .\n",
      "\n",
      "-2.222   no . i ' d rather not be surprised if it was me . i ' d like to ask you a question , but it would be difficult for me to do .\n",
      "\n",
      "-2.233   no . i ' d rather not be surprised if it was me . i ' d like to ask you a question , but it would be difficult for me to do . i ' ve been thinking about this .\n",
      "\n",
      "-2.233   no . i ' d rather not be surprised if it was me . i ' d like to ask you a question , but it would be difficult for me to do . i ' ve been thinking about this before . i ' m sorry .\n",
      "\n",
      "-2.237   no . i ' d like to know what happened to me , but .\n",
      "\n",
      "-2.242   no . i ' d like to have a good idea . it would be difficult for me to do with you .\n",
      "\n",
      "-2.244   no . i ' d rather not be surprised if it was me . i ' d like to ask you a question , but it would be difficult for me .\n",
      "\n",
      "-2.245   no . i ' m not sure you have a problem .\n",
      "\n",
      "-2.247   no . i ' d rather not be surprised if it was me . i ' d like to ask you a question , but it would be difficult for me to do that .\n",
      "\n",
      "-2.273   no . i ' m just a little confused about the other day , but you know what i was thinking about it ? that ' s why we ' re going to have to go back to the hospital and get out of here .\n",
      "\n",
      "-2.278   no . i ' d rather not be surprised if it was me .\n",
      "\n",
      "-2.288   no . i ' m not sure you are .\n",
      "\n",
      "-2.308   no . i ' m just a little confused about the other day , but you know what i was thinking about it ? that ' s why we ' re going to have to go back to the hospital and get out of here --\n",
      "\n",
      "-2.321   no . i ' m just a little confused about the other day , but you know what i was thinking about it ? that ' s why we ' re going to be here .\n",
      "\n",
      "-2.332   no . i ' m just a little confused about the other day , but you know what i was thinking about it ? that ' s why we ' re going to have to go back to the hospital and get out .\n",
      "\n",
      "-2.333   no . i ' m just a little confused about the other day , but you know what i was thinking about it ? that ' s why we ' re going to have to go back to bed .\n",
      "\n",
      "-2.333   no . i ' d rather not be sure .\n",
      "\n",
      "-2.333   no . i ' m just a little confused about the other day , but you know what i was thinking about it ? that ' s why we ' re going to have to go back to the hospital .\n",
      "\n",
      "-2.367   no . i ' m just a little confused about the other day , but you know what i was thinking about it ? that ' s why we ' re here .\n",
      "\n",
      "-2.384   no . i ' m just a little confused about the other day , but you know what i mean ?\n",
      "\n",
      "-2.385   no . i ' m just a little confused about my mother .\n",
      "\n",
      "-2.387   no . i ' d rather not be surprised if it was me --\n",
      "\n",
      "-2.390   no . i ' m just a little confused about the other day .\n",
      "\n",
      "-2.391   no . i ' m just a little confused about the other day , but you know what i was thinking about ?\n",
      "\n",
      "-2.396   no . i ' m just a little confused about the other day , but you know what i was thinking about it ?\n",
      "\n",
      "-2.451   no . i ' m just a little confused about the other day , but you know what i was thinking ?\n",
      "\n",
      "-2.477   no . i ' m just a little confused about the other day , but you know what i was thinking about it .\n",
      "\n",
      "-2.489   no . i ' m just a little confused about the other day , but you know what ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_size = 20\n",
    "group_size = 2\n",
    "con_init, z = context_summary(context, lookup)\n",
    "W = L.layers.get_all_param_values(vhred_net.train_net)[40]\n",
    "b = L.layers.get_all_param_values(vhred_net.train_net)[41]\n",
    "dec_init = np.repeat(np.tanh(np.hstack([con_init, z]).dot(W) + b), beam_size, axis=0)\n",
    "\n",
    "mean = True\n",
    "\n",
    "beamsearch = diverse_beam_search(beam_size, group_size, dec_init, voc_size, vhred_net, \n",
    "                                 init_seq=utt_to_array('<s> '.split()), rank_penalty=0, group_diversity_penalty=1, \n",
    "                                 seq_diversity_penalty=1, verbose_log=False)\n",
    "\n",
    "# print print_utt(beamsearch)\n",
    "\n",
    "len_bonus = lambda size: 0#np.log(size)**2\n",
    "\n",
    "def fn_score(x, y, mean=mean, len_bonus=len_bonus):\n",
    "    denom = (x.size - 1) if mean else 1\n",
    "    return (y + len_bonus(x.size)) / denom\n",
    "\n",
    "sort1 = sorted(beamsearch, key=lambda (x,y): fn_score(x, y), reverse=True)\n",
    "sort2 = sorted(beamsearch, key=lambda x: ' '.join(print_utt(x[0][1:-1])))\n",
    "\n",
    "for utt, scr in sort1:\n",
    "    print '{:.3f}  '.format(fn_score(utt, scr)), print_utt(utt[1:-1])\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> you ' re not going to let me die , are you ! ? <person> ' t let me die ! ignoring the <unk> </s>\n",
      "<s> when we start running suck up your breath . you ' re going to get the wind knocked out of you . </s>\n",
      "-1.042   what ' s that ?\n",
      "\n",
      "<s> <person> says you have to be like me . </s>\n",
      "<s> he does . </s>\n",
      "-0.811   what do you mean ?\n",
      "\n",
      "<s> <person> . what ' s your <number> ? </s>\n",
      "<s> reservation . </s>\n",
      "-1.468   right .\n",
      "\n",
      "<s> what the hell ' s going on here ? </s>\n",
      "<s> we ' re in love with your roommate . </s>\n",
      "-1.591   in the way .\n",
      "\n",
      "<s> i ' m going to the market . i ' ll be back in a bit . </s>\n",
      "<s> can i go with you ? </s>\n",
      "-0.709   sure .\n",
      "\n",
      "<s> yes - </s>\n",
      "<s> <person> ! <person> these men ! escort them to the <unk> ! </s>\n",
      "-0.974   yes , sir .\n",
      "\n",
      "<s> sure . </s>\n",
      "<s> you can let me down now . </s>\n",
      "-1.057   you ' re not going anywhere .\n",
      "\n",
      "<s> i don ' t know . </s>\n",
      "<s> we got a <unk> , you know . <person> -- did you hear what i said . ? </s>\n",
      "-0.793   i don ' t know .\n",
      "\n",
      "<s> what ' s this for ? </s>\n",
      "<s> for <unk> , schmuck . bring your kid something . you know . the dad thing . </s>\n",
      "-0.520   i ' m sorry .\n",
      "\n",
      "<s> what ? </s>\n",
      "<s> a <unk> . </s>\n",
      "-0.834   what ?\n",
      "\n",
      "<s> <person> . you got any soda ? </s>\n",
      "<s> <unk> slowly , <unk> favor . my <unk> no es bien . </s>\n",
      "-1.347   no , i ' m not .\n",
      "\n",
      "<s> no . no , i don ' t . </s>\n",
      "<s> i ' m sorry that i frightened you like that . but i was so touched by your concern . i ' ve been lonely here . perhaps we could be friends . </s>\n",
      "-0.778   i don ' t know .\n",
      "\n",
      "<s> i have an errand that requires your <unk> talents . </s>\n",
      "<s> i was beginning to think you ' d forgotten me . </s>\n",
      "-0.650   yes .\n",
      "\n",
      "<s> just the home shopping <person> . </s>\n",
      "<s> <person> any <unk> dolls ? </s>\n",
      "-0.816   yes .\n",
      "\n",
      "<s> <person> , what the hell are you doing here ? </s>\n",
      "<s> i am not here , ol ' buddy . the cia has absolutely no knowledge of the missing ship , the missing gold , where it was going , or when it left hong kong . </s>\n",
      "-1.155   well , what ' s the matter with you ?\n",
      "\n",
      "<s> ok . he fell asleep watching tv . so he lives there now ? </s>\n",
      "<s> yeah . your grandfather is in the early stages of <unk> , <person> . so sometimes he does things and says things that don ' t make sense . </s>\n",
      "-1.107   so what ' s the matter with you ?\n",
      "\n",
      "<s> you knew him well ? </s>\n",
      "<s> he was my father . </s>\n",
      "-1.026   did you see him ?\n",
      "\n",
      "<s> we don ' t serve formula . <unk> . </s>\n",
      "<s> you serve <unk> , <unk> ? </s>\n",
      "-1.147   yes .\n",
      "\n",
      "<s> what did you say ? </s>\n",
      "<s> <unk> <person> . she is upstairs in my office for an <unk> deposition . i requested she be put on the case personally . she flew out yesterday . <continued_utterance> no matter . <person> away , mr . <unk> . </s>\n",
      "-1.012   what ' s the matter ?\n",
      "\n",
      "<s> i ' m gon na have the police check on the house . </s>\n",
      "<s> oh great , `` can you look in on my wife , she ' s hearing voices ? '' <person> ' ll that gets around . </s>\n",
      "-0.998   no , i don ' t .\n",
      "\n",
      "<s> no i can ' t . </s>\n",
      "<s> <person>y , it ' s one fuckin ' beer for christ sakes . <person> , the big bad beer ' s gon na get ya . <person>y stares at the beer , <unk> . <unk> i ' m worried about you , man . you better learn to have a pop once in a while or you ' re gon na fall off the wagon . you ' re being a <unk> and that ain ' t healthy . </s>\n",
      "-0.908   that ' s right .\n",
      "\n",
      "<s> you can work out of the east coast . we ' ll get a place on long island and burn our suitcases . </s>\n",
      "<s> i still like suitcases . </s>\n",
      "-0.859   i ' m sorry .\n",
      "\n",
      "<s> no you weren ' t . </s>\n",
      "<s> i was , you bastard . <continued_utterance> so what ' ve we got today ? </s>\n",
      "-1.310   no .\n",
      "\n",
      "<s> <person> to your mom , <person> . all of you get out of here , okay ? i ' ll straighten up before i go and when dr . m . comes home , everything will be exactly the way he likes it . </s>\n",
      "<s> <person> you ' re such a dear . <person> good care , all right ? </s>\n",
      "-1.240   okay .\n",
      "\n",
      "<s> <person> to me , <person> . please . </s>\n",
      "<s> if the weather clears enough before we reach anybody -- i ' m sending you and <person> up to <unk> . </s>\n",
      "-1.466   not yet .\n",
      "\n",
      "<s> come back in three days . i ' ll think about it . <continued_utterance> we ' re by appointment only . </s>\n",
      "<s> i received a card from your store . </s>\n",
      "-0.886   no .\n",
      "\n",
      "<s> but not to live . </s>\n",
      "<s> ms . <person> -- you work at a school for <unk> in <unk> , new york . can you tell the members of this committee what exactly you are teaching these <unk> ? </s>\n",
      "-1.067   no , i ' m not .\n",
      "\n",
      "<s> <unk> . <unk> . i like this kind of talk . what the hell nonsense is that ? </s>\n",
      "<s> what are you gon na gain from this thing here ? </s>\n",
      "-1.237   well , it ' s not like that .\n",
      "\n",
      "<s> it was slow . now it seems like everyone is having <unk> at home . <continued_utterance> what could have caused this ? i just changed this damn thing . </s>\n",
      "<s> everything these days is made overseas . </s>\n",
      "-0.799   what are you talking about ?\n",
      "\n",
      "<s> i got your <unk> , <unk> . <continued_utterance> what you doin ' ? </s>\n",
      "<s> nobody ' s getting in here . you can tell them all that ! </s>\n",
      "-1.381   and you don ' t know what they ' re talking about ?\n",
      "\n",
      "<s> <person> -- so you ' re doctor <person> of ' <person> , <person> . ' so ? </s>\n",
      "<s> as i said . this is going to be very difficult -- for both of us . </s>\n",
      "-1.455   well , i ' m not .\n",
      "\n",
      "<s> <person> - </s>\n",
      "<s> this is a mistake ! </s>\n",
      "-1.013   what do you mean ?\n",
      "\n",
      "<s> i ' m just some guy . a guy whose parole officer is probably having a shit fit right about now . </s>\n",
      "<s> what ? ! <person> officer ? you mean you ' re a criminal ? </s>\n",
      "-0.751   no , i ' m not .\n",
      "\n",
      "<s> did you recognize the <unk> bitch who got away ? </s>\n",
      "<s> should i have ? </s>\n",
      "-1.102   what are you talking about ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_size = 20\n",
    "group_size = 2\n",
    "\n",
    "for i in xrange(0, 100, 3):\n",
    "    context = map(lambda x: np.array(x, dtype=np.int32)[np.newaxis], test[i:i+2])\n",
    "    lookup = False\n",
    "    for u in context:\n",
    "        print print_utt(u[0])\n",
    "        \n",
    "    con_init, z = context_summary(context, lookup)\n",
    "    W = L.layers.get_all_param_values(vhred_net.train_net)[40]\n",
    "    b = L.layers.get_all_param_values(vhred_net.train_net)[41]\n",
    "    dec_init = np.repeat(np.tanh(np.hstack([con_init, z]).dot(W) + b), beam_size, axis=0)\n",
    "\n",
    "    beamsearch = diverse_beam_search(beam_size, group_size, dec_init, voc_size, vhred_net,\n",
    "                                     init_seq=utt_to_array('<s> '.split()), )\n",
    "    \n",
    "    len_bonus = lambda size: 0#np.log(size)**2\n",
    "\n",
    "    mean = True\n",
    "        \n",
    "    def fn_score(x, y, mean=mean, len_bonus=len_bonus):\n",
    "        denom = (x.size - 1) if mean else 1\n",
    "        return (y + len_bonus(x.size)) / denom\n",
    "\n",
    "    for utt, scr in sorted(beamsearch, key=lambda (x,y): fn_score(x, y), reverse=True)[:1]:\n",
    "        print '{:.3f}  '.format(fn_score(utt, scr)), print_utt(utt[1:-1])\n",
    "        print ''\n",
    "        \n",
    "# for utt in beamsearch:\n",
    "#     print_utt(utt)\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 100 batches in 4.07s\n",
      "Done 200 batches in 8.39s\n",
      "Done 300 batches in 12.95s\n",
      "Done 400 batches in 17.68s\n",
      "Done 500 batches in 21.70s\n",
      "Done 600 batches in 26.34s\n",
      "Done 700 batches in 31.03s\n",
      "Done 800 batches in 35.56s\n",
      "Done 900 batches in 40.01s\n",
      "Done 1000 batches in 44.49s\n",
      "Done 1100 batches in 48.81s\n",
      "Done 1200 batches in 53.21s\n",
      "Done 1300 batches in 57.49s\n",
      "Done 1400 batches in 61.62s\n",
      "Done 1500 batches in 66.13s\n",
      "Done 1600 batches in 70.65s\n",
      "Done 1700 batches in 74.90s\n",
      "Done 1800 batches in 79.24s\n",
      "Done 1900 batches in 83.80s\n",
      "Done 2000 batches in 88.35s\n",
      "Done 2100 batches in 92.88s\n",
      "Done 2200 batches in 97.45s\n",
      "Done 2300 batches in 101.66s\n",
      "Done 2400 batches in 106.09s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2819798801888118"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hred_net.validate(test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''full softmax, bs=30'''\n",
    "# train, 1 dir, 1 epoch: 3.485554076321884\n",
    "# val: 3.455356876018342\n",
    "\n",
    "# train, 2 dir, concat, 1 epoch: 3.4864403798772239\n",
    "# val: 3.4579001751897063\n",
    "\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.4881669768474675\n",
    "# val: 3.4584704095551695\n",
    "# training time: ~4700s\n",
    "\n",
    "'''sampled softmax'''\n",
    "# bs=30\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.486180601246621\n",
    "# val: 3.4811877499289308\n",
    "# training time: ~2300s\n",
    "\n",
    "# bs=60\n",
    "# train, 2 dir, L2 + concat, 1 epoch: 3.5235153449672456\n",
    "# val: 3.5063306987542759\n",
    "# training time: ~1900s"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
